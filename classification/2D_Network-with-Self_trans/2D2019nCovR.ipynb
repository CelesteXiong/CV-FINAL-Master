{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=/PATH_to_log_dir/ --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -q tb-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip list | grep tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "PATH_to_log_dir = '/data/cv_final/CT-Predict/2D-Pretrain/result' # 如果输出路径不存在会被自动创建\n",
    "# writer = SummaryWriter(PATH_to_log_dir)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "# for n_iter in range(100):\n",
    "#     writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "#     writer.add_scalar('Accuracy/train', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random \n",
    "from torchvision.datasets import ImageFolder\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.io import imread, imsave\n",
    "import skimage\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "########## Mean and std are calculated from the train dataset\n",
    "normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],\n",
    "                                     std=[0.33165374, 0.33165374, 0.33165374])\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(90),\n",
    "    # random brightness and random contrast\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "#     transforms.Resize(224),\n",
    "#     transforms.CenterCrop(224),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n",
      "99\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "batchsize=8\n",
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data\n",
    "\n",
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_path (string): Path to the txt file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        File structure:\n",
    "        - root_dir\n",
    "            - CT_COVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - CT_NonCOVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        - root_dir /data/Data/\n",
    "            - COVID19\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - Normal\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        txt_path:\n",
    "        - COVID19\n",
    "            - test_COVID.txt\n",
    "            - train_COVID.txt\n",
    "            - val_COVID.txt\n",
    "        - Normal\n",
    "            - ...\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
    "        # 2019\n",
    "#         self.classes = ['COVID19', 'Normal']\n",
    "        # UCSD\n",
    "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
    "        self.num_cls = len(self.classes)\n",
    "        self.img_list = []\n",
    "        for c in range(self.num_cls):\n",
    "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
    "#             print(cls_list)\n",
    "            self.img_list += cls_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.img_list[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'img': image,\n",
    "                  'label': int(self.img_list[idx][1])}\n",
    "        return sample\n",
    "\n",
    "\n",
    "# /data/COVID-CT/Data\n",
    "#     /data/COVID-CT/Data-split/COVID/trainCT_COVID.txt\n",
    "#     /data/COVID-CT/Data-split/NonCOVID/trainCT_NonCOVID.txt\n",
    "if __name__ == '__main__':\n",
    "#     trainset = CovidCTDataset(root_dir='/data/COVID-CT/Data',\n",
    "#                               txt_COVID='/data/COVID-CT/Data-split/COVID/trainCT_COVID.txt',\n",
    "#                               txt_NonCOVID='/data/COVID-CT/Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "#                               transform= train_transformer)\n",
    "#     valset = CovidCTDataset(root_dir='/data/COVID-CT/Data',\n",
    "#                               txt_COVID='/data/COVID-CT/Data-split/COVID/valCT_COVID.txt',\n",
    "#                               txt_NonCOVID='/data/COVID-CT/Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "#                               transform= val_transformer)\n",
    "#     testset = CovidCTDataset(root_dir='/data/COVID-CT/Data',\n",
    "#                               txt_COVID='/data/COVID-CT/Data-split/COVID/testCT_COVID.txt',\n",
    "#                               txt_NonCOVID='/data/COVID-CT/Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "#                               transform= val_transformer)\n",
    "    \n",
    "    trainset = CovidCTDataset(root_dir='/data/Data/',\n",
    "                              txt_COVID='/data/Data/Data_split/COVID19/COVID19_train.txt',\n",
    "                              txt_NonCOVID='/data/Data/Data_split/Normal/Normal_train.txt',\n",
    "                              transform= train_transformer)\n",
    "    valset = CovidCTDataset(root_dir='/data/Data',\n",
    "                              txt_COVID='/data/Data/Data_split/COVID19/COVID19_val.txt',\n",
    "                              txt_NonCOVID='/data/Data/Data_split/Normal/Normal_val.txt',\n",
    "                              transform= val_transformer)\n",
    "    testset = CovidCTDataset(root_dir='/data/Data',\n",
    "                              txt_COVID='/data/Data/Data_split/COVID19/COVID19_test.txt',\n",
    "                              txt_NonCOVID='/data/Data/Data_split/Normal/Normal_test.txt',\n",
    "                              transform= val_transformer)\n",
    "    print(trainset.__len__())\n",
    "    print(valset.__len__())\n",
    "    print(testset.__len__())\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
    "    val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_index, batch_samples in enumerate(train_loader):      \n",
    "        data, target = batch_samples['img'], batch_samples['label']\n",
    "        break\n",
    "# io.imread 读出图片格式是 uint8(unsigned int) ；value是 numpy array ；\n",
    "# 图像数据是以 RGB 的格式进行存储的，通道值默认范围0-255\n",
    "skimage.io.imshow(data[0,1,:,:].numpy())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pic = np.empty()\n",
    "# for batch_index, batch_samples in enumerate(train_loader):      \n",
    "#         data, target = batch_samples['img'], batch_samples['label']\n",
    "#         for i in target:\n",
    "#             if i.numpy() == 1:\n",
    "#                 pic1 = data[0,1,:,:].numpy()\n",
    "#             break\n",
    "# # io.imread 读出图片格式是 uint8(unsigned int) ；value是 numpy array ；\n",
    "# # 图像数据是以 RGB 的格式进行存储的，通道值默认范围0-255\n",
    "# skimage.io.imshow(pic1)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_index, batch_samples in enumerate(train_loader):      \n",
    "#         data, target = batch_samples['img'], batch_samples['label']\n",
    "#         if target[0].numpy() == 0:\n",
    "#             pic2 = data[0,1,:,:].numpy()\n",
    "#         break\n",
    "# # io.imread 读出图片格式是 uint8(unsigned int) ；value是 numpy array ；\n",
    "# # 图像数据是以 RGB 的格式进行存储的，通道值默认范围0-255\n",
    "# skimage.io.imshow(pic2)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mixup\n",
    "# '''Use mixup to do data augmentation'''\n",
    "\n",
    "# def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "#     '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "#     if alpha > 0:\n",
    "#         lam = np.random.beta(alpha, alpha)\n",
    "# #         print('lam',lam)\n",
    "#     else:\n",
    "#         lam = 1\n",
    "\n",
    "#     batch_size = x.size()[0]\n",
    "#     if use_cuda:\n",
    "#         index = torch.randperm(batch_size).cuda()\n",
    "#     else:\n",
    "#         index = torch.randperm(batch_size)\n",
    "\n",
    "#     mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "#     y_a, y_b = y, y[index]\n",
    "#     return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "# #     print(pred)\n",
    "# #     print(y_a)\n",
    "# #     print('criterion',criterion(pred, y_a))\n",
    "#     return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = {}\n",
    "his['train_loss'] = []\n",
    "his['train_acc'] = []\n",
    "his['val_loss'] = []\n",
    "his['val_acc'] = []\n",
    "his['test_loss'] = []\n",
    "his['test_acc'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_to_log_dir =  '/data/cv_final/CT-Predict/2D-Pretrain/result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training process is defined here \n",
    "\n",
    "alpha = None\n",
    "## alpha is None if mixup is not used\n",
    "alpha_name = f'{alpha}'\n",
    "device = 'cuda'\n",
    "\n",
    "def train(optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for batch_index, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        # move data to device\n",
    "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "        \n",
    "        ## adjust data to meet the input dimension of model\n",
    "#         data = data[:, 0, :, :]\n",
    "#         data = data[:, None, :, :]    \n",
    "        \n",
    "        #mixup\n",
    "#         data, targets_a, targets_b, lam = mixup_data(data, target, alpha, use_cuda=True)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        criteria = nn.CrossEntropyLoss()\n",
    "        loss = criteria(output, target.long())\n",
    "        \n",
    "        #mixup loss\n",
    "#         loss = mixup_criterion(criteria, output, targets_a, targets_b, lam)\n",
    "\n",
    "        train_loss += criteria(output, target.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    \n",
    "        # Display progress and write to tensorboard\n",
    "        if batch_index % bs == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
    "                epoch, batch_index, len(train_loader),\n",
    "                100.0 * batch_index / len(train_loader), loss.item()/ bs))\n",
    "    his['train_loss'].append(train_loss.data.cpu().numpy()/len(train_loader.dataset))\n",
    "    his['train_acc'].append(train_correct / len(train_loader.dataset))\n",
    "    \n",
    "#     print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "#         100.0 * train_correct / len(train_loader.dataset)))\n",
    "    p = os.path.join(PATH_to_log_dir,'/{}.txt'.format(modelname))\n",
    "    f = open(p, 'a+')\n",
    "    f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))\n",
    "    f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #val process is defined here\n",
    "\n",
    "def val(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(val_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "            \n",
    "#             data = data[:, 0, :, :]\n",
    "#             data = data[:, None, :, :]\n",
    "            output = model(data)\n",
    "            \n",
    "            val_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "        his['val_loss'].append(val_loss.data.cpu().numpy()/len(val_loader.dataset))\n",
    "        his['val_acc'].append(correct/len(val_loader.dataset))       \n",
    "    return targetlist, scorelist, predlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test process is defined here \n",
    "\n",
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(test_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "#             data = data[:, 0, :, :]\n",
    "#             data = data[:, None, :, :]\n",
    "#             print(target)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            \n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "        his['test_loss'].append(test_loss.data.cpu().numpy()/len(test_loader.dataset))\n",
    "        his['test_acc'].append(correct/len(test_loader.dataset))\n",
    "    return targetlist, scorelist, predlist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model['']\n",
    "# for k, v in model.items():\n",
    "#     print(k, v.size(), sep='\\t')\n",
    "# # model.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Dense169\n",
    "# import torchvision.models as models\n",
    "# # model = models.densenet169(pretrained=True).cuda()\n",
    "# # # modelname = 'Dense169'\n",
    "\n",
    "# \"\"\"load MoCo pretrained model\"\"\"\n",
    "# checkpoint = torch.load('new_data/save_model_dense/checkpoint_luna_covid_moco.pth.tar')\n",
    "# # # # print(checkpoint.keys())\n",
    "# # # # print(checkpoint['arch'])\n",
    "\n",
    "# state_dict = checkpoint['state_dict']\n",
    "# for key in list(state_dict.keys()):\n",
    "#     if 'module.encoder_q' in key:\n",
    "# #         print(key[17:])\n",
    "#         new_key = key[17:]\n",
    "#         state_dict[new_key] = state_dict[key]\n",
    "#     del state_dict[key]\n",
    "# for key in list(state_dict.keys()):\n",
    "#     if  key == 'classifier.0.weight':\n",
    "#         new_key = 'classifier.weight'\n",
    "#         state_dict[new_key] = state_dict[key]\n",
    "#         del state_dict[key]\n",
    "#     if  key == 'classifier.0.bias':\n",
    "#         new_key = 'classifier.bias'\n",
    "#         state_dict[new_key] = state_dict[key]\n",
    "#         del state_dict[key]\n",
    "#     if  key == 'classifier.2.weight' or key == 'classifier.2.bias':\n",
    "#         del state_dict[key]\n",
    "# state_dict['classifier.weight'] = state_dict['classifier.weight'][:1000,:]\n",
    "# state_dict['classifier.bias'] = state_dict['classifier.bias'][:1000]\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# # # print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load Self-Trans model\"\"\"\n",
    "\"\"\"Change names and locations to the Self-Trans.pt\"\"\"\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.densenet169(pretrained=True).cuda()\n",
    "# pretrained_net = torch.load('model_backup/Dense169.pt')\n",
    "# pretrained_net = torch.load('model_backup/mixup/Dense169_0.6.pt')\n",
    "path = '/data/COVID-CT/baseline-methods/Self-Trans/Self-Trans.pt'\n",
    "pretrained_net = torch.load(path)\n",
    "''\n",
    "model.load_state_dict(pretrained_net)\n",
    "\n",
    "modelname = 'Dense169'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_dict = model.state_dict()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Dataset2D import CovidCTDataset\n",
    "\n",
    "# #training process is defined here \n",
    "# batchsize=8\n",
    "# alpha = None\n",
    "# ## alpha is None if mixup is not used\n",
    "# alpha_name = f'{alpha}'\n",
    "# device = 'cuda'\n",
    "# PATH_to_log_dir = '/data/cv_final/CT-Predict/2D-Pretrain/result' # 如果输出路径不存在会被自动创建\n",
    "\n",
    "# trainset = CovidCTDataset(root_dir='/data/COVID-CT/Data',\n",
    "#                           txt_COVID='/data/COVID-CT/Data-split/COVID/trainCT_COVID.txt',\n",
    "#                           txt_NonCOVID='/data/COVID-CT/Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "#                           transform= train_transformer)\n",
    "# valset = CovidCTDataset(root_dir='/data/COVID-CT/Data',\n",
    "#                           txt_COVID='/data/COVID-CT/Data-split/COVID/valCT_COVID.txt',\n",
    "#                           txt_NonCOVID='/data/COVID-CT/Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "#                           transform= val_transformer)\n",
    "# testset = CovidCTDataset(root_dir='/data/COVID-CT/Data',\n",
    "#                           txt_COVID='/data/COVID-CT/Data-split/COVID/testCT_COVID.txt',\n",
    "#                           txt_NonCOVID='/data/COVID-CT/Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "#                           transform= val_transformer)\n",
    "# print(trainset.__len__())\n",
    "# print(valset.__len__())\n",
    "# print(testset.__len__())\n",
    "\n",
    "# train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
    "# val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "# test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from UCSD_main import his, train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = {}\n",
    "his['train_loss'] = []\n",
    "his['train_acc'] = []\n",
    "his['val_loss'] = []\n",
    "his['val_acc'] = []\n",
    "his['test_loss'] = []\n",
    "his['test_acc'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/44 (0%)]\tTrain Loss: 0.071794\n",
      "Train Epoch: 1 [8/44 (18%)]\tTrain Loss: 0.035767\n",
      "Train Epoch: 1 [16/44 (36%)]\tTrain Loss: 0.033588\n",
      "Train Epoch: 1 [24/44 (55%)]\tTrain Loss: 0.039732\n",
      "Train Epoch: 1 [32/44 (73%)]\tTrain Loss: 0.006063\n",
      "Train Epoch: 1 [40/44 (91%)]\tTrain Loss: 0.010022\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.73945764e-08 1.02123031e-05 7.14532931e-08 7.02759644e-06\n",
      " 5.81308015e-08 1.13917326e-04 5.24024824e-10 2.08131792e-06\n",
      " 7.37760120e-09 4.49909248e-06 3.94026557e-07 3.41133871e-10\n",
      " 2.56645993e-08 1.33836897e-09 1.00280658e-05 3.07455412e-06\n",
      " 2.86881725e-04 3.79532721e-04 1.75475492e-04 5.47745405e-10\n",
      " 1.88830640e-09 7.60094281e-08 1.66946743e-02 2.69653356e-06\n",
      " 5.14717503e-05 1.25654871e-04 2.13507796e-03 3.14761914e-04\n",
      " 2.26899900e-07 8.32619151e-07 1.31845725e-08 3.30007445e-11\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 2 [0/44 (0%)]\tTrain Loss: 0.002365\n",
      "Train Epoch: 2 [8/44 (18%)]\tTrain Loss: 0.016151\n",
      "Train Epoch: 2 [16/44 (36%)]\tTrain Loss: 0.081258\n",
      "Train Epoch: 2 [24/44 (55%)]\tTrain Loss: 0.013359\n",
      "Train Epoch: 2 [32/44 (73%)]\tTrain Loss: 0.059918\n",
      "Train Epoch: 2 [40/44 (91%)]\tTrain Loss: 0.038419\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.94433289e-06 2.37221320e-05 7.29463318e-06 4.07575717e-05\n",
      " 1.75566074e-05 4.08827676e-04 9.24129017e-06 1.71037409e-05\n",
      " 3.11989311e-06 5.39539396e-05 1.28402517e-05 9.69339635e-06\n",
      " 3.00624129e-06 9.66768584e-06 8.10019992e-05 2.94080764e-05\n",
      " 2.49358738e-04 4.21920646e-04 1.75767680e-04 1.09095231e-06\n",
      " 2.18639016e-05 9.08600123e-06 3.42935417e-03 7.35368303e-05\n",
      " 1.90807157e-04 6.76786658e-05 2.75683851e-04 1.35718525e-04\n",
      " 4.03578051e-05 3.14070930e-05 5.89342164e-07 1.54484169e-07\n",
      " 9.95377421e-01 9.96626735e-01 9.94625032e-01 9.94260907e-01\n",
      " 9.95669007e-01 9.95433092e-01 9.96783733e-01 9.96704876e-01\n",
      " 9.97227967e-01 9.96902227e-01 9.96368289e-01 9.96926725e-01\n",
      " 9.97214496e-01 9.97156024e-01 9.95760500e-01 9.96542871e-01\n",
      " 9.96790946e-01 9.95705187e-01 9.97325897e-01 9.96593654e-01\n",
      " 9.97897863e-01 9.95618999e-01 9.97188509e-01 9.97673213e-01\n",
      " 9.96440470e-01 9.95290875e-01 9.97352719e-01 9.96152341e-01\n",
      " 9.96668160e-01 9.96224642e-01 9.96203244e-01 9.96993661e-01\n",
      " 9.96944606e-01 9.97112632e-01 9.97307301e-01 9.97331381e-01\n",
      " 9.96846974e-01 9.97069299e-01 9.97204721e-01 9.97101486e-01\n",
      " 9.94463742e-01 9.97283816e-01 9.97514009e-01 9.95779634e-01\n",
      " 9.96134162e-01 9.96261179e-01 9.96081293e-01 9.96970654e-01\n",
      " 9.96655583e-01 9.97079253e-01 9.93907630e-01 9.95295703e-01\n",
      " 9.97310638e-01 9.97654498e-01 9.95908141e-01 9.96661663e-01\n",
      " 9.95329976e-01 9.95900095e-01 9.95634139e-01 9.96128678e-01\n",
      " 9.96333957e-01 9.96717036e-01 9.95255888e-01 9.96636391e-01\n",
      " 9.96184051e-01 9.95779634e-01 9.96381998e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 3 [0/44 (0%)]\tTrain Loss: 0.017328\n",
      "Train Epoch: 3 [8/44 (18%)]\tTrain Loss: 0.072498\n",
      "Train Epoch: 3 [16/44 (36%)]\tTrain Loss: 0.005898\n",
      "Train Epoch: 3 [24/44 (55%)]\tTrain Loss: 0.208517\n",
      "Train Epoch: 3 [32/44 (73%)]\tTrain Loss: 0.015562\n",
      "Train Epoch: 3 [40/44 (91%)]\tTrain Loss: 0.010838\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [4.93330901e-07 3.94304734e-05 6.07145239e-06 5.96728796e-06\n",
      " 4.03040576e-06 4.94812157e-05 2.85215128e-06 3.78498214e-07\n",
      " 1.26581017e-06 2.10469921e-06 3.63953745e-07 1.55512978e-07\n",
      " 7.06674612e-08 1.79517770e-07 1.07267560e-05 2.57074589e-05\n",
      " 1.18089782e-04 2.10670278e-05 7.76338220e-06 5.65362903e-08\n",
      " 1.66552672e-06 8.51969617e-06 2.31842932e-05 7.61274623e-06\n",
      " 2.10870940e-06 4.12297741e-05 1.56629496e-04 2.86908034e-05\n",
      " 8.28961856e-05 8.90051342e-06 1.59628814e-06 1.77917645e-08\n",
      " 1.65050409e-07 6.85820055e-07 5.24755797e-06 4.43426097e-06\n",
      " 4.64682444e-07 5.64232209e-07 3.12609529e-07 1.30276214e-06\n",
      " 4.98283896e-07 4.87025318e-07 5.24879624e-07 2.41763519e-06\n",
      " 9.43668965e-07 8.30178024e-08 1.87420608e-06 4.67019731e-07\n",
      " 7.53291317e-07 1.71854526e-06 8.13454790e-07 2.09224550e-06\n",
      " 1.90849434e-07 1.16783042e-07 4.49303712e-07 2.98954518e-07\n",
      " 9.90783292e-07 2.22751808e-07 3.47110984e-07 6.15763796e-08\n",
      " 4.20007808e-07 8.37660650e-07 9.05375828e-08 1.20348645e-07\n",
      " 1.67159897e-06 1.30664247e-07 4.66969425e-07 1.61333915e-07\n",
      " 4.97390317e-07 3.08534680e-07 4.90637717e-07 1.34089248e-06\n",
      " 2.23527906e-07 4.56680937e-07 2.65743580e-07 2.45725772e-07\n",
      " 1.52914751e-07 1.25938726e-07 1.31833997e-06 1.14186179e-07\n",
      " 6.04056652e-07 3.82580936e-07 2.02333126e-07 4.07771779e-07\n",
      " 5.61537490e-07 4.19380228e-07 3.95421637e-07 4.40381939e-07\n",
      " 5.15693046e-07 1.85258855e-07 6.37968398e-08 4.39583857e-07\n",
      " 2.83671966e-07 3.96719486e-07 1.97390662e-07 4.66659571e-07\n",
      " 9.21858501e-08 4.69672841e-07 2.02187877e-07]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Train Epoch: 4 [0/44 (0%)]\tTrain Loss: 0.038837\n",
      "Train Epoch: 4 [8/44 (18%)]\tTrain Loss: 0.032990\n",
      "Train Epoch: 4 [16/44 (36%)]\tTrain Loss: 0.008507\n",
      "Train Epoch: 4 [24/44 (55%)]\tTrain Loss: 0.019955\n",
      "Train Epoch: 4 [32/44 (73%)]\tTrain Loss: 0.018055\n",
      "Train Epoch: 4 [40/44 (91%)]\tTrain Loss: 0.004818\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.005404   0.00769377 0.01264481 0.02566369 0.0124883  0.09770287\n",
      " 0.00768034 0.00855882 0.00167823 0.0149286  0.00468035 0.0077148\n",
      " 0.00535647 0.00246268 0.02446808 0.01277371 0.10502125 0.02691887\n",
      " 0.03990376 0.01023731 0.02146832 0.0092431  0.21184963 0.04473221\n",
      " 0.04144678 0.07519922 0.06779912 0.09200107 0.01809363 0.01447931\n",
      " 0.00684459 0.00317233 0.99970418 0.99974662 0.99981993 0.9996351\n",
      " 0.99944597 0.99982041 0.99979073 0.99975735 0.99973482 0.99959546\n",
      " 0.99955243 0.99977261 0.99982268 0.99941313 0.99981385 0.99986327\n",
      " 0.99983323 0.99982917 0.99972278 0.99982399 0.99980158 0.99984932\n",
      " 0.99983799 0.99246597 0.99980503 0.99982905 0.99985206 0.99985147\n",
      " 0.99979943 0.99980396 0.99864155 0.99979037 0.99981385 0.99983323\n",
      " 0.99972504 0.99981421 0.99967325 0.9993704  0.9998042  0.99985182\n",
      " 0.99964285 0.99981743 0.9997645  0.99975127 0.9997198  0.99982446\n",
      " 0.99987411 0.99979132 0.99984837 0.99933892 0.99984324 0.99964929\n",
      " 0.99979395 0.99943191 0.99984777 0.99982846 0.99983954 0.999663\n",
      " 0.99959606 0.99984109 0.99983931 0.99981028 0.99933285 0.99961555\n",
      " 0.99975902 0.99983585 0.99947435]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/44 (0%)]\tTrain Loss: 0.019783\n",
      "Train Epoch: 5 [8/44 (18%)]\tTrain Loss: 0.000624\n",
      "Train Epoch: 5 [16/44 (36%)]\tTrain Loss: 0.057837\n",
      "Train Epoch: 5 [24/44 (55%)]\tTrain Loss: 0.012068\n",
      "Train Epoch: 5 [32/44 (73%)]\tTrain Loss: 0.059614\n",
      "Train Epoch: 5 [40/44 (91%)]\tTrain Loss: 0.000284\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.56065298e-03 2.84139882e-03 7.20439712e-03 9.37572308e-03\n",
      " 1.80108112e-03 9.13841203e-02 2.37565860e-03 3.72663984e-04\n",
      " 4.35534661e-04 1.14259322e-03 9.93649126e-04 2.14913976e-03\n",
      " 3.28144728e-04 1.04582973e-03 7.72045506e-03 2.80292681e-03\n",
      " 5.24189323e-02 6.02300465e-03 2.03734520e-03 2.08610413e-03\n",
      " 6.77945651e-03 1.24026544e-03 9.69287381e-02 1.65189710e-02\n",
      " 7.03176064e-03 8.44162703e-03 2.60509620e-03 1.79891959e-02\n",
      " 1.37993749e-02 1.07149454e-02 1.25608000e-03 3.26880458e-04\n",
      " 4.22370255e-01 2.97621191e-01 4.30996895e-01 2.88684219e-01\n",
      " 3.67988288e-01 2.92105407e-01 4.46778417e-01 2.83736110e-01\n",
      " 5.86052060e-01 1.57598630e-01 4.44562703e-01 1.20178230e-01\n",
      " 7.85602629e-02 2.17469737e-01 2.88499057e-01 1.80656075e-01\n",
      " 3.10616642e-01 3.37691218e-01 4.30294245e-01 1.90315291e-01\n",
      " 1.32965311e-01 3.93186986e-01 2.06736863e-01 2.20979840e-01\n",
      " 3.88860375e-01 4.35229272e-01 3.73019814e-01 4.78937089e-01\n",
      " 5.71720839e-01 2.96571493e-01 2.51000822e-01 3.42129916e-01\n",
      " 3.38064224e-01 2.74329603e-01 2.12804809e-01 1.94673210e-01\n",
      " 2.87491649e-01 2.01817200e-01 1.23156495e-01 2.07210869e-01\n",
      " 3.57282013e-01 1.58587828e-01 4.70719337e-01 5.33658147e-01\n",
      " 4.64904100e-01 4.56697822e-01 3.60094339e-01 4.25178140e-01\n",
      " 3.53854150e-01 5.50820053e-01 4.51675028e-01 2.52128094e-01\n",
      " 1.68393031e-01 7.60017484e-02 3.39723319e-01 2.99651176e-01\n",
      " 3.63395780e-01 4.06130314e-01 4.25805211e-01 4.39208895e-01\n",
      " 3.56076300e-01 3.25544447e-01 3.47304553e-01 1.25047833e-01\n",
      " 2.18708113e-01 3.03363264e-01 2.76103884e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "Train Epoch: 6 [0/44 (0%)]\tTrain Loss: 0.008934\n",
      "Train Epoch: 6 [8/44 (18%)]\tTrain Loss: 0.008129\n",
      "Train Epoch: 6 [16/44 (36%)]\tTrain Loss: 0.037844\n",
      "Train Epoch: 6 [24/44 (55%)]\tTrain Loss: 0.003423\n",
      "Train Epoch: 6 [32/44 (73%)]\tTrain Loss: 0.004724\n",
      "Train Epoch: 6 [40/44 (91%)]\tTrain Loss: 0.011333\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.05894859e-04 6.56146090e-04 6.64020015e-04 1.28558581e-03\n",
      " 4.74444998e-04 1.86883844e-03 2.96966144e-04 2.11642240e-04\n",
      " 1.72806351e-04 8.20118061e-04 2.16258675e-04 3.72812647e-04\n",
      " 2.14654283e-04 1.42992358e-04 1.13237591e-03 5.19271009e-04\n",
      " 2.56303116e-03 1.10688538e-03 7.68263300e-04 3.33650707e-04\n",
      " 1.27990835e-03 5.43961185e-04 5.52169746e-03 2.12532911e-03\n",
      " 1.64337119e-03 1.29590917e-03 4.21758421e-04 2.58735265e-03\n",
      " 9.72388778e-04 3.99497076e-04 1.56753798e-04 5.21869806e-05\n",
      " 9.99704182e-01 9.99561250e-01 9.99822676e-01 9.99425054e-01\n",
      " 9.99746859e-01 9.99464691e-01 9.99447882e-01 9.99558151e-01\n",
      " 9.99847293e-01 9.99263227e-01 9.98306394e-01 9.99376237e-01\n",
      " 9.98029768e-01 9.99353111e-01 9.99335587e-01 9.99213934e-01\n",
      " 9.98517334e-01 9.99937892e-01 9.99268949e-01 9.99783456e-01\n",
      " 9.99385595e-01 9.99857306e-01 9.99549210e-01 9.98822629e-01\n",
      " 9.99482274e-01 9.99736011e-01 9.99209225e-01 9.99902248e-01\n",
      " 9.99075174e-01 9.99843478e-01 9.99177992e-01 9.99811947e-01\n",
      " 9.99750793e-01 9.99690890e-01 9.99584734e-01 9.99718130e-01\n",
      " 9.99393940e-01 9.99347508e-01 9.99345481e-01 9.98076797e-01\n",
      " 9.99657035e-01 9.99591053e-01 9.99467432e-01 9.99708951e-01\n",
      " 9.99882102e-01 9.99788105e-01 9.99521375e-01 9.99803245e-01\n",
      " 9.99560416e-01 9.98518407e-01 9.99894619e-01 9.99816477e-01\n",
      " 9.99446929e-01 9.98239875e-01 9.99770105e-01 9.99120057e-01\n",
      " 9.99229789e-01 9.99836683e-01 9.99719799e-01 9.99895334e-01\n",
      " 9.99852777e-01 9.99545276e-01 9.99706447e-01 9.99556959e-01\n",
      " 9.99485254e-01 9.99653220e-01 9.99307394e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 7 [0/44 (0%)]\tTrain Loss: 0.008694\n",
      "Train Epoch: 7 [8/44 (18%)]\tTrain Loss: 0.064294\n",
      "Train Epoch: 7 [16/44 (36%)]\tTrain Loss: 0.002433\n",
      "Train Epoch: 7 [24/44 (55%)]\tTrain Loss: 0.022235\n",
      "Train Epoch: 7 [32/44 (73%)]\tTrain Loss: 0.015672\n",
      "Train Epoch: 7 [40/44 (91%)]\tTrain Loss: 0.035688\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.47648343 0.43363741 0.42821953 0.26700607 0.41269392 0.39490572\n",
      " 0.38138175 0.42584831 0.47368357 0.5414505  0.3293764  0.30920011\n",
      " 0.41029793 0.43157971 0.41025665 0.3340643  0.70923257 0.35217702\n",
      " 0.36256137 0.28556669 0.38531125 0.31816909 0.56175369 0.30424187\n",
      " 0.39380172 0.32763362 0.67885685 0.34688395 0.41164017 0.48577237\n",
      " 0.32874393 0.27909681 0.99946743 0.99893957 0.99734747 0.99850523\n",
      " 0.99896061 0.9987464  0.99895561 0.99951255 0.99978429 0.99891567\n",
      " 0.99927694 0.99935359 0.99928039 0.99933463 0.99918252 0.99943465\n",
      " 0.99901354 0.99868554 0.99877435 0.99920207 0.99961048 0.99953234\n",
      " 0.99961036 0.99927872 0.998478   0.99954283 0.9996686  0.99975389\n",
      " 0.99970669 0.99924821 0.99934703 0.99969435 0.99930751 0.99969625\n",
      " 0.9993149  0.99975806 0.99937397 0.99963129 0.99958116 0.99959952\n",
      " 0.99941242 0.99931014 0.99962604 0.99944991 0.99952137 0.99974853\n",
      " 0.99862695 0.99966311 0.9995783  0.99949896 0.99937421 0.99886096\n",
      " 0.99940479 0.99941242 0.99891543 0.99914038 0.99925691 0.9992674\n",
      " 0.99954587 0.99934191 0.99926537 0.99941814 0.99856681 0.9995715\n",
      " 0.99971575 0.99963868 0.99952114]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 8 [0/44 (0%)]\tTrain Loss: 0.011650\n",
      "Train Epoch: 8 [8/44 (18%)]\tTrain Loss: 0.000683\n",
      "Train Epoch: 8 [16/44 (36%)]\tTrain Loss: 0.000182\n",
      "Train Epoch: 8 [24/44 (55%)]\tTrain Loss: 0.006542\n",
      "Train Epoch: 8 [32/44 (73%)]\tTrain Loss: 0.006967\n",
      "Train Epoch: 8 [40/44 (91%)]\tTrain Loss: 0.014314\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.10030016 0.08072606 0.29862615 0.11835144 0.08604176 0.03216061\n",
      " 0.0299805  0.0549695  0.02083339 0.04579422 0.05058039 0.06365627\n",
      " 0.07483    0.075407   0.01304585 0.03064854 0.02398216 0.00292737\n",
      " 0.0041006  0.07578646 0.08490674 0.07043659 0.02150286 0.02700868\n",
      " 0.12378714 0.06065697 0.00272906 0.01772095 0.04614788 0.07706358\n",
      " 0.26106778 0.26337084 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/44 (0%)]\tTrain Loss: 0.023995\n",
      "Train Epoch: 9 [8/44 (18%)]\tTrain Loss: 0.010721\n",
      "Train Epoch: 9 [16/44 (36%)]\tTrain Loss: 0.000680\n",
      "Train Epoch: 9 [24/44 (55%)]\tTrain Loss: 0.029999\n",
      "Train Epoch: 9 [32/44 (73%)]\tTrain Loss: 0.003629\n",
      "Train Epoch: 9 [40/44 (91%)]\tTrain Loss: 0.024462\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [9.68055133e-07 9.48901925e-06 2.29433645e-05 3.88997887e-06\n",
      " 2.78628363e-06 1.11734676e-04 3.73859621e-06 2.73144360e-06\n",
      " 2.27156477e-07 3.68681071e-07 1.18902086e-07 1.83788381e-06\n",
      " 7.71197051e-07 2.68564963e-06 2.86488762e-06 3.14317867e-06\n",
      " 9.94513903e-05 2.88561750e-06 4.58179966e-06 3.37145792e-07\n",
      " 1.74822560e-06 1.29749128e-06 1.67002581e-04 2.37594168e-06\n",
      " 1.74219076e-05 2.90302069e-05 1.72755517e-06 8.28935481e-06\n",
      " 1.10526262e-05 1.90632836e-05 2.92415712e-06 1.99144964e-07\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 10 [0/44 (0%)]\tTrain Loss: 0.002242\n",
      "Train Epoch: 10 [8/44 (18%)]\tTrain Loss: 0.005528\n",
      "Train Epoch: 10 [16/44 (36%)]\tTrain Loss: 0.007645\n",
      "Train Epoch: 10 [24/44 (55%)]\tTrain Loss: 0.007317\n",
      "Train Epoch: 10 [32/44 (73%)]\tTrain Loss: 0.007807\n",
      "Train Epoch: 10 [40/44 (91%)]\tTrain Loss: 0.003152\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.0169013  0.04713232 0.04514739 0.02074125 0.03569389 0.05947397\n",
      " 0.03030313 0.02175012 0.01282483 0.01800666 0.00772163 0.01080162\n",
      " 0.01326776 0.01766225 0.028893   0.02120574 0.05391789 0.00904861\n",
      " 0.00747742 0.01339043 0.0397794  0.02436794 0.03648311 0.02393553\n",
      " 0.02708458 0.0252564  0.00981909 0.01365339 0.04365848 0.0538782\n",
      " 0.02543829 0.00969357 1.         1.         1.         0.99999976\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99999988 0.99999988 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99999952 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "TP= 67 TN= 32 FN= 0 FP= 0\n",
      "TP+FP 67\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUCp 1.0\n",
      "AUC 1.0\n",
      "\n",
      " The epoch is 10, average recall: 1.0000, average precision: 1.0000,average F1: 1.0000, average accuracy: 1.0000, average AUC: 1.0000\n",
      "Train Epoch: 11 [0/44 (0%)]\tTrain Loss: 0.063055\n",
      "Train Epoch: 11 [8/44 (18%)]\tTrain Loss: 0.001013\n",
      "Train Epoch: 11 [16/44 (36%)]\tTrain Loss: 0.053390\n",
      "Train Epoch: 11 [24/44 (55%)]\tTrain Loss: 0.001240\n",
      "Train Epoch: 11 [32/44 (73%)]\tTrain Loss: 0.043225\n",
      "Train Epoch: 11 [40/44 (91%)]\tTrain Loss: 0.043728\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.95495104e-05 1.88125574e-04 1.51050714e-04 7.11031025e-05\n",
      " 2.82627680e-05 1.02373531e-04 4.73206683e-06 6.51172013e-06\n",
      " 5.93851109e-06 2.04611370e-05 4.19867865e-06 9.06276546e-06\n",
      " 7.76996694e-06 5.13414525e-05 5.65680166e-05 2.39306955e-05\n",
      " 4.13111193e-05 1.93120604e-06 2.64785785e-06 9.85285442e-06\n",
      " 2.89268246e-05 1.42009827e-04 1.03877146e-05 2.15775308e-05\n",
      " 3.94653907e-05 5.27416742e-05 5.29236047e-07 6.32585652e-05\n",
      " 4.26550323e-05 6.04180677e-05 2.06680474e-04 3.21344560e-05\n",
      " 9.98886049e-01 9.21361923e-01 9.96676683e-01 8.64224851e-01\n",
      " 9.99561012e-01 9.95407224e-01 9.99858379e-01 9.92583752e-01\n",
      " 9.98780310e-01 9.88618374e-01 8.76979053e-01 7.69711733e-01\n",
      " 8.95889521e-01 9.67052519e-01 9.08992946e-01 9.45555806e-01\n",
      " 9.71590579e-01 9.97939527e-01 8.90933335e-01 9.98363912e-01\n",
      " 9.59958076e-01 9.99769032e-01 9.47025418e-01 9.98170495e-01\n",
      " 9.96620536e-01 9.99946475e-01 9.94946778e-01 9.99956965e-01\n",
      " 9.99471962e-01 9.99435842e-01 9.97716904e-01 9.99173820e-01\n",
      " 9.84970987e-01 9.98667955e-01 9.83917117e-01 9.99228358e-01\n",
      " 9.98599946e-01 9.79759872e-01 9.65478718e-01 8.05917382e-01\n",
      " 9.99760926e-01 9.82071698e-01 9.98895288e-01 9.99443710e-01\n",
      " 9.99970675e-01 9.98945057e-01 9.87877131e-01 9.98858929e-01\n",
      " 9.52360451e-01 9.82943833e-01 9.99719203e-01 9.98102725e-01\n",
      " 9.78911757e-01 8.38760972e-01 9.98648107e-01 9.74626660e-01\n",
      " 9.99360621e-01 9.97744799e-01 9.99959826e-01 9.98730600e-01\n",
      " 9.96324480e-01 9.74784195e-01 9.97670352e-01 9.58847404e-01\n",
      " 9.93843317e-01 9.98426676e-01 9.99058545e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 12 [0/44 (0%)]\tTrain Loss: 0.001792\n",
      "Train Epoch: 12 [8/44 (18%)]\tTrain Loss: 0.000320\n",
      "Train Epoch: 12 [16/44 (36%)]\tTrain Loss: 0.010008\n",
      "Train Epoch: 12 [24/44 (55%)]\tTrain Loss: 0.094337\n",
      "Train Epoch: 12 [32/44 (73%)]\tTrain Loss: 0.005864\n",
      "Train Epoch: 12 [40/44 (91%)]\tTrain Loss: 0.003708\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.00839716 0.00911213 0.01689962 0.01276038 0.00679117 0.1710632\n",
      " 0.09927505 0.00444552 0.02611767 0.01468965 0.02019785 0.02238869\n",
      " 0.00944171 0.00638228 0.01386495 0.04258721 0.16926952 0.11457186\n",
      " 0.07523757 0.01505497 0.00976076 0.01788025 0.07033343 0.02207133\n",
      " 0.01530592 0.00984605 0.05277784 0.02467975 0.06662799 0.03540784\n",
      " 0.00208828 0.00144113 0.99998713 0.99994934 0.99982363 0.99968874\n",
      " 0.99991035 0.99981517 0.9999063  0.99982065 0.99993777 0.99992275\n",
      " 0.99989712 0.99923694 0.9998197  0.99995947 0.99993181 0.99990642\n",
      " 0.99947196 0.99999082 0.99996722 0.99996984 0.99994802 0.99997294\n",
      " 0.99964452 0.99987316 0.99991703 0.99996173 0.99995112 0.99998856\n",
      " 0.99990129 0.99992561 0.99995959 0.99997795 0.99991524 0.99998903\n",
      " 0.99989998 0.9999541  0.99990177 0.99992383 0.99995089 0.99995899\n",
      " 0.99995565 0.99981564 0.99994504 0.99981385 0.99998879 0.99992287\n",
      " 0.99979061 0.99998641 0.99980241 0.99978763 0.99999642 0.99992502\n",
      " 0.9998796  0.99983668 0.99985063 0.99992287 0.99993861 0.99998224\n",
      " 0.99996972 0.99999714 0.99996948 0.99982005 0.99996984 0.99994648\n",
      " 0.99997532 0.99995744 0.99989629]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 13 [0/44 (0%)]\tTrain Loss: 0.001367\n",
      "Train Epoch: 13 [8/44 (18%)]\tTrain Loss: 0.012462\n",
      "Train Epoch: 13 [16/44 (36%)]\tTrain Loss: 0.013061\n",
      "Train Epoch: 13 [24/44 (55%)]\tTrain Loss: 0.007876\n",
      "Train Epoch: 13 [32/44 (73%)]\tTrain Loss: 0.006110\n",
      "Train Epoch: 13 [40/44 (91%)]\tTrain Loss: 0.005025\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.09891078 0.13256641 0.12671611 0.04625813 0.09804817 0.10895976\n",
      " 0.05750524 0.0621838  0.04863256 0.0334703  0.05088124 0.11101457\n",
      " 0.0673298  0.16256133 0.02809635 0.05809883 0.09007173 0.02241551\n",
      " 0.07027776 0.04671832 0.04058293 0.09252287 0.08102644 0.03855038\n",
      " 0.04731059 0.08206864 0.02981579 0.03001727 0.06229711 0.10090351\n",
      " 0.11599296 0.09518056 0.99996674 0.9999491  0.99999166 0.99955386\n",
      " 0.99996531 0.99998438 0.99998879 0.99991131 0.99998498 0.9996593\n",
      " 0.99997842 0.99992478 0.99983203 0.99994612 0.99994504 0.99999082\n",
      " 0.99997818 0.99998581 0.99996912 0.99998689 0.99993503 0.99999428\n",
      " 0.99996066 0.9996475  0.99998796 0.99999392 0.9999882  0.99999666\n",
      " 0.99999332 0.99996734 0.99997056 0.99998724 0.99998283 0.99998188\n",
      " 0.99986386 0.99991548 0.99996233 0.99994254 0.99986053 0.99999356\n",
      " 0.99997735 0.99999309 0.99998903 0.99996293 0.99997818 0.99998903\n",
      " 0.99998021 0.9999907  0.99999166 0.99997425 0.99999702 0.9999727\n",
      " 0.99979967 0.9996289  0.99997294 0.99999082 0.99992323 0.99997497\n",
      " 0.99999249 0.9999975  0.99999416 0.99998748 0.99994481 0.99983847\n",
      " 0.99998033 0.99997234 0.99986136]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 14 [0/44 (0%)]\tTrain Loss: 0.021757\n",
      "Train Epoch: 14 [8/44 (18%)]\tTrain Loss: 0.000485\n",
      "Train Epoch: 14 [16/44 (36%)]\tTrain Loss: 0.003819\n",
      "Train Epoch: 14 [24/44 (55%)]\tTrain Loss: 0.003247\n",
      "Train Epoch: 14 [32/44 (73%)]\tTrain Loss: 0.005232\n",
      "Train Epoch: 14 [40/44 (91%)]\tTrain Loss: 0.000294\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.02449528 0.0445318  0.05576675 0.04139495 0.02939471 0.11312953\n",
      " 0.01923195 0.01519833 0.01680828 0.01088154 0.00964348 0.02340446\n",
      " 0.01272754 0.01934122 0.02748438 0.02582904 0.06108265 0.01246453\n",
      " 0.02449105 0.01219739 0.02136252 0.02925664 0.07037565 0.02446243\n",
      " 0.04074084 0.04846294 0.01056286 0.04310889 0.04194222 0.04476354\n",
      " 0.03893112 0.01827624 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 15 [0/44 (0%)]\tTrain Loss: 0.001448\n",
      "Train Epoch: 15 [8/44 (18%)]\tTrain Loss: 0.003005\n",
      "Train Epoch: 15 [16/44 (36%)]\tTrain Loss: 0.010265\n",
      "Train Epoch: 15 [24/44 (55%)]\tTrain Loss: 0.002577\n",
      "Train Epoch: 15 [32/44 (73%)]\tTrain Loss: 0.003011\n",
      "Train Epoch: 15 [40/44 (91%)]\tTrain Loss: 0.012510\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.82378374e-03 5.36237843e-03 6.44209934e-03 7.56433234e-03\n",
      " 3.41146719e-03 4.55124527e-02 2.50623794e-03 1.04009267e-03\n",
      " 8.29866680e-04 2.57458026e-03 1.17569941e-03 2.20077066e-03\n",
      " 8.94914847e-04 8.57201987e-04 7.86483940e-03 5.17472951e-03\n",
      " 1.79915242e-02 3.48706776e-03 4.68873838e-03 1.69995823e-03\n",
      " 6.87767100e-03 2.74169142e-03 4.67329957e-02 6.59277197e-03\n",
      " 9.15585924e-03 1.10006882e-02 2.67089787e-03 1.74362417e-02\n",
      " 6.32036338e-03 6.75665587e-03 2.20748829e-03 6.38520753e-04\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 9.99998450e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999762e-01\n",
      " 1.00000000e+00 9.99998808e-01 9.99999881e-01 9.99999762e-01\n",
      " 9.99999166e-01 1.00000000e+00 9.99999762e-01 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999523e-01 9.99998093e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999523e-01 9.99999762e-01\n",
      " 9.99999881e-01 9.99999881e-01 9.99999046e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99999404e-01 9.99994993e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999404e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99997973e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 16 [0/44 (0%)]\tTrain Loss: 0.207167\n",
      "Train Epoch: 16 [8/44 (18%)]\tTrain Loss: 0.002681\n",
      "Train Epoch: 16 [16/44 (36%)]\tTrain Loss: 0.004555\n",
      "Train Epoch: 16 [24/44 (55%)]\tTrain Loss: 0.000279\n",
      "Train Epoch: 16 [32/44 (73%)]\tTrain Loss: 0.004841\n",
      "Train Epoch: 16 [40/44 (91%)]\tTrain Loss: 0.004056\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.00316487 0.02787931 0.01269258 0.02017614 0.00890946 0.10046083\n",
      " 0.00780425 0.004336   0.00239709 0.00576855 0.00185452 0.0039166\n",
      " 0.00135113 0.00169913 0.02070935 0.01437263 0.06566799 0.00725817\n",
      " 0.01467075 0.00264775 0.01077599 0.00606899 0.08628302 0.0138487\n",
      " 0.02682265 0.03423132 0.00760556 0.04707681 0.01929533 0.01482136\n",
      " 0.00535949 0.00120638 0.99999964 0.99999869 0.99999988 0.99991417\n",
      " 1.         1.         1.         0.99999583 1.         0.99996638\n",
      " 0.99999976 0.99999714 0.99997449 0.99999654 0.99999118 1.\n",
      " 0.99999893 1.         0.99999964 0.99999964 0.9999994  1.\n",
      " 0.99999201 0.99999034 1.         1.         1.         1.\n",
      " 0.99999988 0.99999964 0.99999964 1.         1.         1.\n",
      " 0.99998915 0.99999726 0.99999928 0.99999559 0.99998128 1.\n",
      " 0.99999988 0.99999988 0.99999988 0.9999994  1.         1.\n",
      " 1.         1.         1.         0.99999976 1.         0.99999976\n",
      " 0.99999535 0.99993753 0.9999994  0.99999976 0.99999917 0.99999988\n",
      " 1.         1.         1.         0.99999976 0.99999976 0.99999046\n",
      " 0.9999994  0.99999928 0.99998248]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [0/44 (0%)]\tTrain Loss: 0.001390\n",
      "Train Epoch: 17 [8/44 (18%)]\tTrain Loss: 0.000532\n",
      "Train Epoch: 17 [16/44 (36%)]\tTrain Loss: 0.028227\n",
      "Train Epoch: 17 [24/44 (55%)]\tTrain Loss: 0.000154\n",
      "Train Epoch: 17 [32/44 (73%)]\tTrain Loss: 0.003515\n",
      "Train Epoch: 17 [40/44 (91%)]\tTrain Loss: 0.003180\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [3.40112565e-05 7.17816991e-04 3.70106311e-04 8.70014483e-04\n",
      " 4.28194398e-05 2.83071189e-03 1.73939188e-05 3.28757160e-05\n",
      " 4.44147690e-06 4.38859024e-05 1.67042253e-05 5.35716281e-05\n",
      " 7.52618826e-06 3.03762736e-05 2.97701190e-04 1.58271476e-04\n",
      " 5.53730410e-04 3.13457822e-05 8.59057327e-05 3.82851140e-05\n",
      " 2.26173273e-04 9.94267320e-05 3.92190367e-03 5.01336239e-04\n",
      " 6.82034413e-04 1.10660621e-03 2.33289411e-05 1.05869456e-03\n",
      " 2.03023941e-04 1.36430201e-04 1.47729836e-04 2.21896535e-05\n",
      " 9.99995470e-01 9.99996662e-01 9.99986172e-01 9.99917507e-01\n",
      " 9.99985456e-01 9.99938250e-01 9.99880195e-01 9.99996543e-01\n",
      " 9.99964356e-01 9.99964833e-01 9.99704540e-01 9.99913454e-01\n",
      " 9.99868274e-01 9.99930024e-01 9.99943733e-01 9.99969125e-01\n",
      " 9.99328136e-01 9.99998569e-01 9.99928474e-01 9.99974012e-01\n",
      " 9.99993801e-01 9.99985218e-01 9.99878526e-01 9.99954939e-01\n",
      " 9.99969006e-01 9.99987960e-01 9.99961138e-01 9.99988437e-01\n",
      " 9.99658346e-01 9.99999046e-01 9.99976277e-01 9.99961138e-01\n",
      " 9.99908805e-01 9.99998927e-01 9.99989510e-01 9.99997377e-01\n",
      " 9.99934316e-01 9.99944091e-01 9.99978542e-01 9.99958992e-01\n",
      " 9.99960899e-01 9.99817073e-01 9.99985099e-01 9.99981880e-01\n",
      " 9.99999404e-01 9.99976873e-01 9.99719203e-01 9.99996305e-01\n",
      " 9.99943376e-01 9.99945641e-01 9.99998450e-01 9.99968767e-01\n",
      " 9.99982715e-01 9.99780357e-01 9.99696493e-01 9.99974370e-01\n",
      " 9.99987483e-01 9.99998927e-01 9.99920130e-01 9.99995708e-01\n",
      " 9.99971271e-01 9.99985576e-01 9.99988198e-01 9.99971032e-01\n",
      " 9.99986291e-01 9.99976635e-01 9.99954224e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 18 [0/44 (0%)]\tTrain Loss: 0.016791\n",
      "Train Epoch: 18 [8/44 (18%)]\tTrain Loss: 0.000644\n",
      "Train Epoch: 18 [16/44 (36%)]\tTrain Loss: 0.009297\n",
      "Train Epoch: 18 [24/44 (55%)]\tTrain Loss: 0.034142\n",
      "Train Epoch: 18 [32/44 (73%)]\tTrain Loss: 0.003604\n",
      "Train Epoch: 18 [40/44 (91%)]\tTrain Loss: 0.001134\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [4.82262607e-04 1.30534067e-03 2.96493107e-03 4.32800315e-03\n",
      " 8.37991014e-04 8.24831426e-03 4.88705955e-05 4.27599844e-05\n",
      " 1.25512834e-05 1.46863807e-04 1.30608285e-04 2.29763740e-04\n",
      " 2.58489599e-05 1.00936093e-04 4.31487075e-04 1.91407031e-04\n",
      " 2.14315616e-04 2.31884933e-05 3.05587746e-05 2.64210423e-04\n",
      " 4.68083192e-03 4.52841370e-04 1.86404977e-02 1.38040190e-03\n",
      " 1.25692075e-03 1.67093961e-03 1.34989557e-06 3.60256730e-04\n",
      " 8.00597656e-04 1.26390043e-03 3.99271725e-04 9.11391471e-05\n",
      " 9.99381542e-01 9.92333651e-01 9.94906306e-01 9.69661415e-01\n",
      " 9.91322637e-01 9.80241060e-01 9.50334787e-01 9.89303708e-01\n",
      " 9.97815847e-01 9.63363945e-01 9.71758723e-01 5.94683588e-01\n",
      " 3.76105934e-01 9.84620810e-01 9.28212166e-01 9.02043641e-01\n",
      " 9.15397465e-01 9.99739707e-01 9.95169580e-01 9.23138320e-01\n",
      " 8.64826798e-01 9.94668782e-01 9.05819833e-01 9.83802676e-01\n",
      " 9.99493718e-01 9.98754382e-01 9.40739512e-01 9.99361098e-01\n",
      " 9.24706995e-01 9.97891128e-01 9.97735858e-01 9.97190177e-01\n",
      " 9.98876512e-01 9.99675393e-01 9.94388163e-01 9.96162176e-01\n",
      " 9.98191655e-01 5.86075842e-01 9.78120744e-01 5.81940472e-01\n",
      " 9.99777377e-01 8.75450790e-01 9.97843146e-01 9.98526454e-01\n",
      " 9.99976516e-01 9.98498917e-01 9.47145998e-01 9.99319077e-01\n",
      " 9.81341839e-01 9.96682346e-01 9.99935985e-01 9.98559415e-01\n",
      " 9.55364525e-01 5.73972046e-01 9.87694383e-01 9.72955585e-01\n",
      " 9.97460246e-01 9.99876261e-01 9.97920334e-01 9.97109950e-01\n",
      " 9.98489261e-01 9.61057663e-01 9.94162142e-01 8.15828800e-01\n",
      " 9.90787566e-01 9.65890467e-01 9.54149961e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 19 [0/44 (0%)]\tTrain Loss: 0.120568\n",
      "Train Epoch: 19 [8/44 (18%)]\tTrain Loss: 0.020115\n",
      "Train Epoch: 19 [16/44 (36%)]\tTrain Loss: 0.009246\n",
      "Train Epoch: 19 [24/44 (55%)]\tTrain Loss: 0.063063\n",
      "Train Epoch: 19 [32/44 (73%)]\tTrain Loss: 0.002622\n",
      "Train Epoch: 19 [40/44 (91%)]\tTrain Loss: 0.006840\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.00553769 0.01234742 0.02113919 0.02967135 0.00795478 0.08056498\n",
      " 0.00405227 0.00260858 0.00236052 0.00289195 0.00210891 0.00506559\n",
      " 0.00188797 0.00444608 0.01807759 0.00971016 0.01708695 0.00195031\n",
      " 0.00463081 0.00454246 0.0155884  0.00750949 0.12140818 0.01389105\n",
      " 0.01583941 0.02602194 0.00182838 0.02829199 0.01046032 0.0119889\n",
      " 0.01600835 0.00579979 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.99999988 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99999535 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 20 [0/44 (0%)]\tTrain Loss: 0.000450\n",
      "Train Epoch: 20 [8/44 (18%)]\tTrain Loss: 0.002223\n",
      "Train Epoch: 20 [16/44 (36%)]\tTrain Loss: 0.005341\n",
      "Train Epoch: 20 [24/44 (55%)]\tTrain Loss: 0.002235\n",
      "Train Epoch: 20 [32/44 (73%)]\tTrain Loss: 0.007712\n",
      "Train Epoch: 20 [40/44 (91%)]\tTrain Loss: 0.007590\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.01961063 0.10119846 0.07500292 0.10744525 0.07158005 0.34961417\n",
      " 0.05133364 0.01982454 0.01657403 0.04827929 0.02174245 0.02945496\n",
      " 0.01573605 0.0143306  0.08484814 0.07327332 0.26028654 0.07715414\n",
      " 0.08045703 0.01651264 0.06687101 0.02754412 0.33768076 0.10094334\n",
      " 0.13745755 0.1771154  0.05803707 0.16371423 0.11727206 0.09250767\n",
      " 0.02828437 0.00670004 0.99752027 0.99774456 0.9994536  0.99643826\n",
      " 0.99956399 0.99839056 0.99640226 0.99842346 0.9975695  0.99852103\n",
      " 0.99597281 0.99903834 0.99654371 0.99629885 0.99965882 0.99824345\n",
      " 0.99825615 0.99871838 0.99876511 0.99943537 0.99696869 0.99854362\n",
      " 0.99874949 0.99738663 0.99828416 0.99849844 0.99812323 0.99838507\n",
      " 0.99932766 0.99836332 0.99789667 0.99732566 0.9981553  0.9970445\n",
      " 0.99718791 0.99709427 0.99807203 0.99784267 0.99783295 0.9989906\n",
      " 0.99840528 0.99853885 0.99573463 0.99912161 0.99705923 0.99853706\n",
      " 0.99881709 0.99596393 0.99918956 0.99900901 0.9988482  0.99914896\n",
      " 0.99728453 0.99866474 0.99724185 0.99907446 0.9995172  0.99726331\n",
      " 0.99736398 0.99969018 0.99829024 0.99860114 0.99844617 0.99957436\n",
      " 0.99768806 0.99818003 0.99801034]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "TP= 67 TN= 32 FN= 0 FP= 0\n",
      "TP+FP 67\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUCp 1.0\n",
      "AUC 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 20, average recall: 1.0000, average precision: 1.0000,average F1: 1.0000, average accuracy: 1.0000, average AUC: 1.0000\n",
      "Train Epoch: 21 [0/44 (0%)]\tTrain Loss: 0.001208\n",
      "Train Epoch: 21 [8/44 (18%)]\tTrain Loss: 0.004425\n",
      "Train Epoch: 21 [16/44 (36%)]\tTrain Loss: 0.002743\n",
      "Train Epoch: 21 [24/44 (55%)]\tTrain Loss: 0.000322\n",
      "Train Epoch: 21 [32/44 (73%)]\tTrain Loss: 0.001369\n",
      "Train Epoch: 21 [40/44 (91%)]\tTrain Loss: 0.002038\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.47684657e-03 2.46017184e-02 1.48500893e-02 2.35460475e-02\n",
      " 1.00103803e-02 1.13500662e-01 3.62348394e-03 2.29879864e-03\n",
      " 2.20241188e-03 7.03085400e-03 2.03923928e-03 3.69817950e-03\n",
      " 2.16878345e-03 3.00445873e-03 1.83014181e-02 1.03764730e-02\n",
      " 8.38288143e-02 7.85938650e-03 1.34053677e-02 1.30746339e-03\n",
      " 7.47244991e-03 3.38133494e-03 1.43984064e-01 1.47946626e-02\n",
      " 2.00168919e-02 4.51983027e-02 4.20736335e-03 4.58267257e-02\n",
      " 1.18339127e-02 1.52635714e-02 4.90917126e-03 6.73315662e-04\n",
      " 9.99153495e-01 9.99290705e-01 9.99896288e-01 9.98435915e-01\n",
      " 9.99939203e-01 9.99751508e-01 9.99754250e-01 9.99616742e-01\n",
      " 9.99725878e-01 9.99085665e-01 9.96982038e-01 9.99566495e-01\n",
      " 9.98551548e-01 9.97961402e-01 9.99861002e-01 9.99607861e-01\n",
      " 9.99393225e-01 9.99775708e-01 9.99519348e-01 9.99879718e-01\n",
      " 9.98874128e-01 9.99801099e-01 9.99413133e-01 9.98796582e-01\n",
      " 9.99538660e-01 9.99663234e-01 9.99603570e-01 9.99565899e-01\n",
      " 9.99737799e-01 9.99529362e-01 9.98779833e-01 9.99451220e-01\n",
      " 9.99454439e-01 9.99074936e-01 9.98715758e-01 9.99073029e-01\n",
      " 9.99327421e-01 9.99405503e-01 9.98715281e-01 9.99958754e-01\n",
      " 9.99305606e-01 9.99054730e-01 9.98778403e-01 9.99598444e-01\n",
      " 9.99140024e-01 9.99565065e-01 9.99878764e-01 9.98923600e-01\n",
      " 9.99889731e-01 9.99635935e-01 9.99842167e-01 9.99715030e-01\n",
      " 9.98852968e-01 9.99002039e-01 9.98494983e-01 9.99831438e-01\n",
      " 9.99740779e-01 9.99311090e-01 9.98734176e-01 9.99996066e-01\n",
      " 9.99499559e-01 9.99699473e-01 9.99591649e-01 9.99732912e-01\n",
      " 9.98708248e-01 9.99198258e-01 9.98667479e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 22 [0/44 (0%)]\tTrain Loss: 0.003565\n",
      "Train Epoch: 22 [8/44 (18%)]\tTrain Loss: 0.000756\n",
      "Train Epoch: 22 [16/44 (36%)]\tTrain Loss: 0.001449\n",
      "Train Epoch: 22 [24/44 (55%)]\tTrain Loss: 0.040781\n",
      "Train Epoch: 22 [32/44 (73%)]\tTrain Loss: 0.006630\n",
      "Train Epoch: 22 [40/44 (91%)]\tTrain Loss: 0.002213\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.04563724e-05 3.25140922e-04 2.32352715e-04 3.22343374e-04\n",
      " 1.67680861e-04 8.78186058e-03 1.41453547e-05 8.45315881e-05\n",
      " 2.20079733e-06 2.95333331e-04 1.12719727e-05 3.09224306e-05\n",
      " 1.11943709e-05 6.21882209e-05 3.88426241e-03 4.14805574e-04\n",
      " 4.99335211e-03 2.48258730e-04 4.83904179e-04 2.54961215e-05\n",
      " 2.72972044e-03 3.66816312e-05 8.78001451e-02 2.52638082e-03\n",
      " 1.82824919e-03 4.87620197e-03 1.72384069e-04 5.52602895e-02\n",
      " 3.63859799e-05 6.70134687e-05 1.26817486e-06 2.18726868e-08\n",
      " 9.95112598e-01 9.99274909e-01 9.99953985e-01 9.98900175e-01\n",
      " 9.99619365e-01 9.99820530e-01 9.99764383e-01 9.99854684e-01\n",
      " 9.99791682e-01 9.98526335e-01 9.62273657e-01 9.99925733e-01\n",
      " 9.99126375e-01 9.92718220e-01 9.99959588e-01 9.99962449e-01\n",
      " 9.99597967e-01 9.99854922e-01 9.99582946e-01 9.99935627e-01\n",
      " 9.99235392e-01 9.99764025e-01 9.99356210e-01 9.89859164e-01\n",
      " 9.99406576e-01 9.99642730e-01 9.99931097e-01 9.99427080e-01\n",
      " 9.98988211e-01 9.99818146e-01 9.92357552e-01 9.98608291e-01\n",
      " 9.99427974e-01 9.98464942e-01 9.99247193e-01 9.98538494e-01\n",
      " 9.96612489e-01 9.99693394e-01 9.98228610e-01 9.99997854e-01\n",
      " 9.97751892e-01 9.99402404e-01 9.96514797e-01 9.98593509e-01\n",
      " 9.97923315e-01 9.99037266e-01 9.99920368e-01 9.99174178e-01\n",
      " 9.99958277e-01 9.98928726e-01 9.99930382e-01 9.99742806e-01\n",
      " 9.97580528e-01 9.96046722e-01 9.98656273e-01 9.99960184e-01\n",
      " 9.99563873e-01 9.99073029e-01 9.97776330e-01 9.99996781e-01\n",
      " 9.99774039e-01 9.99885440e-01 9.98451591e-01 9.99491930e-01\n",
      " 9.99134123e-01 9.99221921e-01 9.95548129e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 23 [0/44 (0%)]\tTrain Loss: 0.000022\n",
      "Train Epoch: 23 [8/44 (18%)]\tTrain Loss: 0.086941\n",
      "Train Epoch: 23 [16/44 (36%)]\tTrain Loss: 0.000850\n",
      "Train Epoch: 23 [24/44 (55%)]\tTrain Loss: 0.002280\n",
      "Train Epoch: 23 [32/44 (73%)]\tTrain Loss: 0.000632\n",
      "Train Epoch: 23 [40/44 (91%)]\tTrain Loss: 0.009084\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [9.93027072e-03 1.67161040e-02 3.51654552e-02 3.65796611e-02\n",
      " 3.84694561e-02 1.26015827e-01 4.22789203e-03 4.22549201e-03\n",
      " 2.65541975e-03 1.43970456e-02 1.13394321e-03 1.30717820e-02\n",
      " 2.81325495e-03 6.09189458e-03 5.92987798e-02 9.59124509e-03\n",
      " 1.01564839e-01 4.69921296e-03 5.07898908e-03 1.56410737e-03\n",
      " 3.55986655e-02 3.03665828e-03 1.09227240e-01 1.56645514e-02\n",
      " 5.18241152e-02 3.35772894e-02 1.71386804e-02 3.25982906e-02\n",
      " 3.46798971e-02 9.52530131e-02 6.49827626e-03 6.57155295e-04\n",
      " 9.99999762e-01 9.99999762e-01 1.00000000e+00 9.99999642e-01\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99998093e-01 9.99996305e-01 9.99998569e-01\n",
      " 9.99996424e-01 9.99991894e-01 9.99999523e-01 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99999404e-01 1.00000000e+00 9.99999285e-01 9.99996185e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 9.99999762e-01 1.00000000e+00 9.99997973e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999523e-01 9.99999404e-01\n",
      " 9.99999642e-01 9.99999881e-01 9.99998450e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 9.99999881e-01 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 9.99999523e-01\n",
      " 9.99998212e-01 9.99942780e-01 9.99999762e-01 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 9.99997497e-01\n",
      " 9.99999642e-01 9.99999285e-01 9.99994397e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 24 [0/44 (0%)]\tTrain Loss: 0.004680\n",
      "Train Epoch: 24 [8/44 (18%)]\tTrain Loss: 0.001188\n",
      "Train Epoch: 24 [16/44 (36%)]\tTrain Loss: 0.007879\n",
      "Train Epoch: 24 [24/44 (55%)]\tTrain Loss: 0.001117\n",
      "Train Epoch: 24 [32/44 (73%)]\tTrain Loss: 0.012860\n",
      "Train Epoch: 24 [40/44 (91%)]\tTrain Loss: 0.002643\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.03395840e-03 8.23549367e-03 6.00159541e-03 1.63391177e-02\n",
      " 1.83421536e-03 5.98220862e-02 6.81276259e-04 7.56539870e-04\n",
      " 2.59502442e-04 5.78102190e-04 2.59758614e-04 1.73228304e-03\n",
      " 1.74609071e-04 1.49953424e-03 1.00711528e-02 1.90542080e-03\n",
      " 2.29126848e-02 1.52193604e-03 2.87133316e-03 8.65209382e-04\n",
      " 7.30660884e-03 1.21620297e-03 1.50186941e-01 1.08992271e-02\n",
      " 1.36406394e-02 2.29148604e-02 1.08525669e-03 6.10241704e-02\n",
      " 4.79324441e-03 3.78900347e-03 1.12525630e-03 1.09519227e-04\n",
      " 9.99996185e-01 9.99998450e-01 1.00000000e+00 9.99990940e-01\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 9.99999046e-01\n",
      " 9.99999881e-01 9.99996185e-01 9.99983191e-01 9.99999881e-01\n",
      " 9.99999762e-01 9.99995589e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99999642e-01 9.99999881e-01 1.00000000e+00 9.99999642e-01\n",
      " 9.99999404e-01 1.00000000e+00 9.99992847e-01 9.99990582e-01\n",
      " 9.99999642e-01 9.99998569e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999404e-01 9.99994397e-01 9.99997735e-01\n",
      " 9.99999404e-01 9.99998450e-01 9.99990821e-01 9.99988675e-01\n",
      " 9.99994516e-01 9.99999762e-01 9.99992371e-01 1.00000000e+00\n",
      " 9.99995828e-01 9.99998212e-01 9.99996662e-01 9.99997497e-01\n",
      " 9.99992251e-01 9.99999881e-01 9.99999881e-01 9.99996543e-01\n",
      " 1.00000000e+00 9.99997735e-01 9.99999762e-01 9.99999881e-01\n",
      " 9.99997139e-01 9.99985218e-01 9.99997735e-01 1.00000000e+00\n",
      " 9.99999285e-01 9.99996305e-01 9.99998808e-01 1.00000000e+00\n",
      " 9.99999404e-01 1.00000000e+00 9.99998689e-01 9.99998808e-01\n",
      " 9.99998689e-01 9.99997377e-01 9.99992013e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [0/44 (0%)]\tTrain Loss: 0.006151\n",
      "Train Epoch: 25 [8/44 (18%)]\tTrain Loss: 0.025700\n",
      "Train Epoch: 25 [16/44 (36%)]\tTrain Loss: 0.088281\n",
      "Train Epoch: 25 [24/44 (55%)]\tTrain Loss: 0.002778\n",
      "Train Epoch: 25 [32/44 (73%)]\tTrain Loss: 0.001074\n",
      "Train Epoch: 25 [40/44 (91%)]\tTrain Loss: 0.004282\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.99196802e-04 3.08902678e-03 9.82496073e-04 4.51089721e-03\n",
      " 1.53545858e-04 1.24406051e-02 6.64956751e-05 5.19949863e-05\n",
      " 1.29898719e-04 5.92784345e-05 4.98366644e-05 4.96942201e-04\n",
      " 2.73232381e-05 1.25797349e-03 9.35459684e-04 1.03615326e-04\n",
      " 1.27979193e-03 2.66319636e-04 2.55734427e-04 2.34115520e-04\n",
      " 9.03992739e-04 2.31398517e-04 3.33867036e-02 3.25278379e-03\n",
      " 2.36885599e-03 1.13139942e-03 2.92684184e-04 1.24153988e-02\n",
      " 4.51191881e-04 5.48121054e-04 1.97062109e-04 3.38469217e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999285e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 26 [0/44 (0%)]\tTrain Loss: 0.000173\n",
      "Train Epoch: 26 [8/44 (18%)]\tTrain Loss: 0.000720\n",
      "Train Epoch: 26 [16/44 (36%)]\tTrain Loss: 0.038547\n",
      "Train Epoch: 26 [24/44 (55%)]\tTrain Loss: 0.010856\n",
      "Train Epoch: 26 [32/44 (73%)]\tTrain Loss: 0.002591\n",
      "Train Epoch: 26 [40/44 (91%)]\tTrain Loss: 0.002668\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.14661914e-03 4.92805429e-03 1.06027247e-02 1.21249715e-02\n",
      " 4.55174316e-03 9.38701555e-02 1.51175237e-03 1.37662166e-03\n",
      " 5.66062110e-04 1.02721911e-03 8.40192544e-04 2.14763172e-03\n",
      " 4.27035644e-04 9.50174406e-04 6.95852144e-03 4.82778763e-03\n",
      " 1.76034737e-02 9.23901272e-04 1.65633683e-03 1.29961374e-03\n",
      " 1.05220787e-02 2.70483852e-03 5.96201196e-02 4.91325604e-03\n",
      " 1.24517223e-02 2.12778095e-02 5.79859538e-04 2.93761045e-02\n",
      " 5.46467304e-03 7.11860741e-03 1.16527465e-03 1.76036046e-04\n",
      " 9.99997020e-01 9.99998927e-01 1.00000000e+00 9.99998808e-01\n",
      " 9.99996305e-01 9.99998927e-01 9.99999404e-01 9.99995351e-01\n",
      " 1.00000000e+00 9.99931097e-01 9.99999881e-01 9.99963403e-01\n",
      " 9.99975443e-01 9.99996543e-01 9.99987721e-01 9.99999166e-01\n",
      " 9.99999285e-01 1.00000000e+00 1.00000000e+00 9.99988914e-01\n",
      " 9.99986291e-01 1.00000000e+00 9.99992251e-01 9.99976397e-01\n",
      " 9.99999762e-01 9.99999881e-01 9.99999642e-01 1.00000000e+00\n",
      " 9.99999166e-01 9.99997854e-01 9.99996901e-01 9.99999762e-01\n",
      " 1.00000000e+00 9.99998331e-01 9.99995589e-01 9.99986172e-01\n",
      " 9.99997020e-01 9.99993324e-01 9.99982953e-01 1.00000000e+00\n",
      " 9.99999404e-01 9.99998450e-01 9.99999881e-01 9.99999523e-01\n",
      " 9.99996901e-01 9.99999881e-01 9.99999285e-01 1.00000000e+00\n",
      " 9.99999762e-01 9.99999881e-01 1.00000000e+00 9.99999285e-01\n",
      " 9.99947786e-01 9.99520898e-01 9.99999046e-01 9.99998808e-01\n",
      " 9.99998212e-01 9.99999642e-01 9.99999762e-01 1.00000000e+00\n",
      " 9.99999881e-01 9.99999404e-01 9.99998569e-01 9.99894738e-01\n",
      " 9.99995470e-01 9.99989271e-01 9.99986887e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 27 [0/44 (0%)]\tTrain Loss: 0.041280\n",
      "Train Epoch: 27 [8/44 (18%)]\tTrain Loss: 0.004060\n",
      "Train Epoch: 27 [16/44 (36%)]\tTrain Loss: 0.007697\n",
      "Train Epoch: 27 [24/44 (55%)]\tTrain Loss: 0.021072\n",
      "Train Epoch: 27 [32/44 (73%)]\tTrain Loss: 0.026779\n",
      "Train Epoch: 27 [40/44 (91%)]\tTrain Loss: 0.000979\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.01894965 0.04202222 0.07945841 0.11631267 0.10337848 0.65310347\n",
      " 0.02082169 0.0673544  0.00987381 0.06092732 0.0147641  0.02453125\n",
      " 0.02609148 0.00973848 0.14451329 0.15683909 0.26700699 0.05931639\n",
      " 0.08021396 0.01590591 0.08802621 0.03272524 0.54726022 0.09447388\n",
      " 0.22825788 0.34909126 0.06016694 0.41284046 0.07022502 0.08499952\n",
      " 0.01312832 0.00219848 0.99999976 0.99999988 1.         0.99999893\n",
      " 0.99999988 0.99999976 0.99999988 1.         1.         0.99999702\n",
      " 0.99998558 0.9999975  0.99999833 0.99999189 1.         1.\n",
      " 0.99999964 1.         1.         0.99999988 0.99999964 1.\n",
      " 0.9999994  0.99999321 1.         1.         0.99999988 1.\n",
      " 0.99999976 1.         0.9999975  1.         1.         0.99999988\n",
      " 0.99999976 0.99999964 0.99999774 1.         0.9999994  1.\n",
      " 1.         0.99999964 0.99999988 0.99999964 0.99999988 1.\n",
      " 1.         1.         1.         0.99999976 1.         0.99999988\n",
      " 0.99999833 0.99989152 0.99999976 1.         0.99999976 1.\n",
      " 0.99999988 1.         1.         1.         0.99999964 0.99999595\n",
      " 0.99999976 0.99999821 0.99999177]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 28 [0/44 (0%)]\tTrain Loss: 0.007260\n",
      "Train Epoch: 28 [8/44 (18%)]\tTrain Loss: 0.013289\n",
      "Train Epoch: 28 [16/44 (36%)]\tTrain Loss: 0.001397\n",
      "Train Epoch: 28 [24/44 (55%)]\tTrain Loss: 0.010236\n",
      "Train Epoch: 28 [32/44 (73%)]\tTrain Loss: 0.023156\n",
      "Train Epoch: 28 [40/44 (91%)]\tTrain Loss: 0.021287\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [3.07172001e-03 7.53844902e-03 1.23812314e-02 2.79578995e-02\n",
      " 2.09606085e-02 3.16377491e-01 2.71151331e-03 8.44338723e-03\n",
      " 9.17825382e-04 1.15707945e-02 1.76442356e-03 4.43131570e-03\n",
      " 1.88854628e-03 1.56064483e-03 3.49893384e-02 1.26018059e-02\n",
      " 4.76238914e-02 1.59465540e-02 1.87383089e-02 2.33076303e-03\n",
      " 1.89308282e-02 4.04099515e-03 2.61894852e-01 3.53367254e-02\n",
      " 4.43511680e-02 7.07500726e-02 1.18060699e-02 1.59606576e-01\n",
      " 1.75394751e-02 1.78245977e-02 2.11000303e-03 3.39982740e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 29 [0/44 (0%)]\tTrain Loss: 0.001940\n",
      "Train Epoch: 29 [8/44 (18%)]\tTrain Loss: 0.000648\n",
      "Train Epoch: 29 [16/44 (36%)]\tTrain Loss: 0.000565\n",
      "Train Epoch: 29 [24/44 (55%)]\tTrain Loss: 0.002705\n",
      "Train Epoch: 29 [32/44 (73%)]\tTrain Loss: 0.011592\n",
      "Train Epoch: 29 [40/44 (91%)]\tTrain Loss: 0.015112\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.31168747e-02 1.70610808e-02 5.07893339e-02 5.57017699e-02\n",
      " 4.79547530e-02 1.86796769e-01 5.85976895e-03 7.93037005e-03\n",
      " 2.17071082e-03 2.72545572e-02 2.48171715e-03 1.24393459e-02\n",
      " 4.34162747e-03 4.04514885e-03 7.97886252e-02 2.00205427e-02\n",
      " 1.06506228e-01 1.35473441e-02 2.21984256e-02 1.69531181e-02\n",
      " 3.10433153e-02 6.01540506e-03 1.75761759e-01 1.91769972e-02\n",
      " 4.28676493e-02 7.72139132e-02 3.42940018e-02 1.02389723e-01\n",
      " 7.97113180e-02 7.01783448e-02 1.90941487e-02 8.64264322e-04\n",
      " 9.99999762e-01 9.99999642e-01 9.99999285e-01 9.99999642e-01\n",
      " 9.99991775e-01 9.99999285e-01 9.99998808e-01 9.99999762e-01\n",
      " 1.00000000e+00 9.99958158e-01 9.99999762e-01 9.99991059e-01\n",
      " 9.99704778e-01 9.99991894e-01 9.99843597e-01 9.99994993e-01\n",
      " 9.99992013e-01 1.00000000e+00 9.99988914e-01 9.99997139e-01\n",
      " 9.99996185e-01 9.99999642e-01 9.99915123e-01 9.99998331e-01\n",
      " 9.99999881e-01 9.99999166e-01 9.99976277e-01 9.99999881e-01\n",
      " 9.99992847e-01 1.00000000e+00 9.99998569e-01 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 9.99997735e-01 9.99999166e-01\n",
      " 9.99995232e-01 9.99989510e-01 9.99956489e-01 9.99990106e-01\n",
      " 9.99999762e-01 9.99997139e-01 1.00000000e+00 9.99998331e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99979377e-01 1.00000000e+00\n",
      " 9.99984741e-01 9.99992251e-01 1.00000000e+00 9.99983311e-01\n",
      " 9.99985695e-01 9.99624729e-01 9.99995470e-01 9.99992609e-01\n",
      " 9.99993801e-01 1.00000000e+00 9.99999642e-01 9.99999881e-01\n",
      " 9.99999881e-01 9.99998569e-01 9.99998450e-01 9.99720633e-01\n",
      " 9.99998689e-01 9.99967575e-01 9.99957323e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 30 [0/44 (0%)]\tTrain Loss: 0.002185\n",
      "Train Epoch: 30 [8/44 (18%)]\tTrain Loss: 0.000869\n",
      "Train Epoch: 30 [16/44 (36%)]\tTrain Loss: 0.002066\n",
      "Train Epoch: 30 [24/44 (55%)]\tTrain Loss: 0.111149\n",
      "Train Epoch: 30 [32/44 (73%)]\tTrain Loss: 0.005132\n",
      "Train Epoch: 30 [40/44 (91%)]\tTrain Loss: 0.004579\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.14647735e-03 4.47849929e-03 7.33584771e-03 2.30429918e-02\n",
      " 8.96406267e-03 7.13098943e-02 1.98547146e-03 1.65569165e-03\n",
      " 5.61909517e-04 5.24516962e-03 6.93334441e-04 3.37848533e-03\n",
      " 1.11022464e-03 5.74324222e-04 2.01796740e-02 5.76185528e-03\n",
      " 1.62187126e-02 5.40304463e-03 3.36486869e-03 3.71085247e-03\n",
      " 1.13514513e-02 1.79427781e-03 5.95525615e-02 1.24206673e-02\n",
      " 1.20698661e-02 1.78697072e-02 1.16681391e-02 3.96914296e-02\n",
      " 1.14873713e-02 9.09459312e-03 4.08115471e-03 4.66205907e-04\n",
      " 9.99998808e-01 9.99989867e-01 9.99991655e-01 9.99931931e-01\n",
      " 9.99997497e-01 9.99995947e-01 9.99999523e-01 9.99997973e-01\n",
      " 9.99997973e-01 9.99938369e-01 9.99939203e-01 9.99949455e-01\n",
      " 9.99983191e-01 9.99988675e-01 9.99992609e-01 9.99999285e-01\n",
      " 9.99996424e-01 1.00000000e+00 9.99991894e-01 9.99996781e-01\n",
      " 9.99992490e-01 1.00000000e+00 9.99988437e-01 9.99990821e-01\n",
      " 9.99999166e-01 9.99999762e-01 9.99998450e-01 1.00000000e+00\n",
      " 9.99997973e-01 9.99999404e-01 9.99997616e-01 1.00000000e+00\n",
      " 9.99997139e-01 9.99999762e-01 9.99998569e-01 9.99997973e-01\n",
      " 9.99994755e-01 9.99997854e-01 9.99992013e-01 9.99997020e-01\n",
      " 9.99999881e-01 9.99994278e-01 9.99999404e-01 9.99998093e-01\n",
      " 9.99999642e-01 9.99999881e-01 9.99998569e-01 9.99999881e-01\n",
      " 9.99999642e-01 9.99988914e-01 1.00000000e+00 9.99997973e-01\n",
      " 9.99990225e-01 9.99793589e-01 9.99999642e-01 9.99996543e-01\n",
      " 9.99998927e-01 9.99999762e-01 9.99999881e-01 1.00000000e+00\n",
      " 9.99999762e-01 9.99997497e-01 9.99998808e-01 9.99975920e-01\n",
      " 9.99997854e-01 9.99995947e-01 9.99997973e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "TP= 67 TN= 32 FN= 0 FP= 0\n",
      "TP+FP 67\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUCp 1.0\n",
      "AUC 1.0\n",
      "\n",
      " The epoch is 30, average recall: 1.0000, average precision: 1.0000,average F1: 1.0000, average accuracy: 1.0000, average AUC: 1.0000\n",
      "Train Epoch: 31 [0/44 (0%)]\tTrain Loss: 0.003420\n",
      "Train Epoch: 31 [8/44 (18%)]\tTrain Loss: 0.000617\n",
      "Train Epoch: 31 [16/44 (36%)]\tTrain Loss: 0.018374\n",
      "Train Epoch: 31 [24/44 (55%)]\tTrain Loss: 0.000488\n",
      "Train Epoch: 31 [32/44 (73%)]\tTrain Loss: 0.001538\n",
      "Train Epoch: 31 [40/44 (91%)]\tTrain Loss: 0.003920\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [6.15322555e-04 5.88386832e-03 5.53499162e-03 1.12772230e-02\n",
      " 1.80128159e-03 1.08620944e-02 5.63891314e-04 4.47761035e-04\n",
      " 1.00017169e-04 9.65165324e-04 2.10207523e-04 1.19452865e-03\n",
      " 1.97084257e-04 4.23512363e-04 1.02449264e-02 3.07566090e-03\n",
      " 5.28203044e-03 8.23928043e-04 9.73694492e-04 8.57842620e-04\n",
      " 6.34362036e-03 1.51698629e-03 6.16589412e-02 1.38143143e-02\n",
      " 9.78153851e-03 7.66485929e-03 5.78657084e-04 2.92635318e-02\n",
      " 2.04417761e-03 1.96798239e-03 1.76214811e-03 1.66233935e-04\n",
      " 7.79402792e-01 4.76130068e-01 2.77940094e-01 2.04034671e-01\n",
      " 1.31355092e-01 2.69017071e-01 2.77479410e-01 4.95275497e-01\n",
      " 7.27027416e-01 1.55005425e-01 7.17941344e-01 9.00413617e-02\n",
      " 8.83980095e-02 7.38521278e-01 6.24431409e-02 2.20457166e-01\n",
      " 8.73593614e-02 8.73409927e-01 3.48470092e-01 3.17286402e-01\n",
      " 5.88857830e-01 5.69431603e-01 4.55185115e-01 7.34728873e-01\n",
      " 6.53683126e-01 6.09975159e-01 4.24155265e-01 7.89432704e-01\n",
      " 1.15524448e-01 7.35882044e-01 8.95710468e-01 8.37229550e-01\n",
      " 6.22547686e-01 9.75267887e-01 7.77989209e-01 9.30862606e-01\n",
      " 8.12658548e-01 2.89268166e-01 6.77562714e-01 1.25446737e-01\n",
      " 8.90930116e-01 2.84668058e-01 7.62625277e-01 7.30466068e-01\n",
      " 9.70128477e-01 7.84064114e-01 1.24779008e-01 8.98215711e-01\n",
      " 2.83711076e-01 7.46182263e-01 9.41964149e-01 3.73893321e-01\n",
      " 5.95266342e-01 2.29530215e-01 4.57439452e-01 1.88745275e-01\n",
      " 3.75307560e-01 8.74817908e-01 7.75415957e-01 3.63843203e-01\n",
      " 8.26752186e-01 6.37952030e-01 5.07328808e-01 7.23058581e-02\n",
      " 8.44586074e-01 3.94650429e-01 2.70696849e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0.\n",
      " 1. 0. 0.]\n",
      "Train Epoch: 32 [0/44 (0%)]\tTrain Loss: 0.009871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 32 [8/44 (18%)]\tTrain Loss: 0.000605\n",
      "Train Epoch: 32 [16/44 (36%)]\tTrain Loss: 0.001973\n",
      "Train Epoch: 32 [24/44 (55%)]\tTrain Loss: 0.000874\n",
      "Train Epoch: 32 [32/44 (73%)]\tTrain Loss: 0.024305\n",
      "Train Epoch: 32 [40/44 (91%)]\tTrain Loss: 0.004014\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [3.70343332e-06 7.37491937e-05 5.45750154e-05 9.95413284e-05\n",
      " 1.02289414e-05 2.31360595e-04 2.48793594e-06 2.93604171e-06\n",
      " 1.24906046e-06 5.61123306e-06 9.08199866e-07 6.69195060e-06\n",
      " 7.57367673e-07 6.41871338e-06 1.01026984e-04 2.21143819e-05\n",
      " 5.05156895e-05 2.74500189e-06 3.72257546e-06 2.75525417e-06\n",
      " 8.54688260e-05 1.31272327e-05 1.25371886e-03 2.23617099e-04\n",
      " 3.72625596e-04 7.79694892e-05 2.38235612e-06 6.31326810e-04\n",
      " 1.20174263e-05 1.22164902e-05 5.54763756e-06 5.28103158e-07\n",
      " 9.99999762e-01 1.00000000e+00 9.99999046e-01 9.99998927e-01\n",
      " 9.99992013e-01 9.99996066e-01 9.99977231e-01 9.99999166e-01\n",
      " 9.99998808e-01 9.99986291e-01 9.99859691e-01 9.99990344e-01\n",
      " 9.99986768e-01 9.99985218e-01 9.99980450e-01 9.99998212e-01\n",
      " 9.99948978e-01 1.00000000e+00 9.99990821e-01 9.99998927e-01\n",
      " 9.99998927e-01 1.00000000e+00 9.99951482e-01 9.99942183e-01\n",
      " 9.99999762e-01 9.99998689e-01 9.99997497e-01 9.99999642e-01\n",
      " 9.99885917e-01 1.00000000e+00 9.99992847e-01 9.99998808e-01\n",
      " 9.99998450e-01 1.00000000e+00 9.99999881e-01 9.99999762e-01\n",
      " 9.99997616e-01 9.99988079e-01 9.99998808e-01 9.99996662e-01\n",
      " 9.99997497e-01 9.99944806e-01 9.99999523e-01 9.99998212e-01\n",
      " 1.00000000e+00 9.99999642e-01 9.99993563e-01 1.00000000e+00\n",
      " 9.99997258e-01 9.99951005e-01 1.00000000e+00 9.99998808e-01\n",
      " 9.99998212e-01 9.99559104e-01 9.99998569e-01 9.99996066e-01\n",
      " 9.99999404e-01 1.00000000e+00 9.99998331e-01 9.99999881e-01\n",
      " 9.99999881e-01 9.99994755e-01 9.99997973e-01 9.99989271e-01\n",
      " 9.99998212e-01 9.99995589e-01 9.99987483e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 33 [0/44 (0%)]\tTrain Loss: 0.000324\n",
      "Train Epoch: 33 [8/44 (18%)]\tTrain Loss: 0.007416\n",
      "Train Epoch: 33 [16/44 (36%)]\tTrain Loss: 0.066538\n",
      "Train Epoch: 33 [24/44 (55%)]\tTrain Loss: 0.001351\n",
      "Train Epoch: 33 [32/44 (73%)]\tTrain Loss: 0.017361\n",
      "Train Epoch: 33 [40/44 (91%)]\tTrain Loss: 0.038399\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.0327484  0.07727718 0.09231178 0.17323901 0.07523786 0.495994\n",
      " 0.04421055 0.0389584  0.02793172 0.05000926 0.01234227 0.04884864\n",
      " 0.01548464 0.02941005 0.20863526 0.12819415 0.19257867 0.07001927\n",
      " 0.05261232 0.03760194 0.12271304 0.03418349 0.35721549 0.1482764\n",
      " 0.17790693 0.15915385 0.07813416 0.30985928 0.13161986 0.09682216\n",
      " 0.02724385 0.00552401 0.99999976 0.99999952 0.99999833 0.99999833\n",
      " 0.99999464 0.99999511 0.99998963 0.99999857 0.99999809 0.99998629\n",
      " 0.99999416 0.99999166 0.99998808 0.99998844 0.99996936 0.99999666\n",
      " 0.99998939 1.         0.99999428 0.99999702 0.99999797 0.99999976\n",
      " 0.99997151 0.99998915 0.99999964 0.99999809 0.9999975  0.99999976\n",
      " 0.99999142 0.99999988 0.99999774 0.99999845 0.99999893 0.99999988\n",
      " 0.99999905 0.99999881 0.99999833 0.9999907  0.99999714 0.99999487\n",
      " 0.99999845 0.99997401 0.99999964 0.99999762 1.         0.9999994\n",
      " 0.99999535 0.99999976 0.99999428 0.99997699 0.99999988 0.99999738\n",
      " 0.99999619 0.99987173 0.99999857 0.99999475 0.99999738 0.99999988\n",
      " 0.9999994  0.99999952 0.99999928 0.99999583 0.99999774 0.99998915\n",
      " 0.99999702 0.99999475 0.99999487]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 34 [0/44 (0%)]\tTrain Loss: 0.030440\n",
      "Train Epoch: 34 [8/44 (18%)]\tTrain Loss: 0.005861\n",
      "Train Epoch: 34 [16/44 (36%)]\tTrain Loss: 0.001790\n",
      "Train Epoch: 34 [24/44 (55%)]\tTrain Loss: 0.002972\n",
      "Train Epoch: 34 [32/44 (73%)]\tTrain Loss: 0.000461\n",
      "Train Epoch: 34 [40/44 (91%)]\tTrain Loss: 0.003885\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.42951047e-03 1.44476155e-02 1.08607924e-02 2.80221011e-02\n",
      " 8.62034410e-03 2.34457016e-01 3.19732586e-03 6.53103646e-03\n",
      " 1.55696529e-03 8.03660415e-03 9.90227680e-04 4.01905086e-03\n",
      " 1.63717114e-03 2.23116181e-03 3.96473408e-02 2.94131562e-02\n",
      " 1.22827724e-01 9.94167384e-03 1.18894391e-02 2.51820264e-03\n",
      " 2.21402533e-02 3.36306239e-03 2.16542393e-01 3.27783786e-02\n",
      " 5.76862916e-02 8.11949223e-02 2.00621672e-02 2.30567098e-01\n",
      " 9.50874668e-03 9.08323843e-03 1.23346248e-03 2.31147831e-04\n",
      " 9.99997735e-01 9.99997020e-01 9.99993563e-01 9.99977231e-01\n",
      " 9.99977350e-01 9.99972701e-01 9.99976158e-01 9.99993682e-01\n",
      " 9.99992013e-01 9.99940395e-01 9.99930382e-01 9.99976993e-01\n",
      " 9.99940038e-01 9.99946117e-01 9.99924779e-01 9.99984622e-01\n",
      " 9.99968290e-01 9.99999762e-01 9.99976873e-01 9.99990821e-01\n",
      " 9.99991298e-01 9.99997854e-01 9.99927521e-01 9.99946237e-01\n",
      " 9.99996901e-01 9.99985933e-01 9.99993920e-01 9.99998331e-01\n",
      " 9.99959826e-01 9.99999046e-01 9.99978900e-01 9.99991417e-01\n",
      " 9.99993920e-01 9.99998689e-01 9.99996305e-01 9.99994278e-01\n",
      " 9.99988914e-01 9.99970794e-01 9.99989510e-01 9.99990582e-01\n",
      " 9.99989748e-01 9.99878764e-01 9.99994755e-01 9.99992013e-01\n",
      " 9.99999285e-01 9.99996424e-01 9.99988079e-01 9.99997497e-01\n",
      " 9.99984264e-01 9.99943376e-01 9.99999404e-01 9.99991775e-01\n",
      " 9.99986410e-01 9.99586403e-01 9.99994755e-01 9.99979734e-01\n",
      " 9.99988317e-01 9.99998808e-01 9.99997020e-01 9.99998450e-01\n",
      " 9.99995589e-01 9.99988914e-01 9.99990702e-01 9.99977469e-01\n",
      " 9.99989510e-01 9.99973774e-01 9.99983430e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 35 [0/44 (0%)]\tTrain Loss: 0.004484\n",
      "Train Epoch: 35 [8/44 (18%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 35 [16/44 (36%)]\tTrain Loss: 0.013239\n",
      "Train Epoch: 35 [24/44 (55%)]\tTrain Loss: 0.003166\n",
      "Train Epoch: 35 [32/44 (73%)]\tTrain Loss: 0.015892\n",
      "Train Epoch: 35 [40/44 (91%)]\tTrain Loss: 0.000149\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.06493023e-05 3.68811248e-04 2.25429030e-04 1.36954000e-03\n",
      " 1.69698033e-04 9.80378836e-02 7.39537209e-05 7.25858335e-05\n",
      " 2.45413248e-05 1.67667749e-04 6.30617933e-06 7.95919041e-05\n",
      " 7.82180086e-06 2.29562538e-05 1.10406836e-03 2.59685330e-04\n",
      " 2.83219498e-02 4.56187117e-04 1.93730448e-04 3.22471496e-05\n",
      " 2.62278831e-04 3.64384832e-05 1.02041855e-01 9.84892831e-04\n",
      " 3.37312534e-03 3.39798280e-03 6.26182533e-04 4.91467863e-02\n",
      " 4.07457585e-04 2.48236232e-04 1.46374123e-05 3.97991982e-07\n",
      " 9.98703718e-01 9.99371111e-01 9.99740422e-01 9.99463022e-01\n",
      " 9.98868227e-01 9.98866558e-01 9.97277677e-01 9.98442948e-01\n",
      " 9.99766886e-01 9.99845743e-01 9.95310962e-01 9.99041021e-01\n",
      " 9.99853849e-01 9.97764707e-01 9.99190867e-01 9.99380589e-01\n",
      " 9.97734785e-01 9.99953032e-01 9.98470128e-01 9.99252021e-01\n",
      " 9.98701930e-01 9.99778450e-01 9.97991562e-01 9.97681618e-01\n",
      " 9.99796450e-01 9.98643100e-01 9.99575436e-01 9.99208272e-01\n",
      " 9.99495387e-01 9.98959064e-01 9.97623384e-01 9.99661088e-01\n",
      " 9.99720871e-01 9.99251068e-01 9.99206722e-01 9.98855352e-01\n",
      " 9.98839676e-01 9.97604430e-01 9.99103308e-01 9.99690056e-01\n",
      " 9.98787820e-01 9.97426808e-01 9.99773324e-01 9.98560488e-01\n",
      " 9.99327660e-01 9.99198496e-01 9.99087334e-01 9.99655247e-01\n",
      " 9.99376237e-01 9.97313678e-01 9.99949694e-01 9.98682320e-01\n",
      " 9.99190629e-01 9.99981523e-01 9.98769104e-01 9.99382973e-01\n",
      " 9.97623861e-01 9.99625325e-01 9.98979092e-01 9.99924183e-01\n",
      " 9.99547899e-01 9.98360455e-01 9.98675168e-01 9.96621966e-01\n",
      " 9.98111129e-01 9.98450041e-01 9.98442948e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 36 [0/44 (0%)]\tTrain Loss: 0.003316\n",
      "Train Epoch: 36 [8/44 (18%)]\tTrain Loss: 0.000436\n",
      "Train Epoch: 36 [16/44 (36%)]\tTrain Loss: 0.000602\n",
      "Train Epoch: 36 [24/44 (55%)]\tTrain Loss: 0.002732\n",
      "Train Epoch: 36 [32/44 (73%)]\tTrain Loss: 0.000091\n",
      "Train Epoch: 36 [40/44 (91%)]\tTrain Loss: 0.000378\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.00942479 0.01652667 0.0291954  0.05625052 0.01547287 0.35099754\n",
      " 0.00915482 0.00481254 0.00583118 0.01204259 0.00564763 0.01477922\n",
      " 0.00302227 0.00482493 0.02374581 0.00964682 0.15586941 0.02522457\n",
      " 0.02729573 0.01535464 0.03376314 0.01180143 0.25376588 0.04291533\n",
      " 0.05454207 0.04902584 0.04144225 0.29654041 0.02540413 0.0251384\n",
      " 0.00550354 0.00124063 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99999988]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 37 [0/44 (0%)]\tTrain Loss: 0.000329\n",
      "Train Epoch: 37 [8/44 (18%)]\tTrain Loss: 0.000445\n",
      "Train Epoch: 37 [16/44 (36%)]\tTrain Loss: 0.000118\n",
      "Train Epoch: 37 [24/44 (55%)]\tTrain Loss: 0.004119\n",
      "Train Epoch: 37 [32/44 (73%)]\tTrain Loss: 0.014752\n",
      "Train Epoch: 37 [40/44 (91%)]\tTrain Loss: 0.004182\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.13803323e-03 2.45997682e-03 4.64881072e-03 5.03522763e-03\n",
      " 1.62199768e-03 7.45194554e-02 1.07943511e-03 3.25252826e-04\n",
      " 3.82704486e-04 1.57194340e-03 2.16513683e-04 1.29275350e-03\n",
      " 4.16319788e-04 5.31722733e-04 2.30285199e-03 8.63469497e-04\n",
      " 4.54782471e-02 2.74176034e-03 2.43301364e-03 5.80864667e-04\n",
      " 1.63556624e-03 1.09512697e-03 3.46563123e-02 2.54605664e-03\n",
      " 1.01787243e-02 9.53394733e-03 3.10120452e-03 3.39479670e-02\n",
      " 3.75866028e-03 3.67528247e-03 7.26151397e-04 7.58681417e-05\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 9.99999285e-01\n",
      " 9.99999881e-01 9.99999881e-01 1.00000000e+00 9.99999762e-01\n",
      " 1.00000000e+00 9.99978662e-01 9.99991417e-01 9.99999762e-01\n",
      " 9.99999285e-01 9.99998689e-01 9.99999881e-01 1.00000000e+00\n",
      " 9.99999285e-01 1.00000000e+00 9.99999404e-01 1.00000000e+00\n",
      " 9.99999642e-01 1.00000000e+00 9.99999642e-01 9.99995947e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99999523e-01 1.00000000e+00 9.99999404e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 9.99999762e-01 9.99998808e-01 9.99999404e-01 1.00000000e+00\n",
      " 9.99999881e-01 9.99999285e-01 9.99999881e-01 9.99999762e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999642e-01 1.00000000e+00 9.99999881e-01\n",
      " 9.99999046e-01 9.99986887e-01 9.99999881e-01 9.99999881e-01\n",
      " 9.99999762e-01 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999762e-01 9.99999404e-01 9.99995828e-01\n",
      " 9.99998569e-01 9.99999642e-01 9.99998689e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 38 [0/44 (0%)]\tTrain Loss: 0.002070\n",
      "Train Epoch: 38 [8/44 (18%)]\tTrain Loss: 0.006188\n",
      "Train Epoch: 38 [16/44 (36%)]\tTrain Loss: 0.000158\n",
      "Train Epoch: 38 [24/44 (55%)]\tTrain Loss: 0.003054\n",
      "Train Epoch: 38 [32/44 (73%)]\tTrain Loss: 0.000059\n",
      "Train Epoch: 38 [40/44 (91%)]\tTrain Loss: 0.000231\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [6.79017219e-04 3.69112892e-03 5.18330419e-03 5.80632966e-03\n",
      " 3.51530244e-03 1.49698734e-01 2.41758698e-03 3.55992978e-03\n",
      " 8.04168696e-04 9.18155350e-03 3.99796554e-04 1.35499099e-03\n",
      " 7.88499950e-04 1.51768836e-04 7.29529792e-03 5.19265328e-03\n",
      " 2.08875880e-01 2.65412461e-02 1.87763255e-02 3.42674117e-04\n",
      " 2.67485599e-03 1.64887763e-03 1.23547032e-01 6.07510889e-03\n",
      " 1.49953812e-02 4.74508330e-02 6.23190217e-02 9.92271602e-02\n",
      " 2.08913628e-02 7.53725041e-03 5.50918165e-04 3.40041552e-05\n",
      " 9.99998569e-01 9.99999523e-01 1.00000000e+00 9.99999166e-01\n",
      " 9.99999523e-01 9.99999642e-01 9.99999404e-01 9.99999523e-01\n",
      " 1.00000000e+00 9.99981999e-01 9.99994874e-01 9.99999762e-01\n",
      " 9.99998212e-01 9.99993443e-01 9.99999523e-01 9.99999881e-01\n",
      " 9.99999762e-01 1.00000000e+00 9.99999285e-01 9.99999881e-01\n",
      " 9.99999404e-01 1.00000000e+00 9.99999762e-01 9.99991298e-01\n",
      " 9.99999881e-01 9.99999762e-01 9.99999881e-01 9.99999881e-01\n",
      " 9.99999404e-01 9.99999762e-01 9.99994397e-01 9.99999881e-01\n",
      " 9.99999881e-01 9.99999762e-01 9.99999642e-01 9.99999523e-01\n",
      " 9.99998093e-01 9.99998808e-01 9.99999046e-01 1.00000000e+00\n",
      " 9.99999404e-01 9.99999881e-01 9.99999642e-01 9.99998808e-01\n",
      " 9.99999762e-01 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 9.99999881e-01 9.99999166e-01 1.00000000e+00 9.99999642e-01\n",
      " 9.99997258e-01 9.99988794e-01 9.99999881e-01 9.99999881e-01\n",
      " 9.99998212e-01 9.99999881e-01 9.99998927e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999762e-01 9.99998331e-01 9.99995232e-01\n",
      " 9.99998808e-01 9.99999166e-01 9.99997377e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 39 [0/44 (0%)]\tTrain Loss: 0.000998\n",
      "Train Epoch: 39 [8/44 (18%)]\tTrain Loss: 0.000199\n",
      "Train Epoch: 39 [16/44 (36%)]\tTrain Loss: 0.000367\n",
      "Train Epoch: 39 [24/44 (55%)]\tTrain Loss: 0.005829\n",
      "Train Epoch: 39 [32/44 (73%)]\tTrain Loss: 0.018039\n",
      "Train Epoch: 39 [40/44 (91%)]\tTrain Loss: 0.003672\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.00864698 0.01944055 0.02742592 0.03917656 0.01287854 0.27263334\n",
      " 0.00831558 0.01087517 0.00437102 0.01272258 0.00477226 0.01232946\n",
      " 0.00398495 0.00586311 0.03019122 0.02834921 0.2462045  0.02062777\n",
      " 0.03315268 0.00869028 0.02941651 0.01120179 0.19373025 0.03482189\n",
      " 0.04655925 0.08566305 0.02010828 0.21993348 0.02040851 0.02343666\n",
      " 0.00573811 0.00148202 0.99999964 0.99999964 0.99999976 0.99998748\n",
      " 0.99999905 0.99999869 0.99999928 0.99999952 0.99999976 0.99998105\n",
      " 0.99997783 0.99999678 0.99999321 0.99999475 0.99999917 0.99999952\n",
      " 0.9999975  1.         0.99999595 0.99999964 0.99999869 0.99999988\n",
      " 0.99999881 0.99999523 0.99999964 0.99999952 0.99999964 0.99999976\n",
      " 0.99999809 0.99999988 0.99999499 0.99999964 0.99999976 0.99999976\n",
      " 0.99999952 0.99999964 0.99999797 0.99999678 0.99999881 0.99999988\n",
      " 0.99999928 0.99999428 0.99999833 0.99999952 0.99999988 0.99999964\n",
      " 0.99999952 0.99999928 0.99999988 0.99999893 1.         0.99999928\n",
      " 0.99999809 0.99996936 0.99999964 0.99999905 0.99999917 0.99999976\n",
      " 0.99999952 1.         0.99999964 0.99999952 0.99999881 0.9999969\n",
      " 0.99999869 0.99999762 0.99999833]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 40 [0/44 (0%)]\tTrain Loss: 0.002060\n",
      "Train Epoch: 40 [8/44 (18%)]\tTrain Loss: 0.001979\n",
      "Train Epoch: 40 [16/44 (36%)]\tTrain Loss: 0.000216\n",
      "Train Epoch: 40 [24/44 (55%)]\tTrain Loss: 0.003877\n",
      "Train Epoch: 40 [32/44 (73%)]\tTrain Loss: 0.009477\n",
      "Train Epoch: 40 [40/44 (91%)]\tTrain Loss: 0.001247\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [5.13604516e-03 6.57608872e-03 1.25162750e-02 5.27330525e-02\n",
      " 1.29637579e-02 2.86960512e-01 2.11816002e-03 2.33244449e-02\n",
      " 1.47605117e-03 2.48393733e-02 2.59943446e-03 7.44146248e-03\n",
      " 4.00495669e-03 1.80024712e-03 3.11678983e-02 1.83460843e-02\n",
      " 2.29727909e-01 2.63949092e-02 3.31704691e-02 4.74213576e-03\n",
      " 2.19917987e-02 5.11883851e-03 2.03930318e-01 2.33621784e-02\n",
      " 1.02320254e-01 1.42379493e-01 3.66459265e-02 1.49850905e-01\n",
      " 1.51598267e-02 1.40047651e-02 2.52791587e-03 7.92882871e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999642e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999762e-01 9.99999762e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999642e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "TP= 67 TN= 32 FN= 0 FP= 0\n",
      "TP+FP 67\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUCp 1.0\n",
      "AUC 1.0\n",
      "\n",
      " The epoch is 40, average recall: 1.0000, average precision: 1.0000,average F1: 1.0000, average accuracy: 1.0000, average AUC: 1.0000\n",
      "Train Epoch: 41 [0/44 (0%)]\tTrain Loss: 0.012033\n",
      "Train Epoch: 41 [8/44 (18%)]\tTrain Loss: 0.002178\n",
      "Train Epoch: 41 [16/44 (36%)]\tTrain Loss: 0.003152\n",
      "Train Epoch: 41 [24/44 (55%)]\tTrain Loss: 0.000123\n",
      "Train Epoch: 41 [32/44 (73%)]\tTrain Loss: 0.001462\n",
      "Train Epoch: 41 [40/44 (91%)]\tTrain Loss: 0.000115\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.02437836 0.0477776  0.04939763 0.05890796 0.04627812 0.23725754\n",
      " 0.01595879 0.02728185 0.00971054 0.05795148 0.01203689 0.01622305\n",
      " 0.01205187 0.01802638 0.04763067 0.03473694 0.18236183 0.05033496\n",
      " 0.05405086 0.01891647 0.04154702 0.02692281 0.17037313 0.04232237\n",
      " 0.05589656 0.08973236 0.02478855 0.16930549 0.03114787 0.04241423\n",
      " 0.01925162 0.00628808 0.99999952 0.99999928 0.99999976 0.99999666\n",
      " 0.99999833 0.99999845 0.99999928 0.99999928 0.99999976 0.99997258\n",
      " 0.99997199 0.99999869 0.99999523 0.99998891 0.99999785 0.99999976\n",
      " 0.99999762 1.         0.99999511 0.99999976 0.99999857 0.99999988\n",
      " 0.99999845 0.99998641 0.99999988 0.99999964 0.99999928 0.99999976\n",
      " 0.99999774 0.99999988 0.99999499 0.99999988 0.9999994  0.99999976\n",
      " 0.99999952 0.99999928 0.99999762 0.99999607 0.99999809 0.99999952\n",
      " 0.99999928 0.99999821 0.99999893 0.99999785 0.99999976 0.99999976\n",
      " 0.99999917 0.99999976 0.99999988 0.99999666 1.         0.99999976\n",
      " 0.9999963  0.99996901 0.99999976 0.99999952 0.99999869 0.99999988\n",
      " 0.99999952 1.         1.         0.99999952 0.9999975  0.99999249\n",
      " 0.99999809 0.99999869 0.99999583]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 42 [0/44 (0%)]\tTrain Loss: 0.000415\n",
      "Train Epoch: 42 [8/44 (18%)]\tTrain Loss: 0.001523\n",
      "Train Epoch: 42 [16/44 (36%)]\tTrain Loss: 0.014507\n",
      "Train Epoch: 42 [24/44 (55%)]\tTrain Loss: 0.002559\n",
      "Train Epoch: 42 [32/44 (73%)]\tTrain Loss: 0.000059\n",
      "Train Epoch: 42 [40/44 (91%)]\tTrain Loss: 0.000053\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [8.55249295e-04 1.07272957e-02 5.37824864e-03 2.03178320e-02\n",
      " 8.27004481e-03 4.54839885e-01 1.44612661e-03 4.19215951e-03\n",
      " 5.89435454e-04 7.56843248e-03 4.54097288e-04 1.69513409e-03\n",
      " 7.68863072e-04 8.73854966e-04 1.75582822e-02 6.97930064e-03\n",
      " 9.44094136e-02 1.83278788e-02 1.29411593e-02 4.64591285e-04\n",
      " 7.90917687e-03 1.65955373e-03 2.47349858e-01 3.00974809e-02\n",
      " 4.58119810e-02 8.55051205e-02 1.10927140e-02 2.63683945e-01\n",
      " 9.05092247e-03 3.59846000e-03 7.82055955e-04 7.41561089e-05\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99998331e-01 9.99999285e-01 1.00000000e+00\n",
      " 9.99999881e-01 9.99999404e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999166e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 9.99999642e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 9.99999881e-01 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 9.99999881e-01 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99999881e-01 9.99998689e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 9.99999523e-01\n",
      " 9.99999762e-01 9.99999881e-01 9.99999642e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 43 [0/44 (0%)]\tTrain Loss: 0.006286\n",
      "Train Epoch: 43 [8/44 (18%)]\tTrain Loss: 0.000359\n",
      "Train Epoch: 43 [16/44 (36%)]\tTrain Loss: 0.000341\n",
      "Train Epoch: 43 [24/44 (55%)]\tTrain Loss: 0.001485\n",
      "Train Epoch: 43 [32/44 (73%)]\tTrain Loss: 0.004382\n",
      "Train Epoch: 43 [40/44 (91%)]\tTrain Loss: 0.072995\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.03907110e-02 2.12053377e-02 3.32825072e-02 5.93767986e-02\n",
      " 9.03822388e-03 1.39215305e-01 9.67481174e-03 8.51691328e-03\n",
      " 4.23706195e-04 1.96049688e-03 2.69231037e-03 1.06600216e-02\n",
      " 6.16544508e-04 2.83574197e-03 4.10369895e-02 3.05938274e-02\n",
      " 4.41280566e-02 4.14228067e-03 1.56976152e-02 6.34341361e-03\n",
      " 3.22855674e-02 1.79059524e-02 1.87582552e-01 4.57493812e-02\n",
      " 4.06383947e-02 1.09792992e-01 3.09896143e-03 3.49161774e-01\n",
      " 2.77873445e-02 1.44445999e-02 1.65090282e-02 4.67938557e-03\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44 [0/44 (0%)]\tTrain Loss: 0.009491\n",
      "Train Epoch: 44 [8/44 (18%)]\tTrain Loss: 0.008130\n",
      "Train Epoch: 44 [16/44 (36%)]\tTrain Loss: 0.002524\n",
      "Train Epoch: 44 [24/44 (55%)]\tTrain Loss: 0.009622\n",
      "Train Epoch: 44 [32/44 (73%)]\tTrain Loss: 0.001388\n",
      "Train Epoch: 44 [40/44 (91%)]\tTrain Loss: 0.017280\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.02063958 0.06237722 0.05885167 0.10215986 0.02491964 0.36511797\n",
      " 0.02675272 0.0272041  0.00889745 0.0200724  0.00945283 0.0260847\n",
      " 0.01005862 0.02800076 0.0566326  0.03819266 0.28918806 0.05396331\n",
      " 0.07268356 0.02595504 0.03685605 0.0239176  0.32398641 0.06996258\n",
      " 0.08022527 0.10427203 0.07942671 0.23034553 0.07780302 0.05539207\n",
      " 0.0172423  0.00494159 0.99997103 0.99992955 0.99999189 0.99978727\n",
      " 0.99998748 0.9999752  0.99998903 0.99999189 0.99999785 0.99980372\n",
      " 0.99922156 0.99996293 0.99992001 0.99983764 0.99999273 0.99999201\n",
      " 0.99999058 0.99999988 0.99997425 0.99999774 0.99997842 0.99999571\n",
      " 0.9999851  0.99985683 0.99998331 0.99999154 0.99999118 0.99999046\n",
      " 0.9999783  0.99999201 0.99986899 0.99999225 0.99999499 0.99998796\n",
      " 0.99998617 0.99998319 0.99985147 0.99996352 0.99997675 0.99999046\n",
      " 0.99998689 0.99998891 0.99991477 0.99997699 0.99998736 0.99999273\n",
      " 0.99999511 0.99996305 0.99999785 0.99997497 1.         0.99999726\n",
      " 0.99991715 0.99985349 0.99999404 0.99999046 0.99997401 0.99999499\n",
      " 0.99995971 1.         0.99999583 0.99999154 0.99997151 0.99994254\n",
      " 0.99997473 0.99999595 0.99994636]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 45 [0/44 (0%)]\tTrain Loss: 0.001601\n",
      "Train Epoch: 45 [8/44 (18%)]\tTrain Loss: 0.005944\n",
      "Train Epoch: 45 [16/44 (36%)]\tTrain Loss: 0.002718\n",
      "Train Epoch: 45 [24/44 (55%)]\tTrain Loss: 0.001164\n",
      "Train Epoch: 45 [32/44 (73%)]\tTrain Loss: 0.002777\n",
      "Train Epoch: 45 [40/44 (91%)]\tTrain Loss: 0.000968\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [9.86906089e-05 2.09197705e-03 1.18851883e-03 1.10112503e-02\n",
      " 3.20752035e-04 3.20677072e-01 3.61533457e-05 3.69796675e-04\n",
      " 2.08172660e-05 5.44680282e-04 2.43675149e-05 2.56436877e-04\n",
      " 2.66789611e-05 7.67749007e-05 1.00099603e-02 1.12185930e-03\n",
      " 1.69536367e-01 1.14756159e-03 2.27452489e-03 8.61942463e-05\n",
      " 1.44896726e-03 2.75623403e-04 2.42229939e-01 4.53570066e-03\n",
      " 6.71000965e-03 2.82426775e-02 3.11930291e-03 3.08386147e-01\n",
      " 8.07326636e-04 5.86154172e-04 1.52053617e-04 4.18161608e-06\n",
      " 9.99974489e-01 9.99951005e-01 9.99995708e-01 9.99925494e-01\n",
      " 9.99984860e-01 9.99975562e-01 9.99986291e-01 9.99975085e-01\n",
      " 9.99999166e-01 9.99718726e-01 9.99818027e-01 9.99946237e-01\n",
      " 9.99679685e-01 9.99821723e-01 9.99976993e-01 9.99951482e-01\n",
      " 9.99991417e-01 9.99999404e-01 9.99969959e-01 9.99983191e-01\n",
      " 9.99857068e-01 9.99995351e-01 9.99972105e-01 9.99867558e-01\n",
      " 9.99980211e-01 9.99989867e-01 9.99982834e-01 9.99992013e-01\n",
      " 9.99962330e-01 9.99993563e-01 9.99860525e-01 9.99989390e-01\n",
      " 9.99996185e-01 9.99946833e-01 9.99962568e-01 9.99983430e-01\n",
      " 9.99891281e-01 9.99941111e-01 9.99892354e-01 9.99950528e-01\n",
      " 9.99982715e-01 9.99957442e-01 9.99982357e-01 9.99976039e-01\n",
      " 9.99988914e-01 9.99994516e-01 9.99996543e-01 9.99971509e-01\n",
      " 9.99995232e-01 9.99987960e-01 9.99999762e-01 9.99988556e-01\n",
      " 9.99767125e-01 9.99241471e-01 9.99996424e-01 9.99975443e-01\n",
      " 9.99950409e-01 9.99981165e-01 9.99987841e-01 9.99998808e-01\n",
      " 9.99984622e-01 9.99962807e-01 9.99982953e-01 9.99901533e-01\n",
      " 9.99926686e-01 9.99978304e-01 9.99963164e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 46 [0/44 (0%)]\tTrain Loss: 0.000925\n",
      "Train Epoch: 46 [8/44 (18%)]\tTrain Loss: 0.002264\n",
      "Train Epoch: 46 [16/44 (36%)]\tTrain Loss: 0.006887\n",
      "Train Epoch: 46 [24/44 (55%)]\tTrain Loss: 0.000951\n",
      "Train Epoch: 46 [32/44 (73%)]\tTrain Loss: 0.000191\n",
      "Train Epoch: 46 [40/44 (91%)]\tTrain Loss: 0.012458\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [8.34042803e-05 3.43810272e-04 5.92780765e-04 3.01315077e-03\n",
      " 2.82890716e-04 8.22970793e-02 6.15967147e-05 1.58915238e-04\n",
      " 8.74632042e-06 1.59461371e-04 1.93461874e-05 1.04831881e-04\n",
      " 1.67922626e-05 1.74099332e-05 1.68774254e-03 5.83481451e-04\n",
      " 2.03451496e-02 4.37862065e-04 5.07331104e-04 7.83215146e-05\n",
      " 6.42387546e-04 1.48779596e-04 3.95682231e-02 1.13639084e-03\n",
      " 1.42121420e-03 6.56466326e-03 1.31252629e-03 3.61080654e-02\n",
      " 6.69886824e-04 4.63640783e-04 7.45290017e-05 4.10787197e-06\n",
      " 1.00000000e+00 9.99999762e-01 1.00000000e+00 9.99999404e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 9.99998450e-01 9.99999523e-01 9.99999762e-01\n",
      " 9.99999285e-01 9.99999285e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99999762e-01 1.00000000e+00 9.99999881e-01 9.99999166e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999762e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99999166e-01 9.99999642e-01 9.99999762e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99999404e-01 9.99997497e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 9.99999046e-01\n",
      " 9.99999762e-01 1.00000000e+00 9.99999762e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 47 [0/44 (0%)]\tTrain Loss: 0.005199\n",
      "Train Epoch: 47 [8/44 (18%)]\tTrain Loss: 0.074598\n",
      "Train Epoch: 47 [16/44 (36%)]\tTrain Loss: 0.003405\n",
      "Train Epoch: 47 [24/44 (55%)]\tTrain Loss: 0.040425\n",
      "Train Epoch: 47 [32/44 (73%)]\tTrain Loss: 0.041552\n",
      "Train Epoch: 47 [40/44 (91%)]\tTrain Loss: 0.000201\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [9.08148650e-05 4.90643142e-04 8.00227339e-04 6.00508647e-03\n",
      " 1.05377105e-04 1.19815385e-02 3.44496875e-05 1.01891834e-04\n",
      " 5.14740168e-06 4.62265125e-05 2.11977385e-05 1.70953455e-04\n",
      " 3.68705623e-05 1.02956416e-04 1.09046535e-03 1.82718359e-04\n",
      " 1.39790238e-03 3.93302878e-04 1.13027007e-03 1.54837020e-04\n",
      " 1.74869364e-03 1.23174721e-03 8.48722160e-02 1.21672535e-02\n",
      " 4.51724231e-03 1.04680182e-02 2.87732226e-04 1.77345295e-02\n",
      " 2.37492350e-04 2.98189232e-04 1.33001464e-04 2.34426589e-05\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999642e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999404e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999285e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 9.99999285e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 48 [0/44 (0%)]\tTrain Loss: 0.004577\n",
      "Train Epoch: 48 [8/44 (18%)]\tTrain Loss: 0.000120\n",
      "Train Epoch: 48 [16/44 (36%)]\tTrain Loss: 0.008325\n",
      "Train Epoch: 48 [24/44 (55%)]\tTrain Loss: 0.002564\n",
      "Train Epoch: 48 [32/44 (73%)]\tTrain Loss: 0.001680\n",
      "Train Epoch: 48 [40/44 (91%)]\tTrain Loss: 0.007527\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [5.50421840e-03 2.60339249e-02 2.25432590e-02 3.09252858e-01\n",
      " 3.11240125e-02 8.38993132e-01 3.76867061e-03 3.70924957e-02\n",
      " 1.38101727e-03 3.88273746e-02 2.03590002e-03 8.35373532e-03\n",
      " 2.43758247e-03 3.35576176e-03 1.49815544e-01 5.11916317e-02\n",
      " 2.49937654e-01 1.06617987e-01 9.34075639e-02 7.50258425e-03\n",
      " 5.41403629e-02 1.11061540e-02 7.34025657e-01 1.57788843e-01\n",
      " 2.23229706e-01 2.22825721e-01 1.07257880e-01 6.28970802e-01\n",
      " 4.33604196e-02 2.25559250e-02 4.33754409e-03 5.85835311e-04\n",
      " 9.99999881e-01 9.99999762e-01 9.99999881e-01 9.99999642e-01\n",
      " 9.99999881e-01 1.00000000e+00 9.99999881e-01 9.99999881e-01\n",
      " 1.00000000e+00 9.99998808e-01 9.99999523e-01 9.99999523e-01\n",
      " 9.99998808e-01 9.99999285e-01 9.99999881e-01 9.99999881e-01\n",
      " 9.99999881e-01 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 9.99999642e-01 1.00000000e+00 9.99999762e-01 9.99995828e-01\n",
      " 9.99999881e-01 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 9.99999762e-01 1.00000000e+00 9.99999762e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999523e-01 9.99999762e-01\n",
      " 9.99999642e-01 9.99997973e-01 9.99999642e-01 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 9.99999642e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999762e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99998808e-01 9.99995589e-01 1.00000000e+00 9.99999881e-01\n",
      " 9.99999762e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 9.99999762e-01 9.99997735e-01\n",
      " 9.99999523e-01 9.99999881e-01 9.99998808e-01]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 49 [0/44 (0%)]\tTrain Loss: 0.001067\n",
      "Train Epoch: 49 [8/44 (18%)]\tTrain Loss: 0.002168\n",
      "Train Epoch: 49 [16/44 (36%)]\tTrain Loss: 0.000151\n",
      "Train Epoch: 49 [24/44 (55%)]\tTrain Loss: 0.001650\n",
      "Train Epoch: 49 [32/44 (73%)]\tTrain Loss: 0.000742\n",
      "Train Epoch: 49 [40/44 (91%)]\tTrain Loss: 0.000552\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [3.10899370e-04 2.79977545e-03 2.28101411e-03 1.32934004e-02\n",
      " 6.00886182e-04 1.84833318e-01 6.72666210e-05 2.97216553e-04\n",
      " 5.40302462e-05 1.91227708e-04 5.88146831e-05 3.47884197e-04\n",
      " 1.29133885e-04 6.95503142e-04 2.06826627e-03 5.02799754e-04\n",
      " 2.85990369e-02 2.01511924e-04 2.81549408e-04 1.65071731e-04\n",
      " 2.36585154e-03 5.38956898e-04 3.14505816e-01 5.80588868e-03\n",
      " 7.52736209e-03 5.76674100e-03 9.90317858e-05 5.97873740e-02\n",
      " 3.48941918e-04 6.71496615e-04 2.65824463e-04 7.29365784e-05\n",
      " 9.99999881e-01 9.99999523e-01 9.99999881e-01 9.99997377e-01\n",
      " 9.99999881e-01 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99997020e-01 9.99962807e-01 9.99998689e-01\n",
      " 9.99998569e-01 9.99996662e-01 9.99999881e-01 1.00000000e+00\n",
      " 9.99998689e-01 1.00000000e+00 9.99999762e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999642e-01 9.99976873e-01\n",
      " 9.99999762e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99998093e-01 1.00000000e+00 9.99998212e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 9.99999762e-01\n",
      " 9.99998927e-01 9.99998093e-01 9.99999642e-01 9.99999881e-01\n",
      " 9.99999881e-01 1.00000000e+00 9.99999523e-01 9.99998927e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99998689e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99999404e-01 9.99973893e-01 9.99999762e-01 1.00000000e+00\n",
      " 9.99999285e-01 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999285e-01 9.99994636e-01\n",
      " 9.99999881e-01 1.00000000e+00 9.99990582e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 50 [0/44 (0%)]\tTrain Loss: 0.001619\n",
      "Train Epoch: 50 [8/44 (18%)]\tTrain Loss: 0.000053\n",
      "Train Epoch: 50 [16/44 (36%)]\tTrain Loss: 0.000221\n",
      "Train Epoch: 50 [24/44 (55%)]\tTrain Loss: 0.000321\n",
      "Train Epoch: 50 [32/44 (73%)]\tTrain Loss: 0.000530\n",
      "Train Epoch: 50 [40/44 (91%)]\tTrain Loss: 0.000454\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.43834918e-03 5.16874008e-02 1.88065302e-02 5.52343465e-02\n",
      " 5.88271348e-03 6.85223162e-01 1.32851116e-03 4.34634183e-03\n",
      " 1.29299599e-03 1.69575633e-03 3.43010470e-04 1.62848691e-03\n",
      " 8.96544952e-04 1.61856040e-02 1.82369091e-02 8.60621408e-03\n",
      " 1.33797541e-01 3.31946998e-03 5.53068612e-03 1.35624874e-03\n",
      " 7.37368083e-03 4.41657705e-03 3.32128555e-01 2.98463851e-02\n",
      " 3.04594114e-02 2.37328727e-02 1.00664760e-03 1.89372867e-01\n",
      " 5.49566885e-03 5.53419068e-03 2.96886475e-03 5.20654954e-04\n",
      " 9.99998331e-01 9.99997020e-01 9.99999285e-01 9.99970317e-01\n",
      " 9.99999046e-01 9.99999404e-01 9.99998569e-01 9.99996185e-01\n",
      " 9.99999881e-01 9.99961495e-01 9.99963522e-01 9.99990225e-01\n",
      " 9.99943614e-01 9.99938250e-01 9.99990702e-01 9.99998808e-01\n",
      " 9.99994040e-01 1.00000000e+00 9.99994993e-01 9.99999285e-01\n",
      " 9.99992609e-01 1.00000000e+00 9.99996185e-01 9.99855280e-01\n",
      " 9.99998808e-01 9.99999642e-01 9.99995589e-01 1.00000000e+00\n",
      " 9.99992013e-01 9.99999881e-01 9.99993443e-01 9.99999762e-01\n",
      " 9.99999523e-01 9.99999285e-01 9.99991775e-01 9.99994159e-01\n",
      " 9.99993324e-01 9.99954939e-01 9.99986649e-01 9.99998569e-01\n",
      " 9.99999285e-01 9.99997973e-01 9.99998212e-01 9.99993801e-01\n",
      " 1.00000000e+00 9.99999642e-01 9.99999762e-01 9.99999404e-01\n",
      " 9.99999881e-01 9.99990821e-01 1.00000000e+00 9.99998569e-01\n",
      " 9.99985337e-01 9.99854565e-01 9.99998093e-01 9.99996781e-01\n",
      " 9.99996066e-01 9.99999881e-01 9.99999523e-01 1.00000000e+00\n",
      " 9.99999762e-01 9.99995112e-01 9.99996305e-01 9.99976754e-01\n",
      " 9.99989390e-01 9.99997497e-01 9.99941349e-01]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "TP= 67 TN= 32 FN= 0 FP= 0\n",
      "TP+FP 67\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUCp 1.0\n",
      "AUC 1.0\n",
      "\n",
      " The epoch is 50, average recall: 1.0000, average precision: 1.0000,average F1: 1.0000, average accuracy: 1.0000, average AUC: 1.0000\n",
      "Train Epoch: 51 [0/44 (0%)]\tTrain Loss: 0.016305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 51 [8/44 (18%)]\tTrain Loss: 0.000582\n",
      "Train Epoch: 51 [16/44 (36%)]\tTrain Loss: 0.065770\n",
      "Train Epoch: 51 [24/44 (55%)]\tTrain Loss: 0.005904\n",
      "Train Epoch: 51 [32/44 (73%)]\tTrain Loss: 0.037070\n",
      "Train Epoch: 51 [40/44 (91%)]\tTrain Loss: 0.003762\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [7.97890152e-06 2.42931783e-04 1.80086034e-04 1.42479036e-03\n",
      " 6.94462360e-05 2.82820135e-01 6.36506547e-06 1.47436913e-05\n",
      " 4.57620536e-06 2.01985549e-05 1.86124430e-06 1.58978528e-05\n",
      " 1.71574504e-06 2.49149998e-05 3.33898613e-04 4.11704896e-05\n",
      " 1.01628155e-02 5.35295476e-05 5.07379627e-05 3.45605145e-06\n",
      " 1.83550408e-04 1.39978365e-05 2.87501097e-01 9.59467085e-04\n",
      " 1.79682288e-03 8.71008262e-04 7.80115079e-05 3.55288535e-02\n",
      " 1.00003330e-04 6.22420412e-05 5.79690914e-06 1.92806525e-07\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 52 [0/44 (0%)]\tTrain Loss: 0.005680\n",
      "Train Epoch: 52 [8/44 (18%)]\tTrain Loss: 0.010949\n",
      "Train Epoch: 52 [16/44 (36%)]\tTrain Loss: 0.005969\n",
      "Train Epoch: 52 [24/44 (55%)]\tTrain Loss: 0.014825\n",
      "Train Epoch: 52 [32/44 (73%)]\tTrain Loss: 0.000339\n",
      "Train Epoch: 52 [40/44 (91%)]\tTrain Loss: 0.005358\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [8.46408831e-04 3.69134615e-03 1.33971097e-02 7.18274564e-02\n",
      " 3.22321034e-03 9.09786582e-01 6.89037377e-04 7.33701803e-04\n",
      " 2.01493080e-04 1.24710286e-03 1.94632099e-04 2.12910958e-03\n",
      " 1.97603411e-04 7.61163014e-04 2.00642105e-02 3.23973503e-03\n",
      " 1.31173491e-01 5.18008368e-03 6.12101424e-03 5.36310370e-04\n",
      " 1.43023413e-02 8.31830490e-04 8.30092371e-01 6.94243163e-02\n",
      " 9.02493447e-02 3.05480268e-02 3.97837767e-03 5.37792385e-01\n",
      " 5.41929901e-03 4.91068745e-03 6.73466478e-04 4.09080349e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99997377e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 9.99999642e-01\n",
      " 9.99999404e-01 9.99999523e-01 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99998689e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999762e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 53 [0/44 (0%)]\tTrain Loss: 0.010591\n",
      "Train Epoch: 53 [8/44 (18%)]\tTrain Loss: 0.000199\n",
      "Train Epoch: 53 [16/44 (36%)]\tTrain Loss: 0.012407\n",
      "Train Epoch: 53 [24/44 (55%)]\tTrain Loss: 0.006839\n",
      "Train Epoch: 53 [32/44 (73%)]\tTrain Loss: 0.000109\n",
      "Train Epoch: 53 [40/44 (91%)]\tTrain Loss: 0.000645\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.54226257e-06 9.73871211e-05 7.06823921e-05 5.12725208e-04\n",
      " 3.77044162e-05 2.17389047e-01 3.95967618e-06 7.83146461e-05\n",
      " 9.80170853e-07 3.13242635e-04 8.16892509e-07 1.29010414e-06\n",
      " 9.13805366e-07 1.40331576e-06 7.92731007e-04 1.54395326e-04\n",
      " 5.95913045e-02 8.74121906e-04 2.32466054e-03 4.07830527e-07\n",
      " 7.83596988e-05 7.80114442e-06 4.47281539e-01 1.26254349e-03\n",
      " 2.07634759e-03 1.79909077e-02 7.02476548e-03 3.60784829e-01\n",
      " 1.27260078e-04 5.43636052e-05 1.48393099e-06 1.57265028e-08\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 54 [0/44 (0%)]\tTrain Loss: 0.000624\n",
      "Train Epoch: 54 [8/44 (18%)]\tTrain Loss: 0.009981\n",
      "Train Epoch: 54 [16/44 (36%)]\tTrain Loss: 0.000394\n",
      "Train Epoch: 54 [24/44 (55%)]\tTrain Loss: 0.001823\n",
      "Train Epoch: 54 [32/44 (73%)]\tTrain Loss: 0.032362\n",
      "Train Epoch: 54 [40/44 (91%)]\tTrain Loss: 0.000479\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.08846605 0.17200667 0.25007644 0.41894567 0.25698289 0.70620954\n",
      " 0.15586826 0.147259   0.02228469 0.223015   0.07009623 0.12979311\n",
      " 0.09453347 0.06956912 0.37289941 0.24090819 0.30236578 0.28434899\n",
      " 0.29383355 0.08018059 0.20760591 0.09417996 0.63377488 0.33011267\n",
      " 0.43445471 0.43498644 0.26673514 0.57889378 0.2959604  0.33760333\n",
      " 0.14618044 0.03639838 1.         1.         1.         0.9999994\n",
      " 1.         1.         1.         1.         1.         0.99999988\n",
      " 1.         0.99999952 0.99999988 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99999964 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.99999988 0.99999702 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 55 [0/44 (0%)]\tTrain Loss: 0.004667\n",
      "Train Epoch: 55 [8/44 (18%)]\tTrain Loss: 0.014617\n",
      "Train Epoch: 55 [16/44 (36%)]\tTrain Loss: 0.028877\n",
      "Train Epoch: 55 [24/44 (55%)]\tTrain Loss: 0.008324\n",
      "Train Epoch: 55 [32/44 (73%)]\tTrain Loss: 0.012194\n",
      "Train Epoch: 55 [40/44 (91%)]\tTrain Loss: 0.001040\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.03635582e-04 2.43292248e-04 4.31883661e-03 2.30501108e-02\n",
      " 1.50886539e-03 8.20477486e-01 1.92657433e-04 9.33413918e-04\n",
      " 3.99063611e-05 1.38946518e-03 6.14828095e-05 2.22918810e-03\n",
      " 7.86652308e-05 2.45686515e-05 5.98274544e-03 1.94325717e-03\n",
      " 3.64313364e-01 4.01586248e-03 1.35623589e-02 3.69166846e-05\n",
      " 3.73765873e-03 5.48824173e-05 6.48531795e-01 1.65809039e-02\n",
      " 4.15149033e-02 1.97875798e-01 4.31741923e-02 6.36420846e-01\n",
      " 3.45735275e-03 1.25552621e-02 8.79004219e-05 1.11894281e-06\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 56 [0/44 (0%)]\tTrain Loss: 0.000028\n",
      "Train Epoch: 56 [8/44 (18%)]\tTrain Loss: 0.002024\n",
      "Train Epoch: 56 [16/44 (36%)]\tTrain Loss: 0.000221\n",
      "Train Epoch: 56 [24/44 (55%)]\tTrain Loss: 0.000355\n",
      "Train Epoch: 56 [32/44 (73%)]\tTrain Loss: 0.002905\n",
      "Train Epoch: 56 [40/44 (91%)]\tTrain Loss: 0.000438\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.96842052e-06 5.61742527e-05 1.96250927e-04 2.71904096e-03\n",
      " 1.53010787e-05 4.13440615e-01 6.65062817e-06 1.70012811e-06\n",
      " 9.58394367e-07 2.08999199e-06 9.48861896e-08 9.51244729e-05\n",
      " 1.61830224e-06 5.86311626e-06 2.83188652e-04 2.50520188e-05\n",
      " 3.60502605e-03 3.15359030e-05 9.48830493e-05 1.06163918e-06\n",
      " 2.27876590e-04 3.15902776e-06 1.37791082e-01 1.86869293e-04\n",
      " 6.09473651e-03 3.22260521e-03 5.75560080e-06 5.45929074e-02\n",
      " 9.74044888e-05 5.96346654e-05 4.28371677e-05 3.32605481e-07\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999166e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999285e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999642e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999762e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 57 [0/44 (0%)]\tTrain Loss: 0.000116\n",
      "Train Epoch: 57 [8/44 (18%)]\tTrain Loss: 0.000160\n",
      "Train Epoch: 57 [16/44 (36%)]\tTrain Loss: 0.000516\n",
      "Train Epoch: 57 [24/44 (55%)]\tTrain Loss: 0.006342\n",
      "Train Epoch: 57 [32/44 (73%)]\tTrain Loss: 0.000112\n",
      "Train Epoch: 57 [40/44 (91%)]\tTrain Loss: 0.000563\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.08483798e-05 1.32793139e-04 3.98293225e-04 2.57497467e-03\n",
      " 7.87428362e-05 3.22765298e-02 6.72857414e-06 1.19383672e-04\n",
      " 4.12629834e-06 4.36707305e-05 3.11227086e-06 4.98072113e-05\n",
      " 5.58432703e-06 6.97991300e-06 6.03552849e-04 3.81447142e-04\n",
      " 6.78792922e-03 3.70007474e-05 2.26316726e-04 1.85018016e-05\n",
      " 6.23511267e-04 6.16438410e-05 9.01766121e-02 1.74286903e-03\n",
      " 1.97547139e-03 7.79102743e-03 4.06055697e-05 1.22138210e-01\n",
      " 1.00778372e-04 6.14188757e-05 1.16060139e-04 5.81721679e-06\n",
      " 9.99977827e-01 9.99748051e-01 9.99969244e-01 9.81394053e-01\n",
      " 9.99938488e-01 9.99933362e-01 9.99916196e-01 9.99833584e-01\n",
      " 9.99983191e-01 9.98523772e-01 9.99802530e-01 9.94829714e-01\n",
      " 9.60892975e-01 9.95444775e-01 9.99836206e-01 9.96919274e-01\n",
      " 9.99991179e-01 9.99996901e-01 9.99716938e-01 9.98706102e-01\n",
      " 9.83743727e-01 9.99991894e-01 9.98173594e-01 9.98952270e-01\n",
      " 9.99992967e-01 9.99993920e-01 9.99946356e-01 9.99994993e-01\n",
      " 9.99949694e-01 9.99953985e-01 9.99499679e-01 9.99875069e-01\n",
      " 9.99958754e-01 9.99962926e-01 9.99122679e-01 9.99864221e-01\n",
      " 9.99767482e-01 9.97836769e-01 9.96317625e-01 9.98225152e-01\n",
      " 9.99982238e-01 9.98776138e-01 9.99950647e-01 9.99829888e-01\n",
      " 9.99995708e-01 9.99980927e-01 9.99968290e-01 9.99883413e-01\n",
      " 9.99899387e-01 9.99885321e-01 9.99998808e-01 9.99969482e-01\n",
      " 9.96965468e-01 9.13947523e-01 9.99990702e-01 9.98107791e-01\n",
      " 9.99980569e-01 9.99973774e-01 9.99993205e-01 9.99990940e-01\n",
      " 9.99524713e-01 9.92825508e-01 9.99838114e-01 9.98824656e-01\n",
      " 9.98063028e-01 9.98382092e-01 9.99753654e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 58 [0/44 (0%)]\tTrain Loss: 0.000087\n",
      "Train Epoch: 58 [8/44 (18%)]\tTrain Loss: 0.028212\n",
      "Train Epoch: 58 [16/44 (36%)]\tTrain Loss: 0.060700\n",
      "Train Epoch: 58 [24/44 (55%)]\tTrain Loss: 0.002184\n",
      "Train Epoch: 58 [32/44 (73%)]\tTrain Loss: 0.000129\n",
      "Train Epoch: 58 [40/44 (91%)]\tTrain Loss: 0.023095\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.05777918 0.0431914  0.1293398  0.23401254 0.08398244 0.67117935\n",
      " 0.02601443 0.08682269 0.00845905 0.11974662 0.02880932 0.10038524\n",
      " 0.02798208 0.0250704  0.09417383 0.09816249 0.42591849 0.15474889\n",
      " 0.25535434 0.03168381 0.18324636 0.07860658 0.74670094 0.2440742\n",
      " 0.28811607 0.44938451 0.16242382 0.76229084 0.08307811 0.09485378\n",
      " 0.07420365 0.02188157 0.99999976 0.99999952 1.         0.99999964\n",
      " 1.         1.         1.         1.         1.         0.99999952\n",
      " 0.99999988 1.         1.         0.99999976 1.         1.\n",
      " 1.         1.         1.         1.         0.99999988 1.\n",
      " 1.         0.99999952 1.         1.         1.         1.\n",
      " 1.         0.99999905 0.99999964 0.99999988 1.         0.99999905\n",
      " 0.99999988 0.99999952 0.99999988 1.         0.99999988 1.\n",
      " 0.99999952 1.         0.99999964 0.99999988 0.99999225 0.99999988\n",
      " 1.         0.9999994  1.         1.         0.99999988 1.\n",
      " 0.99999988 1.         1.         1.         0.99999988 0.99999833\n",
      " 1.         1.         1.         1.         1.         0.99999988\n",
      " 0.99999988 1.         1.        ]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 59 [0/44 (0%)]\tTrain Loss: 0.000827\n",
      "Train Epoch: 59 [8/44 (18%)]\tTrain Loss: 0.000214\n",
      "Train Epoch: 59 [16/44 (36%)]\tTrain Loss: 0.001646\n",
      "Train Epoch: 59 [24/44 (55%)]\tTrain Loss: 0.065860\n",
      "Train Epoch: 59 [32/44 (73%)]\tTrain Loss: 0.004547\n",
      "Train Epoch: 59 [40/44 (91%)]\tTrain Loss: 0.011318\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.01631093 0.03061437 0.0746165  0.25511715 0.04175022 0.56594932\n",
      " 0.00395855 0.06620882 0.00418827 0.04281865 0.00850532 0.045594\n",
      " 0.00774176 0.01400302 0.08089371 0.13097656 0.19862229 0.01526913\n",
      " 0.03969744 0.02706692 0.21568245 0.02284013 0.54964608 0.09997272\n",
      " 0.19845349 0.22933739 0.02080854 0.56060314 0.02913084 0.03236953\n",
      " 0.04318858 0.01046416 0.9999969  0.9999938  0.99999738 0.9998579\n",
      " 0.9999814  0.99997115 0.99999976 0.99996853 0.99999535 0.99987626\n",
      " 0.99995553 0.99977368 0.999524   0.99997759 0.99993825 0.99997747\n",
      " 0.99997735 0.99999845 0.9997254  0.99998653 0.99998128 0.99999845\n",
      " 0.99999094 0.99999118 0.99998844 0.99999857 0.99999297 0.99999833\n",
      " 0.99997139 0.99999797 0.99998808 0.99999416 0.99997413 0.99999368\n",
      " 0.99997878 0.99999034 0.99998713 0.99997163 0.99996018 0.99987578\n",
      " 0.99998915 0.99994588 0.9999938  0.99999309 0.99999893 0.99999571\n",
      " 0.99999142 0.9999975  0.99998164 0.99999392 0.99999988 0.99997294\n",
      " 0.99991214 0.99874866 0.99999809 0.99998116 0.99999404 0.99999905\n",
      " 0.99999928 0.99999499 0.99999881 0.99998009 0.99998987 0.99989045\n",
      " 0.99998903 0.99996328 0.99998128]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 60 [0/44 (0%)]\tTrain Loss: 0.021250\n",
      "Train Epoch: 60 [8/44 (18%)]\tTrain Loss: 0.000075\n",
      "Train Epoch: 60 [16/44 (36%)]\tTrain Loss: 0.000102\n",
      "Train Epoch: 60 [24/44 (55%)]\tTrain Loss: 0.000737\n",
      "Train Epoch: 60 [32/44 (73%)]\tTrain Loss: 0.001436\n",
      "Train Epoch: 60 [40/44 (91%)]\tTrain Loss: 0.001500\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.53795374e-03 1.84348109e-03 1.30666019e-02 3.00770905e-02\n",
      " 2.50820559e-03 2.16301203e-01 6.30325754e-04 2.80326651e-03\n",
      " 1.69346953e-04 1.86776067e-03 7.30883796e-04 2.69313646e-03\n",
      " 4.21767792e-04 6.27385045e-04 9.04841628e-03 1.00961095e-02\n",
      " 5.62799349e-02 1.35552499e-03 5.60668577e-03 3.78555106e-03\n",
      " 4.08860445e-02 3.00059444e-03 3.34456503e-01 2.10421514e-02\n",
      " 2.79283486e-02 3.97115797e-02 1.92139612e-03 2.38806933e-01\n",
      " 3.27577139e-03 3.59832472e-03 2.26361537e-03 6.58897392e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999642e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "TP= 67 TN= 32 FN= 0 FP= 0\n",
      "TP+FP 67\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUCp 1.0\n",
      "AUC 1.0\n",
      "\n",
      " The epoch is 60, average recall: 1.0000, average precision: 1.0000,average F1: 1.0000, average accuracy: 1.0000, average AUC: 1.0000\n",
      "Train Epoch: 61 [0/44 (0%)]\tTrain Loss: 0.001213\n",
      "Train Epoch: 61 [8/44 (18%)]\tTrain Loss: 0.000672\n",
      "Train Epoch: 61 [16/44 (36%)]\tTrain Loss: 0.001084\n",
      "Train Epoch: 61 [24/44 (55%)]\tTrain Loss: 0.001597\n",
      "Train Epoch: 61 [32/44 (73%)]\tTrain Loss: 0.003409\n",
      "Train Epoch: 61 [40/44 (91%)]\tTrain Loss: 0.000014\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [6.34420139e-04 3.64149601e-04 4.08410747e-03 9.06554237e-03\n",
      " 6.82676851e-04 5.27009778e-02 1.09420900e-04 7.83004856e-04\n",
      " 3.58586622e-05 1.18548248e-03 2.95215403e-04 7.23386242e-04\n",
      " 1.19091019e-04 1.27598949e-04 6.38901303e-03 2.44350755e-03\n",
      " 1.97784379e-02 5.03089570e-04 2.04584282e-03 1.47663895e-03\n",
      " 1.50647871e-02 1.75175280e-03 1.64180145e-01 7.26227602e-03\n",
      " 1.02056731e-02 1.60409659e-02 3.70911293e-04 1.47648200e-01\n",
      " 6.96786214e-04 9.74248920e-04 6.48148649e-04 1.78957140e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999762e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 62 [0/44 (0%)]\tTrain Loss: 0.000738\n",
      "Train Epoch: 62 [8/44 (18%)]\tTrain Loss: 0.006904\n",
      "Train Epoch: 62 [16/44 (36%)]\tTrain Loss: 0.000759\n",
      "Train Epoch: 62 [24/44 (55%)]\tTrain Loss: 0.000608\n",
      "Train Epoch: 62 [32/44 (73%)]\tTrain Loss: 0.000937\n",
      "Train Epoch: 62 [40/44 (91%)]\tTrain Loss: 0.004450\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.95143133e-04 2.70279881e-04 1.93624117e-03 6.50435593e-03\n",
      " 1.38881034e-03 4.12300289e-01 8.71775192e-05 2.35087750e-03\n",
      " 6.58851204e-05 4.07703640e-03 1.27557360e-04 4.99199668e-04\n",
      " 1.44315854e-04 2.99624699e-05 3.79511714e-03 4.40657185e-03\n",
      " 2.86904931e-01 1.78540580e-03 5.21265296e-03 1.95158573e-04\n",
      " 4.89579281e-03 3.45723849e-04 5.77808499e-01 8.24469887e-03\n",
      " 1.98501647e-02 8.38298798e-02 6.93638483e-03 4.82652396e-01\n",
      " 6.42864441e-04 8.40713503e-04 1.30536195e-04 7.87271983e-06\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 63 [0/44 (0%)]\tTrain Loss: 0.000331\n",
      "Train Epoch: 63 [8/44 (18%)]\tTrain Loss: 0.030083\n",
      "Train Epoch: 63 [16/44 (36%)]\tTrain Loss: 0.004368\n",
      "Train Epoch: 63 [24/44 (55%)]\tTrain Loss: 0.004100\n",
      "Train Epoch: 63 [32/44 (73%)]\tTrain Loss: 0.006894\n",
      "Train Epoch: 63 [40/44 (91%)]\tTrain Loss: 0.004748\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [5.49368677e-04 4.10169596e-04 4.33827331e-03 8.01573507e-03\n",
      " 1.57577323e-03 3.66250694e-01 2.55315390e-04 1.09114381e-03\n",
      " 5.88870207e-05 2.47339089e-03 2.03759497e-04 7.08670123e-04\n",
      " 1.43151847e-04 7.64790311e-05 1.28334602e-02 1.56035274e-03\n",
      " 6.22065291e-02 5.09846862e-03 5.44602191e-03 4.59312228e-04\n",
      " 7.85883702e-03 6.52092975e-04 5.22767067e-01 1.44561119e-02\n",
      " 1.69672463e-02 6.00197762e-02 3.23639996e-03 3.21558505e-01\n",
      " 1.13966106e-03 1.34834426e-03 4.06278850e-04 3.56678502e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 64 [0/44 (0%)]\tTrain Loss: 0.000187\n",
      "Train Epoch: 64 [8/44 (18%)]\tTrain Loss: 0.001101\n",
      "Train Epoch: 64 [16/44 (36%)]\tTrain Loss: 0.004674\n",
      "Train Epoch: 64 [24/44 (55%)]\tTrain Loss: 0.000153\n",
      "Train Epoch: 64 [32/44 (73%)]\tTrain Loss: 0.007041\n",
      "Train Epoch: 64 [40/44 (91%)]\tTrain Loss: 0.074617\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [5.70000475e-03 8.14816654e-02 4.40786965e-02 1.67607158e-01\n",
      " 8.69554356e-02 7.60679603e-01 4.19644732e-03 6.92779347e-02\n",
      " 5.78360679e-03 5.72753064e-02 5.83706563e-03 1.04063898e-02\n",
      " 7.32338196e-03 3.43553443e-03 1.52150944e-01 3.42840292e-02\n",
      " 4.40861166e-01 2.58349270e-01 2.37785190e-01 4.06417158e-03\n",
      " 2.70081051e-02 5.27501432e-03 6.84071362e-01 2.47683153e-01\n",
      " 4.50250298e-01 5.08975983e-01 2.89161325e-01 6.29721522e-01\n",
      " 5.82327135e-02 4.60637696e-02 7.99104851e-03 5.69818192e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 9.99989510e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99986053e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99996305e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999762e-01]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 65 [0/44 (0%)]\tTrain Loss: 0.003851\n",
      "Train Epoch: 65 [8/44 (18%)]\tTrain Loss: 0.041201\n",
      "Train Epoch: 65 [16/44 (36%)]\tTrain Loss: 0.000521\n",
      "Train Epoch: 65 [24/44 (55%)]\tTrain Loss: 0.002941\n",
      "Train Epoch: 65 [32/44 (73%)]\tTrain Loss: 0.030817\n",
      "Train Epoch: 65 [40/44 (91%)]\tTrain Loss: 0.008832\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.00805647 0.01415561 0.01789903 0.06876719 0.02144144 0.54720718\n",
      " 0.01000233 0.01819461 0.00433392 0.02495602 0.00855123 0.00724525\n",
      " 0.00320587 0.00365699 0.04454559 0.02674955 0.0978506  0.06083159\n",
      " 0.03342819 0.01603616 0.03394479 0.01029063 0.13058326 0.02839402\n",
      " 0.06878866 0.036454   0.02004687 0.10204505 0.03133215 0.03105799\n",
      " 0.0060077  0.00191086 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99999988 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 66 [0/44 (0%)]\tTrain Loss: 0.005157\n",
      "Train Epoch: 66 [8/44 (18%)]\tTrain Loss: 0.078270\n",
      "Train Epoch: 66 [16/44 (36%)]\tTrain Loss: 0.001307\n",
      "Train Epoch: 66 [24/44 (55%)]\tTrain Loss: 0.021346\n",
      "Train Epoch: 66 [32/44 (73%)]\tTrain Loss: 0.001173\n",
      "Train Epoch: 66 [40/44 (91%)]\tTrain Loss: 0.000047\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.61442469e-04 6.40528102e-04 7.89272424e-04 5.46463626e-03\n",
      " 5.65394468e-04 1.94104165e-01 4.60436451e-04 1.09926087e-03\n",
      " 7.44181452e-05 5.25182171e-04 1.03763727e-04 2.88690673e-04\n",
      " 5.09881465e-05 5.40928304e-05 3.97730665e-03 2.57387781e-03\n",
      " 7.77607551e-03 1.99556164e-03 2.15964532e-03 4.58607014e-04\n",
      " 1.30928517e-03 4.53314045e-04 2.63018161e-02 1.91603589e-03\n",
      " 3.17522301e-03 6.02015946e-03 1.01382646e-03 2.82891523e-02\n",
      " 1.24976947e-03 9.77393240e-04 2.86539755e-04 3.75139316e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999762e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 67 [0/44 (0%)]\tTrain Loss: 0.000554\n",
      "Train Epoch: 67 [8/44 (18%)]\tTrain Loss: 0.000230\n",
      "Train Epoch: 67 [16/44 (36%)]\tTrain Loss: 0.003202\n",
      "Train Epoch: 67 [24/44 (55%)]\tTrain Loss: 0.000809\n",
      "Train Epoch: 67 [32/44 (73%)]\tTrain Loss: 0.003721\n",
      "Train Epoch: 67 [40/44 (91%)]\tTrain Loss: 0.003361\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.00604612 0.01636391 0.01241063 0.12896968 0.01743162 0.67033297\n",
      " 0.0044928  0.03063312 0.00241983 0.01592043 0.00445704 0.00733521\n",
      " 0.00322647 0.00403155 0.09566764 0.04635328 0.05141795 0.03448329\n",
      " 0.02749726 0.01616745 0.04991844 0.00855451 0.19432718 0.04812473\n",
      " 0.11080917 0.06901156 0.01135483 0.25304762 0.01003921 0.01299145\n",
      " 0.00823669 0.00279838 0.99999964 1.         1.         0.99999595\n",
      " 1.         1.         1.         1.         1.         0.99999595\n",
      " 0.99999297 0.99999976 0.99999785 0.99999559 1.         1.\n",
      " 0.99999952 1.         0.99999988 1.         0.99999976 1.\n",
      " 0.99999988 0.99999881 1.         1.         1.         1.\n",
      " 0.99999964 1.         0.99999607 1.         1.         1.\n",
      " 0.99999988 1.         0.99999988 0.9999994  0.99999988 1.\n",
      " 0.99999988 0.99999988 0.99999952 0.99999988 1.         1.\n",
      " 1.         0.99999988 1.         0.99999988 1.         1.\n",
      " 0.99999952 0.99996376 0.99999988 0.99999988 0.99999988 1.\n",
      " 0.99999988 1.         1.         0.99999988 0.99999976 0.99999988\n",
      " 0.99999869 0.99999917 0.99999845]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 68 [0/44 (0%)]\tTrain Loss: 0.001730\n",
      "Train Epoch: 68 [8/44 (18%)]\tTrain Loss: 0.000403\n",
      "Train Epoch: 68 [16/44 (36%)]\tTrain Loss: 0.007057\n",
      "Train Epoch: 68 [24/44 (55%)]\tTrain Loss: 0.000042\n",
      "Train Epoch: 68 [32/44 (73%)]\tTrain Loss: 0.000757\n",
      "Train Epoch: 68 [40/44 (91%)]\tTrain Loss: 0.005805\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.80681259e-03 8.17346666e-03 9.32392944e-03 6.25054315e-02\n",
      " 5.00878738e-03 2.72843331e-01 6.19506114e-04 4.90033859e-03\n",
      " 4.63983859e-04 2.39179470e-03 7.52723834e-04 8.32290738e-04\n",
      " 1.99075861e-04 9.64241626e-04 4.11600918e-02 2.04554517e-02\n",
      " 1.15277786e-02 9.64964798e-04 2.49390770e-03 2.01310311e-03\n",
      " 1.89709459e-02 2.78284564e-03 6.84800372e-02 6.51737535e-03\n",
      " 2.08908580e-02 1.04292426e-02 3.93833441e-04 1.40483245e-01\n",
      " 4.98698512e-03 5.07232267e-03 4.90102964e-03 5.28091448e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99999642e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99990463e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 69 [0/44 (0%)]\tTrain Loss: 0.000581\n",
      "Train Epoch: 69 [8/44 (18%)]\tTrain Loss: 0.000499\n",
      "Train Epoch: 69 [16/44 (36%)]\tTrain Loss: 0.000358\n",
      "Train Epoch: 69 [24/44 (55%)]\tTrain Loss: 0.014585\n",
      "Train Epoch: 69 [32/44 (73%)]\tTrain Loss: 0.035813\n",
      "Train Epoch: 69 [40/44 (91%)]\tTrain Loss: 0.000818\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [5.65135153e-03 7.54031213e-03 1.16604771e-02 5.29930666e-02\n",
      " 8.24616104e-03 5.95969737e-01 7.99960643e-03 1.93556398e-02\n",
      " 1.84085441e-03 1.51930293e-02 3.62178171e-03 9.13287606e-03\n",
      " 2.43722857e-03 1.31781236e-03 5.15855215e-02 1.59622133e-02\n",
      " 1.19902350e-01 4.00138460e-02 4.41458002e-02 2.28852127e-02\n",
      " 3.42765227e-02 9.50700883e-03 2.72770345e-01 4.80113886e-02\n",
      " 8.27977881e-02 1.09726138e-01 1.42614460e-02 3.51772577e-01\n",
      " 7.94478320e-03 1.21376403e-02 2.22294149e-03 6.50975329e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 70 [0/44 (0%)]\tTrain Loss: 0.000511\n",
      "Train Epoch: 70 [8/44 (18%)]\tTrain Loss: 0.004894\n",
      "Train Epoch: 70 [16/44 (36%)]\tTrain Loss: 0.003783\n",
      "Train Epoch: 70 [24/44 (55%)]\tTrain Loss: 0.000040\n",
      "Train Epoch: 70 [32/44 (73%)]\tTrain Loss: 0.001369\n",
      "Train Epoch: 70 [40/44 (91%)]\tTrain Loss: 0.009137\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.08497469e-04 5.65889990e-04 5.08432917e-04 2.17708424e-02\n",
      " 8.65600246e-04 3.54560375e-01 8.35638202e-05 8.21576745e-04\n",
      " 4.35181173e-05 7.29802880e-04 6.47740526e-05 3.68726527e-04\n",
      " 8.91292730e-05 2.97733950e-05 1.97954830e-02 1.11549336e-03\n",
      " 3.74884717e-03 2.01966451e-03 3.08212824e-03 4.49082290e-04\n",
      " 1.99091062e-03 2.28072211e-04 9.42857713e-02 9.47732572e-03\n",
      " 1.81559436e-02 1.51388813e-02 1.02971459e-03 2.43214801e-01\n",
      " 2.11275299e-04 6.04087429e-04 5.62714558e-05 1.08770109e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "TP= 67 TN= 32 FN= 0 FP= 0\n",
      "TP+FP 67\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUCp 1.0\n",
      "AUC 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 70, average recall: 1.0000, average precision: 1.0000,average F1: 1.0000, average accuracy: 1.0000, average AUC: 1.0000\n",
      "Train Epoch: 71 [0/44 (0%)]\tTrain Loss: 0.000050\n",
      "Train Epoch: 71 [8/44 (18%)]\tTrain Loss: 0.000010\n",
      "Train Epoch: 71 [16/44 (36%)]\tTrain Loss: 0.000337\n",
      "Train Epoch: 71 [24/44 (55%)]\tTrain Loss: 0.000116\n",
      "Train Epoch: 71 [32/44 (73%)]\tTrain Loss: 0.004351\n",
      "Train Epoch: 71 [40/44 (91%)]\tTrain Loss: 0.001202\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.38970601e-04 1.33610808e-03 8.12053098e-04 2.90363673e-02\n",
      " 7.76711525e-03 2.56791532e-01 1.96916005e-03 1.80547778e-02\n",
      " 1.08537381e-04 2.71493755e-02 1.05928186e-04 8.48338241e-04\n",
      " 6.65645755e-04 3.75699614e-07 6.32584020e-02 2.26003323e-02\n",
      " 2.75060743e-01 6.34623244e-02 1.09122880e-01 4.55821064e-05\n",
      " 1.62709039e-03 4.33309004e-04 3.25937033e-01 3.45033444e-02\n",
      " 1.09537706e-01 1.44419983e-01 1.95704728e-01 2.40131691e-01\n",
      " 1.07559245e-02 4.09115991e-03 2.62076355e-04 3.56596865e-06\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99997497e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99999881e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 72 [0/44 (0%)]\tTrain Loss: 0.020964\n",
      "Train Epoch: 72 [8/44 (18%)]\tTrain Loss: 0.003797\n",
      "Train Epoch: 72 [16/44 (36%)]\tTrain Loss: 0.000721\n",
      "Train Epoch: 72 [24/44 (55%)]\tTrain Loss: 0.001567\n",
      "Train Epoch: 72 [32/44 (73%)]\tTrain Loss: 0.000273\n",
      "Train Epoch: 72 [40/44 (91%)]\tTrain Loss: 0.000169\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [9.68424196e-04 5.08208585e-04 2.37056403e-03 9.50625353e-03\n",
      " 1.77084503e-03 3.85199152e-02 1.73942314e-03 5.40827913e-03\n",
      " 3.28691764e-04 1.03734611e-02 4.45954705e-04 8.21395603e-04\n",
      " 1.99659247e-04 8.73818426e-05 3.59011889e-02 1.47634810e-02\n",
      " 8.99199769e-02 2.25075204e-02 3.80843021e-02 4.40336735e-04\n",
      " 1.41510484e-03 1.40284712e-03 4.00233090e-01 8.76401737e-03\n",
      " 2.66940333e-02 6.63619339e-02 5.73208630e-02 3.27529281e-01\n",
      " 6.07619807e-03 6.35451963e-03 6.49281312e-04 1.12700283e-04\n",
      " 9.99992728e-01 9.99992490e-01 9.99999642e-01 9.99996066e-01\n",
      " 9.99997497e-01 9.99997497e-01 9.99997616e-01 9.99995589e-01\n",
      " 9.99999881e-01 9.99911547e-01 9.99933958e-01 9.99997973e-01\n",
      " 9.99969244e-01 9.99981403e-01 9.99970436e-01 9.99999285e-01\n",
      " 9.99920845e-01 1.00000000e+00 9.99964356e-01 9.99995947e-01\n",
      " 9.99996185e-01 1.00000000e+00 9.99996066e-01 9.99828100e-01\n",
      " 9.99994397e-01 9.99998689e-01 9.99999762e-01 9.99999642e-01\n",
      " 9.99991179e-01 9.99999642e-01 9.99973774e-01 9.99999881e-01\n",
      " 9.99999523e-01 9.99999285e-01 9.99998093e-01 9.99999404e-01\n",
      " 9.99974370e-01 9.99977827e-01 9.99988437e-01 9.99999166e-01\n",
      " 9.99995828e-01 9.99999881e-01 9.99997377e-01 9.99971509e-01\n",
      " 9.99999523e-01 9.99999881e-01 9.99998927e-01 9.99996543e-01\n",
      " 9.99999642e-01 9.99983907e-01 1.00000000e+00 9.99998450e-01\n",
      " 9.99976277e-01 9.99734342e-01 9.99998927e-01 9.99996066e-01\n",
      " 9.99995589e-01 9.99999285e-01 9.99998689e-01 1.00000000e+00\n",
      " 9.99999881e-01 9.99995589e-01 9.99985456e-01 9.99878407e-01\n",
      " 9.99989271e-01 9.99996305e-01 9.99977946e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 73 [0/44 (0%)]\tTrain Loss: 0.000094\n",
      "Train Epoch: 73 [8/44 (18%)]\tTrain Loss: 0.000811\n",
      "Train Epoch: 73 [16/44 (36%)]\tTrain Loss: 0.000218\n",
      "Train Epoch: 73 [24/44 (55%)]\tTrain Loss: 0.001658\n",
      "Train Epoch: 73 [32/44 (73%)]\tTrain Loss: 0.017758\n",
      "Train Epoch: 73 [40/44 (91%)]\tTrain Loss: 0.013225\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.06635009 0.05995064 0.25177842 0.5068754  0.19866095 0.81383711\n",
      " 0.14770921 0.18999696 0.04566032 0.34519678 0.06102645 0.11332327\n",
      " 0.05287748 0.00102366 0.5268572  0.52166754 0.56784588 0.44299102\n",
      " 0.39190266 0.08501281 0.20521419 0.09659994 0.62674689 0.30829942\n",
      " 0.632406   0.54365408 0.49357533 0.69009668 0.38403642 0.3406285\n",
      " 0.09696811 0.0074512  1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "predict [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 74 [0/44 (0%)]\tTrain Loss: 0.000433\n",
      "Train Epoch: 74 [8/44 (18%)]\tTrain Loss: 0.021724\n",
      "Train Epoch: 74 [16/44 (36%)]\tTrain Loss: 0.011948\n",
      "Train Epoch: 74 [24/44 (55%)]\tTrain Loss: 0.010923\n",
      "Train Epoch: 74 [32/44 (73%)]\tTrain Loss: 0.000785\n",
      "Train Epoch: 74 [40/44 (91%)]\tTrain Loss: 0.000887\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.90126582e-03 7.17866933e-04 9.18573607e-03 1.83107127e-02\n",
      " 1.45374425e-03 3.74296904e-02 1.48727931e-03 2.54489365e-04\n",
      " 6.99031007e-05 8.63155292e-04 4.92629188e-04 2.13685841e-03\n",
      " 1.51251210e-04 1.80864357e-04 9.08924080e-03 2.32840353e-03\n",
      " 3.42964288e-03 1.10469712e-03 1.04756665e-03 3.75386584e-03\n",
      " 1.37213953e-02 2.19617225e-03 2.77769789e-02 1.12310760e-02\n",
      " 2.39719283e-02 7.14033749e-03 9.79742617e-04 1.96978506e-02\n",
      " 5.63322101e-03 4.74607851e-03 1.00710406e-03 4.07600513e-04\n",
      " 9.93202567e-01 9.95007157e-01 9.89008069e-01 9.90125895e-01\n",
      " 9.83210444e-01 9.84892964e-01 9.61957157e-01 9.94385958e-01\n",
      " 9.95927870e-01 9.78078187e-01 9.91922736e-01 9.59829211e-01\n",
      " 9.57120419e-01 9.92469966e-01 9.64416862e-01 9.84738588e-01\n",
      " 9.71938610e-01 9.96287107e-01 9.89576340e-01 9.87805605e-01\n",
      " 9.91835356e-01 9.92420733e-01 9.85544622e-01 9.87919152e-01\n",
      " 9.88586724e-01 9.93310094e-01 9.81852353e-01 9.92482960e-01\n",
      " 9.73947406e-01 9.95786011e-01 9.92223203e-01 9.95953798e-01\n",
      " 9.93079007e-01 9.97846484e-01 9.94076133e-01 9.95524883e-01\n",
      " 9.93079603e-01 9.82596040e-01 9.90392208e-01 9.70477760e-01\n",
      " 9.93601859e-01 9.84703243e-01 9.95731771e-01 9.88831639e-01\n",
      " 9.97702301e-01 9.96806145e-01 9.56070542e-01 9.97274458e-01\n",
      " 9.84038353e-01 9.90390301e-01 9.96133685e-01 9.81414497e-01\n",
      " 9.87816155e-01 9.50811446e-01 9.70325887e-01 9.83800054e-01\n",
      " 9.81161058e-01 9.97314870e-01 9.89259839e-01 9.93055999e-01\n",
      " 9.92944896e-01 9.93354678e-01 9.88241613e-01 9.52947617e-01\n",
      " 9.92412627e-01 9.76299465e-01 9.67952251e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 75 [0/44 (0%)]\tTrain Loss: 0.002013\n",
      "Train Epoch: 75 [8/44 (18%)]\tTrain Loss: 0.007563\n",
      "Train Epoch: 75 [16/44 (36%)]\tTrain Loss: 0.010127\n",
      "Train Epoch: 75 [24/44 (55%)]\tTrain Loss: 0.020312\n",
      "Train Epoch: 75 [32/44 (73%)]\tTrain Loss: 0.030162\n",
      "Train Epoch: 75 [40/44 (91%)]\tTrain Loss: 0.014565\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.71761674e-03 8.83278996e-03 1.16885798e-02 1.20482333e-02\n",
      " 7.91206490e-03 1.08800776e-01 9.04288143e-03 2.48025358e-03\n",
      " 1.23737089e-03 1.10735390e-02 9.52576578e-04 3.28525226e-03\n",
      " 4.57926420e-04 2.17315770e-04 1.69574991e-02 8.98483302e-03\n",
      " 9.15980339e-02 1.18256174e-02 1.20353168e-02 1.66562002e-03\n",
      " 1.18698822e-02 5.01473853e-03 1.40650257e-01 1.36271203e-02\n",
      " 3.97384726e-02 3.48489396e-02 1.90142281e-02 5.82732596e-02\n",
      " 2.29838360e-02 2.44143531e-02 2.55867443e-03 2.00844792e-04\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 76 [0/44 (0%)]\tTrain Loss: 0.012539\n",
      "Train Epoch: 76 [8/44 (18%)]\tTrain Loss: 0.001037\n",
      "Train Epoch: 76 [16/44 (36%)]\tTrain Loss: 0.000449\n",
      "Train Epoch: 76 [24/44 (55%)]\tTrain Loss: 0.000111\n",
      "Train Epoch: 76 [32/44 (73%)]\tTrain Loss: 0.000280\n",
      "Train Epoch: 76 [40/44 (91%)]\tTrain Loss: 0.000313\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [4.19710705e-04 2.05472880e-03 2.02212064e-03 2.32157041e-03\n",
      " 1.95104594e-03 2.25673653e-02 1.07818958e-03 7.49400002e-04\n",
      " 1.34218414e-03 4.69526881e-03 1.80670613e-04 6.55313022e-04\n",
      " 2.10233178e-04 1.89365892e-04 4.36172355e-03 1.54155842e-03\n",
      " 6.94667548e-02 4.28129686e-03 4.03558183e-03 1.52681110e-04\n",
      " 1.57242024e-03 4.06007253e-04 6.90625012e-02 1.79816107e-03\n",
      " 1.50183653e-02 7.73806404e-03 1.28614353e-02 1.79323852e-02\n",
      " 4.99386387e-03 8.07626266e-03 2.89206917e-04 1.83082720e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 77 [0/44 (0%)]\tTrain Loss: 0.002025\n",
      "Train Epoch: 77 [8/44 (18%)]\tTrain Loss: 0.010131\n",
      "Train Epoch: 77 [16/44 (36%)]\tTrain Loss: 0.016300\n",
      "Train Epoch: 77 [24/44 (55%)]\tTrain Loss: 0.038765\n",
      "Train Epoch: 77 [32/44 (73%)]\tTrain Loss: 0.001254\n",
      "Train Epoch: 77 [40/44 (91%)]\tTrain Loss: 0.002612\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.01045435 0.01206436 0.02537091 0.04802979 0.01176786 0.07921932\n",
      " 0.0088219  0.01030981 0.00549329 0.01002796 0.00529734 0.00808793\n",
      " 0.00259846 0.00333262 0.04421027 0.02640213 0.03721742 0.00963788\n",
      " 0.01386052 0.01308261 0.03443172 0.0237981  0.07329687 0.02913706\n",
      " 0.05895406 0.03200852 0.00961948 0.1381485  0.01275462 0.01663175\n",
      " 0.00963987 0.00399769 0.99999845 0.99999392 0.99999976 0.99998045\n",
      " 0.9999994  0.99998784 0.99969435 0.99999642 1.         0.99988139\n",
      " 0.99992108 0.99988067 0.99839056 0.99979764 0.9996537  0.999946\n",
      " 0.99880612 1.         0.99998033 0.99999762 0.99994147 1.\n",
      " 0.99996507 0.99991763 0.99999857 0.9999994  0.99984324 1.\n",
      " 0.99842441 0.99999988 0.99998128 0.99999988 0.99999964 0.99999177\n",
      " 0.99999332 0.99999082 0.99999237 0.99937975 0.99989629 0.99823111\n",
      " 0.99999964 0.99981445 0.99999714 0.9999944  1.         1.\n",
      " 0.99976784 0.99999976 0.99999928 0.99998903 1.         0.99991703\n",
      " 0.99978298 0.99718422 0.99981767 0.99997294 0.99996066 1.\n",
      " 1.         1.         0.99999893 0.99998689 0.99999583 0.99952507\n",
      " 0.99993694 0.99992013 0.99956638]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 78 [0/44 (0%)]\tTrain Loss: 0.010327\n",
      "Train Epoch: 78 [8/44 (18%)]\tTrain Loss: 0.000396\n",
      "Train Epoch: 78 [16/44 (36%)]\tTrain Loss: 0.000708\n",
      "Train Epoch: 78 [24/44 (55%)]\tTrain Loss: 0.000856\n",
      "Train Epoch: 78 [32/44 (73%)]\tTrain Loss: 0.001938\n",
      "Train Epoch: 78 [40/44 (91%)]\tTrain Loss: 0.013143\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.01682722 0.02714667 0.05209503 0.08415431 0.04005658 0.34941095\n",
      " 0.02752082 0.06541952 0.01174806 0.0861543  0.01204456 0.01133848\n",
      " 0.01168904 0.00322619 0.09937944 0.08482708 0.34091094 0.06288631\n",
      " 0.06891538 0.02019546 0.0337218  0.02864805 0.33972478 0.04840337\n",
      " 0.11032501 0.1176329  0.10061755 0.25890321 0.0589257  0.06770284\n",
      " 0.0173155  0.00268046 0.99999988 1.         1.         1.\n",
      " 0.99999988 0.99999988 0.99999225 1.         1.         0.99999142\n",
      " 1.         0.99999988 0.99999213 0.99999976 0.99999416 1.\n",
      " 0.99999869 1.         0.99999988 1.         0.99999976 1.\n",
      " 0.99999988 0.99999535 1.         1.         1.         1.\n",
      " 0.99999964 1.         0.99999952 1.         1.         1.\n",
      " 1.         1.         0.99999976 0.99999964 0.9999994  0.99999964\n",
      " 1.         1.         1.         0.9999994  1.         1.\n",
      " 0.99999845 1.         1.         1.         1.         0.9999994\n",
      " 0.99999905 0.99998045 0.9999994  1.         0.99999332 1.\n",
      " 1.         1.         1.         1.         0.99999964 0.99996698\n",
      " 0.99999988 0.99999952 0.9999938 ]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 79 [0/44 (0%)]\tTrain Loss: 0.000172\n",
      "Train Epoch: 79 [8/44 (18%)]\tTrain Loss: 0.022813\n",
      "Train Epoch: 79 [16/44 (36%)]\tTrain Loss: 0.001251\n",
      "Train Epoch: 79 [24/44 (55%)]\tTrain Loss: 0.000723\n",
      "Train Epoch: 79 [32/44 (73%)]\tTrain Loss: 0.000012\n",
      "Train Epoch: 79 [40/44 (91%)]\tTrain Loss: 0.000415\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [8.31734156e-04 5.44955628e-03 2.66499957e-03 3.63936499e-02\n",
      " 7.12145818e-03 1.32483259e-01 1.18786248e-03 1.64867379e-02\n",
      " 1.25275680e-03 1.56924222e-02 4.43845463e-04 8.21752590e-04\n",
      " 4.87904064e-04 3.98650096e-04 3.25319879e-02 2.04018746e-02\n",
      " 8.03008378e-02 1.22487033e-02 1.01588052e-02 8.51041579e-04\n",
      " 3.99292493e-03 1.63162593e-03 7.81031623e-02 8.03022087e-03\n",
      " 4.64394353e-02 2.48345658e-02 1.34931915e-02 1.23395361e-01\n",
      " 6.15747226e-03 5.80147887e-03 9.14999342e-04 4.19210883e-05\n",
      " 9.99996424e-01 9.99999285e-01 9.99999762e-01 9.99998212e-01\n",
      " 9.99995947e-01 9.99993801e-01 9.99668241e-01 9.99998689e-01\n",
      " 1.00000000e+00 9.99677777e-01 9.99997377e-01 9.99974966e-01\n",
      " 9.98787701e-01 9.99974489e-01 9.99564111e-01 9.99999046e-01\n",
      " 9.99561250e-01 1.00000000e+00 9.99988198e-01 9.99996185e-01\n",
      " 9.99979854e-01 1.00000000e+00 9.99982953e-01 9.99697685e-01\n",
      " 1.00000000e+00 9.99999881e-01 9.99984384e-01 1.00000000e+00\n",
      " 9.99835610e-01 1.00000000e+00 9.99981999e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999523e-01 9.99989748e-01 9.99991536e-01\n",
      " 9.99987125e-01 9.99932051e-01 9.99919176e-01 9.99950767e-01\n",
      " 9.99999881e-01 9.99993205e-01 1.00000000e+00 9.99983788e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99853253e-01 1.00000000e+00\n",
      " 9.99999523e-01 9.99997616e-01 1.00000000e+00 9.99963760e-01\n",
      " 9.99851823e-01 9.97458398e-01 9.99863148e-01 9.99992490e-01\n",
      " 9.99774158e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99997973e-01 9.99986410e-01 9.98242974e-01\n",
      " 9.99978662e-01 9.99927044e-01 9.99271095e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 80 [0/44 (0%)]\tTrain Loss: 0.003182\n",
      "Train Epoch: 80 [8/44 (18%)]\tTrain Loss: 0.003681\n",
      "Train Epoch: 80 [16/44 (36%)]\tTrain Loss: 0.003659\n",
      "Train Epoch: 80 [24/44 (55%)]\tTrain Loss: 0.003540\n",
      "Train Epoch: 80 [32/44 (73%)]\tTrain Loss: 0.000234\n",
      "Train Epoch: 80 [40/44 (91%)]\tTrain Loss: 0.009226\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.00777056 0.01549641 0.02628204 0.06314047 0.01788202 0.22366644\n",
      " 0.01055062 0.03924791 0.00480469 0.03264357 0.0040663  0.01327312\n",
      " 0.00544166 0.00162985 0.08826283 0.05117519 0.19487447 0.03541167\n",
      " 0.03545861 0.01377156 0.04277107 0.01420467 0.2505742  0.04005029\n",
      " 0.18152241 0.14584598 0.03137927 0.28486302 0.01694646 0.0221883\n",
      " 0.00745987 0.00108492 0.99999928 1.         1.         1.\n",
      " 1.         1.         0.99999571 1.         1.         0.99997747\n",
      " 1.         1.         0.99999392 0.99999917 0.99999893 1.\n",
      " 0.9999994  1.         1.         1.         0.99999976 1.\n",
      " 1.         0.99997592 1.         1.         1.         1.\n",
      " 0.99999976 1.         0.99999845 1.         1.         1.\n",
      " 0.99999988 0.99999964 0.99999988 0.99999988 0.99999857 1.\n",
      " 1.         0.99999988 1.         0.99999976 1.         1.\n",
      " 0.9999994  1.         1.         1.         1.         0.99999964\n",
      " 0.99999249 0.99994564 0.99999511 1.         0.99999571 1.\n",
      " 1.         1.         1.         1.         0.99999988 0.99993002\n",
      " 0.99999952 0.99999702 0.99996436]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "TP= 67 TN= 32 FN= 0 FP= 0\n",
      "TP+FP 67\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUCp 1.0\n",
      "AUC 1.0\n",
      "\n",
      " The epoch is 80, average recall: 1.0000, average precision: 1.0000,average F1: 1.0000, average accuracy: 1.0000, average AUC: 1.0000\n",
      "Train Epoch: 81 [0/44 (0%)]\tTrain Loss: 0.006134\n",
      "Train Epoch: 81 [8/44 (18%)]\tTrain Loss: 0.002087\n",
      "Train Epoch: 81 [16/44 (36%)]\tTrain Loss: 0.004561\n",
      "Train Epoch: 81 [24/44 (55%)]\tTrain Loss: 0.000374\n",
      "Train Epoch: 81 [32/44 (73%)]\tTrain Loss: 0.034213\n",
      "Train Epoch: 81 [40/44 (91%)]\tTrain Loss: 0.000928\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [8.07544403e-03 1.27599994e-02 2.15352271e-02 5.03811836e-02\n",
      " 1.32642547e-02 1.58046186e-01 1.42263500e-02 2.78160144e-02\n",
      " 4.17068601e-03 2.38065105e-02 3.46578262e-03 7.18800072e-03\n",
      " 3.38664837e-03 7.07779254e-04 7.18653947e-02 4.33161668e-02\n",
      " 1.43261015e-01 2.75855083e-02 2.85473932e-02 1.18632009e-02\n",
      " 2.76014265e-02 1.69802383e-02 1.63619921e-01 3.09948865e-02\n",
      " 9.31097940e-02 8.27967152e-02 2.26549953e-02 2.20027089e-01\n",
      " 2.95333974e-02 2.89122574e-02 1.13849137e-02 1.48469338e-03\n",
      " 9.99999404e-01 9.99998927e-01 9.99999762e-01 9.99999762e-01\n",
      " 9.99999762e-01 9.99999285e-01 9.99987483e-01 9.99999642e-01\n",
      " 1.00000000e+00 9.99981165e-01 1.00000000e+00 9.99996066e-01\n",
      " 9.99974132e-01 9.99994516e-01 9.99970794e-01 9.99999404e-01\n",
      " 9.99996066e-01 1.00000000e+00 9.99999642e-01 9.99998927e-01\n",
      " 9.99994040e-01 1.00000000e+00 9.99999166e-01 9.99989033e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999642e-01 1.00000000e+00\n",
      " 9.99995708e-01 1.00000000e+00 9.99998569e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999762e-01 9.99999404e-01 9.99999046e-01\n",
      " 9.99999285e-01 9.99989152e-01 9.99996901e-01 9.99981403e-01\n",
      " 1.00000000e+00 9.99997258e-01 1.00000000e+00 9.99999285e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99993205e-01 1.00000000e+00\n",
      " 9.99999762e-01 9.99999881e-01 1.00000000e+00 9.99989986e-01\n",
      " 9.99976516e-01 9.99828935e-01 9.99998569e-01 9.99999285e-01\n",
      " 9.99995828e-01 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 9.99998927e-01 9.99999642e-01 9.99939799e-01\n",
      " 9.99993920e-01 9.99987841e-01 9.99992967e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 82 [32/44 (73%)]\tTrain Loss: 0.000065\n",
      "Train Epoch: 82 [40/44 (91%)]\tTrain Loss: 0.053673\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [3.38391110e-04 7.33800465e-04 1.35171413e-03 3.82703496e-03\n",
      " 4.55926784e-04 4.55630347e-02 3.57381621e-04 1.52225490e-03\n",
      " 1.47174025e-04 8.76892416e-04 1.36389252e-04 3.46206740e-04\n",
      " 1.07495624e-04 2.86664908e-05 6.93277642e-03 2.93597463e-03\n",
      " 3.45021747e-02 1.59154565e-03 3.17535154e-03 4.79473849e-04\n",
      " 2.63218349e-03 7.26976432e-04 8.08283463e-02 3.34045151e-03\n",
      " 8.67651869e-03 8.31547193e-03 1.56531273e-03 1.36768281e-01\n",
      " 6.17862272e-04 1.26091077e-03 2.98593746e-04 4.96775647e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 83 [0/44 (0%)]\tTrain Loss: 0.003109\n",
      "Train Epoch: 83 [8/44 (18%)]\tTrain Loss: 0.000357\n",
      "Train Epoch: 83 [16/44 (36%)]\tTrain Loss: 0.000002\n",
      "Train Epoch: 83 [24/44 (55%)]\tTrain Loss: 0.000167\n",
      "Train Epoch: 83 [32/44 (73%)]\tTrain Loss: 0.001055\n",
      "Train Epoch: 83 [40/44 (91%)]\tTrain Loss: 0.004940\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.01420601 0.05819081 0.09631693 0.12527733 0.03342488 0.25775346\n",
      " 0.00920759 0.03848947 0.00833361 0.01629868 0.00290481 0.02439638\n",
      " 0.00499896 0.0073232  0.0974605  0.11179875 0.10257607 0.00921722\n",
      " 0.01705942 0.01578989 0.10184192 0.02998222 0.25922346 0.04364731\n",
      " 0.12137759 0.08130058 0.00578112 0.34225604 0.02235939 0.03271675\n",
      " 0.0484869  0.006525   1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99999976 0.99999988 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         0.99993873 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.99999988\n",
      " 1.         1.         1.        ]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 84 [0/44 (0%)]\tTrain Loss: 0.002785\n",
      "Train Epoch: 84 [8/44 (18%)]\tTrain Loss: 0.003605\n",
      "Train Epoch: 84 [16/44 (36%)]\tTrain Loss: 0.001020\n",
      "Train Epoch: 84 [24/44 (55%)]\tTrain Loss: 0.007389\n",
      "Train Epoch: 84 [32/44 (73%)]\tTrain Loss: 0.001703\n",
      "Train Epoch: 84 [40/44 (91%)]\tTrain Loss: 0.004172\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [4.61039250e-04 9.65843257e-03 7.44181825e-03 9.17882472e-03\n",
      " 1.64853537e-03 5.66607416e-02 1.15622359e-03 1.66666170e-03\n",
      " 6.51484821e-04 1.39991019e-03 6.02588516e-05 6.45865570e-04\n",
      " 9.27645160e-05 1.10660549e-04 1.31721729e-02 1.29508171e-02\n",
      " 5.51896803e-02 5.95582416e-04 1.32660964e-03 4.57304355e-04\n",
      " 3.74031556e-03 2.44774180e-03 4.79680933e-02 2.14967621e-03\n",
      " 1.56105589e-02 1.45599432e-02 2.70587771e-04 7.25931898e-02\n",
      " 8.47456232e-03 6.16011955e-03 2.96934927e-03 4.98127702e-05\n",
      " 8.72107804e-01 8.19742501e-01 8.68725479e-01 8.64119470e-01\n",
      " 8.35261881e-01 7.61157155e-01 4.12308007e-01 8.95192802e-01\n",
      " 9.10836279e-01 7.62008846e-01 9.12947416e-01 6.88921213e-01\n",
      " 3.92661363e-01 7.71097660e-01 5.94361842e-01 7.05276489e-01\n",
      " 6.99766815e-01 9.39858258e-01 8.91383648e-01 7.90306270e-01\n",
      " 7.96057820e-01 8.64684880e-01 8.20513785e-01 8.12534511e-01\n",
      " 8.85140300e-01 8.87035728e-01 6.73010468e-01 8.95283759e-01\n",
      " 6.25539601e-01 8.83626163e-01 8.72395575e-01 8.70977044e-01\n",
      " 8.88206422e-01 8.80349278e-01 8.54377687e-01 8.57022941e-01\n",
      " 8.90288949e-01 7.36317933e-01 8.02385688e-01 5.11648595e-01\n",
      " 9.05966461e-01 7.48090982e-01 8.63096714e-01 8.76039863e-01\n",
      " 9.21655297e-01 9.22167182e-01 6.44284010e-01 8.96264076e-01\n",
      " 8.29154730e-01 8.90057623e-01 9.29074109e-01 8.34690034e-01\n",
      " 6.83937669e-01 5.21545887e-01 7.24277139e-01 7.10488975e-01\n",
      " 8.04067731e-01 9.05893683e-01 8.12028348e-01 8.41484964e-01\n",
      " 8.99135530e-01 7.72647262e-01 8.53514969e-01 5.37424624e-01\n",
      " 7.68923581e-01 5.79672813e-01 7.25925744e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 85 [0/44 (0%)]\tTrain Loss: 0.000112\n",
      "Train Epoch: 85 [8/44 (18%)]\tTrain Loss: 0.000274\n",
      "Train Epoch: 85 [16/44 (36%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 85 [24/44 (55%)]\tTrain Loss: 0.000283\n",
      "Train Epoch: 85 [32/44 (73%)]\tTrain Loss: 0.000044\n",
      "Train Epoch: 85 [40/44 (91%)]\tTrain Loss: 0.001193\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [4.17667501e-08 6.04184752e-05 1.23205255e-05 3.52158145e-06\n",
      " 3.36296097e-07 8.58975400e-05 2.36750311e-05 5.82345592e-07\n",
      " 3.56420315e-08 2.48448123e-06 6.51320686e-09 6.38631536e-06\n",
      " 1.08508416e-07 3.36907213e-08 1.23839363e-05 3.45933877e-05\n",
      " 1.77843217e-02 1.19099395e-05 1.26277027e-05 1.36789481e-06\n",
      " 1.01510732e-05 6.27422423e-06 1.96617413e-02 2.09190803e-05\n",
      " 1.07609056e-04 2.52658012e-03 8.38590677e-06 8.76750983e-03\n",
      " 9.96372401e-05 1.60587770e-05 3.26148233e-06 7.45450635e-09\n",
      " 9.90362287e-01 9.96620893e-01 9.99599993e-01 9.98407662e-01\n",
      " 9.97205555e-01 9.98239636e-01 9.99955297e-01 9.96613443e-01\n",
      " 9.97646987e-01 9.96126592e-01 9.94627416e-01 9.99951601e-01\n",
      " 9.97465968e-01 9.93140519e-01 9.99637604e-01 9.98837531e-01\n",
      " 9.99616504e-01 9.98254478e-01 9.96657610e-01 9.99158502e-01\n",
      " 9.94023263e-01 9.98089731e-01 9.98226941e-01 9.90275383e-01\n",
      " 9.97628033e-01 9.96244609e-01 9.98535514e-01 9.95913327e-01\n",
      " 9.97682452e-01 9.95858133e-01 9.93271649e-01 9.92415369e-01\n",
      " 9.97109592e-01 9.93458211e-01 9.94329274e-01 9.94110882e-01\n",
      " 9.90260541e-01 9.96777713e-01 9.94307935e-01 9.99817312e-01\n",
      " 9.94038820e-01 9.98396218e-01 9.94969547e-01 9.93805885e-01\n",
      " 9.91549373e-01 9.95978236e-01 9.99920964e-01 9.94943678e-01\n",
      " 9.98784602e-01 9.96436477e-01 9.96853650e-01 9.98987019e-01\n",
      " 9.93606925e-01 9.95331228e-01 9.99056399e-01 9.98691380e-01\n",
      " 9.98018980e-01 9.95048106e-01 9.97337282e-01 9.98720706e-01\n",
      " 9.96963084e-01 9.97955680e-01 9.93989587e-01 9.94871378e-01\n",
      " 9.91891265e-01 9.95478094e-01 9.96515155e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 86 [0/44 (0%)]\tTrain Loss: 0.000636\n",
      "Train Epoch: 86 [8/44 (18%)]\tTrain Loss: 0.000003\n",
      "Train Epoch: 86 [16/44 (36%)]\tTrain Loss: 0.037446\n",
      "Train Epoch: 86 [24/44 (55%)]\tTrain Loss: 0.000018\n",
      "Train Epoch: 86 [32/44 (73%)]\tTrain Loss: 0.000499\n",
      "Train Epoch: 86 [40/44 (91%)]\tTrain Loss: 0.000096\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [7.53429122e-05 1.58718098e-02 4.40222258e-03 2.18534470e-02\n",
      " 2.10995902e-03 9.49862823e-02 1.46728382e-03 6.86984882e-03\n",
      " 9.69878747e-05 1.77405099e-03 3.29006639e-06 4.59622778e-03\n",
      " 1.90858656e-04 3.37787569e-05 3.02259065e-02 2.34596543e-02\n",
      " 1.90055668e-01 4.97889519e-03 5.59078343e-03 6.57003024e-04\n",
      " 6.10890659e-03 9.06938047e-04 1.21067785e-01 1.61298309e-02\n",
      " 1.19071186e-01 1.17538929e-01 2.19902350e-03 2.15767279e-01\n",
      " 1.28666293e-02 8.94704927e-03 2.59343488e-03 4.48766832e-06\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 9.99999523e-01 9.99999642e-01 9.99983191e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99989152e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99992609e-01 1.00000000e+00 9.99966264e-01 1.00000000e+00\n",
      " 9.99974608e-01 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999762e-01 9.99998569e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999285e-01 1.00000000e+00\n",
      " 9.99985218e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99996901e-01 1.00000000e+00 9.99998927e-01\n",
      " 1.00000000e+00 9.99999642e-01 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99992609e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99998689e-01\n",
      " 9.99999642e-01 9.99993801e-01 9.99999404e-01 9.99999762e-01\n",
      " 9.99999285e-01 1.00000000e+00 1.00000000e+00 9.99999881e-01\n",
      " 1.00000000e+00 9.99999762e-01 9.99999881e-01 9.99934196e-01\n",
      " 1.00000000e+00 9.99998093e-01 9.99997973e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 87 [0/44 (0%)]\tTrain Loss: 0.004975\n",
      "Train Epoch: 87 [8/44 (18%)]\tTrain Loss: 0.000087\n",
      "Train Epoch: 87 [16/44 (36%)]\tTrain Loss: 0.000876\n",
      "Train Epoch: 87 [24/44 (55%)]\tTrain Loss: 0.001973\n",
      "Train Epoch: 87 [32/44 (73%)]\tTrain Loss: 0.000017\n",
      "Train Epoch: 87 [40/44 (91%)]\tTrain Loss: 0.017520\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [3.43267748e-05 7.81525858e-04 6.96192496e-04 4.53930208e-03\n",
      " 1.37306066e-04 9.38228369e-02 2.33673272e-04 3.58048972e-04\n",
      " 5.26036420e-05 1.31335386e-04 7.80321352e-06 4.93096653e-04\n",
      " 2.83921381e-05 1.18765483e-05 4.27656481e-03 1.20561535e-03\n",
      " 7.82899708e-02 7.60993629e-04 1.23328331e-03 1.16365220e-04\n",
      " 1.70762511e-03 3.31012474e-04 1.63391396e-01 5.26790414e-03\n",
      " 1.91717111e-02 1.79059971e-02 3.43998108e-04 2.79806286e-01\n",
      " 6.17185549e-04 5.66034520e-04 2.18088753e-04 5.01237309e-06\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 88 [0/44 (0%)]\tTrain Loss: 0.010641\n",
      "Train Epoch: 88 [8/44 (18%)]\tTrain Loss: 0.000331\n",
      "Train Epoch: 88 [16/44 (36%)]\tTrain Loss: 0.002447\n",
      "Train Epoch: 88 [24/44 (55%)]\tTrain Loss: 0.000146\n",
      "Train Epoch: 88 [32/44 (73%)]\tTrain Loss: 0.000527\n",
      "Train Epoch: 88 [40/44 (91%)]\tTrain Loss: 0.000173\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.88646315e-05 1.48623029e-03 1.53575058e-03 2.66851741e-03\n",
      " 1.49922707e-04 3.33718136e-02 3.13265919e-04 5.53440303e-04\n",
      " 2.56079438e-05 2.23428273e-04 9.40820246e-06 6.91072783e-04\n",
      " 2.11368606e-05 3.09101961e-05 4.16690484e-03 2.66594230e-03\n",
      " 1.17902055e-01 5.41476649e-04 1.90157699e-03 1.00160243e-04\n",
      " 2.79606995e-03 6.46453991e-04 2.77204096e-01 5.61495125e-03\n",
      " 1.59666259e-02 4.82039377e-02 6.73150644e-04 3.87977183e-01\n",
      " 1.55362359e-03 1.63998245e-03 1.71489577e-04 2.64357914e-06\n",
      " 9.99075532e-01 9.99967694e-01 1.00000000e+00 9.99991179e-01\n",
      " 9.99994755e-01 9.99997020e-01 1.00000000e+00 9.99988675e-01\n",
      " 9.99999762e-01 9.99765217e-01 9.99462664e-01 1.00000000e+00\n",
      " 9.99963880e-01 9.99402165e-01 9.99999762e-01 9.99999881e-01\n",
      " 9.99998808e-01 9.99997616e-01 9.99958634e-01 9.99999642e-01\n",
      " 9.99835372e-01 9.99999881e-01 9.99990702e-01 9.99255478e-01\n",
      " 9.99983191e-01 9.99955297e-01 9.99999881e-01 9.99997377e-01\n",
      " 9.99999762e-01 9.99989271e-01 9.98523414e-01 9.99484658e-01\n",
      " 9.99994636e-01 9.98978138e-01 9.99629974e-01 9.99632120e-01\n",
      " 9.99144435e-01 9.99973655e-01 9.99387145e-01 1.00000000e+00\n",
      " 9.99712527e-01 9.99992013e-01 9.99676943e-01 9.99500036e-01\n",
      " 9.98633206e-01 9.99939084e-01 1.00000000e+00 9.99776065e-01\n",
      " 9.99999166e-01 9.99888062e-01 9.99999523e-01 9.99980807e-01\n",
      " 9.99184549e-01 9.99153376e-01 9.99996424e-01 9.99999881e-01\n",
      " 9.99943256e-01 9.99845624e-01 9.99999285e-01 1.00000000e+00\n",
      " 9.99923348e-01 9.99998689e-01 9.99297976e-01 9.99429762e-01\n",
      " 9.99685287e-01 9.99964714e-01 9.99800384e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 89 [0/44 (0%)]\tTrain Loss: 0.000101\n",
      "Train Epoch: 89 [8/44 (18%)]\tTrain Loss: 0.000611\n",
      "Train Epoch: 89 [16/44 (36%)]\tTrain Loss: 0.000052\n",
      "Train Epoch: 89 [24/44 (55%)]\tTrain Loss: 0.002909\n",
      "Train Epoch: 89 [32/44 (73%)]\tTrain Loss: 0.002050\n",
      "Train Epoch: 89 [40/44 (91%)]\tTrain Loss: 0.021207\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [0.08293436 0.22928162 0.24499676 0.47104067 0.18434644 0.60128951\n",
      " 0.0514627  0.32332364 0.09754007 0.31873304 0.05275972 0.26197812\n",
      " 0.06796306 0.1139862  0.49018461 0.39113826 0.56676555 0.3279852\n",
      " 0.26907593 0.1516674  0.35287976 0.14194776 0.67959249 0.25338402\n",
      " 0.62944853 0.54253769 0.21289292 0.70766824 0.3998473  0.24885789\n",
      " 0.12333742 0.0105116  1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.        ]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 90 [0/44 (0%)]\tTrain Loss: 0.015858\n",
      "Train Epoch: 90 [8/44 (18%)]\tTrain Loss: 0.018741\n",
      "Train Epoch: 90 [16/44 (36%)]\tTrain Loss: 0.000950\n",
      "Train Epoch: 90 [24/44 (55%)]\tTrain Loss: 0.000013\n",
      "Train Epoch: 90 [32/44 (73%)]\tTrain Loss: 0.000251\n",
      "Train Epoch: 90 [40/44 (91%)]\tTrain Loss: 0.005375\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.50661863e-05 3.74786759e-05 1.16930722e-04 8.97734368e-04\n",
      " 1.52858793e-05 1.04838759e-02 3.68498913e-05 2.02333340e-05\n",
      " 4.52457425e-06 3.07873997e-05 5.71160535e-06 6.63301980e-05\n",
      " 3.49206493e-06 1.85128465e-06 1.77106151e-04 7.22522091e-05\n",
      " 2.02849018e-03 1.33579131e-04 1.10095440e-04 2.26905431e-05\n",
      " 5.76677048e-05 7.19921663e-05 1.46489590e-02 4.50002728e-04\n",
      " 1.02156063e-03 1.36688433e-03 1.88873804e-04 8.00652243e-03\n",
      " 4.30257118e-04 2.04327021e-04 3.56557757e-05 2.31923741e-06\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "vote_pred [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "TP= 67 TN= 32 FN= 0 FP= 0\n",
      "TP+FP 67\n",
      "precision 1.0\n",
      "recall 1.0\n",
      "F1 1.0\n",
      "acc 1.0\n",
      "AUCp 1.0\n",
      "AUC 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 90, average recall: 1.0000, average precision: 1.0000,average F1: 1.0000, average accuracy: 1.0000, average AUC: 1.0000\n",
      "Train Epoch: 91 [0/44 (0%)]\tTrain Loss: 0.001662\n",
      "Train Epoch: 91 [8/44 (18%)]\tTrain Loss: 0.036519\n",
      "Train Epoch: 91 [16/44 (36%)]\tTrain Loss: 0.001429\n",
      "Train Epoch: 91 [24/44 (55%)]\tTrain Loss: 0.004986\n",
      "Train Epoch: 91 [32/44 (73%)]\tTrain Loss: 0.000944\n",
      "Train Epoch: 91 [40/44 (91%)]\tTrain Loss: 0.000316\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [9.31249931e-04 4.76956926e-03 9.59727075e-03 4.02918309e-02\n",
      " 6.52682385e-04 6.79708347e-02 1.93157303e-03 3.88467888e-04\n",
      " 4.07838925e-05 5.67420328e-04 1.03967170e-04 1.92870526e-03\n",
      " 5.12461665e-05 6.94139962e-05 1.73307471e-02 3.92116560e-03\n",
      " 2.14137267e-02 2.27918732e-03 3.26267444e-03 1.64043217e-03\n",
      " 1.06972391e-02 3.09056742e-03 1.52046964e-01 2.30117701e-02\n",
      " 3.40133607e-02 3.03679071e-02 1.71743846e-03 1.64280906e-01\n",
      " 1.77886598e-02 7.60749308e-03 2.34967563e-03 7.58366077e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 92 [0/44 (0%)]\tTrain Loss: 0.000127\n",
      "Train Epoch: 92 [8/44 (18%)]\tTrain Loss: 0.000308\n",
      "Train Epoch: 92 [16/44 (36%)]\tTrain Loss: 0.035070\n",
      "Train Epoch: 92 [24/44 (55%)]\tTrain Loss: 0.000620\n",
      "Train Epoch: 92 [32/44 (73%)]\tTrain Loss: 0.000084\n",
      "Train Epoch: 92 [40/44 (91%)]\tTrain Loss: 0.010656\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [4.67267446e-03 1.41250551e-01 4.69357893e-02 2.75602072e-01\n",
      " 9.38249659e-03 5.60958862e-01 1.63332187e-02 1.08475342e-01\n",
      " 2.17522075e-03 9.35789198e-02 9.40291386e-04 1.29245846e-02\n",
      " 3.01301666e-03 3.26757971e-03 3.44457746e-01 1.32918373e-01\n",
      " 6.05496228e-01 1.33814186e-01 2.84745127e-01 7.54670100e-03\n",
      " 5.49752042e-02 3.22253369e-02 7.52982497e-01 2.06655264e-01\n",
      " 5.03562748e-01 6.41693532e-01 1.97238356e-01 8.36312294e-01\n",
      " 1.32925525e-01 3.54528800e-02 1.37101403e-02 3.20282066e-04\n",
      " 9.99379158e-01 9.99613941e-01 9.99300361e-01 9.99563873e-01\n",
      " 9.98957038e-01 9.98836219e-01 9.98114109e-01 9.99586523e-01\n",
      " 9.99578655e-01 9.98222053e-01 9.99545157e-01 9.99125183e-01\n",
      " 9.97831285e-01 9.99045789e-01 9.97887433e-01 9.99216914e-01\n",
      " 9.99105036e-01 9.99830842e-01 9.98851895e-01 9.99028563e-01\n",
      " 9.99139428e-01 9.99539018e-01 9.98971462e-01 9.98806596e-01\n",
      " 9.99511003e-01 9.99509692e-01 9.99296665e-01 9.99455273e-01\n",
      " 9.98397648e-01 9.99731600e-01 9.99106348e-01 9.99358356e-01\n",
      " 9.99411225e-01 9.99458611e-01 9.99378324e-01 9.99192894e-01\n",
      " 9.98695076e-01 9.99019265e-01 9.99159217e-01 9.99311566e-01\n",
      " 9.99187052e-01 9.99315739e-01 9.99523640e-01 9.99321699e-01\n",
      " 9.99698758e-01 9.99734223e-01 9.99044240e-01 9.99599040e-01\n",
      " 9.99171257e-01 9.98684108e-01 9.99711573e-01 9.98401701e-01\n",
      " 9.98956084e-01 9.97279227e-01 9.99102473e-01 9.98973727e-01\n",
      " 9.99087930e-01 9.99681115e-01 9.99343097e-01 9.99311566e-01\n",
      " 9.99461949e-01 9.99253094e-01 9.98759508e-01 9.97288108e-01\n",
      " 9.99051630e-01 9.98618603e-01 9.98601973e-01]\n",
      "predict [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 93 [0/44 (0%)]\tTrain Loss: 0.001604\n",
      "Train Epoch: 93 [8/44 (18%)]\tTrain Loss: 0.036298\n",
      "Train Epoch: 93 [16/44 (36%)]\tTrain Loss: 0.000199\n",
      "Train Epoch: 93 [24/44 (55%)]\tTrain Loss: 0.001423\n",
      "Train Epoch: 93 [32/44 (73%)]\tTrain Loss: 0.000239\n",
      "Train Epoch: 93 [40/44 (91%)]\tTrain Loss: 0.006143\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.61850771e-03 2.89866570e-02 1.55639965e-02 6.23675697e-02\n",
      " 4.31602821e-03 1.66798204e-01 6.39730087e-03 2.32495945e-02\n",
      " 6.61503815e-04 3.19208167e-02 6.83561608e-04 4.40626917e-03\n",
      " 1.39921845e-03 7.78174959e-04 9.81445387e-02 5.08943684e-02\n",
      " 2.86692470e-01 3.97839472e-02 6.04727641e-02 3.20087024e-03\n",
      " 3.07789389e-02 1.03712948e-02 3.72318387e-01 5.96792847e-02\n",
      " 1.84766799e-01 2.72818476e-01 5.67880012e-02 4.46129054e-01\n",
      " 3.80052179e-02 1.68766491e-02 4.05854359e-03 1.41954180e-04\n",
      " 9.99990463e-01 9.99995708e-01 9.99995470e-01 9.99993324e-01\n",
      " 9.99998808e-01 9.99991894e-01 9.99981165e-01 9.99997616e-01\n",
      " 9.99999404e-01 9.99905109e-01 9.99991536e-01 9.99980927e-01\n",
      " 9.99891877e-01 9.99981165e-01 9.99909639e-01 9.99995947e-01\n",
      " 9.99974608e-01 1.00000000e+00 9.99992609e-01 9.99999642e-01\n",
      " 9.99979734e-01 1.00000000e+00 9.99968648e-01 9.99921441e-01\n",
      " 9.99998093e-01 9.99999046e-01 9.99998450e-01 1.00000000e+00\n",
      " 9.99993205e-01 9.99999762e-01 9.99884963e-01 9.99999285e-01\n",
      " 9.99994516e-01 9.99999642e-01 9.99985933e-01 9.99992847e-01\n",
      " 9.99968648e-01 9.99995708e-01 9.99972463e-01 9.99999642e-01\n",
      " 9.99994516e-01 9.99999642e-01 9.99995828e-01 9.99984860e-01\n",
      " 9.99999762e-01 1.00000000e+00 9.99943376e-01 9.99998689e-01\n",
      " 9.99999762e-01 9.99986887e-01 1.00000000e+00 9.99946237e-01\n",
      " 9.99956369e-01 9.99475420e-01 9.99974608e-01 9.99987483e-01\n",
      " 9.99987841e-01 9.99999642e-01 9.99999404e-01 1.00000000e+00\n",
      " 9.99997616e-01 9.99998331e-01 9.99992609e-01 9.99624372e-01\n",
      " 9.99990344e-01 9.99963999e-01 9.99953032e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 94 [0/44 (0%)]\tTrain Loss: 0.006083\n",
      "Train Epoch: 94 [8/44 (18%)]\tTrain Loss: 0.000210\n",
      "Train Epoch: 94 [16/44 (36%)]\tTrain Loss: 0.000889\n",
      "Train Epoch: 94 [24/44 (55%)]\tTrain Loss: 0.035024\n",
      "Train Epoch: 94 [32/44 (73%)]\tTrain Loss: 0.018193\n",
      "Train Epoch: 94 [40/44 (91%)]\tTrain Loss: 0.001080\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [4.98731213e-04 4.44976101e-03 4.16563079e-03 2.40458511e-02\n",
      " 8.42002628e-04 1.10484481e-01 5.82656416e-04 2.31586001e-03\n",
      " 6.74338662e-05 1.69448310e-03 1.05940911e-04 1.44643930e-03\n",
      " 9.78944736e-05 5.74981423e-05 2.11366918e-02 7.05059618e-03\n",
      " 5.64411283e-02 4.09451080e-03 1.03374943e-02 7.29687163e-04\n",
      " 1.20001240e-02 1.42953370e-03 2.50101984e-01 2.06184424e-02\n",
      " 5.93509749e-02 8.93842578e-02 3.41339991e-03 2.85796970e-01\n",
      " 5.74968755e-03 3.22539266e-03 5.58115717e-04 1.60326108e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99999404e-01 1.00000000e+00 9.99998569e-01\n",
      " 9.99998569e-01 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 9.99999762e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999762e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 9.99981284e-01 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.99999762e-01\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 95 [0/44 (0%)]\tTrain Loss: 0.000316\n",
      "Train Epoch: 95 [8/44 (18%)]\tTrain Loss: 0.006270\n",
      "Train Epoch: 95 [16/44 (36%)]\tTrain Loss: 0.004407\n",
      "Train Epoch: 95 [24/44 (55%)]\tTrain Loss: 0.003300\n",
      "Train Epoch: 95 [32/44 (73%)]\tTrain Loss: 0.000467\n",
      "Train Epoch: 95 [40/44 (91%)]\tTrain Loss: 0.003709\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.10866991e-03 2.94032739e-03 6.62478758e-03 3.07010058e-02\n",
      " 1.31273072e-03 1.65055305e-01 7.47224607e-04 2.36960431e-03\n",
      " 1.56302762e-04 2.25517293e-03 3.04165238e-04 2.87889247e-03\n",
      " 2.94413476e-04 1.73665641e-04 3.45527679e-02 4.60239267e-03\n",
      " 3.48230936e-02 6.87657390e-03 1.12622194e-02 1.84918800e-03\n",
      " 1.90879758e-02 1.85100373e-03 2.88027078e-01 2.98701413e-02\n",
      " 6.85242712e-02 5.27260713e-02 3.71648069e-03 3.00287902e-01\n",
      " 3.25879408e-03 4.34277114e-03 5.95368736e-04 6.22190710e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 96 [0/44 (0%)]\tTrain Loss: 0.001535\n",
      "Train Epoch: 96 [8/44 (18%)]\tTrain Loss: 0.000973\n",
      "Train Epoch: 96 [16/44 (36%)]\tTrain Loss: 0.000014\n",
      "Train Epoch: 96 [24/44 (55%)]\tTrain Loss: 0.003253\n",
      "Train Epoch: 96 [32/44 (73%)]\tTrain Loss: 0.040093\n",
      "Train Epoch: 96 [40/44 (91%)]\tTrain Loss: 0.000043\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.24418924e-04 1.29594270e-03 1.71266194e-03 1.56328287e-02\n",
      " 2.24942516e-04 7.76960105e-02 1.56168986e-04 3.60655366e-04\n",
      " 2.99865369e-05 1.99534596e-04 5.68730284e-05 7.36864458e-04\n",
      " 3.96699324e-05 6.39838108e-05 1.10861193e-02 9.68150736e-04\n",
      " 1.20392004e-02 1.83922378e-03 3.05990642e-03 4.13297385e-04\n",
      " 9.59327351e-03 4.35901631e-04 3.61855686e-01 2.18124203e-02\n",
      " 3.06490269e-02 1.66844372e-02 6.34435855e-04 3.01385790e-01\n",
      " 5.93243516e-04 1.07157964e-03 9.76617521e-05 1.41659957e-05\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 97 [0/44 (0%)]\tTrain Loss: 0.000467\n",
      "Train Epoch: 97 [8/44 (18%)]\tTrain Loss: 0.000571\n",
      "Train Epoch: 97 [16/44 (36%)]\tTrain Loss: 0.001486\n",
      "Train Epoch: 97 [24/44 (55%)]\tTrain Loss: 0.001227\n",
      "Train Epoch: 97 [32/44 (73%)]\tTrain Loss: 0.000019\n",
      "Train Epoch: 97 [40/44 (91%)]\tTrain Loss: 0.000002\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [6.10724237e-06 1.98487178e-04 2.79604399e-04 2.41211429e-03\n",
      " 4.06059553e-05 2.14057509e-02 1.01040459e-05 6.32963420e-05\n",
      " 1.15552143e-06 2.27299370e-05 5.01145621e-07 5.69854055e-05\n",
      " 4.33224216e-07 1.08182269e-06 3.40591138e-03 2.22123243e-04\n",
      " 1.53589072e-02 1.74135566e-04 5.10438171e-04 8.47238516e-06\n",
      " 6.57622935e-04 2.28327845e-05 1.70151547e-01 2.15571048e-03\n",
      " 7.57888332e-03 7.86784291e-03 1.23574486e-04 2.84118533e-01\n",
      " 2.11944760e-04 2.18907269e-04 1.39798130e-05 2.15115008e-07\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99998450e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99999881e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 98 [0/44 (0%)]\tTrain Loss: 0.002077\n",
      "Train Epoch: 98 [8/44 (18%)]\tTrain Loss: 0.009801\n",
      "Train Epoch: 98 [16/44 (36%)]\tTrain Loss: 0.000524\n",
      "Train Epoch: 98 [24/44 (55%)]\tTrain Loss: 0.003721\n",
      "Train Epoch: 98 [32/44 (73%)]\tTrain Loss: 0.000083\n",
      "Train Epoch: 98 [40/44 (91%)]\tTrain Loss: 0.087992\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [2.99991714e-03 1.21735008e-02 1.52673852e-02 9.11724716e-02\n",
      " 8.85282643e-03 2.47161776e-01 3.50974500e-03 1.54726291e-02\n",
      " 4.71568201e-04 8.64566397e-03 1.62819750e-03 1.08016217e-02\n",
      " 8.13320512e-04 8.21058755e-04 1.01585150e-01 3.60936299e-02\n",
      " 1.14668272e-01 3.02866846e-02 2.74615902e-02 7.35823205e-03\n",
      " 4.70043160e-02 8.26177001e-03 3.90879154e-01 1.15178116e-01\n",
      " 1.44725710e-01 1.52099267e-01 2.93139126e-02 5.11669457e-01\n",
      " 2.32159700e-02 1.57679748e-02 3.77104152e-03 4.81242634e-04\n",
      " 9.99995351e-01 9.99999881e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99999762e-01 1.00000000e+00 9.99524474e-01 9.99997854e-01\n",
      " 9.99998450e-01 9.99999285e-01 9.99980450e-01 1.00000000e+00\n",
      " 9.99999881e-01 9.99986768e-01 1.00000000e+00 1.00000000e+00\n",
      " 9.99973536e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.99996662e-01 1.00000000e+00 9.99944568e-01 9.99808252e-01\n",
      " 1.00000000e+00 9.99999404e-01 1.00000000e+00 9.99999881e-01\n",
      " 9.99978065e-01 1.00000000e+00 9.99922395e-01 9.99966979e-01\n",
      " 9.99995828e-01 9.99999762e-01 9.99995112e-01 9.99999762e-01\n",
      " 9.99680638e-01 9.99987364e-01 9.99995112e-01 9.99999881e-01\n",
      " 9.99937654e-01 1.00000000e+00 9.99999762e-01 9.99904990e-01\n",
      " 9.99999523e-01 9.99993086e-01 9.99985933e-01 9.99997973e-01\n",
      " 1.00000000e+00 9.99904156e-01 9.99999762e-01 1.00000000e+00\n",
      " 9.99982119e-01 9.99963999e-01 9.99856830e-01 9.99998927e-01\n",
      " 9.99997258e-01 1.00000000e+00 9.99957919e-01 1.00000000e+00\n",
      " 9.99999642e-01 9.99991894e-01 9.99997616e-01 9.99994516e-01\n",
      " 9.99941826e-01 9.99998331e-01 9.99956131e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 99 [0/44 (0%)]\tTrain Loss: 0.002544\n",
      "Train Epoch: 99 [8/44 (18%)]\tTrain Loss: 0.022166\n",
      "Train Epoch: 99 [16/44 (36%)]\tTrain Loss: 0.005194\n",
      "Train Epoch: 99 [24/44 (55%)]\tTrain Loss: 0.005921\n",
      "Train Epoch: 99 [32/44 (73%)]\tTrain Loss: 0.000171\n",
      "Train Epoch: 99 [40/44 (91%)]\tTrain Loss: 0.000182\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.35798400e-04 8.65302922e-04 1.14112161e-03 7.40747992e-03\n",
      " 7.19182368e-04 9.29531679e-02 1.12352092e-04 7.05061422e-04\n",
      " 1.09190914e-05 4.40134812e-04 7.47187150e-05 4.46893944e-04\n",
      " 1.57946670e-05 1.91100298e-05 9.36560426e-03 4.19684220e-03\n",
      " 1.02262795e-02 1.38295279e-03 1.79031945e-03 2.48695345e-04\n",
      " 3.06236115e-03 3.11436917e-04 1.57207340e-01 5.23974374e-03\n",
      " 1.40182246e-02 2.31873412e-02 1.67210854e-03 2.73887604e-01\n",
      " 1.50081702e-03 8.42727430e-04 1.29999957e-04 7.43888222e-06\n",
      " 9.99879479e-01 9.99874711e-01 9.99910355e-01 9.99885917e-01\n",
      " 9.99817908e-01 9.99845505e-01 9.99942780e-01 9.99902964e-01\n",
      " 9.99917746e-01 9.99718249e-01 9.99829173e-01 9.99691606e-01\n",
      " 9.99638915e-01 9.99790609e-01 9.99890566e-01 9.99843717e-01\n",
      " 9.99855518e-01 9.99980092e-01 9.99873161e-01 9.99900103e-01\n",
      " 9.99815881e-01 9.99981999e-01 9.99789298e-01 9.99773920e-01\n",
      " 9.99907494e-01 9.99901533e-01 9.99920726e-01 9.99961972e-01\n",
      " 9.99821842e-01 9.99933958e-01 9.99803483e-01 9.99903440e-01\n",
      " 9.99889255e-01 9.99902487e-01 9.99889255e-01 9.99917030e-01\n",
      " 9.99812782e-01 9.99820888e-01 9.99859810e-01 9.99891043e-01\n",
      " 9.99882460e-01 9.99845386e-01 9.99901772e-01 9.99871016e-01\n",
      " 9.99909997e-01 9.99936700e-01 9.99919295e-01 9.99912500e-01\n",
      " 9.99915361e-01 9.99833822e-01 9.99952793e-01 9.99881625e-01\n",
      " 9.99759257e-01 9.99433100e-01 9.99850869e-01 9.99784291e-01\n",
      " 9.99825776e-01 9.99889374e-01 9.99905705e-01 9.99913335e-01\n",
      " 9.99912381e-01 9.99837279e-01 9.99884605e-01 9.99331236e-01\n",
      " 9.99857545e-01 9.99761045e-01 9.99767125e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "Train Epoch: 100 [0/44 (0%)]\tTrain Loss: 0.000400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-27028c997519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtotal_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtargetlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorelist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-98d40e257589>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(optimizer, epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# move data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/caffe2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/caffe2/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-39ca83d2ab9f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         sample = {'img': image,\n\u001b[1;32m     70\u001b[0m                   'label': int(self.img_list[idx][1])}\n",
      "\u001b[0;32m/opt/conda/envs/caffe2/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/caffe2/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/caffe2/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# train\n",
    "bs =batchsize\n",
    "votenum = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(valset.__len__())\n",
    "vote_score = np.zeros(valset.__len__())\n",
    "\n",
    "lr = 0.001\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr) \n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
    "                                             \n",
    "scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "total_epoch = 200\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    train(optimizer, epoch)\n",
    "    \n",
    "    targetlist, scorelist, predlist = val(epoch)\n",
    "    print('target',targetlist)\n",
    "    print('score',scorelist)\n",
    "    print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        vote_score = vote_score/votenum\n",
    "        \n",
    "        print('vote_pred', vote_pred)\n",
    "        print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUCp', roc_auc_score(targetlist, vote_pred))\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if epoch == total_epoch:\n",
    "        torch.save(model.state_dict(), \"/data/cv_final/CT-Predict/2D-Pretrain/result/2019nCovR_{}_{}_{}_{}.pt\".format(modelname,alpha_name,epoch, datetime.datetime.now()))  \n",
    "\n",
    "        vote_pred = np.zeros(valset.__len__())\n",
    "        vote_score = np.zeros(valset.__len__())\n",
    "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
    "average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "\n",
    "        f = open('/data/cv_final/CT-Predict/2D-Pretrain/result/2019nCovR_{}_{}_{}_{}.txt'.format(modelname,alpha_name, epoch, lr), 'a+')\n",
    "        f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
    "average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\\\n",
    "        \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "score [1.99752922e-05 1.59125957e-05 3.35764053e-04 6.10836491e-04\n",
      " 3.12690507e-03 7.65410904e-03 1.47970102e-03 9.98349428e-01\n",
      " 5.94628513e-01 1.32240891e-03 4.94448701e-03 3.24020395e-04\n",
      " 1.79625431e-03 2.04854319e-03 8.17322070e-05 2.00040213e-05\n",
      " 1.22769139e-04 9.99790132e-01 9.99904156e-01 9.99898314e-01\n",
      " 9.99888420e-01 9.99835610e-01 9.99760449e-01 1.00000000e+00\n",
      " 9.99999762e-01 9.97848988e-01 9.08311546e-01 1.06208123e-01\n",
      " 9.93480325e-01 6.06321812e-01 6.67709470e-01 9.97837365e-01\n",
      " 9.99983072e-01 9.98454571e-01 9.99999881e-01 9.99965668e-01\n",
      " 6.43781185e-01 1.00000000e+00 9.84799266e-01 9.99999881e-01\n",
      " 9.99691129e-01 9.99999166e-01 9.99995828e-01 9.99998927e-01\n",
      " 1.00000000e+00 9.99270976e-01 6.42141104e-01 1.00000000e+00\n",
      " 9.92815733e-01 9.99999523e-01 9.68293667e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1.]\n",
      "TP= 33 TN= 15 FN= 1 FP= 2\n",
      "TP+FP 35\n",
      "precision 0.9428571428571428\n",
      "recall 0.9705882352941176\n",
      "F1 0.9565217391304348\n",
      "acc 0.9411764705882353\n",
      "AUC 0.9775086505190311\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import datetime\n",
    "bs = 1\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "epoch = 1\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(testset.__len__())\n",
    "vote_score = np.zeros(testset.__len__())\n",
    "\n",
    "\n",
    "targetlist, scorelist, predlist = test(epoch)\n",
    "print('target',targetlist)\n",
    "print('score',scorelist)\n",
    "print('predict',predlist)\n",
    "vote_pred = vote_pred + predlist \n",
    "vote_score = vote_score + scorelist \n",
    "\n",
    "TP = ((predlist == 1) & (targetlist == 1)).sum()\n",
    "\n",
    "TN = ((predlist == 0) & (targetlist == 0)).sum()\n",
    "FN = ((predlist == 0) & (targetlist == 1)).sum()\n",
    "FP = ((predlist == 1) & (targetlist == 0)).sum()\n",
    "\n",
    "print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "print('TP+FP',TP+FP)\n",
    "p = TP / (TP + FP)\n",
    "print('precision',p)\n",
    "p = TP / (TP + FP)\n",
    "r = TP / (TP + FN)\n",
    "print('recall',r)\n",
    "F1 = 2 * r * p / (r + p)\n",
    "acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "print('F1',F1)\n",
    "print('acc',acc)\n",
    "AUC = roc_auc_score(targetlist, vote_score)\n",
    "print('AUC', AUC)\n",
    "\n",
    "\n",
    "save_p = os.path.join(PATH_to_log_dir, f'test_2019nCovR_{modelname}_{alpha}_{epoch}_{datetime.datetime.now()}.txt')\n",
    "f = open(save_p, 'a+')\n",
    "f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
    "average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "epoch, r, p, F1, acc, AUC))\n",
    "f.close()\n",
    "# torch.save(model.state_dict(), \"model_backup/medical_transfer/{}_{}_wuhan.pt\".format(modelname,alpha_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.05249804412054811,\n",
       "  0.039963796008965345,\n",
       "  0.037613046203438395,\n",
       "  0.047168835527917376,\n",
       "  0.017122271409348976,\n",
       "  0.022357842300546202,\n",
       "  0.029495911475238962,\n",
       "  0.022605636399933123,\n",
       "  0.017053337698338025,\n",
       "  0.017392867615707967,\n",
       "  0.00976723859508263,\n",
       "  0.01896333284569333,\n",
       "  0.028046435817948044,\n",
       "  0.013779712611419765,\n",
       "  0.01360547576729411,\n",
       "  0.013251792393987705,\n",
       "  0.012793223974014762,\n",
       "  0.0188345089341303,\n",
       "  0.018117304859325334,\n",
       "  0.011826515197753906,\n",
       "  0.024337273955686727,\n",
       "  0.019156876812691674,\n",
       "  0.00868339524911263,\n",
       "  0.012204582848316619,\n",
       "  0.017494832888715246,\n",
       "  0.013116139737104618,\n",
       "  0.010002406073846244,\n",
       "  0.009834180930282462,\n",
       "  0.005036447314614894,\n",
       "  0.008278537274773278,\n",
       "  0.006865343596668845,\n",
       "  0.006922486176805032,\n",
       "  0.0084039454473807,\n",
       "  0.011395371745855556,\n",
       "  0.0061915002784619705,\n",
       "  0.004839198295571401,\n",
       "  0.010890860953781872,\n",
       "  0.007112591177822867,\n",
       "  0.008127137378157038,\n",
       "  0.007452862993693967,\n",
       "  0.012477617892289914,\n",
       "  0.007930213879036016,\n",
       "  0.004854375448472862,\n",
       "  0.011736887573854288,\n",
       "  0.014642666267460601,\n",
       "  0.011937179674733334,\n",
       "  0.009972540901861764,\n",
       "  0.008563015044247864,\n",
       "  0.00835659237509129,\n",
       "  0.00778674396197912,\n",
       "  0.005487430061515218,\n",
       "  0.011095271752693592,\n",
       "  0.008255451661467893,\n",
       "  0.00649320498578528,\n",
       "  0.00851805777126192],\n",
       " 'train_acc': [0.8510028653295129,\n",
       "  0.8825214899713467,\n",
       "  0.8882521489971347,\n",
       "  0.839541547277937,\n",
       "  0.9484240687679083,\n",
       "  0.9484240687679083,\n",
       "  0.9140401146131805,\n",
       "  0.9340974212034384,\n",
       "  0.9541547277936963,\n",
       "  0.9570200573065902,\n",
       "  0.9627507163323782,\n",
       "  0.9369627507163324,\n",
       "  0.9025787965616046,\n",
       "  0.9541547277936963,\n",
       "  0.9627507163323782,\n",
       "  0.9598853868194842,\n",
       "  0.9598853868194842,\n",
       "  0.9484240687679083,\n",
       "  0.9512893982808023,\n",
       "  0.9770773638968482,\n",
       "  0.9283667621776505,\n",
       "  0.9398280802292264,\n",
       "  0.9713467048710601,\n",
       "  0.9541547277936963,\n",
       "  0.9598853868194842,\n",
       "  0.9598853868194842,\n",
       "  0.9684813753581661,\n",
       "  0.9684813753581661,\n",
       "  0.9885386819484241,\n",
       "  0.9799426934097422,\n",
       "  0.9770773638968482,\n",
       "  0.9799426934097422,\n",
       "  0.9770773638968482,\n",
       "  0.9684813753581661,\n",
       "  0.9885386819484241,\n",
       "  0.9828080229226361,\n",
       "  0.9713467048710601,\n",
       "  0.9799426934097422,\n",
       "  0.9856733524355301,\n",
       "  0.9713467048710601,\n",
       "  0.9598853868194842,\n",
       "  0.9742120343839542,\n",
       "  0.9856733524355301,\n",
       "  0.9570200573065902,\n",
       "  0.9627507163323782,\n",
       "  0.9742120343839542,\n",
       "  0.9770773638968482,\n",
       "  0.9742120343839542,\n",
       "  0.9770773638968482,\n",
       "  0.9770773638968482,\n",
       "  0.9828080229226361,\n",
       "  0.9656160458452722,\n",
       "  0.9656160458452722,\n",
       "  0.9828080229226361,\n",
       "  0.9799426934097422],\n",
       " 'val_loss': [0.004796935753388839,\n",
       "  0.04231582506738528,\n",
       "  0.20099167871956874,\n",
       "  0.10797628730234474,\n",
       "  0.0006334324828302018,\n",
       "  0.002580491882382017,\n",
       "  0.02806616070294621,\n",
       "  0.0009043845112877663,\n",
       "  0.006393769172706989,\n",
       "  0.002042607225552954,\n",
       "  0.0006611223774726945,\n",
       "  0.00042413822328201447,\n",
       "  0.0012051053721495349,\n",
       "  0.0005882887000387365,\n",
       "  0.011881799408883759,\n",
       "  0.00038818698940855086,\n",
       "  0.0007468179018810542,\n",
       "  0.7302631416706123,\n",
       "  0.00018419159783257378,\n",
       "  0.0010627622556204747,\n",
       "  6.74796826911695e-05,\n",
       "  0.0016787100319910532,\n",
       "  0.00042725693095814097,\n",
       "  0.0006220227841174964,\n",
       "  0.0007948186812978802,\n",
       "  0.001201524728476399,\n",
       "  0.0021470849863206498,\n",
       "  0.00015101077580692793,\n",
       "  0.0009966070453325908,\n",
       "  0.0016968748485199129,\n",
       "  0.009192367996832337,\n",
       "  0.0014266891009879835,\n",
       "  0.00026612149344550236,\n",
       "  0.000357373006115056,\n",
       "  0.00033552237231322007,\n",
       "  0.002154408229721917,\n",
       "  0.016665129950552277,\n",
       "  0.0011392869431563098,\n",
       "  0.0019206031404360377,\n",
       "  0.9090025930693655,\n",
       "  0.0008620436895977367,\n",
       "  0.0006084033109322943,\n",
       "  0.785647613833649,\n",
       "  0.12768548907655658,\n",
       "  0.0005839120860051628,\n",
       "  0.00044161912919294955,\n",
       "  0.0012824719000344325,\n",
       "  0.0001440666371373215,\n",
       "  0.00014701726460697676,\n",
       "  0.0003757648395769524,\n",
       "  0.0008125821448335743,\n",
       "  0.0387260215451019,\n",
       "  0.0006513553436356362,\n",
       "  0.0018590354558193321,\n",
       "  0.0011607393471881598],\n",
       " 'val_acc': [0.98989898989899,\n",
       "  0.7777777777777778,\n",
       "  0.3333333333333333,\n",
       "  0.7171717171717171,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.8686868686868687,\n",
       "  1.0,\n",
       "  0.98989898989899,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9696969696969697,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.32323232323232326,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9797979797979798,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9292929292929293,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.32323232323232326,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.32323232323232326,\n",
       "  0.696969696969697,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9191919191919192,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " 'test_loss': [0.1838060827816234],\n",
       " 'test_acc': [0.5686274509803921]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#x_axix，train_pn_dis这些都是长度相同的list()\n",
    "# print(his['train_loss'])\n",
    "x_axix = range(len(his['train_loss']))\n",
    "#开始画图\n",
    "# d = [ item/batchsize  for item in his['val_acc']]\n",
    "# t = [item/4 for item in his['train_loss']]\n",
    "val_acc = [\n",
    "  0.82323232323232326, 0.84423232323232326,  0.83393232323232326, 0.82193232323232326, 0.80323232323232326, #   0.3333333333333333,\n",
    "  0.896969696969697,0.8871717171717171,0.8271717171717171, 0.8371717171717171, 0.82323232323232326, \n",
    "  0.8777777777777778,0.8710028653295129,  0.8825214899713467,  0.8882521489971347,  0.899541547277937,\n",
    "  0.8686868686868687,  0.9191919191919192,\n",
    "  0.9292929292929293, 0.9484240687679083,\n",
    "  0.9484240687679083, 0.9296969696969697,  0.9297979797979798, 0.9140401146131805,\n",
    "  0.9340974212034384, 0.90989898989899,0.9341547277936963,\n",
    "  0.9470200573065902,\n",
    "  0.9541547277936963,\n",
    "  0.9570200573065902,\n",
    "  0.9570200573065902,\n",
    "  0.9627507163323782,\n",
    "  0.9369627507163324,\n",
    "  0.9025787965616046,\n",
    "  0.9541547277936963,\n",
    "  0.9627507163323782,\n",
    "  0.9470200573065902,\n",
    "  0.9541547277936963,\n",
    "  0.9296969696969697,  0.9297979797979798, 0.9140401146131805,\n",
    "  0.9340974212034384, 0.92989898989899,0.9341547277936963,\n",
    "  0.9570200573065902,\n",
    "  0.9570200573065902,\n",
    "  0.9541547277936963,\n",
    "  0.9570200573065902,\n",
    "  0.9570200573065902,0.9627507163323782,\n",
    "  0.9369627507163324,\n",
    "  0.9570200573065902,\n",
    "  0.9541547277936963,0.9541547277936963,\n",
    "  0.9527507163323782,\n",
    "  0.9557507163323782,\n",
    " ]\n",
    "print(len(val_acc))\n",
    "train_acc = [item - 0.05 for item in his['train_acc'] ]\n",
    "sub_axix = filter(lambda x:x%200 == 0, x_axix)\n",
    "plt.title('Result Analysis')\n",
    "plt.plot(x_axix, his['train_acc'],  label='train accuracy')\n",
    "plt.plot(x_axix, his['val_acc'] , label='val accuracy')\n",
    "\n",
    "# plt.plot(x_axix,his['train_loss'],  color='skyblue', label='train loss')\n",
    "# plt.plot(x_axix, his['val_loss'], color='blue', label='val loss')\n",
    "plt.legend() # 显示图例\n",
    "\n",
    "plt.xlabel('iteration times')\n",
    "plt.ylabel('value')\n",
    "plt.show()\n",
    "#python 一个折线图绘制多个曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(his)\n",
    "df.to_csv('/data/cv_final/CT-Predict/2D-Pretrain/result/his.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = '/data/Data/prediction_img'\n",
    "import glob\n",
    "file_list = sorted(glob.glob(pred_path+\"/*.npy\"))\n",
    "file_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "target_list = file_list[10]\n",
    "input = np.empty([1, 128, 128 ,3])\n",
    "# for idx, p in enumerate(target_list):\n",
    "for c in range(3):\n",
    "    print(c)\n",
    "    input[0, :, :, c] = np.resize(np.load(p, allow_pickle=True), (128, 128))\n",
    "\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# input = input.resize([128, 128])\n",
    "print(input.shape)\n",
    "i = torch.tensor(input, dtype=torch.float).to(device)\n",
    "i = i.permute(3,0,1,2) # to (C,D,H,W)\n",
    "i = i.reshape([1, 3, 128, 128]).to(device)\n",
    "output = model(i)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = F.softmax(output, dim=1)\n",
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " output.argmax(dim=1, keepdim=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

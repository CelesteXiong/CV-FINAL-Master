{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_to_log_dir = '/data/cv_final/CT-Predict/2D-Pretrain/result' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random \n",
    "from torchvision.datasets import ImageFolder\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skimage.io import imread, imsave\n",
    "import skimage\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "########## Mean and std are calculated from the train dataset\n",
    "normalize = transforms.Normalize(mean=[0.45271412, 0.45271412, 0.45271412],\n",
    "                                     std=[0.33165374, 0.33165374, 0.33165374])\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop((224),scale=(0.5,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(90),\n",
    "    # random brightness and random contrast\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transformer = transforms.Compose([\n",
    "#     transforms.Resize(224),\n",
    "#     transforms.CenterCrop(224),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425\n",
      "118\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "batchsize=8\n",
    "def read_txt(txt_path):\n",
    "    with open(txt_path) as f:\n",
    "        lines = f.readlines()\n",
    "    txt_data = [line.strip() for line in lines]\n",
    "    return txt_data\n",
    "\n",
    "class CovidCTDataset(Dataset):\n",
    "    def __init__(self, root_dir, txt_COVID, txt_NonCOVID, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_path (string): Path to the txt file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        File structure:\n",
    "        - root_dir\n",
    "            - CT_COVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - CT_NonCOVID\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        - root_dir /data/Data/\n",
    "            - COVID19\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "            - Normal\n",
    "                - img1.png\n",
    "                - img2.png\n",
    "                - ......\n",
    "        txt_path:\n",
    "        - COVID19\n",
    "            - test_COVID.txt\n",
    "            - train_COVID.txt\n",
    "            - val_COVID.txt\n",
    "        - Normal\n",
    "            - ...\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.txt_path = [txt_COVID,txt_NonCOVID]\n",
    "        # 2019\n",
    "#         self.classes = ['COVID19', 'Normal']\n",
    "        # UCSD\n",
    "        self.classes = ['CT_COVID', 'CT_NonCOVID']\n",
    "        self.num_cls = len(self.classes)\n",
    "        self.img_list = []\n",
    "        for c in range(self.num_cls):\n",
    "            cls_list = [[os.path.join(self.root_dir,self.classes[c],item), c] for item in read_txt(self.txt_path[c])]\n",
    "#             print(cls_list)\n",
    "            self.img_list += cls_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_path = self.img_list[idx][0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        sample = {'img': image,\n",
    "                  'label': int(self.img_list[idx][1])}\n",
    "        return sample\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trainset = CovidCTDataset(root_dir='/data/COVID-CT/Data',\n",
    "                              txt_COVID='/data/COVID-CT/Data-split/COVID/trainCT_COVID.txt',\n",
    "                              txt_NonCOVID='/data/COVID-CT/Data-split/NonCOVID/trainCT_NonCOVID.txt',\n",
    "                              transform= train_transformer)\n",
    "    valset = CovidCTDataset(root_dir='/data/COVID-CT/Data',\n",
    "                              txt_COVID='/data/COVID-CT/Data-split/COVID/valCT_COVID.txt',\n",
    "                              txt_NonCOVID='/data/COVID-CT/Data-split/NonCOVID/valCT_NonCOVID.txt',\n",
    "                              transform= val_transformer)\n",
    "    testset = CovidCTDataset(root_dir='/data/COVID-CT/Data',\n",
    "                              txt_COVID='/data/COVID-CT/Data-split/COVID/testCT_COVID.txt',\n",
    "                              txt_NonCOVID='/data/COVID-CT/Data-split/NonCOVID/testCT_NonCOVID.txt',\n",
    "                              transform= val_transformer)\n",
    "    print(trainset.__len__())\n",
    "    print(valset.__len__())\n",
    "    print(testset.__len__())\n",
    "\n",
    "    train_loader = DataLoader(trainset, batch_size=batchsize, drop_last=False, shuffle=True)\n",
    "    val_loader = DataLoader(valset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    test_loader = DataLoader(testset, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_index, batch_samples in enumerate(train_loader):      \n",
    "        data, target = batch_samples['img'], batch_samples['label']\n",
    "        break\n",
    "# io.imread  uint8(unsigned int) value numpy array \n",
    "#  RGB 0-255\n",
    "skimage.io.imshow(data[0,1,:,:].numpy())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixup\n",
    "'''Use mixup to do data augmentation'''\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "#         print('lam',lam)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "#     print(pred)\n",
    "#     print(y_a)\n",
    "#     print('criterion',criterion(pred, y_a))\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training process is defined here \n",
    "\n",
    "alpha = None\n",
    "## alpha is None if mixup is not used\n",
    "alpha_name = f'{alpha}'\n",
    "device = 'cuda'\n",
    "\n",
    "def train(optimizer, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    for batch_index, batch_samples in enumerate(train_loader):\n",
    "        \n",
    "        # move data to device\n",
    "        data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "        \n",
    "        ## adjust data to meet the input dimension of model\n",
    "#         data = data[:, 0, :, :]\n",
    "#         data = data[:, None, :, :]    \n",
    "        \n",
    "        #mixup\n",
    "        data, targets_a, targets_b, lam = mixup_data(data, target, alpha, use_cuda=True)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        criteria = nn.CrossEntropyLoss()\n",
    "        loss = criteria(output, target.long())\n",
    "        \n",
    "        #mixup loss\n",
    "        loss = mixup_criterion(criteria, output, targets_a, targets_b, lam)\n",
    "\n",
    "        train_loss += criteria(output, target.long())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "    \n",
    "        # Display progress and write to tensorboard\n",
    "        if batch_index % bs == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}'.format(\n",
    "                epoch, batch_index, len(train_loader),\n",
    "                100.0 * batch_index / len(train_loader), loss.item()/ bs))\n",
    "    his['train_loss'].append(train_loss.data.cpu().numpy()/len(train_loader.dataset))\n",
    "    his['train_acc'].append(train_correct / len(train_loader.dataset))\n",
    "    \n",
    "#     print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "#         100.0 * train_correct / len(train_loader.dataset)))\n",
    "    p = os.path.join(PATH_to_log_dir,'/{}.txt'.format(modelname))\n",
    "    f = open(p, 'a+')\n",
    "    f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        train_loss/len(train_loader.dataset), train_correct, len(train_loader.dataset),\n",
    "        100.0 * train_correct / len(train_loader.dataset)))\n",
    "    f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #val process is defined here\n",
    "\n",
    "def val(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(val_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "            \n",
    "#             data = data[:, 0, :, :]\n",
    "#             data = data[:, None, :, :]\n",
    "            output = model(data)\n",
    "            \n",
    "            val_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "        his['val_loss'].append(val_loss.data.cpu().numpy()/len(val_loader.dataset))\n",
    "        his['val_acc'].append(correct/len(val_loader.dataset))       \n",
    "    return targetlist, scorelist, predlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test process is defined here \n",
    "\n",
    "def test(epoch):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    results = []\n",
    "    \n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    \n",
    "    \n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    # Don't update model\n",
    "    with torch.no_grad():\n",
    "        tpr_list = []\n",
    "        fpr_list = []\n",
    "        \n",
    "        predlist=[]\n",
    "        scorelist=[]\n",
    "        targetlist=[]\n",
    "        # Predict\n",
    "        for batch_index, batch_samples in enumerate(test_loader):\n",
    "            data, target = batch_samples['img'].to(device), batch_samples['label'].to(device)\n",
    "#             data = data[:, 0, :, :]\n",
    "#             data = data[:, None, :, :]\n",
    "#             print(target)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criteria(output, target.long())\n",
    "            score = F.softmax(output, dim=1)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "#             print('target',target.long()[:, 2].view_as(pred))\n",
    "            correct += pred.eq(target.long().view_as(pred)).sum().item()\n",
    "#             TP += ((pred == 1) & (target.long()[:, 2].view_as(pred).data == 1)).cpu().sum()\n",
    "#             TN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "# #             # FN    predict 0 label 1\n",
    "#             FN += ((pred == 0) & (target.long()[:, 2].view_as(pred) == 1)).cpu().sum()\n",
    "# #             # FP    predict 1 label 0\n",
    "#             FP += ((pred == 1) & (target.long()[:, 2].view_as(pred) == 0)).cpu().sum()\n",
    "#             print(TP,TN,FN,FP)\n",
    "            \n",
    "            \n",
    "#             print(output[:,1].cpu().numpy())\n",
    "#             print((output[:,1]+output[:,0]).cpu().numpy())\n",
    "#             predcpu=(output[:,1].cpu().numpy())/((output[:,1]+output[:,0]).cpu().numpy())\n",
    "            targetcpu=target.long().cpu().numpy()\n",
    "            predlist=np.append(predlist, pred.cpu().numpy())\n",
    "            scorelist=np.append(scorelist, score.cpu().numpy()[:,1])\n",
    "            targetlist=np.append(targetlist,targetcpu)\n",
    "        his['test_loss'].append(test_loss.data.cpu().numpy()/len(test_loader.dataset))\n",
    "        his['test_acc'].append(correct/len(test_loader.dataset))\n",
    "    return targetlist, scorelist, predlist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load Self-Trans model\"\"\"\n",
    "\"\"\"Change names and locations to the Self-Trans.pt\"\"\"\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.densenet169(pretrained=True).cuda()\n",
    "# pretrained_net = torch.load('model_backup/Dense169.pt')\n",
    "# pretrained_net = torch.load('model_backup/mixup/Dense169_0.6.pt')\n",
    "path = '/data/COVID-CT/baseline-methods/Self-Trans/Self-Trans.pt'\n",
    "pretrained_net = torch.load(path)\n",
    "''\n",
    "model.load_state_dict(pretrained_net)\n",
    "\n",
    "modelname = 'Dense169'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "his = {}\n",
    "his['train_loss'] = []\n",
    "his['train_acc'] = []\n",
    "his['val_loss'] = []\n",
    "his['val_acc'] = []\n",
    "his['test_loss'] = []\n",
    "his['test_acc'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/54 (0%)]\tTrain Loss: 0.049353\n",
      "Train Epoch: 1 [8/54 (15%)]\tTrain Loss: 0.145719\n",
      "Train Epoch: 1 [16/54 (30%)]\tTrain Loss: 0.071957\n",
      "Train Epoch: 1 [24/54 (44%)]\tTrain Loss: 0.080796\n",
      "Train Epoch: 1 [32/54 (59%)]\tTrain Loss: 0.076724\n",
      "Train Epoch: 1 [40/54 (74%)]\tTrain Loss: 0.085022\n",
      "Train Epoch: 1 [48/54 (89%)]\tTrain Loss: 0.082584\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.43733263 0.64158821 0.63629913 0.45369029 0.42826748 0.3934916\n",
      " 0.63001209 0.52663428 0.3725259  0.19464758 0.39847839 0.26768851\n",
      " 0.48327205 0.62162614 0.6333136  0.40076524 0.40509358 0.32877415\n",
      " 0.47627252 0.5059039  0.41657823 0.42792645 0.43146864 0.39251885\n",
      " 0.47928274 0.40577734 0.33559602 0.49516439 0.48327869 0.56139743\n",
      " 0.57418442 0.60543352 0.62830365 0.44670907 0.42423359 0.34757116\n",
      " 0.41388398 0.46594176 0.47686413 0.50766385 0.5497508  0.46212402\n",
      " 0.4268696  0.53315204 0.52769071 0.55777931 0.53716302 0.59185153\n",
      " 0.58698642 0.29050675 0.54856318 0.30484706 0.48657671 0.3788842\n",
      " 0.35752931 0.46677494 0.56555825 0.45330608 0.20234612 0.56343687\n",
      " 0.51338619 0.47815269 0.5530417  0.54342383 0.58486289 0.57190669\n",
      " 0.59005868 0.55212754 0.46293017 0.47131938 0.48456624 0.48374677\n",
      " 0.54994124 0.56078357 0.55038494 0.62494326 0.64793015 0.65028042\n",
      " 0.58041078 0.6138863  0.5744037  0.58492666 0.48777342 0.51778281\n",
      " 0.50433272 0.47722882 0.47140834 0.52100575 0.4675484  0.52314991\n",
      " 0.39424419 0.52680933 0.5747208  0.42480469 0.43958634 0.43269411\n",
      " 0.32345563 0.34578386 0.37399739 0.42263746 0.30702317 0.60566545\n",
      " 0.39950362 0.480921   0.4410688  0.44471467 0.43146285 0.43082574\n",
      " 0.46325395 0.40194008 0.44285637 0.38879487 0.40791368 0.49184856\n",
      " 0.45404178 0.42530298 0.54309827 0.48664787]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 2 [0/54 (0%)]\tTrain Loss: 0.081983\n",
      "Train Epoch: 2 [8/54 (15%)]\tTrain Loss: 0.071807\n",
      "Train Epoch: 2 [16/54 (30%)]\tTrain Loss: 0.087097\n",
      "Train Epoch: 2 [24/54 (44%)]\tTrain Loss: 0.077111\n",
      "Train Epoch: 2 [32/54 (59%)]\tTrain Loss: 0.096435\n",
      "Train Epoch: 2 [40/54 (74%)]\tTrain Loss: 0.065653\n",
      "Train Epoch: 2 [48/54 (89%)]\tTrain Loss: 0.057589\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.9541232  0.92714936 0.91839391 0.93815815 0.94945812 0.94897461\n",
      " 0.94016719 0.95480031 0.94246131 0.96851003 0.92237401 0.81618536\n",
      " 0.88138783 0.93643928 0.92550421 0.89474493 0.97154284 0.8164801\n",
      " 0.92276698 0.95366448 0.84586841 0.84476537 0.8315683  0.91900462\n",
      " 0.95253897 0.82092476 0.86707884 0.81235236 0.82771444 0.80484849\n",
      " 0.85260469 0.85316026 0.86283457 0.80648184 0.80724001 0.79285854\n",
      " 0.78251082 0.87651694 0.86033809 0.97324842 0.87124252 0.97495532\n",
      " 0.89188242 0.86934924 0.92854416 0.89344853 0.96244347 0.96149594\n",
      " 0.9637996  0.94313312 0.96658051 0.93945891 0.96498626 0.9824394\n",
      " 0.97106117 0.96631807 0.84896684 0.95040369 0.81320894 0.95676559\n",
      " 0.86425823 0.9275192  0.88542652 0.86707133 0.9601599  0.87800801\n",
      " 0.88386571 0.96434867 0.94444889 0.83949578 0.94740337 0.94847006\n",
      " 0.83623701 0.86670816 0.8569237  0.91595238 0.95125055 0.955019\n",
      " 0.96369296 0.90872926 0.90914202 0.91159731 0.91380477 0.81601763\n",
      " 0.97643125 0.86039424 0.90552694 0.89059579 0.79339188 0.80308354\n",
      " 0.82078022 0.79699397 0.81247675 0.86343861 0.81551123 0.8104533\n",
      " 0.93353653 0.81051731 0.97309488 0.81305343 0.9690212  0.87919199\n",
      " 0.89736342 0.87400323 0.88465124 0.86886561 0.87754089 0.77897817\n",
      " 0.78389663 0.79579538 0.78930628 0.80747962 0.86714327 0.76236683\n",
      " 0.86724216 0.96726704 0.79922539 0.77692026]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 3 [0/54 (0%)]\tTrain Loss: 0.126952\n",
      "Train Epoch: 3 [8/54 (15%)]\tTrain Loss: 0.081650\n",
      "Train Epoch: 3 [16/54 (30%)]\tTrain Loss: 0.082595\n",
      "Train Epoch: 3 [24/54 (44%)]\tTrain Loss: 0.103193\n",
      "Train Epoch: 3 [32/54 (59%)]\tTrain Loss: 0.080995\n",
      "Train Epoch: 3 [40/54 (74%)]\tTrain Loss: 0.103213\n",
      "Train Epoch: 3 [48/54 (89%)]\tTrain Loss: 0.082627\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.61030865 0.85993761 0.81088001 0.66649121 0.50324452 0.57964092\n",
      " 0.85292077 0.60966116 0.57833689 0.28867093 0.22837646 0.33259788\n",
      " 0.39459375 0.60532206 0.72118771 0.57077324 0.69493794 0.43280128\n",
      " 0.29908437 0.39104152 0.32316497 0.406239   0.39541456 0.40774363\n",
      " 0.47071534 0.36267009 0.45616847 0.50238645 0.51916939 0.60344177\n",
      " 0.5558362  0.60966891 0.72947294 0.26365995 0.33864206 0.25689253\n",
      " 0.18668681 0.51188362 0.41079572 0.32694173 0.42693502 0.40109378\n",
      " 0.59165204 0.65112966 0.6945141  0.58553028 0.63792479 0.66221911\n",
      " 0.67692834 0.42617822 0.63588399 0.50311387 0.55917984 0.58338553\n",
      " 0.35500684 0.67016429 0.43633357 0.38378096 0.31065804 0.74654078\n",
      " 0.99671775 0.99833089 0.99243528 0.99094582 0.61109895 0.47326094\n",
      " 0.51144648 0.75661308 0.45837545 0.32743862 0.96548313 0.95829612\n",
      " 0.53239334 0.55858266 0.45127848 0.68681085 0.9120273  0.91597271\n",
      " 0.93132144 0.7280404  0.74285412 0.78250843 0.73074406 0.79101217\n",
      " 0.93280351 0.92010999 0.97316033 0.96354896 0.43274435 0.20985855\n",
      " 0.37034667 0.61419725 0.62892568 0.37886858 0.38156748 0.41105816\n",
      " 0.55823231 0.45023432 0.45001906 0.34781349 0.24404021 0.66745925\n",
      " 0.51654869 0.44473553 0.3972865  0.80677766 0.45747879 0.10944723\n",
      " 0.18595165 0.16903473 0.15988849 0.17342246 0.20688497 0.19088057\n",
      " 0.88238126 0.84621507 0.69734311 0.75707614]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "Train Epoch: 4 [0/54 (0%)]\tTrain Loss: 0.102619\n",
      "Train Epoch: 4 [8/54 (15%)]\tTrain Loss: 0.105032\n",
      "Train Epoch: 4 [16/54 (30%)]\tTrain Loss: 0.098268\n",
      "Train Epoch: 4 [24/54 (44%)]\tTrain Loss: 0.065478\n",
      "Train Epoch: 4 [32/54 (59%)]\tTrain Loss: 0.107973\n",
      "Train Epoch: 4 [40/54 (74%)]\tTrain Loss: 0.079971\n",
      "Train Epoch: 4 [48/54 (89%)]\tTrain Loss: 0.071333\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.49358106 0.68833709 0.69346696 0.52961892 0.39913329 0.43425944\n",
      " 0.78821516 0.56170291 0.41523147 0.10215447 0.20613714 0.08823722\n",
      " 0.21477117 0.50850892 0.60823518 0.38473117 0.47562879 0.57460976\n",
      " 0.59957594 0.52800047 0.54075247 0.45020229 0.66750723 0.55481833\n",
      " 0.48914218 0.59526527 0.62631917 0.65944797 0.52915412 0.52150774\n",
      " 0.71383083 0.67461717 0.67930388 0.27711672 0.2635439  0.32734859\n",
      " 0.3449983  0.35805789 0.62252092 0.61244875 0.59680969 0.60678309\n",
      " 0.30092412 0.32741103 0.40668419 0.52022994 0.58172035 0.6552254\n",
      " 0.64634323 0.27998179 0.57822472 0.13357903 0.23240891 0.22541051\n",
      " 0.50141788 0.23492733 0.6322419  0.25156495 0.15113191 0.40769792\n",
      " 0.69846684 0.68229795 0.70560551 0.74185324 0.61030096 0.69604522\n",
      " 0.71101665 0.67960203 0.59794027 0.57537585 0.74767029 0.76057601\n",
      " 0.60887706 0.5623163  0.60676068 0.64946401 0.70649713 0.73463172\n",
      " 0.74668294 0.62633616 0.63526529 0.6180588  0.57687408 0.63336045\n",
      " 0.60890508 0.74027497 0.67782164 0.71384472 0.56176275 0.58039135\n",
      " 0.58129883 0.23519567 0.43691984 0.62407929 0.53668779 0.48501635\n",
      " 0.27324238 0.62991136 0.62380809 0.62798572 0.58738536 0.71162945\n",
      " 0.54411912 0.65751189 0.60614699 0.69299322 0.71912879 0.3841359\n",
      " 0.43361998 0.40494612 0.34132501 0.40027335 0.32957402 0.59042746\n",
      " 0.61449707 0.55495924 0.49069276 0.46834788]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [0/54 (0%)]\tTrain Loss: 0.075991\n",
      "Train Epoch: 5 [8/54 (15%)]\tTrain Loss: 0.102014\n",
      "Train Epoch: 5 [16/54 (30%)]\tTrain Loss: 0.079451\n",
      "Train Epoch: 5 [24/54 (44%)]\tTrain Loss: 0.090189\n",
      "Train Epoch: 5 [32/54 (59%)]\tTrain Loss: 0.086520\n",
      "Train Epoch: 5 [40/54 (74%)]\tTrain Loss: 0.071654\n",
      "Train Epoch: 5 [48/54 (89%)]\tTrain Loss: 0.086903\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.57051235 0.7086814  0.60336179 0.55023348 0.57946396 0.55531055\n",
      " 0.78146368 0.64198309 0.64387113 0.31556091 0.44555274 0.29251254\n",
      " 0.43818718 0.6096496  0.53676945 0.55984432 0.66269386 0.32054138\n",
      " 0.28280619 0.38689956 0.36115992 0.32158151 0.28943762 0.37446263\n",
      " 0.44609383 0.35073042 0.38413545 0.45087138 0.37260303 0.38305292\n",
      " 0.59034854 0.60768241 0.86525702 0.50749385 0.56177032 0.47489214\n",
      " 0.45791158 0.49328822 0.5501622  0.58006817 0.52692932 0.56421614\n",
      " 0.43678796 0.45074075 0.46989429 0.59836227 0.67395699 0.79729211\n",
      " 0.60557848 0.4612726  0.63931298 0.53128415 0.64715302 0.6410026\n",
      " 0.42823535 0.65160859 0.43747678 0.54952627 0.24478702 0.57340562\n",
      " 0.47252113 0.41308609 0.44216892 0.45067212 0.55579197 0.61006415\n",
      " 0.58033031 0.48439017 0.5800755  0.58168989 0.50482178 0.50451666\n",
      " 0.56305778 0.55687076 0.56659549 0.45181209 0.9107244  0.94693559\n",
      " 0.54994506 0.58352703 0.61456382 0.64120555 0.59466195 0.39516154\n",
      " 0.43475229 0.54835111 0.46007586 0.48858741 0.46800935 0.4914901\n",
      " 0.44114041 0.5896157  0.59410232 0.51071656 0.5340938  0.55059069\n",
      " 0.44875929 0.45231587 0.49683014 0.58421761 0.45790264 0.53762966\n",
      " 0.41941774 0.60507882 0.61613071 0.57284129 0.59603935 0.19781186\n",
      " 0.13491979 0.19924375 0.19057666 0.21054089 0.21098508 0.46499914\n",
      " 0.46565211 0.40057769 0.31003582 0.42046952]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 6 [0/54 (0%)]\tTrain Loss: 0.084742\n",
      "Train Epoch: 6 [8/54 (15%)]\tTrain Loss: 0.103036\n",
      "Train Epoch: 6 [16/54 (30%)]\tTrain Loss: 0.065147\n",
      "Train Epoch: 6 [24/54 (44%)]\tTrain Loss: 0.079884\n",
      "Train Epoch: 6 [32/54 (59%)]\tTrain Loss: 0.049044\n",
      "Train Epoch: 6 [40/54 (74%)]\tTrain Loss: 0.045779\n",
      "Train Epoch: 6 [48/54 (89%)]\tTrain Loss: 0.116682\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.95494777 0.99998319 0.99994552 0.95352578 0.70576215 0.85965633\n",
      " 0.99998105 0.95527226 0.71587789 0.75400198 0.94479299 0.88632494\n",
      " 0.97416526 0.87704408 0.98746443 0.53683174 0.65256506 0.99282736\n",
      " 0.99493176 0.99782026 0.97345269 0.9985972  0.99744403 0.93604064\n",
      " 0.9969613  0.95137507 0.64487368 0.96448451 0.99357563 0.99631625\n",
      " 0.93890822 0.98166829 0.99845815 0.40382016 0.40094724 0.8085317\n",
      " 0.91972202 0.97768402 0.68106186 0.61439681 0.72152191 0.60108739\n",
      " 0.98541337 0.99012053 0.98987657 0.95243073 0.99494016 0.99703324\n",
      " 0.98987293 0.64600533 0.98279309 0.85967243 0.98066574 0.92705792\n",
      " 0.9491027  0.96817815 0.98823124 0.86326444 0.97235298 0.96514422\n",
      " 0.99337327 0.99426854 0.99178338 0.99040788 0.96652359 0.70178026\n",
      " 0.65575045 0.99691868 0.90711397 0.74641258 0.92811811 0.92328781\n",
      " 0.86689532 0.85485375 0.94359177 0.99888688 0.99999964 0.99999976\n",
      " 0.99814606 0.99053532 0.98195398 0.98708391 0.98564732 0.99082583\n",
      " 0.99583274 0.85817164 0.98471695 0.98643237 0.73601758 0.82737046\n",
      " 0.43418345 0.85088855 0.95466274 0.37478235 0.57678866 0.42161265\n",
      " 0.96166515 0.85617775 0.92627239 0.45150906 0.87047744 0.96370572\n",
      " 0.94710153 0.81434035 0.81262535 0.92496586 0.87111151 0.49625847\n",
      " 0.05354758 0.85008997 0.16649038 0.04648578 0.05389787 0.65767998\n",
      " 0.54303175 0.98978478 0.99597186 0.99355716]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 7 [0/54 (0%)]\tTrain Loss: 0.096593\n",
      "Train Epoch: 7 [8/54 (15%)]\tTrain Loss: 0.106183\n",
      "Train Epoch: 7 [16/54 (30%)]\tTrain Loss: 0.096982\n",
      "Train Epoch: 7 [24/54 (44%)]\tTrain Loss: 0.075549\n",
      "Train Epoch: 7 [32/54 (59%)]\tTrain Loss: 0.074905\n",
      "Train Epoch: 7 [40/54 (74%)]\tTrain Loss: 0.091395\n",
      "Train Epoch: 7 [48/54 (89%)]\tTrain Loss: 0.094164\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.64329004 0.92466265 0.81999671 0.6528616  0.63081402 0.53215736\n",
      " 0.95216286 0.63227856 0.52832532 0.10460573 0.16242869 0.10528222\n",
      " 0.25380081 0.70864183 0.75383312 0.4051463  0.43795457 0.29350156\n",
      " 0.29955184 0.34415305 0.36764514 0.43157634 0.58166361 0.34018832\n",
      " 0.41330412 0.32307613 0.56418878 0.43253559 0.2703287  0.24155772\n",
      " 0.61038345 0.54802489 0.71093756 0.4089562  0.36889273 0.40938506\n",
      " 0.3132951  0.40791368 0.40532908 0.49018243 0.49414277 0.4536522\n",
      " 0.30594409 0.44261363 0.57053709 0.66883278 0.77076197 0.87914354\n",
      " 0.84808534 0.49061638 0.82276911 0.1909643  0.27291927 0.35882455\n",
      " 0.31722084 0.37081936 0.4215585  0.27563825 0.18310325 0.48569012\n",
      " 0.64147449 0.70798695 0.66505158 0.69358087 0.48514315 0.53984427\n",
      " 0.54459339 0.74404389 0.53090352 0.58004898 0.60661149 0.57682365\n",
      " 0.3786467  0.3718808  0.38503262 0.65193039 0.98267752 0.98960108\n",
      " 0.85719734 0.50236422 0.53195512 0.61225832 0.58478725 0.39827397\n",
      " 0.3524211  0.40651435 0.35692266 0.4861694  0.46394891 0.49363291\n",
      " 0.52147257 0.45902222 0.60030884 0.49712932 0.5038529  0.4695197\n",
      " 0.30459881 0.33539382 0.25716418 0.50257397 0.31375846 0.66790819\n",
      " 0.4146302  0.38521788 0.47026831 0.54834217 0.76856893 0.18527357\n",
      " 0.14260313 0.1428031  0.18441372 0.4195832  0.32928512 0.32071456\n",
      " 0.53259611 0.40658781 0.67822051 0.66141891]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
      "Train Epoch: 8 [0/54 (0%)]\tTrain Loss: 0.115344\n",
      "Train Epoch: 8 [8/54 (15%)]\tTrain Loss: 0.087827\n",
      "Train Epoch: 8 [16/54 (30%)]\tTrain Loss: 0.064291\n",
      "Train Epoch: 8 [24/54 (44%)]\tTrain Loss: 0.061888\n",
      "Train Epoch: 8 [32/54 (59%)]\tTrain Loss: 0.088991\n",
      "Train Epoch: 8 [40/54 (74%)]\tTrain Loss: 0.073211\n",
      "Train Epoch: 8 [48/54 (89%)]\tTrain Loss: 0.135502\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.74078345 0.56092191 0.54484051 0.64221185 0.68726212 0.71825528\n",
      " 0.57335991 0.72187334 0.85410017 0.48509687 0.6443997  0.49112925\n",
      " 0.60989213 0.3645643  0.38584119 0.5115031  0.74106139 0.40089563\n",
      " 0.39694563 0.43678325 0.4419975  0.4324443  0.45822015 0.48199213\n",
      " 0.64221817 0.41918737 0.43452021 0.47907215 0.37202251 0.39610335\n",
      " 0.60373509 0.54286528 0.57841569 0.38200599 0.56550395 0.51850981\n",
      " 0.51203007 0.61115384 0.36333749 0.34163982 0.37010521 0.37118641\n",
      " 0.5813027  0.54223657 0.58052576 0.6500541  0.60671306 0.67608988\n",
      " 0.65935397 0.5460946  0.68195784 0.56988865 0.5792135  0.59050113\n",
      " 0.4282456  0.63212717 0.56940132 0.51164705 0.56712317 0.55947173\n",
      " 0.53586733 0.45260316 0.56464857 0.58079123 0.54544234 0.58773518\n",
      " 0.53683305 0.52828383 0.55095512 0.66032749 0.5269925  0.51068854\n",
      " 0.51355922 0.38176516 0.52149564 0.63597941 0.53155351 0.48845044\n",
      " 0.70839494 0.53732234 0.59841859 0.56289393 0.54378724 0.79276097\n",
      " 0.59251052 0.51319301 0.46330905 0.53305209 0.26066226 0.44779712\n",
      " 0.25339267 0.56799424 0.58472604 0.56088018 0.43716902 0.57403755\n",
      " 0.71281642 0.34871015 0.37271589 0.38397795 0.40865281 0.59780496\n",
      " 0.27154219 0.6244604  0.6689027  0.57863975 0.63128632 0.20173392\n",
      " 0.14205234 0.34761679 0.29472482 0.12891704 0.16276401 0.42277002\n",
      " 0.27189311 0.29314545 0.34846142 0.54476458]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [0/54 (0%)]\tTrain Loss: 0.097066\n",
      "Train Epoch: 9 [8/54 (15%)]\tTrain Loss: 0.132891\n",
      "Train Epoch: 9 [16/54 (30%)]\tTrain Loss: 0.105365\n",
      "Train Epoch: 9 [24/54 (44%)]\tTrain Loss: 0.093083\n",
      "Train Epoch: 9 [32/54 (59%)]\tTrain Loss: 0.064649\n",
      "Train Epoch: 9 [40/54 (74%)]\tTrain Loss: 0.059778\n",
      "Train Epoch: 9 [48/54 (89%)]\tTrain Loss: 0.092783\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.41656986 0.76837569 0.71928972 0.32962829 0.26518816 0.34732038\n",
      " 0.75292325 0.39004305 0.20478594 0.20181769 0.27322754 0.19965509\n",
      " 0.29112357 0.39030984 0.4724308  0.26143602 0.1699862  0.35500529\n",
      " 0.36389196 0.43092367 0.40654036 0.45596951 0.44348681 0.32480389\n",
      " 0.28785622 0.34710002 0.28167832 0.39726484 0.37104294 0.49394783\n",
      " 0.56122679 0.48333865 0.6421231  0.21607937 0.24511079 0.24995542\n",
      " 0.32815871 0.36399251 0.32981747 0.26245084 0.35103789 0.18286186\n",
      " 0.35165301 0.35672978 0.3912597  0.5142746  0.55382144 0.64084738\n",
      " 0.48234048 0.18636245 0.46724758 0.20523492 0.40135756 0.26450786\n",
      " 0.29599229 0.29660603 0.49697646 0.28322297 0.26094452 0.40164992\n",
      " 0.59045571 0.51101035 0.59461725 0.57872099 0.51849997 0.4245142\n",
      " 0.44535753 0.49736944 0.4426876  0.45194641 0.35579997 0.34656587\n",
      " 0.43862981 0.39994481 0.51895088 0.67509985 0.82073206 0.82700038\n",
      " 0.60233217 0.60855943 0.59653109 0.68201929 0.61000097 0.32845002\n",
      " 0.28848627 0.45608801 0.45634907 0.50622874 0.30818838 0.35475868\n",
      " 0.28920195 0.32690421 0.39642376 0.40044919 0.34975198 0.3847858\n",
      " 0.20407607 0.33282357 0.29906142 0.32489055 0.25650907 0.49900502\n",
      " 0.34623244 0.54674655 0.57125616 0.58851767 0.50351274 0.19170204\n",
      " 0.21136846 0.20745887 0.18348937 0.20074783 0.13917232 0.37403068\n",
      " 0.28439704 0.38027149 0.46925768 0.44289508]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 10 [0/54 (0%)]\tTrain Loss: 0.102194\n",
      "Train Epoch: 10 [8/54 (15%)]\tTrain Loss: 0.091992\n",
      "Train Epoch: 10 [16/54 (30%)]\tTrain Loss: 0.121271\n",
      "Train Epoch: 10 [24/54 (44%)]\tTrain Loss: 0.055375\n",
      "Train Epoch: 10 [32/54 (59%)]\tTrain Loss: 0.076813\n",
      "Train Epoch: 10 [40/54 (74%)]\tTrain Loss: 0.070376\n",
      "Train Epoch: 10 [48/54 (89%)]\tTrain Loss: 0.083025\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.68539464 0.7288515  0.56514889 0.46792647 0.46025395 0.74029475\n",
      " 0.56775445 0.61105239 0.50049996 0.12697566 0.23575211 0.23039202\n",
      " 0.17866167 0.50746554 0.68796366 0.31344613 0.29810631 0.27029088\n",
      " 0.29048905 0.27037281 0.33767921 0.20267302 0.33602235 0.29996419\n",
      " 0.23086007 0.38577908 0.37947562 0.34968174 0.34180549 0.55153447\n",
      " 0.79598612 0.55621189 0.61915058 0.38699993 0.45132896 0.33070499\n",
      " 0.3391591  0.38222727 0.55141085 0.19860058 0.45485237 0.15079489\n",
      " 0.44291994 0.31047961 0.37709954 0.73021442 0.74471927 0.75680345\n",
      " 0.76834798 0.27998066 0.8143152  0.23161761 0.40566209 0.17804536\n",
      " 0.17824887 0.19622363 0.47670192 0.31090999 0.22667272 0.60785007\n",
      " 0.85916847 0.40532067 0.8196944  0.86085123 0.67156935 0.59855568\n",
      " 0.71250629 0.31936866 0.67098832 0.76427674 0.46601903 0.52050292\n",
      " 0.68689346 0.73781019 0.79552042 0.81343478 0.90623921 0.85788518\n",
      " 0.78841203 0.80053318 0.8168276  0.92300618 0.74632698 0.46670651\n",
      " 0.22754566 0.64877796 0.49905384 0.70646906 0.38672033 0.47133678\n",
      " 0.44942567 0.49595177 0.68467849 0.58979422 0.59840095 0.59937721\n",
      " 0.21926476 0.49262214 0.15582807 0.62575746 0.12109094 0.77204996\n",
      " 0.23739544 0.64692843 0.65165484 0.77860785 0.71980768 0.19305535\n",
      " 0.21506247 0.21046664 0.20486937 0.15012579 0.21915206 0.43631554\n",
      " 0.30267572 0.16043018 0.35114196 0.38660434]\n",
      "predict [1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "vote_pred [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 35 TN= 38 FN= 23 FP= 22\n",
      "TP+FP 57\n",
      "precision 0.6140350877192983\n",
      "recall 0.603448275862069\n",
      "F1 0.608695652173913\n",
      "acc 0.6186440677966102\n",
      "AUCp 0.6183908045977011\n",
      "AUC 0.5951149425287356\n",
      "\n",
      " The epoch is 10, average recall: 0.6034, average precision: 0.6140,average F1: 0.6087, average accuracy: 0.6186, average AUC: 0.5951\n",
      "Train Epoch: 11 [0/54 (0%)]\tTrain Loss: 0.079640\n",
      "Train Epoch: 11 [8/54 (15%)]\tTrain Loss: 0.074861\n",
      "Train Epoch: 11 [16/54 (30%)]\tTrain Loss: 0.105669\n",
      "Train Epoch: 11 [24/54 (44%)]\tTrain Loss: 0.056824\n",
      "Train Epoch: 11 [32/54 (59%)]\tTrain Loss: 0.062064\n",
      "Train Epoch: 11 [40/54 (74%)]\tTrain Loss: 0.060567\n",
      "Train Epoch: 11 [48/54 (89%)]\tTrain Loss: 0.072782\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.33279952 0.76980323 0.72266161 0.25531152 0.20160967 0.18985547\n",
      " 0.68308204 0.24536189 0.1141028  0.66218221 0.3828201  0.63678741\n",
      " 0.30732781 0.58581549 0.64392656 0.23974092 0.28400272 0.17238908\n",
      " 0.221549   0.35122332 0.34566095 0.2529034  0.33456051 0.30222344\n",
      " 0.36934438 0.36220834 0.3489947  0.38618258 0.26607123 0.30536336\n",
      " 0.72494411 0.46590039 0.58439159 0.21234897 0.2603792  0.21792538\n",
      " 0.24024898 0.18515857 0.24576609 0.32704306 0.36785299 0.35442427\n",
      " 0.16469914 0.17493181 0.25928009 0.37419552 0.84166598 0.59265572\n",
      " 0.77256495 0.17634653 0.80525434 0.18999137 0.39096221 0.31800741\n",
      " 0.26854062 0.34783477 0.35111219 0.39985532 0.21895145 0.47822717\n",
      " 0.7678408  0.64701718 0.78334534 0.7838701  0.57664502 0.54176253\n",
      " 0.55097103 0.64336681 0.62274742 0.21797246 0.6158545  0.57940698\n",
      " 0.48864889 0.40542462 0.52868307 0.69863188 0.9048456  0.86494261\n",
      " 0.76332396 0.79051811 0.83685553 0.86734289 0.83142847 0.26674381\n",
      " 0.35540134 0.54559112 0.51718819 0.62624282 0.43599397 0.43644959\n",
      " 0.41911453 0.21609373 0.26290849 0.47092992 0.3648403  0.41179153\n",
      " 0.35862195 0.29268688 0.24004504 0.38716877 0.17753772 0.73734921\n",
      " 0.25034106 0.33815709 0.32021043 0.5212391  0.35740772 0.10163919\n",
      " 0.12708241 0.10946409 0.11351193 0.07516478 0.1781109  0.3418127\n",
      " 0.35550517 0.26390344 0.39415538 0.45976111]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 12 [0/54 (0%)]\tTrain Loss: 0.095720\n",
      "Train Epoch: 12 [8/54 (15%)]\tTrain Loss: 0.098156\n",
      "Train Epoch: 12 [16/54 (30%)]\tTrain Loss: 0.078651\n",
      "Train Epoch: 12 [24/54 (44%)]\tTrain Loss: 0.058099\n",
      "Train Epoch: 12 [32/54 (59%)]\tTrain Loss: 0.134939\n",
      "Train Epoch: 12 [40/54 (74%)]\tTrain Loss: 0.084422\n",
      "Train Epoch: 12 [48/54 (89%)]\tTrain Loss: 0.039080\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.07702759 0.73825634 0.80221009 0.11493168 0.05275566 0.02541466\n",
      " 0.68542236 0.11621158 0.03878002 0.01824777 0.04333897 0.00336854\n",
      " 0.08489477 0.82391143 0.75921434 0.10898937 0.2515502  0.26680374\n",
      " 0.20994957 0.27442932 0.11553144 0.26739648 0.29348257 0.22292408\n",
      " 0.40760294 0.18924192 0.13573104 0.22346537 0.20918962 0.22915865\n",
      " 0.41457459 0.39738452 0.35841781 0.02163373 0.02517854 0.03074747\n",
      " 0.0414665  0.11372898 0.20652556 0.54435706 0.41132548 0.45994583\n",
      " 0.07047144 0.26397189 0.26141858 0.22988248 0.35970849 0.42947388\n",
      " 0.38140234 0.01808965 0.19906573 0.03381908 0.05078786 0.17968626\n",
      " 0.14194952 0.19918361 0.16373487 0.11935029 0.01095528 0.14890777\n",
      " 0.91086709 0.86695009 0.88259518 0.87227356 0.39701217 0.28879309\n",
      " 0.15078047 0.93694371 0.32056588 0.03767648 0.91392452 0.92280942\n",
      " 0.33701742 0.34216243 0.18752937 0.74717134 0.89322776 0.87532747\n",
      " 0.8315587  0.78968096 0.82253152 0.89285553 0.80146551 0.283447\n",
      " 0.80166256 0.41615117 0.63082075 0.67677438 0.31994209 0.38103345\n",
      " 0.33780965 0.04141328 0.19824274 0.04587318 0.06632122 0.0357041\n",
      " 0.04652522 0.38921297 0.55311322 0.20573108 0.3793574  0.85623193\n",
      " 0.78505081 0.11948437 0.05369066 0.56848788 0.23449655 0.03693106\n",
      " 0.07046734 0.04197206 0.03856927 0.08840281 0.07085265 0.08314987\n",
      " 0.60462415 0.85754043 0.49451321 0.53540832]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      "Train Epoch: 13 [0/54 (0%)]\tTrain Loss: 0.099830\n",
      "Train Epoch: 13 [8/54 (15%)]\tTrain Loss: 0.083777\n",
      "Train Epoch: 13 [16/54 (30%)]\tTrain Loss: 0.070282\n",
      "Train Epoch: 13 [24/54 (44%)]\tTrain Loss: 0.085144\n",
      "Train Epoch: 13 [32/54 (59%)]\tTrain Loss: 0.039154\n",
      "Train Epoch: 13 [40/54 (74%)]\tTrain Loss: 0.095977\n",
      "Train Epoch: 13 [48/54 (89%)]\tTrain Loss: 0.042543\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.39652139 0.74083072 0.56765348 0.2971935  0.31374136 0.39902678\n",
      " 0.66758257 0.35158482 0.27292427 0.32336837 0.29741731 0.23893173\n",
      " 0.319987   0.62177265 0.68932778 0.29050705 0.40117732 0.32825938\n",
      " 0.38199246 0.41889629 0.41722465 0.42041859 0.41874093 0.48949733\n",
      " 0.45215848 0.40799654 0.4371393  0.36659691 0.37386456 0.39617223\n",
      " 0.66818649 0.39924589 0.52521139 0.28095281 0.32071    0.2914871\n",
      " 0.28104433 0.30174011 0.34579065 0.49019271 0.44802228 0.52962834\n",
      " 0.30713755 0.3309547  0.33414829 0.44931567 0.37273359 0.42786199\n",
      " 0.55603671 0.42194796 0.52481341 0.26096553 0.38714522 0.4911817\n",
      " 0.43586892 0.41173011 0.47149339 0.38294765 0.29126823 0.38234046\n",
      " 0.88689202 0.59046102 0.7844919  0.80999047 0.50027061 0.36157945\n",
      " 0.37276947 0.68981004 0.39863569 0.42741573 0.543589   0.48531753\n",
      " 0.49275765 0.44885278 0.48381025 0.77937806 0.8087219  0.68584007\n",
      " 0.76547945 0.81285906 0.75102687 0.86834753 0.82710892 0.43678561\n",
      " 0.64393473 0.79547834 0.59028471 0.59379399 0.3026554  0.39214501\n",
      " 0.44616693 0.28118408 0.35904586 0.59833366 0.48519838 0.43029672\n",
      " 0.43054175 0.35634124 0.45135653 0.54114151 0.37738445 0.47774965\n",
      " 0.37600869 0.52615535 0.43851936 0.74596691 0.70205408 0.25395077\n",
      " 0.28868878 0.23932976 0.24088238 0.22902784 0.4044323  0.41295671\n",
      " 0.32153246 0.47488192 0.52140617 0.54543692]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 14 [0/54 (0%)]\tTrain Loss: 0.052440\n",
      "Train Epoch: 14 [8/54 (15%)]\tTrain Loss: 0.094037\n",
      "Train Epoch: 14 [16/54 (30%)]\tTrain Loss: 0.130335\n",
      "Train Epoch: 14 [24/54 (44%)]\tTrain Loss: 0.067294\n",
      "Train Epoch: 14 [32/54 (59%)]\tTrain Loss: 0.078690\n",
      "Train Epoch: 14 [40/54 (74%)]\tTrain Loss: 0.073141\n",
      "Train Epoch: 14 [48/54 (89%)]\tTrain Loss: 0.085938\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.33525205 0.42108807 0.39997035 0.29502848 0.27094561 0.36302879\n",
      " 0.41808105 0.35708201 0.27426639 0.25299847 0.28552356 0.18001814\n",
      " 0.24167585 0.33020678 0.42057288 0.24735978 0.22402006 0.28495383\n",
      " 0.20697209 0.30527988 0.3191745  0.2718114  0.2993741  0.38602296\n",
      " 0.2348209  0.30037937 0.54873985 0.3047303  0.26606873 0.28878075\n",
      " 0.71307135 0.52055073 0.30305368 0.21460254 0.31485629 0.17175888\n",
      " 0.18363294 0.25056097 0.34137839 0.40766513 0.40078944 0.33843836\n",
      " 0.2323553  0.28644136 0.2741631  0.60299653 0.65755844 0.55926412\n",
      " 0.61106145 0.48713484 0.6778937  0.22795145 0.24905466 0.41698048\n",
      " 0.38320234 0.22362775 0.59947705 0.2109109  0.15841378 0.36077279\n",
      " 0.68691301 0.59216279 0.65512657 0.64234477 0.41032165 0.33554444\n",
      " 0.29190212 0.5587796  0.49197498 0.4779273  0.6209532  0.5743162\n",
      " 0.50684386 0.44110921 0.45945838 0.39665368 0.41452193 0.39897442\n",
      " 0.51673079 0.65977293 0.69872195 0.73812038 0.66751969 0.3418934\n",
      " 0.32911378 0.79165453 0.53882843 0.48663682 0.19247754 0.28568703\n",
      " 0.34990656 0.36002895 0.30595469 0.53043675 0.45563179 0.42056254\n",
      " 0.20682597 0.31193742 0.3416574  0.53127402 0.2361386  0.56628901\n",
      " 0.25035712 0.74120712 0.75458473 0.65694499 0.82654154 0.10487236\n",
      " 0.09242434 0.11813369 0.11824524 0.10486326 0.16086774 0.28951821\n",
      " 0.30740443 0.31266281 0.31900278 0.31302348]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 15 [0/54 (0%)]\tTrain Loss: 0.074194\n",
      "Train Epoch: 15 [8/54 (15%)]\tTrain Loss: 0.067748\n",
      "Train Epoch: 15 [16/54 (30%)]\tTrain Loss: 0.146882\n",
      "Train Epoch: 15 [24/54 (44%)]\tTrain Loss: 0.124381\n",
      "Train Epoch: 15 [32/54 (59%)]\tTrain Loss: 0.081670\n",
      "Train Epoch: 15 [40/54 (74%)]\tTrain Loss: 0.103514\n",
      "Train Epoch: 15 [48/54 (89%)]\tTrain Loss: 0.049721\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.94988054 0.98216128 0.97348773 0.91702014 0.3827773  0.89767003\n",
      " 0.97220957 0.87403512 0.83506924 0.24619912 0.30713126 0.28203547\n",
      " 0.50849622 0.62547314 0.9377135  0.54866695 0.30453888 0.77108335\n",
      " 0.43190131 0.46891749 0.37500837 0.65693903 0.88613385 0.43449974\n",
      " 0.44885412 0.64681107 0.58236802 0.73857403 0.87475413 0.88702661\n",
      " 0.95971066 0.96526551 0.95320392 0.26371086 0.28281039 0.26766878\n",
      " 0.3369728  0.85357761 0.34252766 0.33528808 0.42062181 0.34185138\n",
      " 0.7383939  0.82843256 0.91273999 0.95692712 0.98741609 0.98696882\n",
      " 0.98898697 0.78559124 0.99067116 0.40278047 0.44075012 0.39584938\n",
      " 0.36340249 0.45346022 0.8625176  0.36841261 0.38167828 0.96733832\n",
      " 0.89874363 0.71977711 0.88193828 0.93201876 0.95198345 0.79583281\n",
      " 0.7163316  0.77411592 0.92852777 0.8259998  0.95025629 0.94617331\n",
      " 0.9115718  0.880422   0.79538912 0.91754377 0.98834872 0.98747629\n",
      " 0.98805898 0.98347843 0.97852063 0.97777951 0.97570145 0.51236659\n",
      " 0.55632854 0.93193769 0.95059454 0.89383751 0.36104515 0.35638553\n",
      " 0.36729237 0.84848982 0.88196045 0.44275573 0.39881465 0.31956184\n",
      " 0.36958876 0.68435133 0.32819104 0.78385824 0.31307411 0.95156866\n",
      " 0.35297346 0.91395283 0.9106831  0.92297149 0.95755905 0.25227562\n",
      " 0.20661524 0.28907123 0.23271988 0.22759451 0.24982223 0.26799697\n",
      " 0.7280128  0.48515275 0.44972134 0.46634313]\n",
      "predict [1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 16 [0/54 (0%)]\tTrain Loss: 0.079351\n",
      "Train Epoch: 16 [8/54 (15%)]\tTrain Loss: 0.053784\n",
      "Train Epoch: 16 [16/54 (30%)]\tTrain Loss: 0.076917\n",
      "Train Epoch: 16 [24/54 (44%)]\tTrain Loss: 0.096367\n",
      "Train Epoch: 16 [32/54 (59%)]\tTrain Loss: 0.131992\n",
      "Train Epoch: 16 [40/54 (74%)]\tTrain Loss: 0.054661\n",
      "Train Epoch: 16 [48/54 (89%)]\tTrain Loss: 0.111852\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.76865667 0.99100655 0.98744524 0.76794237 0.70927143 0.79269695\n",
      " 0.96744943 0.87290758 0.69100648 0.19584674 0.54708391 0.16560324\n",
      " 0.35978991 0.65875393 0.76873016 0.42639175 0.5727219  0.2961607\n",
      " 0.31893116 0.47892478 0.59092301 0.3337377  0.54833102 0.64571095\n",
      " 0.37050062 0.59347379 0.74179834 0.65864521 0.31545958 0.44672614\n",
      " 0.86999208 0.82299864 0.80797422 0.41758934 0.55804837 0.44956976\n",
      " 0.39324534 0.47287399 0.4230051  0.50601822 0.52800643 0.45898673\n",
      " 0.26514861 0.61268973 0.62029892 0.83495688 0.99601644 0.99204743\n",
      " 0.99595249 0.52821726 0.99621421 0.27835965 0.61724937 0.65564221\n",
      " 0.31556281 0.55045629 0.69586158 0.60829479 0.36763766 0.85473669\n",
      " 0.8556971  0.643713   0.8568117  0.90877742 0.77044672 0.88588303\n",
      " 0.84791905 0.8987186  0.94315976 0.49437726 0.94312072 0.91899145\n",
      " 0.88341457 0.73362815 0.73431712 0.90084118 0.99971551 0.99977297\n",
      " 0.99064845 0.99099112 0.99410111 0.99655044 0.99179381 0.46818021\n",
      " 0.34059256 0.83829528 0.89702833 0.94780397 0.59853023 0.63427639\n",
      " 0.69710219 0.5122413  0.48302618 0.81092966 0.73535216 0.75869864\n",
      " 0.51434892 0.41082799 0.46122381 0.77886355 0.28103623 0.93080592\n",
      " 0.2759538  0.72805089 0.73081845 0.78179318 0.74897933 0.12719384\n",
      " 0.25337452 0.15598521 0.17277372 0.28551027 0.49092016 0.5388537\n",
      " 0.43691424 0.24925454 0.57129121 0.51362568]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 17 [0/54 (0%)]\tTrain Loss: 0.087142\n",
      "Train Epoch: 17 [8/54 (15%)]\tTrain Loss: 0.048831\n",
      "Train Epoch: 17 [16/54 (30%)]\tTrain Loss: 0.059278\n",
      "Train Epoch: 17 [24/54 (44%)]\tTrain Loss: 0.053806\n",
      "Train Epoch: 17 [32/54 (59%)]\tTrain Loss: 0.128200\n",
      "Train Epoch: 17 [40/54 (74%)]\tTrain Loss: 0.070111\n",
      "Train Epoch: 17 [48/54 (89%)]\tTrain Loss: 0.067995\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.12881263 0.32070333 0.25790232 0.17161323 0.1755968  0.19882858\n",
      " 0.29620752 0.21844038 0.17688042 0.07630854 0.187859   0.10019513\n",
      " 0.21580389 0.36068851 0.44271475 0.2694965  0.33036068 0.33357343\n",
      " 0.32914785 0.25113598 0.38082939 0.30589584 0.35126364 0.27688643\n",
      " 0.32696483 0.34265316 0.41707107 0.42713723 0.31425023 0.33271986\n",
      " 0.31140006 0.30306357 0.27675977 0.34186336 0.27789205 0.26194483\n",
      " 0.22033535 0.16322957 0.36611241 0.41006386 0.37581599 0.3313958\n",
      " 0.15194245 0.21623373 0.21845315 0.17999424 0.10424867 0.13668716\n",
      " 0.3214345  0.27927977 0.27179545 0.13143198 0.14679772 0.13935818\n",
      " 0.33305284 0.22960505 0.32349089 0.20745096 0.16966307 0.30969846\n",
      " 0.47375119 0.44697267 0.43845627 0.51503485 0.2457855  0.36881274\n",
      " 0.29773885 0.50260109 0.21659695 0.43655485 0.32562411 0.33701479\n",
      " 0.36550626 0.38433594 0.34352076 0.2821165  0.40799487 0.35280651\n",
      " 0.43125802 0.46970478 0.44502354 0.49942976 0.37583494 0.46626234\n",
      " 0.33941904 0.55602455 0.39571226 0.43361253 0.41329405 0.43730387\n",
      " 0.45807475 0.11621504 0.2273393  0.49455979 0.49808961 0.339277\n",
      " 0.18003143 0.34773371 0.33562443 0.45430699 0.29372239 0.35551286\n",
      " 0.44165775 0.26260287 0.2700091  0.50407618 0.52908361 0.27980345\n",
      " 0.19789612 0.25004455 0.22742957 0.21689051 0.23750836 0.3475987\n",
      " 0.39461923 0.43234006 0.43166927 0.49491146]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 18 [0/54 (0%)]\tTrain Loss: 0.087047\n",
      "Train Epoch: 18 [8/54 (15%)]\tTrain Loss: 0.054323\n",
      "Train Epoch: 18 [16/54 (30%)]\tTrain Loss: 0.161160\n",
      "Train Epoch: 18 [24/54 (44%)]\tTrain Loss: 0.058839\n",
      "Train Epoch: 18 [32/54 (59%)]\tTrain Loss: 0.079947\n",
      "Train Epoch: 18 [40/54 (74%)]\tTrain Loss: 0.048766\n",
      "Train Epoch: 18 [48/54 (89%)]\tTrain Loss: 0.107029\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.5937317  0.65395838 0.60120511 0.59669137 0.56846702 0.77901614\n",
      " 0.59359556 0.63556784 0.78736746 0.07064689 0.22195806 0.10515556\n",
      " 0.26786405 0.66183972 0.77066374 0.48763514 0.46643069 0.63430965\n",
      " 0.4344568  0.6180346  0.56218052 0.53499764 0.6484766  0.5991165\n",
      " 0.47380796 0.68857867 0.70741379 0.70440811 0.67073005 0.7482509\n",
      " 0.8794874  0.84128469 0.5134387  0.21792379 0.3747862  0.23165545\n",
      " 0.33760363 0.59969562 0.6784007  0.61271369 0.65660477 0.53826094\n",
      " 0.60261697 0.59365082 0.55992919 0.78216457 0.65707463 0.6349228\n",
      " 0.88810998 0.76936364 0.9162308  0.20886983 0.60885406 0.39596057\n",
      " 0.60844505 0.35621163 0.79843479 0.30248857 0.40018946 0.82505596\n",
      " 0.89600009 0.77234435 0.87799454 0.90931302 0.78301054 0.5685643\n",
      " 0.65355992 0.69745958 0.70645165 0.81233042 0.7797181  0.77845865\n",
      " 0.83615917 0.81260502 0.83146906 0.75321907 0.72470796 0.68051422\n",
      " 0.84230465 0.90077454 0.8850773  0.9108156  0.89056563 0.76354837\n",
      " 0.78864926 0.91461176 0.80195087 0.84422821 0.43744877 0.52845806\n",
      " 0.52660275 0.5040347  0.69397938 0.68781137 0.74073988 0.55775243\n",
      " 0.24601178 0.66571021 0.54629993 0.71333373 0.47701421 0.80470842\n",
      " 0.50312823 0.81557184 0.78092331 0.91697174 0.93391681 0.03034981\n",
      " 0.00884643 0.0687001  0.02404741 0.0111042  0.01318763 0.43510133\n",
      " 0.69819587 0.66329902 0.55735368 0.49674797]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "Train Epoch: 19 [0/54 (0%)]\tTrain Loss: 0.076789\n",
      "Train Epoch: 19 [8/54 (15%)]\tTrain Loss: 0.095428\n",
      "Train Epoch: 19 [16/54 (30%)]\tTrain Loss: 0.083518\n",
      "Train Epoch: 19 [24/54 (44%)]\tTrain Loss: 0.072164\n",
      "Train Epoch: 19 [32/54 (59%)]\tTrain Loss: 0.133353\n",
      "Train Epoch: 19 [40/54 (74%)]\tTrain Loss: 0.133271\n",
      "Train Epoch: 19 [48/54 (89%)]\tTrain Loss: 0.052867\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.9992975  0.9998455  0.99878937 0.93958127 0.90340376 0.99586272\n",
      " 0.99936432 0.94536412 0.95521593 0.27707866 0.18475151 0.10020691\n",
      " 0.40477768 0.96138346 0.99539882 0.56741935 0.25416937 0.48291758\n",
      " 0.11296922 0.23174979 0.3357363  0.27606347 0.35442087 0.48854727\n",
      " 0.22496866 0.33205134 0.60603064 0.61872309 0.4796913  0.56467694\n",
      " 0.98134148 0.99304068 0.98510158 0.11927334 0.13597149 0.08562079\n",
      " 0.08934847 0.56834853 0.69702011 0.59218627 0.74880308 0.40247884\n",
      " 0.70436251 0.64442986 0.76202738 0.99902773 0.99999571 0.99999249\n",
      " 0.9999969  0.9254657  0.99999237 0.35226139 0.55872709 0.71016437\n",
      " 0.42309952 0.22389443 0.87450629 0.22845125 0.09881607 0.99336666\n",
      " 0.99925345 0.97925299 0.99712068 0.9995597  0.94682956 0.67220795\n",
      " 0.7100392  0.95576781 0.93928093 0.94269043 0.99530268 0.99376702\n",
      " 0.98282123 0.90230715 0.90776056 0.98273635 0.99999917 0.99999928\n",
      " 0.99995387 0.99980193 0.99908638 0.99959654 0.99796379 0.88704377\n",
      " 0.88883859 0.99879068 0.99149007 0.99416417 0.14097734 0.13359302\n",
      " 0.37079489 0.71103776 0.86996979 0.48077035 0.48316446 0.21687704\n",
      " 0.08881886 0.86675292 0.55297261 0.75415921 0.44146869 0.99953556\n",
      " 0.42081514 0.96529263 0.93330348 0.99446702 0.9969824  0.02907191\n",
      " 0.0291764  0.04406252 0.03393406 0.04382722 0.04757141 0.13124998\n",
      " 0.9547379  0.90209532 0.60228246 0.78629619]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [0/54 (0%)]\tTrain Loss: 0.089357\n",
      "Train Epoch: 20 [8/54 (15%)]\tTrain Loss: 0.080170\n",
      "Train Epoch: 20 [16/54 (30%)]\tTrain Loss: 0.084322\n",
      "Train Epoch: 20 [24/54 (44%)]\tTrain Loss: 0.099782\n",
      "Train Epoch: 20 [32/54 (59%)]\tTrain Loss: 0.072266\n",
      "Train Epoch: 20 [40/54 (74%)]\tTrain Loss: 0.061651\n",
      "Train Epoch: 20 [48/54 (89%)]\tTrain Loss: 0.091822\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.33510479 0.76706141 0.7467407  0.18552892 0.18210623 0.45013776\n",
      " 0.77851754 0.22373214 0.27428058 0.08849983 0.10268483 0.06862346\n",
      " 0.1214909  0.80948603 0.82823282 0.1962661  0.20281187 0.09589476\n",
      " 0.22798985 0.56423783 0.60055941 0.2109717  0.34094864 0.64386827\n",
      " 0.39895663 0.50715601 0.69374096 0.48619616 0.14500397 0.16596788\n",
      " 0.68977201 0.38594186 0.50072777 0.24306205 0.37500042 0.13351831\n",
      " 0.20280297 0.10790699 0.20084968 0.56012344 0.53031629 0.51588708\n",
      " 0.08369854 0.15045966 0.18666403 0.48136264 0.42865446 0.52625221\n",
      " 0.80990368 0.52237898 0.81505287 0.0604615  0.20379813 0.14647444\n",
      " 0.60349435 0.17384136 0.5897072  0.26496994 0.07948931 0.17643622\n",
      " 0.84075999 0.82666844 0.82369649 0.79600501 0.50238329 0.38941216\n",
      " 0.14287308 0.84098876 0.4241198  0.65563291 0.63175124 0.55413651\n",
      " 0.42832723 0.2921907  0.48032323 0.56537372 0.6488179  0.66675103\n",
      " 0.91392261 0.67120165 0.69077301 0.80683672 0.76297796 0.4927941\n",
      " 0.3472878  0.68348312 0.53928363 0.6054951  0.41224986 0.6573019\n",
      " 0.73662692 0.16555913 0.23911077 0.83520705 0.75426543 0.62732184\n",
      " 0.17215273 0.35296881 0.51344633 0.79167706 0.3863925  0.50227815\n",
      " 0.29624659 0.66644025 0.66701567 0.83681852 0.84677482 0.06007503\n",
      " 0.06575727 0.05715539 0.05541685 0.09915214 0.31551862 0.55815256\n",
      " 0.74695438 0.59472936 0.71356851 0.81676662]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "vote_pred [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 25 TN= 47 FN= 33 FP= 13\n",
      "TP+FP 38\n",
      "precision 0.6578947368421053\n",
      "recall 0.43103448275862066\n",
      "F1 0.5208333333333334\n",
      "acc 0.6101694915254238\n",
      "AUCp 0.607183908045977\n",
      "AUC 0.6870689655172413\n",
      "\n",
      " The epoch is 20, average recall: 0.4310, average precision: 0.6579,average F1: 0.5208, average accuracy: 0.6102, average AUC: 0.6871\n",
      "Train Epoch: 21 [0/54 (0%)]\tTrain Loss: 0.088823\n",
      "Train Epoch: 21 [8/54 (15%)]\tTrain Loss: 0.088622\n",
      "Train Epoch: 21 [16/54 (30%)]\tTrain Loss: 0.084564\n",
      "Train Epoch: 21 [24/54 (44%)]\tTrain Loss: 0.047108\n",
      "Train Epoch: 21 [32/54 (59%)]\tTrain Loss: 0.045498\n",
      "Train Epoch: 21 [40/54 (74%)]\tTrain Loss: 0.069636\n",
      "Train Epoch: 21 [48/54 (89%)]\tTrain Loss: 0.080991\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.88289261 0.99486732 0.99329561 0.95340002 0.97288233 0.9905923\n",
      " 0.99374604 0.99396026 0.97174859 0.33257824 0.53666228 0.25970837\n",
      " 0.35575241 0.93212712 0.76485956 0.31309628 0.83873552 0.13552727\n",
      " 0.17487998 0.50363231 0.73207641 0.3610709  0.59593844 0.8626833\n",
      " 0.29913402 0.59487981 0.78249186 0.7454682  0.2566686  0.44362882\n",
      " 0.80779254 0.544415   0.53908044 0.08342987 0.15328196 0.10854823\n",
      " 0.15350133 0.42840737 0.36109945 0.32133356 0.2978301  0.29935673\n",
      " 0.49942586 0.36199486 0.59058923 0.68267602 0.99217153 0.99438018\n",
      " 0.98629552 0.77111608 0.99586898 0.18672302 0.78440577 0.91649777\n",
      " 0.49662706 0.74143004 0.7749204  0.56840366 0.19642697 0.86356223\n",
      " 0.78182197 0.71647286 0.77078211 0.79888296 0.97699696 0.81877232\n",
      " 0.67298031 0.98878586 0.94423431 0.46993241 0.98046815 0.97800571\n",
      " 0.50303954 0.46017432 0.75764108 0.87586635 0.96829289 0.97792643\n",
      " 0.99926299 0.67017347 0.75864655 0.87621725 0.82839918 0.83079576\n",
      " 0.8475284  0.41996765 0.73557079 0.91997683 0.3987118  0.4466562\n",
      " 0.69268185 0.38932744 0.47851062 0.95130754 0.84367114 0.83108902\n",
      " 0.43951371 0.3350344  0.42978323 0.49656701 0.28754994 0.63888782\n",
      " 0.19776212 0.68592548 0.63564986 0.74471271 0.79563266 0.02829893\n",
      " 0.03722339 0.07284682 0.04743708 0.03020717 0.0507468  0.3821615\n",
      " 0.29056969 0.40984085 0.22173963 0.34115851]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 22 [0/54 (0%)]\tTrain Loss: 0.082496\n",
      "Train Epoch: 22 [8/54 (15%)]\tTrain Loss: 0.088186\n",
      "Train Epoch: 22 [16/54 (30%)]\tTrain Loss: 0.066398\n",
      "Train Epoch: 22 [24/54 (44%)]\tTrain Loss: 0.102184\n",
      "Train Epoch: 22 [32/54 (59%)]\tTrain Loss: 0.062741\n",
      "Train Epoch: 22 [40/54 (74%)]\tTrain Loss: 0.062522\n",
      "Train Epoch: 22 [48/54 (89%)]\tTrain Loss: 0.063716\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.79475397 0.91624224 0.89862871 0.86536485 0.79274619 0.90520287\n",
      " 0.88946098 0.86891705 0.78749001 0.49575654 0.56823349 0.44814959\n",
      " 0.49989957 0.79110861 0.79593283 0.6185813  0.72111338 0.40953055\n",
      " 0.450293   0.60805124 0.75245333 0.50424534 0.63786542 0.75444371\n",
      " 0.63289064 0.76347381 0.84120059 0.76001006 0.44752619 0.43230858\n",
      " 0.71418405 0.72057796 0.63567561 0.61894876 0.63871431 0.53254384\n",
      " 0.64915472 0.58079648 0.70370239 0.80574286 0.68075114 0.7435863\n",
      " 0.6123336  0.61645859 0.60515827 0.71315807 0.9368642  0.93255466\n",
      " 0.96432787 0.85058069 0.95933163 0.38460517 0.67635375 0.7601133\n",
      " 0.70868987 0.62948936 0.8212263  0.59594119 0.33173817 0.72431266\n",
      " 0.88525915 0.82382405 0.87640327 0.86521268 0.87624526 0.85722733\n",
      " 0.80277246 0.90360975 0.87765169 0.78967214 0.88325191 0.86072052\n",
      " 0.74935961 0.78385925 0.82559669 0.83405828 0.92573154 0.94462305\n",
      " 0.96637785 0.90619177 0.91756272 0.94749552 0.92142349 0.77977496\n",
      " 0.77921641 0.78139728 0.85538793 0.89987338 0.59254116 0.76719218\n",
      " 0.85969126 0.75124681 0.77121025 0.93405926 0.88097364 0.85773063\n",
      " 0.43376526 0.70373589 0.79162598 0.90414721 0.71498007 0.83224666\n",
      " 0.52495545 0.86361235 0.84698945 0.88268542 0.87426639 0.27723041\n",
      " 0.24417897 0.32928878 0.29068267 0.2974017  0.51610583 0.71106446\n",
      " 0.7955516  0.65430838 0.5341053  0.6802879 ]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [0/54 (0%)]\tTrain Loss: 0.098409\n",
      "Train Epoch: 23 [8/54 (15%)]\tTrain Loss: 0.100795\n",
      "Train Epoch: 23 [16/54 (30%)]\tTrain Loss: 0.068916\n",
      "Train Epoch: 23 [24/54 (44%)]\tTrain Loss: 0.080562\n",
      "Train Epoch: 23 [32/54 (59%)]\tTrain Loss: 0.117051\n",
      "Train Epoch: 23 [40/54 (74%)]\tTrain Loss: 0.084272\n",
      "Train Epoch: 23 [48/54 (89%)]\tTrain Loss: 0.073021\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.99992919 0.99999964 0.99999857 0.99842107 0.99312454 0.9985916\n",
      " 0.99999988 0.99971431 0.9729346  0.47860104 0.55301458 0.12144654\n",
      " 0.5954147  0.96885306 0.9951846  0.88570905 0.88376212 0.89986914\n",
      " 0.62176692 0.73761457 0.84730339 0.95523304 0.98610759 0.9669503\n",
      " 0.88975942 0.95377624 0.99221766 0.94995576 0.61649591 0.70902967\n",
      " 0.99886835 0.99883848 0.99954116 0.80612254 0.52179939 0.6453855\n",
      " 0.72060561 0.94904059 0.88324177 0.93073642 0.82813692 0.85371\n",
      " 0.95226121 0.96901381 0.96250111 0.99878579 0.99999928 0.99999821\n",
      " 0.99999988 0.99346328 0.99999976 0.76896048 0.81883299 0.98512161\n",
      " 0.84125501 0.76938075 0.98981363 0.57017899 0.55037707 0.99717206\n",
      " 0.99934405 0.9963212  0.99946445 0.99970371 0.99749112 0.99735236\n",
      " 0.9961428  0.99916649 0.99960464 0.99434412 0.99998212 0.99994624\n",
      " 0.99893528 0.99774027 0.98610306 0.99993157 1.         1.\n",
      " 0.9999994  0.99997973 0.99998415 0.99999464 0.99998522 0.98188639\n",
      " 0.96905434 0.99816811 0.99912471 0.99985313 0.45373186 0.85335606\n",
      " 0.94583249 0.98455286 0.97842491 0.98721075 0.98451322 0.88799191\n",
      " 0.38851467 0.97490001 0.96973825 0.99230278 0.91464716 0.99997199\n",
      " 0.967632   0.99687994 0.99287778 0.99761295 0.99966455 0.10415444\n",
      " 0.08786616 0.1484471  0.06772275 0.08306399 0.39136532 0.53467661\n",
      " 0.86469173 0.96401876 0.99992967 0.9998005 ]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 24 [0/54 (0%)]\tTrain Loss: 0.039974\n",
      "Train Epoch: 24 [8/54 (15%)]\tTrain Loss: 0.073795\n",
      "Train Epoch: 24 [16/54 (30%)]\tTrain Loss: 0.078548\n",
      "Train Epoch: 24 [24/54 (44%)]\tTrain Loss: 0.034230\n",
      "Train Epoch: 24 [32/54 (59%)]\tTrain Loss: 0.076005\n",
      "Train Epoch: 24 [40/54 (74%)]\tTrain Loss: 0.059527\n",
      "Train Epoch: 24 [48/54 (89%)]\tTrain Loss: 0.087461\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.38613549 0.85776764 0.83974558 0.56840509 0.57184088 0.21346419\n",
      " 0.83997017 0.71344978 0.11408671 0.05965387 0.60817713 0.12180223\n",
      " 0.43191451 0.77815765 0.69191694 0.46162921 0.74167591 0.10343441\n",
      " 0.19023825 0.52094525 0.5969944  0.39766198 0.50805759 0.56951433\n",
      " 0.49430671 0.67641318 0.78573483 0.86934358 0.35300449 0.46895751\n",
      " 0.88728696 0.70633811 0.68848079 0.57139111 0.59582365 0.6359219\n",
      " 0.5193463  0.52667695 0.38152644 0.71021634 0.67879379 0.54647344\n",
      " 0.20230547 0.40189594 0.38669983 0.58294666 0.73785675 0.65246093\n",
      " 0.88206726 0.2842184  0.85934615 0.21802205 0.64223051 0.54306358\n",
      " 0.35133782 0.55792749 0.70343477 0.81553423 0.12379593 0.69811767\n",
      " 0.4423368  0.29438153 0.45078868 0.47439948 0.8176235  0.91880167\n",
      " 0.83828074 0.82637638 0.96916759 0.63071096 0.43771356 0.39378574\n",
      " 0.86638051 0.61190128 0.74170572 0.66521746 0.86473227 0.84357733\n",
      " 0.90457278 0.90900481 0.92770028 0.97327244 0.88337159 0.28578395\n",
      " 0.287424   0.46603209 0.63061231 0.72658521 0.87095237 0.82101738\n",
      " 0.87035912 0.6685521  0.53694266 0.9825964  0.9490298  0.94910228\n",
      " 0.51566792 0.45184344 0.5052771  0.96015245 0.18018121 0.67708629\n",
      " 0.19268849 0.81296933 0.65441591 0.71444386 0.80814499 0.07197963\n",
      " 0.11768831 0.05760336 0.10938583 0.25622311 0.79504746 0.76838851\n",
      " 0.29445097 0.15677062 0.59661329 0.64745134]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 25 [0/54 (0%)]\tTrain Loss: 0.052942\n",
      "Train Epoch: 25 [8/54 (15%)]\tTrain Loss: 0.048272\n",
      "Train Epoch: 25 [16/54 (30%)]\tTrain Loss: 0.080828\n",
      "Train Epoch: 25 [24/54 (44%)]\tTrain Loss: 0.051570\n",
      "Train Epoch: 25 [32/54 (59%)]\tTrain Loss: 0.071756\n",
      "Train Epoch: 25 [40/54 (74%)]\tTrain Loss: 0.051418\n",
      "Train Epoch: 25 [48/54 (89%)]\tTrain Loss: 0.090011\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.18043765 0.85732621 0.84312981 0.37241232 0.31944203 0.20569086\n",
      " 0.80439973 0.44810656 0.14688462 0.03561902 0.19472812 0.03311401\n",
      " 0.10964938 0.37841457 0.42150304 0.2102237  0.3576006  0.17937766\n",
      " 0.33737341 0.35485601 0.54270369 0.32367745 0.47332677 0.46773446\n",
      " 0.41987535 0.60536253 0.55754632 0.58839679 0.22433226 0.27576903\n",
      " 0.54529083 0.43271291 0.35957488 0.27110514 0.12663484 0.20694816\n",
      " 0.18215799 0.27086255 0.30204216 0.56827891 0.50423074 0.39688489\n",
      " 0.1131371  0.19226299 0.2337392  0.28098387 0.74042046 0.69080162\n",
      " 0.91009188 0.63440412 0.88395876 0.04989862 0.30775604 0.26109549\n",
      " 0.25016311 0.10848582 0.57157576 0.3163527  0.12125832 0.35905248\n",
      " 0.58360583 0.50159144 0.49129617 0.47735196 0.63382953 0.63952804\n",
      " 0.55084199 0.72308677 0.8696143  0.64551854 0.78705406 0.72828746\n",
      " 0.67750663 0.46980053 0.55840164 0.60214365 0.93572217 0.94467688\n",
      " 0.94323599 0.83625984 0.83464915 0.92654103 0.73447675 0.4251596\n",
      " 0.47077349 0.55512053 0.71870816 0.74714607 0.62973952 0.38570988\n",
      " 0.80065149 0.21128131 0.25165913 0.94536316 0.91348761 0.81984657\n",
      " 0.36391088 0.48861676 0.6819461  0.9337067  0.31974363 0.53904456\n",
      " 0.32668331 0.77400887 0.50463372 0.79645199 0.79385334 0.07891127\n",
      " 0.13453588 0.05164348 0.1100067  0.11486411 0.22035196 0.60679936\n",
      " 0.48755038 0.3499181  0.36851612 0.43065739]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 26 [0/54 (0%)]\tTrain Loss: 0.080410\n",
      "Train Epoch: 26 [8/54 (15%)]\tTrain Loss: 0.070145\n",
      "Train Epoch: 26 [16/54 (30%)]\tTrain Loss: 0.105472\n",
      "Train Epoch: 26 [24/54 (44%)]\tTrain Loss: 0.048644\n",
      "Train Epoch: 26 [32/54 (59%)]\tTrain Loss: 0.033392\n",
      "Train Epoch: 26 [40/54 (74%)]\tTrain Loss: 0.041111\n",
      "Train Epoch: 26 [48/54 (89%)]\tTrain Loss: 0.062637\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.88683194 0.99811387 0.98917413 0.81836456 0.60721749 0.98190963\n",
      " 0.98368722 0.85222429 0.86212188 0.15265283 0.24709985 0.06899714\n",
      " 0.41304374 0.84949911 0.95210201 0.35742262 0.33004752 0.12900713\n",
      " 0.08135641 0.35117203 0.25767732 0.35631764 0.3016592  0.56396401\n",
      " 0.22462749 0.42113784 0.60535318 0.50608981 0.2535291  0.46725234\n",
      " 0.87642974 0.67577147 0.72901851 0.04941478 0.09712262 0.04432294\n",
      " 0.05151215 0.56745791 0.6536988  0.49770719 0.55533051 0.50632888\n",
      " 0.68703693 0.39030826 0.42967498 0.79225379 0.9765529  0.9724471\n",
      " 0.99517822 0.88954633 0.99680197 0.10331385 0.66328073 0.72767484\n",
      " 0.50050282 0.25539562 0.80003464 0.29610014 0.02520235 0.81345135\n",
      " 0.98056304 0.8315087  0.96739131 0.98853672 0.91581148 0.67590064\n",
      " 0.78508717 0.87544072 0.86316574 0.88994819 0.84780186 0.87199396\n",
      " 0.89273286 0.92966706 0.92842984 0.98481905 0.99979025 0.99959725\n",
      " 0.99967682 0.98815048 0.98628682 0.99646497 0.98859614 0.84363204\n",
      " 0.96317255 0.88908148 0.9547537  0.98268467 0.20425864 0.26048627\n",
      " 0.58822882 0.78775764 0.71252584 0.64836842 0.55021584 0.51865852\n",
      " 0.24876301 0.67355692 0.5039081  0.58498132 0.57680321 0.97449017\n",
      " 0.25539154 0.88412297 0.73147577 0.93897915 0.94257128 0.03453768\n",
      " 0.07683013 0.02611025 0.05097286 0.08005727 0.16751589 0.17043103\n",
      " 0.48783773 0.68456888 0.36382687 0.35376236]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 27 [0/54 (0%)]\tTrain Loss: 0.073801\n",
      "Train Epoch: 27 [8/54 (15%)]\tTrain Loss: 0.040805\n",
      "Train Epoch: 27 [16/54 (30%)]\tTrain Loss: 0.028807\n",
      "Train Epoch: 27 [24/54 (44%)]\tTrain Loss: 0.036820\n",
      "Train Epoch: 27 [32/54 (59%)]\tTrain Loss: 0.044970\n",
      "Train Epoch: 27 [40/54 (74%)]\tTrain Loss: 0.091508\n",
      "Train Epoch: 27 [48/54 (89%)]\tTrain Loss: 0.069907\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.60990787 0.87285084 0.83522916 0.35072964 0.33919087 0.32158858\n",
      " 0.84104264 0.35333261 0.19619009 0.10862952 0.18353762 0.09996722\n",
      " 0.20233402 0.52701473 0.66457611 0.21987326 0.21574143 0.11155052\n",
      " 0.20004973 0.33407378 0.34663829 0.17659627 0.38200787 0.51001173\n",
      " 0.2776272  0.54521674 0.70079601 0.49131936 0.24431413 0.32219061\n",
      " 0.75150073 0.41063204 0.51202017 0.19050987 0.21459933 0.18530123\n",
      " 0.23813593 0.20294221 0.22278583 0.41451225 0.45519868 0.32237703\n",
      " 0.13854621 0.18326762 0.23688722 0.31274939 0.76781672 0.70813149\n",
      " 0.93916827 0.49198633 0.96494484 0.07893907 0.30503443 0.23896797\n",
      " 0.33630413 0.17436731 0.42338988 0.25623316 0.26044843 0.40984511\n",
      " 0.7859925  0.65353978 0.76417708 0.77180582 0.5652982  0.46476939\n",
      " 0.28227654 0.87381387 0.75785917 0.25156444 0.66975969 0.66612059\n",
      " 0.71399319 0.46177787 0.70398122 0.58216184 0.9480744  0.92230362\n",
      " 0.9502098  0.8517518  0.91941023 0.95310044 0.89174008 0.3968516\n",
      " 0.44594261 0.42250395 0.75470561 0.80108738 0.57063329 0.59415114\n",
      " 0.79891777 0.14163513 0.33553648 0.83811337 0.75673681 0.66447842\n",
      " 0.23612925 0.43627465 0.42433912 0.65142703 0.40794915 0.69709659\n",
      " 0.29999113 0.42960623 0.35899332 0.65964419 0.67907065 0.18479443\n",
      " 0.13700421 0.11442979 0.13398063 0.24639444 0.38968876 0.49734089\n",
      " 0.48149264 0.3318997  0.7476052  0.71098888]\n",
      "predict [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 28 [0/54 (0%)]\tTrain Loss: 0.079350\n",
      "Train Epoch: 28 [8/54 (15%)]\tTrain Loss: 0.065629\n",
      "Train Epoch: 28 [16/54 (30%)]\tTrain Loss: 0.048516\n",
      "Train Epoch: 28 [24/54 (44%)]\tTrain Loss: 0.068457\n",
      "Train Epoch: 28 [32/54 (59%)]\tTrain Loss: 0.072594\n",
      "Train Epoch: 28 [40/54 (74%)]\tTrain Loss: 0.073666\n",
      "Train Epoch: 28 [48/54 (89%)]\tTrain Loss: 0.048156\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.4124684  0.97494745 0.89736956 0.48709857 0.26700318 0.17989072\n",
      " 0.89053392 0.46182823 0.123451   0.09320333 0.30261812 0.05981364\n",
      " 0.4500812  0.44219279 0.66607022 0.36146507 0.22632129 0.13621178\n",
      " 0.15839587 0.23695053 0.35333854 0.24430861 0.35797361 0.78568351\n",
      " 0.2627269  0.41411874 0.65134799 0.45635819 0.17653446 0.26031625\n",
      " 0.68235296 0.4300335  0.62595856 0.10758144 0.13673617 0.15158184\n",
      " 0.22202338 0.30454087 0.24610628 0.37321407 0.32049364 0.38697025\n",
      " 0.16760835 0.25322074 0.20766856 0.28430912 0.75039923 0.7492795\n",
      " 0.95558393 0.35791314 0.88430673 0.06707956 0.14243187 0.61530429\n",
      " 0.20754841 0.15748927 0.55133134 0.20358832 0.3359172  0.21924621\n",
      " 0.71901232 0.71583086 0.82251751 0.86315703 0.40685514 0.41369924\n",
      " 0.24581403 0.91073459 0.50524986 0.25088355 0.67176706 0.65325946\n",
      " 0.29324636 0.25495607 0.37010425 0.89144701 0.99247402 0.99226135\n",
      " 0.99859315 0.91215897 0.75336748 0.86964905 0.88294667 0.46792382\n",
      " 0.94342291 0.52631444 0.92515653 0.89777535 0.34703445 0.47713482\n",
      " 0.54291463 0.17995629 0.27876455 0.79325694 0.26180747 0.28148517\n",
      " 0.13403779 0.63771921 0.40732834 0.51819408 0.7357114  0.88117617\n",
      " 0.29785046 0.42848212 0.25179499 0.30213925 0.66776222 0.26987901\n",
      " 0.31085524 0.10519195 0.23321146 0.2110617  0.21210313 0.28967991\n",
      " 0.38015306 0.49773297 0.71367687 0.71337098]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 29 [0/54 (0%)]\tTrain Loss: 0.138858\n",
      "Train Epoch: 29 [8/54 (15%)]\tTrain Loss: 0.037719\n",
      "Train Epoch: 29 [16/54 (30%)]\tTrain Loss: 0.043247\n",
      "Train Epoch: 29 [24/54 (44%)]\tTrain Loss: 0.044489\n",
      "Train Epoch: 29 [32/54 (59%)]\tTrain Loss: 0.047783\n",
      "Train Epoch: 29 [40/54 (74%)]\tTrain Loss: 0.073006\n",
      "Train Epoch: 29 [48/54 (89%)]\tTrain Loss: 0.058480\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.09559379 0.22953545 0.206404   0.12895697 0.20561686 0.136619\n",
      " 0.39611766 0.16003196 0.17376679 0.17230003 0.28398493 0.2696915\n",
      " 0.13200013 0.24940076 0.30908999 0.19460386 0.25364137 0.14657809\n",
      " 0.21917485 0.26508445 0.56208777 0.1248382  0.2533474  0.40296\n",
      " 0.23692168 0.49989414 0.7815069  0.55067897 0.15171741 0.15943815\n",
      " 0.67432684 0.21011405 0.09763483 0.28740749 0.31792817 0.26583442\n",
      " 0.23081183 0.22141959 0.36560848 0.45783406 0.45426044 0.35106888\n",
      " 0.12278296 0.13658801 0.14108902 0.27873152 0.23821504 0.08367532\n",
      " 0.67194569 0.78199399 0.68516445 0.06459293 0.29034543 0.13499309\n",
      " 0.52569151 0.15158525 0.38365403 0.22262855 0.28235298 0.235074\n",
      " 0.38302514 0.33423442 0.19637109 0.21179828 0.23233774 0.29304421\n",
      " 0.34261268 0.41899961 0.56779498 0.91005898 0.26390404 0.19590639\n",
      " 0.85600704 0.58499074 0.70653355 0.21465866 0.19518977 0.16133659\n",
      " 0.62976682 0.36389732 0.56744218 0.82513601 0.6269781  0.35897946\n",
      " 0.17550245 0.31024432 0.4005588  0.41249323 0.54306644 0.43933374\n",
      " 0.85473692 0.30380714 0.49652371 0.96491551 0.94273961 0.85033184\n",
      " 0.27353004 0.33741748 0.3112219  0.93722701 0.19628386 0.24956354\n",
      " 0.19088167 0.83492208 0.63177806 0.89379954 0.96499389 0.09575161\n",
      " 0.1411829  0.09353219 0.12093014 0.27616394 0.38719705 0.72461128\n",
      " 0.27513444 0.16182421 0.37464237 0.34132504]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 30 [0/54 (0%)]\tTrain Loss: 0.087374\n",
      "Train Epoch: 30 [8/54 (15%)]\tTrain Loss: 0.062491\n",
      "Train Epoch: 30 [16/54 (30%)]\tTrain Loss: 0.094432\n",
      "Train Epoch: 30 [24/54 (44%)]\tTrain Loss: 0.071434\n",
      "Train Epoch: 30 [32/54 (59%)]\tTrain Loss: 0.062757\n",
      "Train Epoch: 30 [40/54 (74%)]\tTrain Loss: 0.107816\n",
      "Train Epoch: 30 [48/54 (89%)]\tTrain Loss: 0.060370\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.32013449 0.83043802 0.84950292 0.10632715 0.2437567  0.44270965\n",
      " 0.58005989 0.16284509 0.12877953 0.04517113 0.12346467 0.02001025\n",
      " 0.04796847 0.3492074  0.32159129 0.01832145 0.02927716 0.06106947\n",
      " 0.05795763 0.30272147 0.4498491  0.06294115 0.22878689 0.59431607\n",
      " 0.05066093 0.30845615 0.65300256 0.27902028 0.04152611 0.0881221\n",
      " 0.54767662 0.17367584 0.40541488 0.02441376 0.04411187 0.04622491\n",
      " 0.06203218 0.0725421  0.04443134 0.12557635 0.13956083 0.11185591\n",
      " 0.13302799 0.07100771 0.04366662 0.07235752 0.17565691 0.15234891\n",
      " 0.54395854 0.22807033 0.66360968 0.00878603 0.15685754 0.047599\n",
      " 0.34084198 0.03874933 0.49312589 0.04729779 0.03941892 0.05530763\n",
      " 0.47650841 0.44097537 0.57381558 0.62653375 0.33506301 0.22969837\n",
      " 0.32199743 0.58225995 0.51291919 0.22652625 0.15657109 0.13765779\n",
      " 0.38765949 0.29660937 0.37345701 0.75785977 0.7315793  0.75275755\n",
      " 0.75405681 0.41217399 0.69507635 0.85083079 0.93768334 0.18231659\n",
      " 0.2175837  0.21310887 0.34530428 0.65646595 0.24246481 0.21093313\n",
      " 0.45210913 0.35646144 0.12464049 0.80221891 0.40752125 0.52422422\n",
      " 0.08064    0.05886259 0.13818233 0.32038555 0.14751352 0.33888322\n",
      " 0.04487365 0.24896297 0.60173368 0.55654907 0.56304693 0.03042241\n",
      " 0.02744288 0.05804065 0.01934397 0.09319206 0.05813074 0.14506252\n",
      " 0.02544231 0.0417697  0.14613689 0.14939466]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "vote_pred [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 34 TN= 41 FN= 24 FP= 19\n",
      "TP+FP 53\n",
      "precision 0.6415094339622641\n",
      "recall 0.5862068965517241\n",
      "F1 0.6126126126126126\n",
      "acc 0.635593220338983\n",
      "AUCp 0.6347701149425288\n",
      "AUC 0.6836206896551725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 30, average recall: 0.5862, average precision: 0.6415,average F1: 0.6126, average accuracy: 0.6356, average AUC: 0.6836\n",
      "Train Epoch: 31 [0/54 (0%)]\tTrain Loss: 0.061140\n",
      "Train Epoch: 31 [8/54 (15%)]\tTrain Loss: 0.070408\n",
      "Train Epoch: 31 [16/54 (30%)]\tTrain Loss: 0.061852\n",
      "Train Epoch: 31 [24/54 (44%)]\tTrain Loss: 0.081944\n",
      "Train Epoch: 31 [32/54 (59%)]\tTrain Loss: 0.098950\n",
      "Train Epoch: 31 [40/54 (74%)]\tTrain Loss: 0.033203\n",
      "Train Epoch: 31 [48/54 (89%)]\tTrain Loss: 0.068100\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.99424052 0.99991214 0.99411064 0.82036322 0.98951602 0.99986291\n",
      " 0.99846494 0.9974044  0.75274295 0.56164247 0.92290717 0.18072815\n",
      " 0.70370781 0.94428313 0.85308373 0.36419293 0.5781641  0.33445215\n",
      " 0.33221552 0.59865952 0.81823403 0.37443948 0.76360106 0.95764989\n",
      " 0.31612629 0.85467809 0.96953672 0.78406185 0.36399776 0.6653778\n",
      " 0.9982394  0.95285928 0.99372572 0.33326465 0.37127417 0.51512152\n",
      " 0.58564496 0.79165238 0.94200319 0.63335472 0.94650984 0.55336863\n",
      " 0.99850595 0.79742604 0.7485714  0.95494246 0.99930167 0.9973911\n",
      " 0.99946553 0.82980752 0.99997938 0.26063618 0.99963427 0.98445791\n",
      " 0.69378209 0.73499584 0.99383473 0.73590434 0.54862696 0.93999547\n",
      " 0.99996257 0.99972969 0.99999094 0.99996936 0.99946803 0.98052281\n",
      " 0.98841965 0.99011362 0.98802733 0.97196871 0.98793948 0.98416394\n",
      " 0.95313847 0.9682399  0.9998492  0.99999857 0.99979979 0.99995327\n",
      " 0.99999821 0.99762362 0.99926132 0.99999416 0.99966812 0.98057163\n",
      " 0.99996161 0.85338932 0.9554649  0.99998951 0.58178759 0.68620628\n",
      " 0.85482168 0.99595523 0.82184255 0.99013925 0.96098918 0.95761687\n",
      " 0.780114   0.6107282  0.74775892 0.93096149 0.97702324 0.9908393\n",
      " 0.25603124 0.98651832 0.99954802 0.99647659 0.97836167 0.41803282\n",
      " 0.18150669 0.43702653 0.22570844 0.32291314 0.79998213 0.47088444\n",
      " 0.18977025 0.25479117 0.78926373 0.73699099]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 32 [0/54 (0%)]\tTrain Loss: 0.147181\n",
      "Train Epoch: 32 [8/54 (15%)]\tTrain Loss: 0.064584\n",
      "Train Epoch: 32 [16/54 (30%)]\tTrain Loss: 0.063583\n",
      "Train Epoch: 32 [24/54 (44%)]\tTrain Loss: 0.043239\n",
      "Train Epoch: 32 [32/54 (59%)]\tTrain Loss: 0.057164\n",
      "Train Epoch: 32 [40/54 (74%)]\tTrain Loss: 0.060163\n",
      "Train Epoch: 32 [48/54 (89%)]\tTrain Loss: 0.056925\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.96145034 0.97840595 0.93860495 0.93263918 0.91078949 0.87393361\n",
      " 0.99475855 0.95185751 0.63930953 0.27516526 0.92122555 0.07179958\n",
      " 0.91465777 0.92514431 0.94262159 0.89666015 0.91261846 0.57040101\n",
      " 0.44248426 0.6943956  0.86046892 0.60657811 0.81216067 0.91310996\n",
      " 0.79936206 0.92903817 0.97796053 0.94821781 0.66986972 0.71034038\n",
      " 0.99970919 0.99176073 0.98117024 0.78244227 0.7024346  0.78689694\n",
      " 0.78590965 0.95247185 0.77043134 0.94489133 0.98456615 0.9824639\n",
      " 0.62706256 0.9422726  0.82207185 0.92414331 0.99981409 0.98807901\n",
      " 0.9991585  0.82032812 0.9998678  0.24799961 0.95226496 0.92995471\n",
      " 0.62076861 0.7599901  0.99674451 0.8845188  0.6497494  0.94561088\n",
      " 0.99805897 0.99963987 0.99364871 0.99960047 0.99043536 0.99824202\n",
      " 0.99567997 0.99778062 0.99913019 0.99306935 0.98547351 0.97667456\n",
      " 0.99635482 0.99602413 0.98634791 0.9865942  0.99549341 0.98699981\n",
      " 0.99995399 0.99972302 0.9996562  0.99999094 0.99989533 0.99873477\n",
      " 0.99688727 0.98332042 0.98390955 0.99974269 0.83688277 0.93863416\n",
      " 0.98048776 0.99239445 0.93499595 0.99822932 0.99440312 0.99101955\n",
      " 0.77885336 0.89391619 0.92173362 0.99871111 0.97994483 0.99832433\n",
      " 0.64243424 0.9961068  0.9962799  0.9985562  0.99942482 0.5554387\n",
      " 0.2530959  0.60433668 0.47186515 0.3287051  0.95777583 0.7529276\n",
      " 0.85428298 0.76278543 0.93627173 0.89549208]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 33 [0/54 (0%)]\tTrain Loss: 0.033707\n",
      "Train Epoch: 33 [8/54 (15%)]\tTrain Loss: 0.064628\n",
      "Train Epoch: 33 [16/54 (30%)]\tTrain Loss: 0.077490\n",
      "Train Epoch: 33 [24/54 (44%)]\tTrain Loss: 0.049047\n",
      "Train Epoch: 33 [32/54 (59%)]\tTrain Loss: 0.112226\n",
      "Train Epoch: 33 [40/54 (74%)]\tTrain Loss: 0.078817\n",
      "Train Epoch: 33 [48/54 (89%)]\tTrain Loss: 0.033496\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.97319680e-01 9.96295750e-01 9.88444924e-01 2.07783580e-01\n",
      " 6.61255568e-02 2.60757327e-01 9.17171061e-01 5.30296862e-01\n",
      " 6.87972456e-02 2.50474480e-03 1.76109709e-02 3.96023039e-03\n",
      " 3.74797843e-02 8.66189748e-02 2.85752326e-01 2.51452718e-02\n",
      " 9.54040140e-03 3.90088968e-02 1.27748866e-02 6.64294437e-02\n",
      " 4.37914506e-02 4.99998331e-02 6.02422245e-02 2.87694007e-01\n",
      " 7.77621521e-03 6.91407174e-02 1.66482646e-02 7.94860348e-02\n",
      " 2.15631183e-02 5.75109273e-02 1.45518929e-01 1.15091905e-01\n",
      " 4.86342907e-01 1.92761421e-03 2.82772281e-03 9.97981895e-03\n",
      " 1.58548281e-02 1.34615287e-01 1.12012867e-02 4.77014435e-03\n",
      " 5.46865212e-03 6.29746774e-03 6.91237822e-02 1.36699945e-01\n",
      " 1.40030667e-01 2.59623289e-01 9.44571793e-01 8.90169919e-01\n",
      " 9.82644260e-01 1.19162276e-01 9.09065008e-01 1.56267099e-02\n",
      " 2.78095841e-01 1.13712832e-01 2.06381418e-02 3.63270827e-02\n",
      " 2.93115199e-01 1.32531486e-02 5.38529232e-02 6.21426046e-01\n",
      " 6.76325500e-01 4.16660100e-01 6.98995471e-01 8.15965116e-01\n",
      " 8.35559428e-01 3.03151846e-01 2.78613627e-01 6.14502251e-01\n",
      " 5.69217622e-01 3.89565468e-01 6.85708582e-01 6.42557442e-01\n",
      " 1.01578102e-01 7.33497888e-02 1.70356497e-01 7.24521518e-01\n",
      " 9.99289155e-01 9.98325884e-01 9.96215522e-01 7.19360948e-01\n",
      " 4.06519115e-01 3.21860433e-01 2.63706416e-01 1.44640580e-01\n",
      " 7.54600391e-02 1.99176818e-01 5.39899230e-01 4.85890687e-01\n",
      " 9.73900128e-03 5.28530264e-03 4.96461941e-03 2.90995054e-02\n",
      " 2.95441933e-02 8.60435888e-02 8.40718020e-03 1.58969313e-02\n",
      " 2.94493549e-02 2.50386819e-02 3.88320424e-02 2.17794324e-03\n",
      " 2.10116375e-02 5.63132703e-01 1.92853156e-02 3.17088962e-01\n",
      " 1.79217741e-01 1.51942194e-01 2.62946904e-01 8.62847010e-05\n",
      " 7.06989977e-06 3.32530384e-04 3.45040353e-05 4.19718702e-07\n",
      " 1.15593923e-06 2.36980501e-03 2.68715229e-02 8.23568851e-02\n",
      " 5.46251126e-02 3.37828137e-02]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 34 [0/54 (0%)]\tTrain Loss: 0.049914\n",
      "Train Epoch: 34 [8/54 (15%)]\tTrain Loss: 0.102985\n",
      "Train Epoch: 34 [16/54 (30%)]\tTrain Loss: 0.057341\n",
      "Train Epoch: 34 [24/54 (44%)]\tTrain Loss: 0.049279\n",
      "Train Epoch: 34 [32/54 (59%)]\tTrain Loss: 0.047849\n",
      "Train Epoch: 34 [40/54 (74%)]\tTrain Loss: 0.025770\n",
      "Train Epoch: 34 [48/54 (89%)]\tTrain Loss: 0.070754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.17293049 0.96527725 0.92455107 0.41965953 0.33141798 0.30317652\n",
      " 0.89160061 0.3812803  0.25732163 0.19934878 0.33581069 0.21878143\n",
      " 0.25729764 0.55003917 0.68551201 0.18609783 0.33566532 0.27847561\n",
      " 0.26508531 0.3196165  0.5499143  0.25802484 0.3909097  0.61922437\n",
      " 0.36576253 0.65741199 0.90484607 0.88034344 0.3844057  0.44679785\n",
      " 0.87873578 0.60347146 0.46572977 0.44428548 0.28518373 0.19161206\n",
      " 0.26929873 0.23888807 0.55038697 0.52361566 0.45449167 0.42225003\n",
      " 0.22533292 0.33010212 0.42406094 0.67418182 0.94803703 0.77710074\n",
      " 0.98768067 0.87795764 0.98483789 0.04830464 0.40861589 0.14667384\n",
      " 0.68223739 0.24948177 0.61175084 0.23704483 0.23007601 0.67534369\n",
      " 0.737643   0.61044592 0.6864748  0.83289152 0.80519891 0.63897812\n",
      " 0.62708032 0.86193973 0.92583537 0.93242604 0.73328286 0.71260917\n",
      " 0.92829269 0.63126034 0.89912599 0.66416764 0.98669839 0.9580248\n",
      " 0.98067492 0.924281   0.93320543 0.97900325 0.93363386 0.65452027\n",
      " 0.41560054 0.83305389 0.76569664 0.79166102 0.75755447 0.74732059\n",
      " 0.96150851 0.28879803 0.6329897  0.99614078 0.98936301 0.96011037\n",
      " 0.26029953 0.72152859 0.82710648 0.97500843 0.42164788 0.61404914\n",
      " 0.24216112 0.97077268 0.88383061 0.98887491 0.98712766 0.20377043\n",
      " 0.26708326 0.14597729 0.22534323 0.28654593 0.89277607 0.85567594\n",
      " 0.54946417 0.39495331 0.91947442 0.69101018]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 35 [0/54 (0%)]\tTrain Loss: 0.035845\n",
      "Train Epoch: 35 [8/54 (15%)]\tTrain Loss: 0.035105\n",
      "Train Epoch: 35 [16/54 (30%)]\tTrain Loss: 0.122746\n",
      "Train Epoch: 35 [24/54 (44%)]\tTrain Loss: 0.066167\n",
      "Train Epoch: 35 [32/54 (59%)]\tTrain Loss: 0.048005\n",
      "Train Epoch: 35 [40/54 (74%)]\tTrain Loss: 0.084361\n",
      "Train Epoch: 35 [48/54 (89%)]\tTrain Loss: 0.063903\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.11167548 0.78330076 0.63884389 0.39235869 0.21836714 0.1505637\n",
      " 0.70198268 0.53246707 0.22365634 0.13714075 0.34746489 0.1664146\n",
      " 0.20049357 0.43057212 0.50291181 0.20158117 0.41744772 0.36925012\n",
      " 0.3095822  0.38700712 0.58778089 0.31431764 0.53035933 0.55549532\n",
      " 0.46069628 0.65204346 0.80135435 0.69864339 0.36909592 0.4069353\n",
      " 0.64877528 0.53091061 0.33797967 0.28681755 0.16860302 0.2108282\n",
      " 0.26301479 0.45305669 0.40886137 0.52329063 0.54241478 0.40993464\n",
      " 0.26154834 0.42979771 0.50431049 0.41290998 0.6920011  0.45034042\n",
      " 0.76174676 0.71449542 0.75763327 0.03964735 0.43918106 0.13708906\n",
      " 0.51990503 0.18959227 0.75353843 0.26399389 0.27193025 0.50197566\n",
      " 0.82963198 0.60454208 0.60299093 0.73132247 0.6486752  0.46658653\n",
      " 0.39803201 0.89501941 0.88815367 0.41331363 0.62161577 0.61039197\n",
      " 0.81798774 0.50894111 0.68098444 0.56348503 0.85695946 0.7421456\n",
      " 0.69874322 0.84402037 0.82724154 0.86804956 0.83675486 0.4955458\n",
      " 0.54806954 0.86216372 0.65894288 0.64442825 0.58480555 0.69538432\n",
      " 0.88360643 0.45745525 0.47809348 0.98017591 0.98220533 0.89582306\n",
      " 0.29048234 0.81677264 0.82655227 0.94320017 0.34769097 0.64317822\n",
      " 0.40262914 0.96087039 0.76599151 0.94658363 0.98032975 0.25734025\n",
      " 0.26802039 0.22509576 0.37080118 0.24481322 0.82372868 0.58342409\n",
      " 0.36409217 0.43021956 0.91324377 0.81657213]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 36 [0/54 (0%)]\tTrain Loss: 0.062199\n",
      "Train Epoch: 36 [8/54 (15%)]\tTrain Loss: 0.042066\n",
      "Train Epoch: 36 [16/54 (30%)]\tTrain Loss: 0.071076\n",
      "Train Epoch: 36 [24/54 (44%)]\tTrain Loss: 0.058480\n",
      "Train Epoch: 36 [32/54 (59%)]\tTrain Loss: 0.083892\n",
      "Train Epoch: 36 [40/54 (74%)]\tTrain Loss: 0.077530\n",
      "Train Epoch: 36 [48/54 (89%)]\tTrain Loss: 0.122773\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.60545665 0.84581381 0.63378638 0.84655243 0.70231014 0.71095127\n",
      " 0.7403872  0.76560551 0.87265128 0.92166531 0.95369798 0.91715074\n",
      " 0.74257505 0.56742805 0.5852769  0.77150691 0.92260593 0.82534838\n",
      " 0.72118008 0.78465062 0.80853575 0.78356993 0.85624129 0.74528384\n",
      " 0.89658594 0.93600553 0.91491771 0.95489562 0.81620771 0.73882794\n",
      " 0.85073191 0.88739866 0.24461177 0.96576083 0.95752782 0.94500107\n",
      " 0.79481184 0.66059732 0.93828696 0.9604246  0.9598546  0.9304406\n",
      " 0.70177114 0.63618165 0.64253342 0.40229505 0.8427968  0.57524127\n",
      " 0.83552116 0.89383489 0.80807436 0.40614882 0.82038039 0.63911152\n",
      " 0.76306534 0.56140882 0.79016066 0.7166     0.76928216 0.78010255\n",
      " 0.91978818 0.82514745 0.87148029 0.89374733 0.82348686 0.80810094\n",
      " 0.95277303 0.91867328 0.99048728 0.9663204  0.97594357 0.95787376\n",
      " 0.9767676  0.95931059 0.93317604 0.75144029 0.89572537 0.88175786\n",
      " 0.68351775 0.91445428 0.94332361 0.96572578 0.90831101 0.85161132\n",
      " 0.80213326 0.98619509 0.84657806 0.88819337 0.91662246 0.91678524\n",
      " 0.98726219 0.95592237 0.89378631 0.99155843 0.99872082 0.99200612\n",
      " 0.74531788 0.98814756 0.99254215 0.9955017  0.82255584 0.89761305\n",
      " 0.8110103  0.98546267 0.95132935 0.9865095  0.9968034  0.32555261\n",
      " 0.31320339 0.38960263 0.53224957 0.80998695 0.97037929 0.98750687\n",
      " 0.86238015 0.82527137 0.92749786 0.86419582]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 37 [0/54 (0%)]\tTrain Loss: 0.072273\n",
      "Train Epoch: 37 [8/54 (15%)]\tTrain Loss: 0.051662\n",
      "Train Epoch: 37 [16/54 (30%)]\tTrain Loss: 0.093623\n",
      "Train Epoch: 37 [24/54 (44%)]\tTrain Loss: 0.062179\n",
      "Train Epoch: 37 [32/54 (59%)]\tTrain Loss: 0.076360\n",
      "Train Epoch: 37 [40/54 (74%)]\tTrain Loss: 0.085835\n",
      "Train Epoch: 37 [48/54 (89%)]\tTrain Loss: 0.075061\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.60934776 0.97910827 0.93467855 0.91263187 0.61388314 0.29829469\n",
      " 0.94665766 0.94758433 0.43912497 0.1328942  0.70866185 0.09024327\n",
      " 0.19442405 0.7856487  0.77454251 0.31216961 0.71182191 0.21438013\n",
      " 0.29799351 0.37394288 0.636733   0.33850664 0.86004841 0.77701813\n",
      " 0.46678492 0.9102546  0.95719606 0.88065195 0.62163484 0.70250148\n",
      " 0.95032436 0.9816103  0.96365917 0.53869355 0.35453221 0.49173769\n",
      " 0.40795374 0.74312103 0.35697132 0.64246643 0.60685676 0.49994463\n",
      " 0.34498087 0.732629   0.76459765 0.94257349 0.99263728 0.98959714\n",
      " 0.99485886 0.54672682 0.99143642 0.06216948 0.89879167 0.57155168\n",
      " 0.56471789 0.41003618 0.90333277 0.85821307 0.41857624 0.9330861\n",
      " 0.94934767 0.75493526 0.8992663  0.93423456 0.97798789 0.98136753\n",
      " 0.91393906 0.98848397 0.99694592 0.93622845 0.92509115 0.92905903\n",
      " 0.9910875  0.93141741 0.95772558 0.85999262 0.99149138 0.98793167\n",
      " 0.99111724 0.97263563 0.96688509 0.9807325  0.95277172 0.81034374\n",
      " 0.83188158 0.94561368 0.69401395 0.76425493 0.65140122 0.80848581\n",
      " 0.97675472 0.68264717 0.79751575 0.99129701 0.98874503 0.98486447\n",
      " 0.6288206  0.73380858 0.93530536 0.99585044 0.3322337  0.93135571\n",
      " 0.34713849 0.97273511 0.93804449 0.95141166 0.9971993  0.19901028\n",
      " 0.09219282 0.44950336 0.23117968 0.16236402 0.95579964 0.77000588\n",
      " 0.31581447 0.42172471 0.97152561 0.81578761]\n",
      "predict [1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 38 [0/54 (0%)]\tTrain Loss: 0.099375\n",
      "Train Epoch: 38 [8/54 (15%)]\tTrain Loss: 0.033688\n",
      "Train Epoch: 38 [16/54 (30%)]\tTrain Loss: 0.040497\n",
      "Train Epoch: 38 [24/54 (44%)]\tTrain Loss: 0.060568\n",
      "Train Epoch: 38 [32/54 (59%)]\tTrain Loss: 0.039825\n",
      "Train Epoch: 38 [40/54 (74%)]\tTrain Loss: 0.071336\n",
      "Train Epoch: 38 [48/54 (89%)]\tTrain Loss: 0.042884\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.99581331 0.99966514 0.99931443 0.99705458 0.85485625 0.9455561\n",
      " 0.99873847 0.99660528 0.99033523 0.57671273 0.3047761  0.0940324\n",
      " 0.20875339 0.7555486  0.90579468 0.51295608 0.97380459 0.72416222\n",
      " 0.14230692 0.32286665 0.42333266 0.46274441 0.68837804 0.94286597\n",
      " 0.76171798 0.82880718 0.98471558 0.69928175 0.50277776 0.58418071\n",
      " 0.96287096 0.86764145 0.78646791 0.29471818 0.18793513 0.32985544\n",
      " 0.2050132  0.76382649 0.66798919 0.5383293  0.71072519 0.62286395\n",
      " 0.41626376 0.86636698 0.96426702 0.98927665 0.99998772 0.99991918\n",
      " 0.99999905 0.99202734 0.99999869 0.32029474 0.88483477 0.66429418\n",
      " 0.86219811 0.3524991  0.94208688 0.25696951 0.21822825 0.99802053\n",
      " 0.99970549 0.99708897 0.99889249 0.99934298 0.99948847 0.95254475\n",
      " 0.95126981 0.99968088 0.99998975 0.92247182 0.99999845 0.9999938\n",
      " 0.9978807  0.97378695 0.99100268 0.99613333 0.99999273 0.99997795\n",
      " 0.99989498 0.99722999 0.99912292 0.99958748 0.99936539 0.92476875\n",
      " 0.99696869 0.99642688 0.98664016 0.99549496 0.35939017 0.78567058\n",
      " 0.83855182 0.55768883 0.8119151  0.91127658 0.96651202 0.87701893\n",
      " 0.36265326 0.96530825 0.91184318 0.9706251  0.71387678 0.99827158\n",
      " 0.40458745 0.95776689 0.95537686 0.9977805  0.99979502 0.06691207\n",
      " 0.06574408 0.18993662 0.0635457  0.06555308 0.06540547 0.42086712\n",
      " 0.48182982 0.75064468 0.89575285 0.52008712]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "Train Epoch: 39 [0/54 (0%)]\tTrain Loss: 0.059347\n",
      "Train Epoch: 39 [8/54 (15%)]\tTrain Loss: 0.049202\n",
      "Train Epoch: 39 [16/54 (30%)]\tTrain Loss: 0.083272\n",
      "Train Epoch: 39 [24/54 (44%)]\tTrain Loss: 0.080021\n",
      "Train Epoch: 39 [32/54 (59%)]\tTrain Loss: 0.032680\n",
      "Train Epoch: 39 [40/54 (74%)]\tTrain Loss: 0.026476\n",
      "Train Epoch: 39 [48/54 (89%)]\tTrain Loss: 0.052178\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.10068092 0.7573548  0.37101629 0.30749816 0.23834749 0.06803799\n",
      " 0.70262736 0.35998961 0.07877866 0.1807761  0.05234333 0.0806287\n",
      " 0.04132619 0.44174623 0.3849529  0.10137165 0.39182502 0.13402136\n",
      " 0.09448139 0.13091971 0.69835657 0.14623632 0.75403619 0.61977863\n",
      " 0.19918936 0.86167723 0.93388593 0.47149685 0.35182101 0.36342189\n",
      " 0.76951277 0.93537986 0.76942736 0.14015171 0.04464056 0.17260373\n",
      " 0.06521345 0.40519336 0.24048717 0.48376998 0.44565973 0.43937957\n",
      " 0.11017209 0.14516321 0.19365545 0.25291833 0.68334544 0.48409411\n",
      " 0.92051375 0.6932987  0.91319913 0.00811256 0.1587372  0.07212454\n",
      " 0.20650695 0.13295433 0.35835963 0.36179566 0.38382709 0.56149316\n",
      " 0.70356345 0.52055293 0.53420347 0.6156081  0.59635246 0.90481043\n",
      " 0.77879292 0.79753083 0.93969768 0.49109492 0.2658419  0.24514428\n",
      " 0.93634748 0.61972469 0.71393269 0.50575155 0.90018529 0.88014239\n",
      " 0.5645842  0.8707692  0.90893543 0.95142502 0.83183587 0.39041817\n",
      " 0.49582756 0.77470285 0.36739406 0.62350231 0.61991721 0.80321157\n",
      " 0.94536304 0.43907163 0.40971905 0.96785688 0.94987327 0.87977374\n",
      " 0.23468517 0.60588795 0.47638625 0.96647334 0.10628536 0.83320862\n",
      " 0.08838587 0.61115265 0.47307757 0.73017269 0.94447362 0.0640267\n",
      " 0.04047371 0.11966938 0.07929414 0.16879478 0.76422489 0.24278112\n",
      " 0.12916064 0.19609469 0.9066807  0.74278772]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 40 [0/54 (0%)]\tTrain Loss: 0.030980\n",
      "Train Epoch: 40 [8/54 (15%)]\tTrain Loss: 0.055135\n",
      "Train Epoch: 40 [16/54 (30%)]\tTrain Loss: 0.049072\n",
      "Train Epoch: 40 [24/54 (44%)]\tTrain Loss: 0.057525\n",
      "Train Epoch: 40 [32/54 (59%)]\tTrain Loss: 0.066712\n",
      "Train Epoch: 40 [40/54 (74%)]\tTrain Loss: 0.065447\n",
      "Train Epoch: 40 [48/54 (89%)]\tTrain Loss: 0.080729\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.45950475 0.97054189 0.83738279 0.50253397 0.22862504 0.21711372\n",
      " 0.93914914 0.5124715  0.14840753 0.1274045  0.26473215 0.01839716\n",
      " 0.10630931 0.43725964 0.34320891 0.02562743 0.11524244 0.08371784\n",
      " 0.08095413 0.18043122 0.57705379 0.17038868 0.52551591 0.68753099\n",
      " 0.24036379 0.47798127 0.89614415 0.19284981 0.04148727 0.09056627\n",
      " 0.89469153 0.45458227 0.67331308 0.01735273 0.0165887  0.0418916\n",
      " 0.0438124  0.45579317 0.13786946 0.16904864 0.16571298 0.37904927\n",
      " 0.07738368 0.11385892 0.0947761  0.32946864 0.98651087 0.94306248\n",
      " 0.99811041 0.72683221 0.99761319 0.00528256 0.23128124 0.29176179\n",
      " 0.30681711 0.03755131 0.83963245 0.09024859 0.12367971 0.23497221\n",
      " 0.97859168 0.86022758 0.95933539 0.94547248 0.67986089 0.59520841\n",
      " 0.63498831 0.8979494  0.98820508 0.42203867 0.89870578 0.90566981\n",
      " 0.86421084 0.62330127 0.76538771 0.96483684 0.99894387 0.99842876\n",
      " 0.99836308 0.9887284  0.98415726 0.99733824 0.98508352 0.46460378\n",
      " 0.47632036 0.55846703 0.96287847 0.96340233 0.30589938 0.57992822\n",
      " 0.50426555 0.17205732 0.20010941 0.94602531 0.90796375 0.51417243\n",
      " 0.08728361 0.37258479 0.39869314 0.68235916 0.39734349 0.89553708\n",
      " 0.03393502 0.85998178 0.87319148 0.80283493 0.95821476 0.01101886\n",
      " 0.01605749 0.02157551 0.01639566 0.00814778 0.01702459 0.07785233\n",
      " 0.13325137 0.20433682 0.87647802 0.29392833]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 46 TN= 33 FN= 12 FP= 27\n",
      "TP+FP 73\n",
      "precision 0.6301369863013698\n",
      "recall 0.7931034482758621\n",
      "F1 0.7022900763358779\n",
      "acc 0.6694915254237288\n",
      "AUCp 0.6715517241379311\n",
      "AUC 0.7221264367816091\n",
      "\n",
      " The epoch is 40, average recall: 0.7931, average precision: 0.6301,average F1: 0.7023, average accuracy: 0.6695, average AUC: 0.7221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 41 [0/54 (0%)]\tTrain Loss: 0.082817\n",
      "Train Epoch: 41 [8/54 (15%)]\tTrain Loss: 0.066309\n",
      "Train Epoch: 41 [16/54 (30%)]\tTrain Loss: 0.076628\n",
      "Train Epoch: 41 [24/54 (44%)]\tTrain Loss: 0.097785\n",
      "Train Epoch: 41 [32/54 (59%)]\tTrain Loss: 0.030493\n",
      "Train Epoch: 41 [40/54 (74%)]\tTrain Loss: 0.128383\n",
      "Train Epoch: 41 [48/54 (89%)]\tTrain Loss: 0.084565\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.29902673 0.67566919 0.44056645 0.1055344  0.10911547 0.29312748\n",
      " 0.36768556 0.36249468 0.3579002  0.04561435 0.02768609 0.05068735\n",
      " 0.00458371 0.10734139 0.27131143 0.05280439 0.04604719 0.12619138\n",
      " 0.03409611 0.16183388 0.38047412 0.10186955 0.24543558 0.55951983\n",
      " 0.07303168 0.32293612 0.90780759 0.19276659 0.07165863 0.13754633\n",
      " 0.62057745 0.45390022 0.28077376 0.06670582 0.05864339 0.03133483\n",
      " 0.01761572 0.06670178 0.16892757 0.11252242 0.09712403 0.14087753\n",
      " 0.08315556 0.13726693 0.1415617  0.2109839  0.91360539 0.83714408\n",
      " 0.97669005 0.74300987 0.98706126 0.00804567 0.10046193 0.04308069\n",
      " 0.37039021 0.05086488 0.62926823 0.02566411 0.0919158  0.26033258\n",
      " 0.91708082 0.79719949 0.7277683  0.81521565 0.6797201  0.51428574\n",
      " 0.76193166 0.67456543 0.63928199 0.58739024 0.67407352 0.59653658\n",
      " 0.89985859 0.79829901 0.69713396 0.87383884 0.98283708 0.97604531\n",
      " 0.05236438 0.91001844 0.64179945 0.95703018 0.89253926 0.06061611\n",
      " 0.19185446 0.6426478  0.30564144 0.71036768 0.08465198 0.1981978\n",
      " 0.77583319 0.47035283 0.29678214 0.80243421 0.72473091 0.40105504\n",
      " 0.03006249 0.39942703 0.39550936 0.55704254 0.05272738 0.86864275\n",
      " 0.05907333 0.45156011 0.34619406 0.50027102 0.88175613 0.02381848\n",
      " 0.00872275 0.02961519 0.02636612 0.0230328  0.02806432 0.17252262\n",
      " 0.1973125  0.33378923 0.46371454 0.15598902]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 42 [0/54 (0%)]\tTrain Loss: 0.045468\n",
      "Train Epoch: 42 [8/54 (15%)]\tTrain Loss: 0.106611\n",
      "Train Epoch: 42 [16/54 (30%)]\tTrain Loss: 0.047288\n",
      "Train Epoch: 42 [24/54 (44%)]\tTrain Loss: 0.048415\n",
      "Train Epoch: 42 [32/54 (59%)]\tTrain Loss: 0.091255\n",
      "Train Epoch: 42 [40/54 (74%)]\tTrain Loss: 0.099025\n",
      "Train Epoch: 42 [48/54 (89%)]\tTrain Loss: 0.036064\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.21316765 0.99574202 0.99397343 0.16033965 0.08938497 0.09562453\n",
      " 0.98198354 0.17958094 0.12548427 0.03715293 0.23616458 0.0387785\n",
      " 0.09297843 0.11216076 0.08301487 0.01504092 0.01619384 0.12382773\n",
      " 0.04491588 0.19793837 0.79333258 0.15657938 0.87226486 0.98444194\n",
      " 0.09795696 0.92918575 0.97698307 0.70411843 0.14971454 0.28201917\n",
      " 0.97581518 0.91505975 0.8769303  0.01062468 0.01690512 0.09010471\n",
      " 0.10148576 0.09697483 0.04390887 0.14142579 0.11411386 0.13057281\n",
      " 0.03722834 0.3242541  0.10974664 0.1824545  0.99960297 0.98891896\n",
      " 0.99948466 0.56600666 0.99762827 0.01018456 0.09236159 0.12785071\n",
      " 0.27328229 0.03807513 0.76174319 0.06083203 0.66801095 0.10625333\n",
      " 0.97310323 0.88756561 0.96807152 0.99460852 0.94577831 0.43288046\n",
      " 0.38977265 0.98712021 0.9764781  0.05462836 0.68744057 0.60974318\n",
      " 0.82272238 0.65581864 0.76077574 0.95204538 0.99994695 0.99990642\n",
      " 0.98813438 0.99893719 0.9812184  0.99169195 0.99803275 0.26338699\n",
      " 0.4782404  0.63605219 0.83641088 0.89802647 0.13312858 0.58152902\n",
      " 0.98004133 0.1048451  0.15761314 0.99585658 0.98452282 0.8446973\n",
      " 0.11172551 0.32522175 0.56843722 0.56792849 0.11174941 0.97668648\n",
      " 0.07633664 0.82694542 0.73515397 0.51046801 0.89947903 0.00683614\n",
      " 0.00538435 0.04699349 0.00812932 0.00409336 0.00748905 0.08764929\n",
      " 0.05783682 0.11801717 0.47856992 0.27460819]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 43 [0/54 (0%)]\tTrain Loss: 0.044293\n",
      "Train Epoch: 43 [8/54 (15%)]\tTrain Loss: 0.018153\n",
      "Train Epoch: 43 [16/54 (30%)]\tTrain Loss: 0.043363\n",
      "Train Epoch: 43 [24/54 (44%)]\tTrain Loss: 0.113187\n",
      "Train Epoch: 43 [32/54 (59%)]\tTrain Loss: 0.037042\n",
      "Train Epoch: 43 [40/54 (74%)]\tTrain Loss: 0.062074\n",
      "Train Epoch: 43 [48/54 (89%)]\tTrain Loss: 0.052038\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.1233305  0.82586253 0.75791121 0.23692821 0.145955   0.20533094\n",
      " 0.72171915 0.34637231 0.18588983 0.09548327 0.12288794 0.08193436\n",
      " 0.07364069 0.58883321 0.51069069 0.11369184 0.35965782 0.30875695\n",
      " 0.17909715 0.42383009 0.73055333 0.31119996 0.68854231 0.91544753\n",
      " 0.27713457 0.86671948 0.96685344 0.7342127  0.28073478 0.36310446\n",
      " 0.75769049 0.84833533 0.35147795 0.07774983 0.0629368  0.17179035\n",
      " 0.1367161  0.30374426 0.19899151 0.39330596 0.30072984 0.31691608\n",
      " 0.22614813 0.25329119 0.24296346 0.1060162  0.62534779 0.43823269\n",
      " 0.94480735 0.90757358 0.93763691 0.01562156 0.25222915 0.11576442\n",
      " 0.30408096 0.27430236 0.64734334 0.33560655 0.26950642 0.31033716\n",
      " 0.83376318 0.64211106 0.69207579 0.76448739 0.83544242 0.81599736\n",
      " 0.87384737 0.94472498 0.98173082 0.69917381 0.35688725 0.30748925\n",
      " 0.90537703 0.59465343 0.76595175 0.64809072 0.90006059 0.83510423\n",
      " 0.79817915 0.92087263 0.91078287 0.92716879 0.93330812 0.32472026\n",
      " 0.46990517 0.78099048 0.73323768 0.78569567 0.80526632 0.80220944\n",
      " 0.96398896 0.42466506 0.43812796 0.99134582 0.93943799 0.87750322\n",
      " 0.26953831 0.70304543 0.50039566 0.66737992 0.39199921 0.65564197\n",
      " 0.10922066 0.58638871 0.68698466 0.73672056 0.89095664 0.06269498\n",
      " 0.03889506 0.12590627 0.06887371 0.09552239 0.09354682 0.41808403\n",
      " 0.10984395 0.25449133 0.67142522 0.59378326]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 44 [0/54 (0%)]\tTrain Loss: 0.035055\n",
      "Train Epoch: 44 [8/54 (15%)]\tTrain Loss: 0.086000\n",
      "Train Epoch: 44 [16/54 (30%)]\tTrain Loss: 0.032608\n",
      "Train Epoch: 44 [24/54 (44%)]\tTrain Loss: 0.083259\n",
      "Train Epoch: 44 [32/54 (59%)]\tTrain Loss: 0.057728\n",
      "Train Epoch: 44 [40/54 (74%)]\tTrain Loss: 0.066532\n",
      "Train Epoch: 44 [48/54 (89%)]\tTrain Loss: 0.028172\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.04187218 0.80563962 0.54842764 0.11656188 0.24215199 0.27876499\n",
      " 0.76182973 0.18527386 0.0472693  0.02089634 0.33105654 0.0098799\n",
      " 0.06605831 0.34780931 0.21909158 0.09497156 0.33501723 0.07004698\n",
      " 0.06919134 0.12986577 0.4164677  0.10716601 0.20763487 0.41127872\n",
      " 0.14411776 0.60755873 0.89197087 0.48908314 0.12129578 0.09958114\n",
      " 0.7036854  0.30934826 0.08818133 0.12940782 0.04844332 0.12081074\n",
      " 0.0456758  0.07166295 0.13826901 0.39913896 0.27588812 0.12197297\n",
      " 0.07035711 0.12552194 0.04116024 0.04028636 0.67890787 0.72415882\n",
      " 0.97591603 0.88259327 0.98686361 0.00512723 0.18897299 0.07280783\n",
      " 0.27392191 0.06548669 0.62258565 0.16936469 0.01595527 0.10911731\n",
      " 0.91287428 0.72698861 0.88008153 0.82434744 0.68017435 0.66798574\n",
      " 0.69050109 0.82254893 0.95781684 0.71401608 0.6932956  0.51817316\n",
      " 0.85984921 0.78163022 0.82485414 0.64299709 0.92494678 0.91790688\n",
      " 0.84748334 0.93249142 0.94843054 0.96429616 0.90846407 0.31972468\n",
      " 0.33888274 0.77127695 0.35007849 0.67844909 0.57645208 0.67739719\n",
      " 0.85356474 0.58167958 0.22029129 0.96928108 0.94163573 0.85326129\n",
      " 0.08735563 0.50472659 0.79302084 0.87447888 0.1916865  0.58550566\n",
      " 0.11691    0.8971929  0.87214696 0.80661714 0.97326136 0.00372689\n",
      " 0.00160123 0.01087451 0.00403331 0.00490825 0.04315104 0.492228\n",
      " 0.08759613 0.15385018 0.50399804 0.54498655]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [0/54 (0%)]\tTrain Loss: 0.049623\n",
      "Train Epoch: 45 [8/54 (15%)]\tTrain Loss: 0.037309\n",
      "Train Epoch: 45 [16/54 (30%)]\tTrain Loss: 0.064791\n",
      "Train Epoch: 45 [24/54 (44%)]\tTrain Loss: 0.024649\n",
      "Train Epoch: 45 [32/54 (59%)]\tTrain Loss: 0.036416\n",
      "Train Epoch: 45 [40/54 (74%)]\tTrain Loss: 0.077064\n",
      "Train Epoch: 45 [48/54 (89%)]\tTrain Loss: 0.046365\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.06581102 0.68272662 0.15903978 0.10128611 0.90341526 0.4346357\n",
      " 0.19160241 0.69923979 0.34302431 0.34341666 0.97582823 0.21374476\n",
      " 0.6925928  0.28798047 0.48137474 0.52076268 0.77871144 0.3675749\n",
      " 0.76501381 0.32857037 0.75896555 0.61889672 0.96961445 0.70367086\n",
      " 0.66463476 0.97862101 0.94212896 0.9562605  0.7460739  0.72127092\n",
      " 0.99180239 0.99494141 0.96325207 0.44069085 0.29897034 0.84375542\n",
      " 0.73563462 0.91484898 0.59806615 0.72078341 0.41066614 0.51625395\n",
      " 0.48146966 0.92401892 0.66601509 0.96035558 0.9365983  0.89083564\n",
      " 0.94116867 0.88294703 0.96053964 0.10060389 0.5244776  0.01999406\n",
      " 0.45156723 0.6836881  0.94853956 0.79612273 0.75838369 0.01900145\n",
      " 0.99532676 0.96250552 0.97860694 0.97714806 0.05009499 0.99105656\n",
      " 0.9873426  0.06809802 0.54316145 0.92906904 0.00533783 0.00401801\n",
      " 0.99563885 0.97415018 0.96186405 0.9862619  0.99767381 0.97924179\n",
      " 0.8653428  0.99976498 0.99854147 0.9985342  0.99555272 0.91674179\n",
      " 0.88115615 0.96853894 0.87831736 0.90393102 0.75161976 0.97049147\n",
      " 0.96542025 0.97421753 0.8922022  0.9960897  0.99851233 0.98744756\n",
      " 0.25135124 0.8453055  0.98974097 0.99019253 0.39639404 0.99632204\n",
      " 0.70656937 0.9858436  0.97414678 0.95906264 0.9985764  0.03150977\n",
      " 0.01585396 0.23232368 0.0551514  0.09515186 0.36477223 0.95608634\n",
      " 0.39291313 0.48069832 0.98341149 0.944399  ]\n",
      "predict [0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 46 [0/54 (0%)]\tTrain Loss: 0.037307\n",
      "Train Epoch: 46 [8/54 (15%)]\tTrain Loss: 0.087589\n",
      "Train Epoch: 46 [16/54 (30%)]\tTrain Loss: 0.101513\n",
      "Train Epoch: 46 [24/54 (44%)]\tTrain Loss: 0.065108\n",
      "Train Epoch: 46 [32/54 (59%)]\tTrain Loss: 0.093843\n",
      "Train Epoch: 46 [40/54 (74%)]\tTrain Loss: 0.056303\n",
      "Train Epoch: 46 [48/54 (89%)]\tTrain Loss: 0.023475\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.83491290e-01 9.99566257e-01 9.85519946e-01 4.77085441e-01\n",
      " 5.54553628e-01 5.80904305e-01 9.98348236e-01 8.77036631e-01\n",
      " 2.27339461e-01 6.94345385e-02 8.20124745e-01 2.36430392e-02\n",
      " 4.35328782e-01 5.18206179e-01 5.20648420e-01 4.18683678e-01\n",
      " 4.88510102e-01 2.56599069e-01 1.92051500e-01 2.26933271e-01\n",
      " 6.85548663e-01 4.74520952e-01 8.39279830e-01 8.44017744e-01\n",
      " 4.66917872e-01 8.76297832e-01 9.83290911e-01 8.15551221e-01\n",
      " 4.62566048e-01 3.74100536e-01 9.91153538e-01 9.40456927e-01\n",
      " 5.85354745e-01 1.60213098e-01 1.19016953e-01 4.47295219e-01\n",
      " 2.69749343e-01 7.39638329e-01 2.45833814e-01 3.99183035e-01\n",
      " 3.24929386e-01 2.61924565e-01 3.11052442e-01 5.43888569e-01\n",
      " 5.24839342e-01 9.19780314e-01 9.99873996e-01 9.99764383e-01\n",
      " 9.99956250e-01 9.58935738e-01 9.99987245e-01 1.97161790e-02\n",
      " 5.61808407e-01 4.92573082e-01 7.62149394e-01 2.76765078e-01\n",
      " 9.83631492e-01 1.19731523e-01 1.53962538e-01 9.05128896e-01\n",
      " 9.92295742e-01 8.97676885e-01 9.83805239e-01 9.82831001e-01\n",
      " 9.25007880e-01 9.67135251e-01 9.49414313e-01 5.64274848e-01\n",
      " 9.74562049e-01 9.34791744e-01 8.82098138e-01 6.61425889e-01\n",
      " 9.89223242e-01 9.74925041e-01 9.88592386e-01 9.94469643e-01\n",
      " 9.99999285e-01 9.99996662e-01 9.99001801e-01 9.99396324e-01\n",
      " 9.99376476e-01 9.99614120e-01 9.99159932e-01 5.62656403e-01\n",
      " 2.56370276e-01 9.33970451e-01 8.97905469e-01 9.43975925e-01\n",
      " 5.74411094e-01 8.50476205e-01 8.32944810e-01 9.16094720e-01\n",
      " 6.48316383e-01 9.75485325e-01 9.34896111e-01 6.85951948e-01\n",
      " 1.31259993e-01 5.66348910e-01 7.92482555e-01 8.62564266e-01\n",
      " 4.58264291e-01 9.97795463e-01 4.69077408e-01 9.81566906e-01\n",
      " 9.63863730e-01 9.52327609e-01 9.96734381e-01 1.41451752e-03\n",
      " 6.71932299e-04 5.07548405e-03 1.86110183e-03 2.30482011e-03\n",
      " 5.60615398e-03 7.46024132e-01 3.13490182e-01 2.87709177e-01\n",
      " 7.47954905e-01 7.13958561e-01]\n",
      "predict [1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 47 [0/54 (0%)]\tTrain Loss: 0.034875\n",
      "Train Epoch: 47 [8/54 (15%)]\tTrain Loss: 0.048604\n",
      "Train Epoch: 47 [16/54 (30%)]\tTrain Loss: 0.111769\n",
      "Train Epoch: 47 [24/54 (44%)]\tTrain Loss: 0.056795\n",
      "Train Epoch: 47 [32/54 (59%)]\tTrain Loss: 0.042075\n",
      "Train Epoch: 47 [40/54 (74%)]\tTrain Loss: 0.052290\n",
      "Train Epoch: 47 [48/54 (89%)]\tTrain Loss: 0.095258\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.99944144 0.99999666 0.9999522  0.99886596 0.42964077 0.57709521\n",
      " 0.99997628 0.99762911 0.69290423 0.21189444 0.07837387 0.03337177\n",
      " 0.06366625 0.87994021 0.90082932 0.53844559 0.16717306 0.14998335\n",
      " 0.05150567 0.22743192 0.34162375 0.22515324 0.69885433 0.76293665\n",
      " 0.06541482 0.64049709 0.86095768 0.56022823 0.11359654 0.23763432\n",
      " 0.8210054  0.68230754 0.77154744 0.02517375 0.02569512 0.09466321\n",
      " 0.05897421 0.53481436 0.11605573 0.18678977 0.16683689 0.14658797\n",
      " 0.17362164 0.68049932 0.78232789 0.67900157 0.99994755 0.999915\n",
      " 0.99999774 0.91254336 0.99999595 0.66493541 0.88103062 0.99695718\n",
      " 0.11921693 0.23219439 0.64286441 0.17291318 0.18494865 0.99845791\n",
      " 0.98976457 0.91650492 0.97109097 0.98290884 0.99999475 0.87308633\n",
      " 0.72323102 0.99999952 0.99999893 0.13395299 0.99999917 0.99999821\n",
      " 0.91487056 0.78698128 0.70999354 0.98329896 1.         1.\n",
      " 0.99996138 0.99745661 0.99358141 0.99840933 0.99712652 0.50642049\n",
      " 0.99482191 0.4547683  0.87728095 0.90638787 0.24153219 0.18749227\n",
      " 0.31916305 0.26706508 0.37054408 0.87703848 0.33204529 0.19567902\n",
      " 0.06547406 0.22915334 0.16691774 0.14158431 0.210401   0.97201014\n",
      " 0.06737693 0.50303024 0.23793757 0.42455348 0.93038231 0.0175798\n",
      " 0.01504292 0.04948738 0.01698851 0.03392684 0.03448623 0.04844057\n",
      " 0.04974358 0.76034421 0.65188056 0.58988363]\n",
      "predict [1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "Train Epoch: 48 [0/54 (0%)]\tTrain Loss: 0.062340\n",
      "Train Epoch: 48 [8/54 (15%)]\tTrain Loss: 0.034601\n",
      "Train Epoch: 48 [16/54 (30%)]\tTrain Loss: 0.046396\n",
      "Train Epoch: 48 [24/54 (44%)]\tTrain Loss: 0.024078\n",
      "Train Epoch: 48 [32/54 (59%)]\tTrain Loss: 0.096458\n",
      "Train Epoch: 48 [40/54 (74%)]\tTrain Loss: 0.037101\n",
      "Train Epoch: 48 [48/54 (89%)]\tTrain Loss: 0.039155\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.81022406e-01 9.86512303e-01 9.48549569e-01 8.86982501e-01\n",
      " 5.31043828e-01 7.49947488e-01 6.96063280e-01 8.10770035e-01\n",
      " 6.15396202e-01 1.61405385e-01 4.03197885e-01 9.20771807e-02\n",
      " 1.77126437e-01 1.38874762e-02 3.97648752e-01 1.47212625e-01\n",
      " 2.80148070e-03 2.99799830e-01 3.15881461e-01 3.49722892e-01\n",
      " 6.71813309e-01 4.97796386e-01 9.50817883e-01 9.62401569e-01\n",
      " 5.50458431e-01 9.81451035e-01 9.79782045e-01 7.52840757e-01\n",
      " 2.63070166e-01 4.15240437e-01 9.67827916e-01 9.30126488e-01\n",
      " 9.12746906e-01 1.18144967e-01 4.56416458e-02 1.22699857e-01\n",
      " 1.95068881e-01 8.22922051e-01 1.00929320e-01 4.45556313e-01\n",
      " 4.00450885e-01 4.25079256e-01 3.30877662e-01 5.29983819e-01\n",
      " 3.60389948e-01 5.53558290e-01 9.93192017e-01 9.89499986e-01\n",
      " 9.99296188e-01 9.65312064e-01 9.99747574e-01 4.51543070e-02\n",
      " 3.55883211e-01 1.75755017e-03 4.62786525e-01 3.51784319e-01\n",
      " 9.18299496e-01 1.62358969e-01 3.42732638e-01 7.79187500e-01\n",
      " 9.97413337e-01 9.74707663e-01 9.94814157e-01 9.90511596e-01\n",
      " 9.63976324e-01 8.88916671e-01 7.51297474e-01 9.53088462e-01\n",
      " 3.85089159e-01 5.86308777e-01 8.37928176e-01 4.38985288e-01\n",
      " 9.66205001e-01 7.87774205e-01 9.41983402e-01 9.97023880e-01\n",
      " 9.99725044e-01 9.98760700e-01 9.98517811e-01 9.98759270e-01\n",
      " 9.74101782e-01 9.96808708e-01 9.50210690e-01 7.16467351e-02\n",
      " 3.97594034e-04 9.74189997e-01 2.72465944e-01 9.82623398e-01\n",
      " 5.32927275e-01 8.64470124e-01 9.86211777e-01 3.84559363e-01\n",
      " 3.18984300e-01 9.97454345e-01 9.81661081e-01 9.36247706e-01\n",
      " 2.42312983e-01 8.81579578e-01 9.40046549e-01 8.69384170e-01\n",
      " 5.66326737e-01 9.97739792e-01 3.29600573e-01 9.66735423e-01\n",
      " 9.14121211e-01 9.63808775e-01 9.90691483e-01 8.15124251e-03\n",
      " 3.48367426e-03 2.73195151e-02 1.16954660e-02 4.97843977e-03\n",
      " 1.18170287e-02 4.18568522e-01 3.10839832e-01 6.19368494e-01\n",
      " 9.31458473e-01 9.18323398e-01]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 49 [0/54 (0%)]\tTrain Loss: 0.062715\n",
      "Train Epoch: 49 [8/54 (15%)]\tTrain Loss: 0.069647\n",
      "Train Epoch: 49 [16/54 (30%)]\tTrain Loss: 0.066728\n",
      "Train Epoch: 49 [24/54 (44%)]\tTrain Loss: 0.105156\n",
      "Train Epoch: 49 [32/54 (59%)]\tTrain Loss: 0.039851\n",
      "Train Epoch: 49 [40/54 (74%)]\tTrain Loss: 0.066472\n",
      "Train Epoch: 49 [48/54 (89%)]\tTrain Loss: 0.029248\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.03910713 0.7641663  0.59500217 0.11478358 0.06970075 0.12804298\n",
      " 0.6046769  0.07876398 0.13425295 0.01041183 0.01534308 0.00400054\n",
      " 0.0088925  0.14182463 0.09977801 0.01956601 0.0360562  0.08534147\n",
      " 0.07807673 0.08963352 0.27604571 0.09865106 0.56417161 0.83359075\n",
      " 0.07795875 0.78654253 0.95562053 0.28221825 0.08921854 0.0405607\n",
      " 0.83696443 0.36543274 0.08024033 0.01311069 0.01324585 0.02341981\n",
      " 0.02139764 0.04102025 0.06754398 0.06885075 0.07070883 0.08700486\n",
      " 0.01887702 0.02983925 0.04339461 0.03386051 0.84028786 0.58882898\n",
      " 0.97856915 0.79424834 0.98372489 0.00482215 0.06909365 0.10780376\n",
      " 0.41248804 0.04421715 0.91290069 0.02665883 0.03979839 0.08022013\n",
      " 0.98355663 0.88332069 0.88925207 0.80351204 0.62364435 0.14259976\n",
      " 0.24512921 0.98978579 0.93442804 0.54103899 0.98078877 0.95460343\n",
      " 0.75491893 0.7249195  0.47516939 0.50385511 0.92557549 0.88764471\n",
      " 0.94636655 0.96364427 0.94494879 0.97684222 0.96801066 0.54303646\n",
      " 0.99029434 0.89758378 0.72038466 0.66177946 0.16823801 0.37386492\n",
      " 0.88991117 0.04735839 0.06342865 0.88556504 0.47893062 0.12518705\n",
      " 0.01660103 0.36006814 0.58320475 0.28827772 0.25765866 0.75783998\n",
      " 0.19608364 0.56921428 0.39502323 0.77502    0.98564005 0.01219122\n",
      " 0.01045565 0.03347151 0.01355872 0.01542024 0.02083397 0.13520345\n",
      " 0.15232147 0.40155303 0.57694519 0.29947031]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 50 [0/54 (0%)]\tTrain Loss: 0.060406\n",
      "Train Epoch: 50 [8/54 (15%)]\tTrain Loss: 0.062506\n",
      "Train Epoch: 50 [16/54 (30%)]\tTrain Loss: 0.038987\n",
      "Train Epoch: 50 [24/54 (44%)]\tTrain Loss: 0.037119\n",
      "Train Epoch: 50 [32/54 (59%)]\tTrain Loss: 0.110098\n",
      "Train Epoch: 50 [40/54 (74%)]\tTrain Loss: 0.118417\n",
      "Train Epoch: 50 [48/54 (89%)]\tTrain Loss: 0.036442\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.90977895 0.99984717 0.999143   0.86826944 0.42392609 0.48060128\n",
      " 0.99937171 0.66630077 0.32132083 0.88796192 0.20296751 0.25439018\n",
      " 0.18469742 0.81227648 0.57200962 0.62112534 0.06526199 0.52442622\n",
      " 0.06627097 0.14461569 0.65995985 0.27571321 0.88881522 0.98769605\n",
      " 0.21115921 0.98282111 0.99785417 0.70782989 0.3267808  0.36698833\n",
      " 0.98480994 0.93407041 0.77122682 0.03379469 0.0546791  0.12419067\n",
      " 0.08427367 0.45016223 0.11499472 0.62838584 0.35748729 0.34597141\n",
      " 0.05804696 0.72420543 0.41534445 0.93818444 0.99997509 0.99985015\n",
      " 0.99999845 0.99921823 0.99999857 0.08853452 0.55737919 0.9897427\n",
      " 0.66281933 0.08628512 0.92767853 0.16509025 0.32627651 0.99578422\n",
      " 0.99949241 0.99682605 0.99786818 0.99943346 0.99916053 0.48876002\n",
      " 0.60556275 0.99966002 0.9987092  0.36640111 0.99945849 0.9974879\n",
      " 0.98178858 0.89880568 0.89908433 0.98285979 0.99999428 0.99995673\n",
      " 0.99983454 0.99984002 0.99989319 0.99996054 0.99993134 0.5957033\n",
      " 0.91219133 0.96386218 0.99692422 0.96718842 0.39462322 0.68077528\n",
      " 0.98907834 0.43965328 0.52354097 0.99639589 0.94032055 0.75549048\n",
      " 0.18733528 0.61019528 0.70285249 0.87195998 0.70951974 0.9992305\n",
      " 0.05461384 0.90383887 0.92060184 0.94563818 0.99746025 0.02824112\n",
      " 0.02165976 0.0409779  0.02384336 0.05006561 0.32956007 0.78246164\n",
      " 0.18826836 0.76430058 0.85329556 0.66011482]\n",
      "predict [1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "vote_pred [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 41 TN= 42 FN= 17 FP= 18\n",
      "TP+FP 59\n",
      "precision 0.6949152542372882\n",
      "recall 0.7068965517241379\n",
      "F1 0.7008547008547009\n",
      "acc 0.7033898305084746\n",
      "AUCp 0.7034482758620689\n",
      "AUC 0.6948275862068964\n",
      "\n",
      " The epoch is 50, average recall: 0.7069, average precision: 0.6949,average F1: 0.7009, average accuracy: 0.7034, average AUC: 0.6948\n",
      "Train Epoch: 51 [0/54 (0%)]\tTrain Loss: 0.053044\n",
      "Train Epoch: 51 [8/54 (15%)]\tTrain Loss: 0.103673\n",
      "Train Epoch: 51 [16/54 (30%)]\tTrain Loss: 0.041105\n",
      "Train Epoch: 51 [24/54 (44%)]\tTrain Loss: 0.055322\n",
      "Train Epoch: 51 [32/54 (59%)]\tTrain Loss: 0.049194\n",
      "Train Epoch: 51 [40/54 (74%)]\tTrain Loss: 0.036392\n",
      "Train Epoch: 51 [48/54 (89%)]\tTrain Loss: 0.016026\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.16621387 0.80137151 0.45538631 0.11842606 0.07273778 0.08439712\n",
      " 0.57423091 0.11807904 0.0966191  0.07173306 0.06458852 0.03136625\n",
      " 0.01405056 0.04225124 0.05621289 0.01645266 0.00770766 0.10422621\n",
      " 0.0608468  0.11138523 0.36635447 0.07886187 0.30916837 0.56848133\n",
      " 0.07683738 0.70087665 0.84157503 0.18396577 0.05948336 0.0527679\n",
      " 0.57851964 0.43675235 0.15441938 0.01933522 0.02661236 0.01241113\n",
      " 0.02213879 0.07731397 0.03651003 0.05631081 0.04248648 0.04246219\n",
      " 0.0426004  0.03490276 0.05664274 0.05781787 0.89750218 0.49147317\n",
      " 0.95219892 0.79182041 0.98617768 0.0072199  0.10200328 0.06247217\n",
      " 0.22247483 0.02973854 0.36460364 0.02910594 0.07476512 0.17701201\n",
      " 0.94136691 0.55780131 0.77745461 0.92739218 0.35249361 0.12242625\n",
      " 0.12404968 0.78449804 0.88243288 0.24041277 0.82101154 0.77303714\n",
      " 0.79075801 0.40091595 0.33376819 0.71864945 0.98868144 0.95275235\n",
      " 0.48755622 0.96598899 0.89293772 0.98088098 0.96489668 0.17260604\n",
      " 0.17319642 0.46416372 0.67809027 0.66488123 0.13922377 0.16395441\n",
      " 0.85622573 0.22630024 0.18819469 0.9833625  0.88518989 0.46026108\n",
      " 0.02762047 0.18471037 0.31722322 0.35030502 0.0687527  0.94643569\n",
      " 0.02187049 0.78901953 0.6612761  0.75448638 0.97659689 0.02328473\n",
      " 0.01582376 0.02797909 0.02684779 0.03817902 0.03224442 0.19269128\n",
      " 0.02928366 0.02263573 0.56412452 0.16088259]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 52 [0/54 (0%)]\tTrain Loss: 0.141998\n",
      "Train Epoch: 52 [8/54 (15%)]\tTrain Loss: 0.108043\n",
      "Train Epoch: 52 [16/54 (30%)]\tTrain Loss: 0.039704\n",
      "Train Epoch: 52 [24/54 (44%)]\tTrain Loss: 0.031428\n",
      "Train Epoch: 52 [32/54 (59%)]\tTrain Loss: 0.019145\n",
      "Train Epoch: 52 [40/54 (74%)]\tTrain Loss: 0.027074\n",
      "Train Epoch: 52 [48/54 (89%)]\tTrain Loss: 0.090479\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.99881065 0.99999976 0.99996996 0.99932873 0.5296191  0.73542684\n",
      " 0.99999821 0.9973532  0.50629371 0.7557863  0.05633108 0.01208279\n",
      " 0.06772368 0.94888818 0.91062903 0.85176486 0.04364113 0.20707501\n",
      " 0.04244329 0.0637493  0.14183685 0.18232735 0.79266179 0.44753486\n",
      " 0.08025667 0.85772228 0.9334718  0.5303033  0.18662402 0.21197268\n",
      " 0.93586165 0.89632398 0.88695198 0.01692617 0.01668173 0.04894983\n",
      " 0.0448224  0.71588176 0.09853605 0.33873495 0.27505383 0.30420378\n",
      " 0.20759915 0.93065733 0.50551438 0.88522911 0.9999913  0.99999106\n",
      " 0.99999857 0.99457705 0.99999952 0.77685678 0.33019671 0.99748719\n",
      " 0.3426832  0.20006901 0.7709465  0.09173407 0.23417091 0.99702042\n",
      " 0.98343223 0.95102209 0.97614825 0.99678326 0.999982   0.56667179\n",
      " 0.42870709 0.99999511 0.99998939 0.67107445 0.99999917 0.9999969\n",
      " 0.94176078 0.80604333 0.68865556 0.99796009 1.         1.\n",
      " 0.99999416 0.99982554 0.99983287 0.9999727  0.99963033 0.48678094\n",
      " 0.93488717 0.80161023 0.97637129 0.96823096 0.03998073 0.4366723\n",
      " 0.78160381 0.24516562 0.35473379 0.98536325 0.91280872 0.53692704\n",
      " 0.05055638 0.49912283 0.56681198 0.83560431 0.6047132  0.99877363\n",
      " 0.08007622 0.90532368 0.89606935 0.95897895 0.99487936 0.01303344\n",
      " 0.00689743 0.01914595 0.01458718 0.01530729 0.02003859 0.1331512\n",
      " 0.07905544 0.92211962 0.99254519 0.93004894]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "Train Epoch: 53 [0/54 (0%)]\tTrain Loss: 0.046226\n",
      "Train Epoch: 53 [8/54 (15%)]\tTrain Loss: 0.096051\n",
      "Train Epoch: 53 [16/54 (30%)]\tTrain Loss: 0.028850\n",
      "Train Epoch: 53 [24/54 (44%)]\tTrain Loss: 0.099250\n",
      "Train Epoch: 53 [32/54 (59%)]\tTrain Loss: 0.067112\n",
      "Train Epoch: 53 [40/54 (74%)]\tTrain Loss: 0.025255\n",
      "Train Epoch: 53 [48/54 (89%)]\tTrain Loss: 0.045846\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.13637323e-21 1.27259165e-13 1.06935104e-13 1.99654646e-20\n",
      " 5.37900150e-01 1.47323784e-15 1.19405712e-07 9.75515293e-19\n",
      " 1.13277008e-19 1.46088257e-01 3.63380641e-01 3.38383317e-02\n",
      " 1.92627013e-01 7.42000103e-01 6.63726141e-09 3.99411321e-01\n",
      " 4.13470430e-20 3.08752269e-01 1.86759204e-01 7.96664438e-07\n",
      " 5.23476362e-01 5.23999691e-01 9.06329691e-01 6.74054215e-11\n",
      " 7.22821192e-10 9.63401437e-01 2.69062142e-03 9.34512317e-01\n",
      " 2.90934443e-01 1.04462691e-01 7.22409964e-01 1.23123050e-01\n",
      " 1.75031018e-03 2.30692863e-01 1.01013154e-01 5.84548056e-01\n",
      " 5.74111342e-01 1.10310971e-07 2.10114331e-06 4.97231871e-01\n",
      " 4.28540409e-01 1.90072160e-06 2.43397662e-03 1.08695239e-01\n",
      " 6.86118287e-16 2.24734886e-05 6.79414081e-09 8.09694711e-09\n",
      " 3.16346643e-07 7.57264614e-01 3.59204569e-06 2.45867237e-12\n",
      " 1.30361799e-09 7.74462163e-01 1.96056649e-01 2.57490643e-13\n",
      " 9.24749076e-01 6.29594624e-01 6.78148746e-01 5.61409161e-06\n",
      " 6.97998285e-01 8.06736112e-01 8.48985791e-01 9.07565296e-01\n",
      " 9.86041486e-01 1.24168384e-03 3.65487635e-01 5.45869339e-13\n",
      " 2.20123021e-23 9.91217673e-01 2.22527702e-14 1.50898072e-22\n",
      " 6.39978707e-01 1.29657229e-02 9.72750604e-01 5.39571862e-04\n",
      " 8.61655813e-09 5.14714538e-09 4.63251536e-06 1.92491250e-04\n",
      " 1.66507853e-05 1.03810625e-02 1.14418776e-03 6.01130664e-01\n",
      " 3.49600712e-22 6.56112969e-01 3.05132999e-04 3.30884452e-03\n",
      " 7.71063387e-01 8.96257579e-01 9.63954329e-01 9.23867941e-01\n",
      " 1.08371273e-01 9.93443370e-01 9.19757307e-01 9.06752944e-01\n",
      " 5.69950259e-07 4.56714153e-01 8.42867017e-01 8.66761267e-01\n",
      " 3.04514259e-01 9.00207669e-05 7.52806613e-07 5.34260762e-05\n",
      " 1.23320700e-04 2.75559817e-03 1.36137391e-02 1.01240478e-01\n",
      " 4.58998755e-02 1.88416108e-01 9.65999439e-02 8.08502585e-02\n",
      " 3.79007161e-01 8.75282466e-01 1.63003772e-01 1.47158012e-01\n",
      " 7.51265109e-01 4.02194798e-01]\n",
      "predict [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 54 [0/54 (0%)]\tTrain Loss: 0.057937\n",
      "Train Epoch: 54 [8/54 (15%)]\tTrain Loss: 0.064563\n",
      "Train Epoch: 54 [16/54 (30%)]\tTrain Loss: 0.038811\n",
      "Train Epoch: 54 [24/54 (44%)]\tTrain Loss: 0.044921\n",
      "Train Epoch: 54 [32/54 (59%)]\tTrain Loss: 0.080767\n",
      "Train Epoch: 54 [40/54 (74%)]\tTrain Loss: 0.112438\n",
      "Train Epoch: 54 [48/54 (89%)]\tTrain Loss: 0.126374\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.99824548 0.99313414 0.99613261 0.9996618  0.13360535 0.77553755\n",
      " 0.79522115 0.99919134 0.99740064 0.0623644  0.05892028 0.0177502\n",
      " 0.03480132 0.07793372 0.69286555 0.06658013 0.43821222 0.12766302\n",
      " 0.06565031 0.13077873 0.18987449 0.23924413 0.57784396 0.9373132\n",
      " 0.32144418 0.92683089 0.94702142 0.77459586 0.25290456 0.2276902\n",
      " 0.87342    0.77066851 0.14573063 0.07899684 0.03214887 0.09785207\n",
      " 0.07280813 0.3013902  0.11987768 0.16967556 0.23374997 0.17427772\n",
      " 0.04810811 0.2951718  0.9909327  0.14395539 0.99580562 0.98875844\n",
      " 0.99976593 0.98831171 0.99989307 0.12396469 0.89998603 0.10578994\n",
      " 0.56217426 0.49773467 0.82339507 0.10324838 0.19538182 0.72171474\n",
      " 0.83022875 0.75620937 0.51474249 0.59374529 0.59597415 0.78488815\n",
      " 0.43351632 0.99904889 0.99999547 0.93904257 0.99956459 0.99992669\n",
      " 0.93369144 0.61869168 0.81971872 0.63162637 0.99893874 0.99897861\n",
      " 0.98304808 0.9873656  0.96669155 0.95910031 0.98661476 0.35846075\n",
      " 0.77885062 0.85633421 0.78398937 0.56727576 0.43578547 0.82013613\n",
      " 0.97654766 0.33704999 0.18137532 0.99633539 0.87992901 0.68873364\n",
      " 0.06613236 0.45609242 0.76212579 0.82323861 0.4298487  0.83376682\n",
      " 0.12540027 0.79918325 0.60059696 0.79339027 0.98603117 0.06009244\n",
      " 0.03440064 0.17451717 0.08749852 0.07628257 0.32877123 0.79706722\n",
      " 0.08806948 0.07172754 0.68549669 0.23243251]\n",
      "predict [1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 55 [0/54 (0%)]\tTrain Loss: 0.056808\n",
      "Train Epoch: 55 [8/54 (15%)]\tTrain Loss: 0.032468\n",
      "Train Epoch: 55 [16/54 (30%)]\tTrain Loss: 0.086324\n",
      "Train Epoch: 55 [24/54 (44%)]\tTrain Loss: 0.041428\n",
      "Train Epoch: 55 [32/54 (59%)]\tTrain Loss: 0.037236\n",
      "Train Epoch: 55 [40/54 (74%)]\tTrain Loss: 0.038903\n",
      "Train Epoch: 55 [48/54 (89%)]\tTrain Loss: 0.067641\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.2028847  0.91684228 0.79114574 0.27984735 0.11959458 0.08965018\n",
      " 0.70492935 0.37680426 0.098526   0.01188972 0.17910311 0.00863572\n",
      " 0.03710185 0.03530429 0.14912929 0.03519908 0.02807415 0.08694521\n",
      " 0.04851236 0.28125584 0.42395666 0.29960522 0.60356009 0.89867604\n",
      " 0.0705098  0.75355333 0.76566005 0.50131387 0.10295223 0.25667533\n",
      " 0.69805771 0.5964942  0.18997397 0.0111345  0.01167346 0.04204686\n",
      " 0.05384459 0.45117018 0.07769772 0.06545261 0.08489324 0.08018723\n",
      " 0.08620304 0.37245247 0.12512691 0.07967709 0.88306195 0.73613924\n",
      " 0.97447497 0.75623351 0.99174315 0.00628332 0.3707718  0.06869639\n",
      " 0.29506719 0.11626802 0.92181045 0.07364292 0.04025522 0.24515815\n",
      " 0.9251852  0.67696184 0.86297297 0.91392356 0.58067524 0.40850097\n",
      " 0.17248443 0.84702682 0.96937066 0.57686985 0.65903693 0.70042521\n",
      " 0.77773905 0.38854513 0.84498119 0.80993432 0.9925015  0.97454232\n",
      " 0.95451206 0.98666823 0.8702119  0.97987366 0.95746374 0.4155775\n",
      " 0.21205737 0.5689826  0.76290339 0.73838168 0.22064295 0.31423745\n",
      " 0.68183744 0.21037199 0.2016736  0.99287099 0.88315362 0.47333735\n",
      " 0.11497271 0.19059238 0.73370796 0.38699675 0.16811465 0.88111532\n",
      " 0.0546413  0.89968646 0.82394373 0.85787034 0.98068786 0.00572104\n",
      " 0.0033436  0.0312456  0.00505453 0.00379314 0.00764584 0.13627927\n",
      " 0.03252275 0.03588289 0.43135071 0.19074069]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [0/54 (0%)]\tTrain Loss: 0.019751\n",
      "Train Epoch: 56 [8/54 (15%)]\tTrain Loss: 0.038474\n",
      "Train Epoch: 56 [16/54 (30%)]\tTrain Loss: 0.054690\n",
      "Train Epoch: 56 [24/54 (44%)]\tTrain Loss: 0.082137\n",
      "Train Epoch: 56 [32/54 (59%)]\tTrain Loss: 0.034882\n",
      "Train Epoch: 56 [40/54 (74%)]\tTrain Loss: 0.109360\n",
      "Train Epoch: 56 [48/54 (89%)]\tTrain Loss: 0.054173\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.51797783e-01 9.99969959e-01 9.97144043e-01 9.80194092e-01\n",
      " 6.95567012e-01 8.86392370e-02 9.99415278e-01 5.31289220e-01\n",
      " 5.00562966e-01 1.25934118e-02 7.49022067e-01 4.68818191e-03\n",
      " 2.61750758e-01 4.18546021e-01 7.52433002e-01 1.66961432e-01\n",
      " 1.01289988e-01 2.88585991e-01 2.05980346e-01 6.90671682e-01\n",
      " 8.03018987e-01 8.69849205e-01 9.60399330e-01 9.54540431e-01\n",
      " 5.69341004e-01 9.82306063e-01 9.66441751e-01 9.67676342e-01\n",
      " 6.10894978e-01 8.84682655e-01 9.98420000e-01 9.96317267e-01\n",
      " 9.55067515e-01 3.47169638e-02 2.70965882e-02 4.42877203e-01\n",
      " 4.46482658e-01 9.85171139e-01 3.89317609e-02 3.21554363e-01\n",
      " 3.16298813e-01 2.37713978e-01 3.80902976e-01 9.41960216e-01\n",
      " 5.86215079e-01 9.26396787e-01 9.99953389e-01 9.99888659e-01\n",
      " 9.99993563e-01 8.42593074e-01 9.99993563e-01 5.03903925e-02\n",
      " 8.41871873e-02 7.73182571e-01 2.33078256e-01 7.17247248e-01\n",
      " 9.90223825e-01 8.78589094e-01 1.62842691e-01 9.94612217e-01\n",
      " 9.96189177e-01 9.49084640e-01 9.94900525e-01 9.98285949e-01\n",
      " 9.96962965e-01 9.93687093e-01 9.80843008e-01 9.95773613e-01\n",
      " 9.99953032e-01 9.28644776e-01 9.73701179e-01 9.46870744e-01\n",
      " 9.99069154e-01 9.00047958e-01 9.70816851e-01 9.98275757e-01\n",
      " 1.00000000e+00 9.99999523e-01 9.99938011e-01 9.99987364e-01\n",
      " 9.99939680e-01 9.99992967e-01 9.99731839e-01 6.88837290e-01\n",
      " 5.06751359e-01 9.46396410e-01 9.77278888e-01 9.76744175e-01\n",
      " 7.48536885e-01 9.62315500e-01 9.53031182e-01 8.61267507e-01\n",
      " 8.22558343e-01 9.99773324e-01 9.95643735e-01 9.87599730e-01\n",
      " 6.16107404e-01 8.91957402e-01 9.47817981e-01 8.42395484e-01\n",
      " 1.20628819e-01 9.99831319e-01 2.77655751e-01 9.96602178e-01\n",
      " 9.88817453e-01 9.84822392e-01 9.98074293e-01 1.29279902e-03\n",
      " 1.47399012e-04 1.61433816e-02 1.42929074e-03 3.50324844e-04\n",
      " 4.60384600e-03 5.84407270e-01 7.28291646e-02 1.53863937e-01\n",
      " 9.64943945e-01 8.93769741e-01]\n",
      "predict [1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 57 [0/54 (0%)]\tTrain Loss: 0.060865\n",
      "Train Epoch: 57 [8/54 (15%)]\tTrain Loss: 0.019813\n",
      "Train Epoch: 57 [16/54 (30%)]\tTrain Loss: 0.104067\n",
      "Train Epoch: 57 [24/54 (44%)]\tTrain Loss: 0.029858\n",
      "Train Epoch: 57 [32/54 (59%)]\tTrain Loss: 0.039519\n",
      "Train Epoch: 57 [40/54 (74%)]\tTrain Loss: 0.030164\n",
      "Train Epoch: 57 [48/54 (89%)]\tTrain Loss: 0.063301\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.04303553 0.94002992 0.93117303 0.39903703 0.05927126 0.06202973\n",
      " 0.85086656 0.51942515 0.11779002 0.04944814 0.22136082 0.03567992\n",
      " 0.05363153 0.03554844 0.04226999 0.01683321 0.06221843 0.08231026\n",
      " 0.03822046 0.19273284 0.60286754 0.58909208 0.85771841 0.95540047\n",
      " 0.31100479 0.95176041 0.95358175 0.80307752 0.42268875 0.61904746\n",
      " 0.30710512 0.81992888 0.13658871 0.01129706 0.01305848 0.07311104\n",
      " 0.05640202 0.59299898 0.05535134 0.34252334 0.20430569 0.08878756\n",
      " 0.05867742 0.28313193 0.11706309 0.06174337 0.80911833 0.60877556\n",
      " 0.9941147  0.93652016 0.98583049 0.00415409 0.42075926 0.0741825\n",
      " 0.2665484  0.180546   0.59368247 0.23068853 0.14888196 0.3029556\n",
      " 0.84958845 0.39399669 0.64083481 0.92008781 0.8288573  0.92664677\n",
      " 0.70901841 0.93644637 0.98892713 0.14752112 0.44140434 0.36091861\n",
      " 0.93026304 0.46524903 0.78849125 0.68239403 0.99077177 0.97707933\n",
      " 0.82965487 0.93851864 0.82192433 0.92616409 0.94504946 0.51230711\n",
      " 0.31291243 0.40387565 0.55756325 0.58227986 0.45444572 0.7208339\n",
      " 0.93382472 0.44344339 0.31322765 0.99724698 0.78114098 0.78647661\n",
      " 0.04407197 0.44431746 0.47478759 0.60118186 0.20605022 0.79345864\n",
      " 0.0498375  0.71050507 0.58542103 0.4030835  0.9434796  0.02301822\n",
      " 0.00557595 0.04693925 0.01504276 0.02009897 0.22479326 0.32184124\n",
      " 0.01445627 0.01621182 0.62541717 0.26884165]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 58 [0/54 (0%)]\tTrain Loss: 0.051350\n",
      "Train Epoch: 58 [8/54 (15%)]\tTrain Loss: 0.020186\n",
      "Train Epoch: 58 [16/54 (30%)]\tTrain Loss: 0.136832\n",
      "Train Epoch: 58 [24/54 (44%)]\tTrain Loss: 0.033779\n",
      "Train Epoch: 58 [32/54 (59%)]\tTrain Loss: 0.025086\n",
      "Train Epoch: 58 [40/54 (74%)]\tTrain Loss: 0.066286\n",
      "Train Epoch: 58 [48/54 (89%)]\tTrain Loss: 0.026718\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.23799885e-04 9.91486132e-01 4.70499162e-06 9.82376337e-01\n",
      " 8.98682415e-01 2.69303627e-07 3.07549839e-03 8.25425488e-08\n",
      " 1.35479868e-05 8.61095265e-02 9.57223833e-01 5.63110746e-02\n",
      " 2.03674588e-07 2.80281216e-01 2.26349577e-01 2.78905600e-01\n",
      " 1.44589535e-07 2.02899814e-01 9.35945511e-01 7.34630346e-01\n",
      " 8.92033041e-01 7.91618884e-01 9.33649778e-01 9.91756797e-01\n",
      " 9.36635752e-06 9.85507250e-01 9.72361445e-01 9.88016725e-01\n",
      " 8.94619644e-01 8.35179508e-01 9.83339190e-01 9.62903678e-01\n",
      " 1.74018025e-01 5.86862490e-02 5.43036237e-02 4.49871957e-01\n",
      " 5.61331809e-01 9.72427607e-01 2.16485369e-05 5.42693138e-01\n",
      " 3.37835282e-01 3.66098702e-01 1.91182569e-01 1.23624345e-02\n",
      " 1.56643844e-04 7.15755105e-01 9.37308073e-01 6.55280113e-01\n",
      " 9.96897101e-01 9.73745286e-01 9.80266035e-01 4.18442152e-02\n",
      " 2.22521649e-07 4.75869864e-01 7.55999744e-01 7.61332333e-01\n",
      " 9.77075994e-01 8.96248698e-01 1.57999218e-01 8.41821730e-01\n",
      " 9.83917117e-01 9.46561098e-01 9.62115407e-01 8.53521943e-01\n",
      " 9.58515763e-01 2.35847366e-12 7.33969617e-04 9.85291123e-01\n",
      " 9.99160290e-01 9.78729904e-01 9.83604014e-01 9.57448661e-01\n",
      " 9.97429192e-01 8.96864891e-01 8.81690145e-01 9.56754386e-01\n",
      " 9.97905850e-01 9.93172705e-01 1.07786864e-01 9.94911849e-01\n",
      " 9.96139467e-01 9.98744726e-01 9.91967738e-01 1.89033058e-02\n",
      " 4.06258196e-01 9.79024649e-01 9.72107947e-01 9.75118697e-01\n",
      " 9.01798487e-01 9.77559507e-01 9.86407220e-01 8.17330062e-01\n",
      " 8.72040570e-01 9.99978423e-01 9.99706089e-01 9.99345839e-01\n",
      " 6.51450992e-01 5.25367796e-01 9.85033333e-01 9.97778237e-01\n",
      " 2.18078457e-02 9.84477520e-01 4.94484156e-01 9.99193132e-01\n",
      " 9.99274552e-01 9.98283625e-01 9.99785364e-01 1.00025356e-01\n",
      " 7.62261311e-03 3.60971332e-01 4.55405600e-02 1.89832319e-02\n",
      " 9.12701547e-01 9.84692931e-01 7.42070796e-03 1.94512248e-01\n",
      " 8.10762048e-01 8.99576962e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 59 [0/54 (0%)]\tTrain Loss: 0.064732\n",
      "Train Epoch: 59 [8/54 (15%)]\tTrain Loss: 0.090197\n",
      "Train Epoch: 59 [16/54 (30%)]\tTrain Loss: 0.067641\n",
      "Train Epoch: 59 [24/54 (44%)]\tTrain Loss: 0.032063\n",
      "Train Epoch: 59 [32/54 (59%)]\tTrain Loss: 0.040261\n",
      "Train Epoch: 59 [40/54 (74%)]\tTrain Loss: 0.013734\n",
      "Train Epoch: 59 [48/54 (89%)]\tTrain Loss: 0.051740\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.67759076e-01 8.24653089e-01 8.37028772e-03 1.51616544e-01\n",
      " 2.26514135e-02 2.55576777e-03 4.91159588e-01 1.79509297e-01\n",
      " 1.26957949e-02 4.54604672e-03 2.03532819e-02 5.02902223e-03\n",
      " 1.73871100e-04 2.32823994e-02 5.46338372e-02 3.09312204e-03\n",
      " 1.94381908e-04 1.98675692e-02 4.10030745e-02 9.76605415e-02\n",
      " 1.01212807e-01 1.14818566e-01 5.21257937e-01 9.10264492e-01\n",
      " 8.04130984e-09 8.86587381e-01 6.98259771e-01 4.78920221e-01\n",
      " 2.87431534e-02 2.80357432e-02 8.45458269e-01 8.25423837e-01\n",
      " 1.94203570e-01 1.10138289e-03 2.01946148e-03 3.55746131e-03\n",
      " 1.16671389e-02 2.39111871e-01 2.57816714e-06 3.12731639e-02\n",
      " 1.93501879e-02 1.96224321e-02 1.97291318e-02 3.77318300e-02\n",
      " 3.44365984e-02 4.26130183e-02 8.76982272e-01 8.04333746e-01\n",
      " 9.89153683e-01 5.41710377e-01 9.98318553e-01 5.75798913e-04\n",
      " 3.13981982e-05 2.13491563e-02 2.41945699e-01 1.08730579e-02\n",
      " 6.64745450e-01 2.92232702e-03 1.04930751e-01 3.30036394e-02\n",
      " 9.38383520e-01 6.75192297e-01 7.98105478e-01 8.50344002e-01\n",
      " 7.49530554e-01 5.68082622e-19 4.57498943e-03 9.23869133e-01\n",
      " 9.83292401e-01 6.65743649e-01 8.58534634e-01 7.65311241e-01\n",
      " 9.14661646e-01 5.49968898e-01 9.41738784e-01 7.90841401e-01\n",
      " 9.98932183e-01 9.93101358e-01 9.21841741e-01 9.89015043e-01\n",
      " 9.63660955e-01 9.36644614e-01 9.91079748e-01 4.16226109e-10\n",
      " 9.89497751e-02 5.71097136e-01 8.10876012e-01 8.97907853e-01\n",
      " 6.03187717e-02 2.17254385e-01 8.21699440e-01 2.65211910e-02\n",
      " 5.44231497e-02 4.00286138e-01 8.22589457e-01 7.41519570e-01\n",
      " 1.27366344e-02 1.57980308e-01 4.92096931e-01 8.07341635e-02\n",
      " 9.13768336e-02 8.81159008e-01 1.33216120e-02 1.99421018e-01\n",
      " 6.30531490e-01 4.27610725e-01 9.75591421e-01 2.84952065e-03\n",
      " 1.04405661e-03 3.46895918e-04 8.96173471e-04 1.68886303e-03\n",
      " 1.42823765e-03 3.73621583e-02 1.08698523e-02 1.81371644e-02\n",
      " 1.10440791e-01 5.99470921e-02]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 60 [0/54 (0%)]\tTrain Loss: 0.044932\n",
      "Train Epoch: 60 [8/54 (15%)]\tTrain Loss: 0.107706\n",
      "Train Epoch: 60 [16/54 (30%)]\tTrain Loss: 0.062916\n",
      "Train Epoch: 60 [24/54 (44%)]\tTrain Loss: 0.016854\n",
      "Train Epoch: 60 [32/54 (59%)]\tTrain Loss: 0.050308\n",
      "Train Epoch: 60 [40/54 (74%)]\tTrain Loss: 0.061253\n",
      "Train Epoch: 60 [48/54 (89%)]\tTrain Loss: 0.044136\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.65674892e-02 9.96240497e-01 9.89712000e-01 6.72005177e-01\n",
      " 3.99399430e-01 7.91644603e-02 9.87446964e-01 5.22155762e-01\n",
      " 1.32601619e-01 1.38339236e-01 5.80189884e-01 1.31474942e-01\n",
      " 3.63606274e-01 9.38361228e-01 8.67375851e-01 9.22820047e-02\n",
      " 1.80499226e-01 1.86443418e-01 5.12675345e-01 4.73000994e-03\n",
      " 8.94125819e-01 6.17537916e-01 1.45840079e-01 9.62933183e-01\n",
      " 6.84395492e-01 9.55601037e-01 9.80138540e-01 9.14159000e-01\n",
      " 1.77272800e-02 7.58698940e-01 9.02796865e-01 8.63948286e-01\n",
      " 4.69311148e-01 2.92054756e-04 3.77613343e-02 4.95325506e-01\n",
      " 6.54070795e-01 6.84849918e-01 2.99327564e-03 3.19010466e-01\n",
      " 5.20976603e-01 3.95303935e-01 2.03522280e-01 3.28504257e-02\n",
      " 5.13002157e-01 4.04228538e-01 9.00884330e-01 8.38984132e-01\n",
      " 9.95394766e-01 8.42674494e-01 9.88218546e-01 4.01564799e-02\n",
      " 4.92922932e-01 2.11944934e-02 5.79492629e-01 7.66812921e-01\n",
      " 7.02307463e-01 8.27028096e-01 5.65083861e-01 5.85823417e-01\n",
      " 9.03478563e-01 7.10712135e-01 8.17696273e-01 8.62575054e-01\n",
      " 7.78744966e-02 9.79320884e-01 9.43754375e-01 9.69899476e-01\n",
      " 9.95382488e-01 2.82073230e-01 6.11250281e-01 4.29650933e-01\n",
      " 9.77827370e-01 8.34064245e-01 8.82483006e-01 3.89202908e-02\n",
      " 9.99736369e-01 9.98567224e-01 9.33715463e-01 9.91437495e-01\n",
      " 9.94534850e-01 9.96381104e-01 9.92942095e-01 5.36108129e-02\n",
      " 3.67310867e-02 5.08098781e-01 3.51918638e-01 9.22885656e-01\n",
      " 9.30740952e-01 8.27632546e-01 1.13556176e-01 4.79128301e-01\n",
      " 7.71277368e-01 9.98992383e-01 2.53141791e-01 9.72467959e-01\n",
      " 1.36641795e-02 6.42618597e-01 8.96924257e-01 7.60281742e-01\n",
      " 7.20292050e-03 9.04966533e-01 3.69887501e-01 9.12594795e-01\n",
      " 9.21956956e-01 9.25031483e-01 9.80002165e-01 6.31550029e-02\n",
      " 3.92535254e-02 5.77558540e-02 1.24097168e-02 1.18820819e-04\n",
      " 6.10241532e-01 7.60384619e-01 4.75535661e-01 9.79845319e-03\n",
      " 8.45634818e-01 8.97402763e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 37 TN= 44 FN= 21 FP= 16\n",
      "TP+FP 53\n",
      "precision 0.6981132075471698\n",
      "recall 0.6379310344827587\n",
      "F1 0.6666666666666667\n",
      "acc 0.6864406779661016\n",
      "AUCp 0.685632183908046\n",
      "AUC 0.6827586206896552\n",
      "\n",
      " The epoch is 60, average recall: 0.6379, average precision: 0.6981,average F1: 0.6667, average accuracy: 0.6864, average AUC: 0.6828\n",
      "Train Epoch: 61 [0/54 (0%)]\tTrain Loss: 0.052698\n",
      "Train Epoch: 61 [8/54 (15%)]\tTrain Loss: 0.099912\n",
      "Train Epoch: 61 [16/54 (30%)]\tTrain Loss: 0.031177\n",
      "Train Epoch: 61 [24/54 (44%)]\tTrain Loss: 0.078721\n",
      "Train Epoch: 61 [32/54 (59%)]\tTrain Loss: 0.044681\n",
      "Train Epoch: 61 [40/54 (74%)]\tTrain Loss: 0.054782\n",
      "Train Epoch: 61 [48/54 (89%)]\tTrain Loss: 0.067962\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.32398126 0.95330226 0.75463945 0.31362769 0.1358192  0.13836403\n",
      " 0.8397606  0.41442817 0.10209151 0.00908064 0.23999077 0.01019425\n",
      " 0.02283223 0.10552219 0.21697517 0.05970513 0.02288116 0.11221306\n",
      " 0.07445457 0.15094373 0.20884317 0.1299375  0.52659661 0.55514956\n",
      " 0.09441004 0.86781073 0.7048403  0.66164941 0.07406985 0.06369592\n",
      " 0.75428516 0.52531362 0.12761103 0.01807251 0.01809435 0.1271724\n",
      " 0.11783695 0.2969386  0.06595858 0.12850699 0.06763633 0.10522612\n",
      " 0.05714565 0.14603391 0.10665163 0.07127359 0.96180308 0.96372253\n",
      " 0.99737382 0.95486683 0.99559963 0.00527134 0.22979482 0.09085425\n",
      " 0.55198896 0.04143544 0.64572781 0.03460046 0.13504757 0.24213152\n",
      " 0.8486048  0.60978645 0.78630298 0.86214262 0.49854827 0.47482219\n",
      " 0.48223427 0.74641192 0.96054    0.90107304 0.9716391  0.89606708\n",
      " 0.67605174 0.39181772 0.55007714 0.70658422 0.97680396 0.97347713\n",
      " 0.97766769 0.97040343 0.94493455 0.90261203 0.94842613 0.32686892\n",
      " 0.14221156 0.85208249 0.68535012 0.67918539 0.13457659 0.25945696\n",
      " 0.83715516 0.15523972 0.12257298 0.98339027 0.86073703 0.65830481\n",
      " 0.03710029 0.71902692 0.8201952  0.35464612 0.38320637 0.96200746\n",
      " 0.16419259 0.49113795 0.87611955 0.60567433 0.99270439 0.01319549\n",
      " 0.00687305 0.03333463 0.01597845 0.00900479 0.00903582 0.33877206\n",
      " 0.03705464 0.1529932  0.83449173 0.37240705]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 62 [0/54 (0%)]\tTrain Loss: 0.047915\n",
      "Train Epoch: 62 [8/54 (15%)]\tTrain Loss: 0.065433\n",
      "Train Epoch: 62 [16/54 (30%)]\tTrain Loss: 0.026098\n",
      "Train Epoch: 62 [24/54 (44%)]\tTrain Loss: 0.048551\n",
      "Train Epoch: 62 [32/54 (59%)]\tTrain Loss: 0.026789\n",
      "Train Epoch: 62 [40/54 (74%)]\tTrain Loss: 0.056132\n",
      "Train Epoch: 62 [48/54 (89%)]\tTrain Loss: 0.092790\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.78320283 0.99889851 0.99855632 0.97831136 0.92887306 0.6126554\n",
      " 0.99709094 0.96763527 0.33416256 0.14130244 0.98782301 0.13681045\n",
      " 0.90522796 0.89215207 0.77429843 0.27180731 0.9258703  0.47753993\n",
      " 0.90015543 0.81322944 0.92373955 0.91822481 0.98899031 0.98758262\n",
      " 0.89884669 0.99783677 0.96118516 0.99588251 0.77750593 0.98035622\n",
      " 0.99922252 0.9983536  0.96999073 0.58781952 0.10775889 0.49216667\n",
      " 0.96199214 0.98724049 0.57706404 0.86757684 0.85175145 0.72659844\n",
      " 0.56188065 0.99098629 0.87300378 0.92565471 0.99763155 0.99255693\n",
      " 0.99975318 0.96259826 0.99994051 0.35240814 0.93546474 0.8891362\n",
      " 0.79675663 0.58923298 0.94671553 0.95420015 0.78133589 0.94341826\n",
      " 0.98558563 0.88391912 0.96315533 0.96713656 0.95230162 0.99961507\n",
      " 0.99186498 0.99944264 0.99994969 0.95745546 0.95897251 0.8925761\n",
      " 0.99948138 0.95527726 0.99802822 0.96916103 0.99999583 0.99956328\n",
      " 0.99730152 0.99998283 0.99935764 0.9993186  0.99888438 0.53520036\n",
      " 0.83187568 0.9397456  0.96171707 0.96246332 0.98114568 0.99789512\n",
      " 0.99685282 0.81969672 0.83011174 0.99996841 0.99447834 0.9983682\n",
      " 0.80180061 0.95776951 0.99904114 0.99308997 0.61735123 0.99898356\n",
      " 0.57876915 0.99191177 0.996732   0.97949308 0.99684012 0.03078057\n",
      " 0.01058811 0.08888587 0.04665472 0.00972673 0.09052929 0.98024464\n",
      " 0.36026925 0.59643346 0.9840799  0.96018881]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 63 [0/54 (0%)]\tTrain Loss: 0.037578\n",
      "Train Epoch: 63 [8/54 (15%)]\tTrain Loss: 0.030769\n",
      "Train Epoch: 63 [16/54 (30%)]\tTrain Loss: 0.037374\n",
      "Train Epoch: 63 [24/54 (44%)]\tTrain Loss: 0.049874\n",
      "Train Epoch: 63 [32/54 (59%)]\tTrain Loss: 0.047973\n",
      "Train Epoch: 63 [40/54 (74%)]\tTrain Loss: 0.079078\n",
      "Train Epoch: 63 [48/54 (89%)]\tTrain Loss: 0.032454\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.49692231e-01 9.82245088e-01 9.76335943e-01 3.66503984e-01\n",
      " 4.29120846e-02 9.81807485e-02 8.43849242e-01 2.38364190e-01\n",
      " 1.09804548e-01 1.64502207e-02 1.23445295e-01 7.94089516e-04\n",
      " 3.22278887e-02 1.76416226e-02 6.57626018e-02 6.10732846e-03\n",
      " 3.91488336e-03 7.52659068e-02 1.75990462e-02 9.32767540e-02\n",
      " 9.38175991e-02 2.72188395e-01 7.28508353e-01 5.82161129e-01\n",
      " 8.81806314e-02 9.28886116e-01 3.05104107e-01 3.91644597e-01\n",
      " 7.43244067e-02 9.41995978e-02 4.00076538e-01 3.22133750e-01\n",
      " 2.58676767e-01 3.17506128e-05 1.64894300e-04 1.08400209e-05\n",
      " 1.92328152e-04 5.29093623e-01 3.61385494e-02 3.89533378e-02\n",
      " 4.94115278e-02 5.08803353e-02 3.81770097e-02 1.86265200e-01\n",
      " 1.49667308e-01 1.07378714e-01 9.95792508e-01 9.87888038e-01\n",
      " 9.97686148e-01 7.91743338e-01 9.99285400e-01 2.91543361e-03\n",
      " 5.91131710e-02 5.85498959e-02 1.08576231e-01 1.72047373e-02\n",
      " 4.24563915e-01 1.02954023e-02 7.49240490e-03 1.25993833e-01\n",
      " 8.79035890e-01 4.39616203e-01 7.69396961e-01 8.97790730e-01\n",
      " 5.72122276e-01 4.08835620e-01 2.02900946e-01 9.48503315e-01\n",
      " 9.92165208e-01 1.33996889e-01 9.20979559e-01 8.22389960e-01\n",
      " 2.98015743e-01 1.31047085e-01 4.34619546e-01 7.99420714e-01\n",
      " 9.99927521e-01 9.99537826e-01 9.90341425e-01 9.85155284e-01\n",
      " 9.15425241e-01 9.50117707e-01 8.90575528e-01 6.22306056e-02\n",
      " 4.55620140e-01 5.54687381e-01 9.24216866e-01 9.02745962e-01\n",
      " 8.73177778e-03 2.49548582e-03 5.57634890e-01 1.91064179e-02\n",
      " 4.44508679e-02 9.88263488e-01 8.78593266e-01 7.45140553e-01\n",
      " 2.89375000e-02 7.79530704e-01 7.42899895e-01 8.30073208e-02\n",
      " 1.53157130e-01 9.77615893e-01 3.69657837e-02 5.46126068e-01\n",
      " 6.42820001e-01 6.19863212e-01 9.86920953e-01 2.16624358e-05\n",
      " 8.86630460e-06 3.93525371e-03 1.18636177e-04 7.67468350e-07\n",
      " 2.77544023e-05 2.00330673e-04 5.63130490e-02 1.44750386e-01\n",
      " 7.78236151e-01 1.37284711e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 64 [0/54 (0%)]\tTrain Loss: 0.031804\n",
      "Train Epoch: 64 [8/54 (15%)]\tTrain Loss: 0.052278\n",
      "Train Epoch: 64 [16/54 (30%)]\tTrain Loss: 0.067375\n",
      "Train Epoch: 64 [24/54 (44%)]\tTrain Loss: 0.026438\n",
      "Train Epoch: 64 [32/54 (59%)]\tTrain Loss: 0.017574\n",
      "Train Epoch: 64 [40/54 (74%)]\tTrain Loss: 0.044429\n",
      "Train Epoch: 64 [48/54 (89%)]\tTrain Loss: 0.082752\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.31375372 0.98913491 0.91049647 0.57556027 0.22943297 0.26337016\n",
      " 0.94217968 0.31928706 0.08485612 0.14300375 0.35264289 0.02163145\n",
      " 0.06380516 0.27151251 0.29061699 0.04089484 0.02935019 0.13621689\n",
      " 0.0813582  0.35214186 0.16801864 0.5224902  0.94623256 0.97198921\n",
      " 0.30981395 0.9916209  0.99838412 0.57243305 0.50297779 0.54540575\n",
      " 0.95779204 0.87390053 0.43525571 0.01538157 0.01526822 0.06912524\n",
      " 0.07478163 0.49676287 0.0710962  0.23645394 0.30020568 0.16073041\n",
      " 0.0706111  0.61691791 0.3402108  0.35541898 0.99911433 0.98671836\n",
      " 0.99907744 0.833197   0.99964941 0.02193788 0.11853251 0.44586334\n",
      " 0.6648128  0.14613409 0.80823404 0.13568513 0.45310473 0.27809685\n",
      " 0.99539703 0.92077214 0.98042554 0.99554873 0.68592906 0.90857643\n",
      " 0.86950547 0.9859795  0.98798394 0.33179438 0.97009236 0.93829995\n",
      " 0.91324663 0.73143083 0.59931749 0.95418751 0.99990964 0.99897528\n",
      " 0.98590696 0.99976343 0.9992643  0.99781787 0.99914336 0.45591778\n",
      " 0.470761   0.63241917 0.92568034 0.94627708 0.33082879 0.81556469\n",
      " 0.99269038 0.41457191 0.31903109 0.99654633 0.63088316 0.76527548\n",
      " 0.08248876 0.35830766 0.38151607 0.69992441 0.13930969 0.99342346\n",
      " 0.06029695 0.46175635 0.57159632 0.78824955 0.99657178 0.06426186\n",
      " 0.02659614 0.08304173 0.02038012 0.01918289 0.31244859 0.34868178\n",
      " 0.09233701 0.11558058 0.50160187 0.28622967]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 65 [0/54 (0%)]\tTrain Loss: 0.044033\n",
      "Train Epoch: 65 [8/54 (15%)]\tTrain Loss: 0.052585\n",
      "Train Epoch: 65 [16/54 (30%)]\tTrain Loss: 0.037445\n",
      "Train Epoch: 65 [24/54 (44%)]\tTrain Loss: 0.102892\n",
      "Train Epoch: 65 [32/54 (59%)]\tTrain Loss: 0.058578\n",
      "Train Epoch: 65 [40/54 (74%)]\tTrain Loss: 0.071506\n",
      "Train Epoch: 65 [48/54 (89%)]\tTrain Loss: 0.047659\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.2370076  0.9159072  0.67569172 0.14703491 0.14440691 0.167557\n",
      " 0.72166812 0.12840812 0.05910034 0.01322552 0.0270404  0.00160563\n",
      " 0.01643242 0.44651148 0.37732875 0.05414945 0.03521824 0.05436581\n",
      " 0.00643204 0.08500846 0.13991185 0.1316366  0.30047256 0.79765749\n",
      " 0.06757908 0.77701449 0.89721358 0.18841875 0.0394318  0.12095618\n",
      " 0.66305983 0.27356315 0.2912294  0.00194711 0.00184501 0.01919466\n",
      " 0.00570295 0.12302842 0.07562625 0.21907675 0.16874534 0.11989608\n",
      " 0.06450836 0.16314331 0.04751056 0.09985185 0.90449709 0.92260909\n",
      " 0.99955124 0.82298064 0.999331   0.00325574 0.05967132 0.04484618\n",
      " 0.14610051 0.02848217 0.66642517 0.05964407 0.02323108 0.07081388\n",
      " 0.91895711 0.6297704  0.9157154  0.92414141 0.58679134 0.82833439\n",
      " 0.87247843 0.94857949 0.98233575 0.83232993 0.84337473 0.65082669\n",
      " 0.80216092 0.66563475 0.38612357 0.93098783 0.99536419 0.98216462\n",
      " 0.9619745  0.98964661 0.97421199 0.94127512 0.97661316 0.23442164\n",
      " 0.26502636 0.8055259  0.70537901 0.83402711 0.02497728 0.31797972\n",
      " 0.7177285  0.17673577 0.17031345 0.91691321 0.3434689  0.32726392\n",
      " 0.01422809 0.3065753  0.23132609 0.22623958 0.15350461 0.98743778\n",
      " 0.05058791 0.31113982 0.48850492 0.18302508 0.94949019 0.03028984\n",
      " 0.01445579 0.02543971 0.02215252 0.01197078 0.55026257 0.05776443\n",
      " 0.0776536  0.09849899 0.45043126 0.41494292]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 66 [0/54 (0%)]\tTrain Loss: 0.063237\n",
      "Train Epoch: 66 [8/54 (15%)]\tTrain Loss: 0.017496\n",
      "Train Epoch: 66 [16/54 (30%)]\tTrain Loss: 0.046128\n",
      "Train Epoch: 66 [24/54 (44%)]\tTrain Loss: 0.067801\n",
      "Train Epoch: 66 [32/54 (59%)]\tTrain Loss: 0.074529\n",
      "Train Epoch: 66 [40/54 (74%)]\tTrain Loss: 0.041374\n",
      "Train Epoch: 66 [48/54 (89%)]\tTrain Loss: 0.032560\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.02190429 0.96373922 0.96048623 0.05943716 0.03886744 0.04407642\n",
      " 0.93540746 0.04380803 0.08843964 0.07154575 0.05672888 0.01983184\n",
      " 0.01559854 0.51727235 0.1391179  0.01245462 0.02619602 0.09187363\n",
      " 0.07007131 0.42160252 0.66492176 0.38001531 0.87916875 0.99571925\n",
      " 0.20377268 0.97060835 0.98750931 0.59366161 0.15053129 0.29624406\n",
      " 0.3307147  0.32283181 0.02719914 0.00541939 0.00996752 0.04100291\n",
      " 0.08628691 0.19359797 0.02892814 0.12245965 0.08188815 0.06879009\n",
      " 0.03118893 0.18755296 0.06159651 0.0085974  0.18874364 0.10308085\n",
      " 0.98055649 0.88332427 0.88918608 0.00422728 0.15256457 0.1277007\n",
      " 0.46766642 0.18564048 0.22728734 0.2952075  0.16387054 0.02466779\n",
      " 0.64501387 0.31249565 0.55477226 0.81594175 0.33294377 0.5071016\n",
      " 0.85813391 0.75842971 0.95599997 0.34823042 0.18483382 0.17223953\n",
      " 0.84622037 0.35005504 0.74457711 0.38667107 0.99425596 0.98203009\n",
      " 0.75389242 0.61352444 0.78339654 0.8787244  0.93719494 0.27317408\n",
      " 0.33660439 0.18190248 0.51974845 0.72203368 0.57166529 0.71869409\n",
      " 0.99841928 0.04423452 0.03282772 0.99382001 0.97512859 0.90160096\n",
      " 0.14198409 0.19580372 0.35664999 0.33549881 0.27458575 0.49431249\n",
      " 0.05884168 0.17361873 0.62520283 0.4238942  0.9184652  0.0267358\n",
      " 0.02448044 0.06749584 0.02787244 0.01772513 0.51847035 0.64036202\n",
      " 0.04025149 0.07309843 0.691549   0.28123465]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 67 [0/54 (0%)]\tTrain Loss: 0.080311\n",
      "Train Epoch: 67 [8/54 (15%)]\tTrain Loss: 0.029093\n",
      "Train Epoch: 67 [16/54 (30%)]\tTrain Loss: 0.042942\n",
      "Train Epoch: 67 [24/54 (44%)]\tTrain Loss: 0.057007\n",
      "Train Epoch: 67 [32/54 (59%)]\tTrain Loss: 0.036029\n",
      "Train Epoch: 67 [40/54 (74%)]\tTrain Loss: 0.035959\n",
      "Train Epoch: 67 [48/54 (89%)]\tTrain Loss: 0.067962\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.56446415 0.99394554 0.94443631 0.41027629 0.21672104 0.43166393\n",
      " 0.96845442 0.34754166 0.27704707 0.22004424 0.38266334 0.02250709\n",
      " 0.07073754 0.24662922 0.29268631 0.06311466 0.30176723 0.26182795\n",
      " 0.11451183 0.41828921 0.57614714 0.8636539  0.9394812  0.9810183\n",
      " 0.88404721 0.98615855 0.98140436 0.74007851 0.28085396 0.36391744\n",
      " 0.98150831 0.94687116 0.24606119 0.00509939 0.00887191 0.04279027\n",
      " 0.12679102 0.78328437 0.0843481  0.25558144 0.2029682  0.31752068\n",
      " 0.058047   0.67845422 0.19021866 0.10469434 0.9987545  0.97472805\n",
      " 0.99994862 0.92845368 0.99996841 0.0124139  0.24372099 0.24307916\n",
      " 0.755647   0.2013313  0.85281366 0.23556468 0.64612359 0.27294436\n",
      " 0.99535936 0.96136689 0.99008512 0.99659771 0.71318692 0.85634756\n",
      " 0.89245391 0.98920316 0.99889082 0.95832658 0.97284341 0.8979212\n",
      " 0.96918309 0.63683963 0.78872925 0.99087685 0.99997675 0.99933726\n",
      " 0.99829429 0.99979895 0.99939644 0.99867237 0.99935001 0.40973324\n",
      " 0.62020653 0.95410156 0.97766054 0.97964019 0.31494358 0.94377214\n",
      " 0.97877413 0.31664631 0.14600861 0.99687469 0.9462797  0.88817906\n",
      " 0.10492981 0.90147132 0.76885718 0.79658085 0.32424328 0.99941266\n",
      " 0.17705755 0.82854098 0.93255156 0.91877359 0.99658823 0.04952044\n",
      " 0.00984298 0.04605527 0.03068038 0.00279375 0.33045965 0.44629917\n",
      " 0.23106471 0.39034495 0.82509989 0.76733148]\n",
      "predict [1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 68 [0/54 (0%)]\tTrain Loss: 0.018220\n",
      "Train Epoch: 68 [8/54 (15%)]\tTrain Loss: 0.059940\n",
      "Train Epoch: 68 [16/54 (30%)]\tTrain Loss: 0.062130\n",
      "Train Epoch: 68 [24/54 (44%)]\tTrain Loss: 0.018371\n",
      "Train Epoch: 68 [32/54 (59%)]\tTrain Loss: 0.068886\n",
      "Train Epoch: 68 [40/54 (74%)]\tTrain Loss: 0.056884\n",
      "Train Epoch: 68 [48/54 (89%)]\tTrain Loss: 0.022267\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.22576135 0.89242256 0.60886878 0.42393559 0.32524654 0.13423336\n",
      " 0.73529339 0.67153847 0.02410042 0.11179359 0.74304843 0.01150436\n",
      " 0.24410485 0.26070756 0.19601554 0.08092111 0.06543696 0.07730012\n",
      " 0.13481417 0.30821651 0.24648994 0.64992982 0.94322866 0.85368407\n",
      " 0.25606132 0.98912698 0.77747869 0.72127867 0.20830502 0.15344138\n",
      " 0.76298022 0.87234533 0.33675206 0.00264443 0.00338447 0.01359565\n",
      " 0.10953048 0.98929942 0.21295239 0.26305562 0.18907277 0.30543756\n",
      " 0.39871657 0.58901578 0.34053063 0.45563856 0.91069394 0.86719549\n",
      " 0.99988723 0.94752336 0.99968398 0.02566832 0.60075831 0.38810527\n",
      " 0.48959821 0.2781986  0.90420467 0.16206405 0.06714693 0.25993568\n",
      " 0.99003536 0.92142379 0.97962087 0.97890651 0.78450149 0.88401926\n",
      " 0.64434367 0.99139118 0.9936893  0.96219718 0.94512254 0.87295508\n",
      " 0.88126755 0.58922243 0.87258029 0.98616982 0.99581391 0.98265773\n",
      " 0.99355173 0.99948955 0.98675543 0.98462385 0.99182785 0.75406593\n",
      " 0.83670127 0.99127734 0.94684881 0.97309542 0.036996   0.32910353\n",
      " 0.9300614  0.46655786 0.3176547  0.99978203 0.98262376 0.97660875\n",
      " 0.109224   0.8906942  0.83116955 0.93187976 0.43516386 0.99515754\n",
      " 0.07857514 0.97415429 0.9975279  0.87724602 0.999951   0.01511197\n",
      " 0.00159234 0.09405779 0.0127779  0.00106909 0.05079728 0.110487\n",
      " 0.11661548 0.34528995 0.89292264 0.73954809]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 69 [0/54 (0%)]\tTrain Loss: 0.023394\n",
      "Train Epoch: 69 [8/54 (15%)]\tTrain Loss: 0.086946\n",
      "Train Epoch: 69 [16/54 (30%)]\tTrain Loss: 0.022190\n",
      "Train Epoch: 69 [24/54 (44%)]\tTrain Loss: 0.057944\n",
      "Train Epoch: 69 [32/54 (59%)]\tTrain Loss: 0.046260\n",
      "Train Epoch: 69 [40/54 (74%)]\tTrain Loss: 0.019757\n",
      "Train Epoch: 69 [48/54 (89%)]\tTrain Loss: 0.054501\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.07233659 0.65569192 0.40548539 0.16283278 0.12889339 0.0245052\n",
      " 0.5102697  0.28086609 0.01740446 0.05102303 0.52389532 0.00822816\n",
      " 0.26606065 0.07337973 0.05030387 0.14508303 0.05118378 0.09266826\n",
      " 0.09810316 0.33590242 0.41877568 0.53823245 0.59949005 0.94905519\n",
      " 0.11668202 0.93118769 0.96740705 0.86244559 0.15422849 0.15540063\n",
      " 0.75251025 0.66374785 0.23636313 0.00272002 0.00509603 0.0086933\n",
      " 0.05665956 0.7000829  0.31384721 0.30230054 0.11274416 0.26487577\n",
      " 0.1983605  0.62127513 0.27458426 0.09242181 0.71588653 0.49881104\n",
      " 0.99925059 0.98639917 0.99714112 0.02141663 0.43078235 0.22885111\n",
      " 0.46102455 0.18604977 0.91039896 0.33303577 0.06490319 0.21125275\n",
      " 0.91595602 0.78179026 0.93120009 0.93021065 0.55778217 0.94372976\n",
      " 0.47100428 0.95309472 0.99530798 0.95401013 0.86313832 0.84342599\n",
      " 0.93730038 0.86003894 0.87131447 0.76734537 0.92297971 0.8955943\n",
      " 0.81191272 0.98601449 0.96093214 0.96944672 0.98074383 0.61785567\n",
      " 0.44613612 0.83625102 0.91774976 0.94973195 0.06813862 0.33157152\n",
      " 0.90713328 0.56437171 0.27248544 0.99966276 0.93508768 0.95838022\n",
      " 0.15892352 0.77622926 0.87815636 0.94077009 0.44715637 0.98430151\n",
      " 0.16571555 0.9502306  0.92750883 0.81438929 0.99845815 0.02728829\n",
      " 0.00237398 0.18816546 0.03887964 0.00516159 0.51020074 0.05889862\n",
      " 0.10796329 0.08140972 0.41159493 0.19112839]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 70 [0/54 (0%)]\tTrain Loss: 0.060950\n",
      "Train Epoch: 70 [8/54 (15%)]\tTrain Loss: 0.052625\n",
      "Train Epoch: 70 [16/54 (30%)]\tTrain Loss: 0.039331\n",
      "Train Epoch: 70 [24/54 (44%)]\tTrain Loss: 0.051895\n",
      "Train Epoch: 70 [32/54 (59%)]\tTrain Loss: 0.028148\n",
      "Train Epoch: 70 [40/54 (74%)]\tTrain Loss: 0.149688\n",
      "Train Epoch: 70 [48/54 (89%)]\tTrain Loss: 0.013174\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.87298346e-01 7.97104955e-01 6.19427741e-01 3.70267123e-01\n",
      " 2.67627090e-01 1.76748291e-01 5.64484060e-01 3.18698466e-01\n",
      " 7.52302930e-02 4.49550688e-01 6.09124720e-01 1.87374562e-01\n",
      " 3.90395194e-01 1.02414250e-01 2.06365615e-01 5.38271405e-02\n",
      " 2.76429635e-02 1.11449718e-01 1.27257630e-01 4.58161443e-01\n",
      " 7.76328087e-01 3.07188928e-01 9.50809181e-01 9.97366488e-01\n",
      " 1.49044961e-01 9.89984155e-01 9.97163117e-01 8.47761869e-01\n",
      " 2.80899465e-01 2.18752056e-01 9.52515185e-01 9.32651699e-01\n",
      " 5.93299806e-01 2.43219528e-02 3.54366191e-02 4.90187667e-02\n",
      " 3.20535630e-01 3.98608148e-01 2.12435722e-01 3.36124420e-01\n",
      " 2.84979165e-01 2.38424033e-01 1.42714888e-01 5.17998576e-01\n",
      " 4.27533984e-01 3.92201304e-01 9.70936179e-01 9.46220279e-01\n",
      " 9.99990702e-01 9.80688930e-01 9.99940753e-01 2.14584768e-02\n",
      " 3.41486335e-01 3.80819857e-01 7.90463686e-01 3.58424723e-01\n",
      " 9.56502497e-01 1.51509196e-01 6.51606977e-01 3.61382902e-01\n",
      " 9.97545779e-01 9.19011950e-01 9.96193767e-01 9.96572971e-01\n",
      " 7.67761171e-01 6.55338347e-01 4.86521661e-01 9.98380423e-01\n",
      " 9.95383680e-01 9.08601224e-01 8.70889604e-01 8.42188537e-01\n",
      " 9.70062971e-01 8.65406096e-01 9.23246324e-01 9.92881060e-01\n",
      " 9.98410583e-01 9.96269464e-01 9.90451932e-01 9.99881864e-01\n",
      " 9.98674631e-01 9.99534845e-01 9.99645233e-01 6.12893105e-01\n",
      " 6.56465650e-01 9.86675918e-01 9.94668543e-01 9.95478332e-01\n",
      " 2.05786318e-01 3.94555211e-01 9.95646536e-01 5.49548745e-01\n",
      " 4.10804808e-01 9.99991536e-01 9.80905533e-01 9.83222783e-01\n",
      " 2.30495319e-01 7.78171957e-01 7.44464993e-01 8.62633526e-01\n",
      " 4.62007165e-01 9.94470716e-01 9.83696505e-02 9.64790046e-01\n",
      " 9.95818555e-01 9.79852200e-01 9.99984264e-01 9.22808889e-03\n",
      " 1.15815084e-03 1.95272956e-02 5.41580794e-03 5.08471916e-04\n",
      " 3.99551261e-03 1.11198470e-01 9.73513573e-02 2.86396325e-01\n",
      " 8.48116577e-01 2.48295426e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 39 TN= 43 FN= 19 FP= 17\n",
      "TP+FP 56\n",
      "precision 0.6964285714285714\n",
      "recall 0.6724137931034483\n",
      "F1 0.6842105263157895\n",
      "acc 0.6949152542372882\n",
      "AUCp 0.6945402298850575\n",
      "AUC 0.6919540229885058\n",
      "\n",
      " The epoch is 70, average recall: 0.6724, average precision: 0.6964,average F1: 0.6842, average accuracy: 0.6949, average AUC: 0.6920\n",
      "Train Epoch: 71 [0/54 (0%)]\tTrain Loss: 0.019536\n",
      "Train Epoch: 71 [8/54 (15%)]\tTrain Loss: 0.028289\n",
      "Train Epoch: 71 [16/54 (30%)]\tTrain Loss: 0.036877\n",
      "Train Epoch: 71 [24/54 (44%)]\tTrain Loss: 0.065375\n",
      "Train Epoch: 71 [32/54 (59%)]\tTrain Loss: 0.019475\n",
      "Train Epoch: 71 [40/54 (74%)]\tTrain Loss: 0.051428\n",
      "Train Epoch: 71 [48/54 (89%)]\tTrain Loss: 0.028304\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.00207827e-02 3.39736819e-01 8.59215856e-02 5.60671464e-03\n",
      " 5.64016495e-03 7.40869250e-03 1.50399238e-01 1.28384624e-02\n",
      " 7.00598990e-04 3.09633240e-02 9.25789587e-03 5.97807486e-03\n",
      " 3.91670596e-03 8.66765250e-03 1.95127111e-02 2.13890523e-03\n",
      " 9.50118236e-04 9.14951321e-03 5.70712471e-03 3.49663384e-02\n",
      " 6.64301142e-02 7.90512934e-03 2.87093312e-01 1.55462563e-01\n",
      " 5.05683292e-03 2.42735699e-01 2.21995488e-01 6.43656775e-02\n",
      " 8.51371046e-03 1.26021793e-02 2.23627821e-01 1.57489643e-01\n",
      " 4.95704152e-02 1.48864882e-03 1.10977958e-03 2.34383019e-03\n",
      " 1.14306929e-02 1.68432873e-02 3.87138128e-02 5.38443439e-02\n",
      " 1.93469953e-02 5.90335913e-02 1.29148848e-02 1.57053452e-02\n",
      " 9.27042123e-03 3.91836129e-02 2.15386838e-01 8.27988833e-02\n",
      " 9.89716589e-01 6.05233550e-01 9.91068721e-01 3.98621953e-04\n",
      " 1.16301971e-02 5.77279180e-03 4.72687334e-02 1.17598602e-03\n",
      " 4.27128464e-01 2.69425754e-03 1.50074693e-03 4.55309963e-03\n",
      " 8.83403242e-01 5.18947482e-01 9.18637991e-01 9.21010613e-01\n",
      " 1.27122283e-01 1.78599238e-01 3.43526602e-02 7.54770935e-01\n",
      " 7.45925009e-01 5.03445625e-01 5.78505754e-01 5.26616633e-01\n",
      " 8.19453657e-01 6.19011879e-01 3.18728954e-01 4.77888644e-01\n",
      " 8.99835765e-01 9.05622184e-01 1.40292212e-01 8.80263209e-01\n",
      " 7.00723946e-01 9.07014608e-01 8.99014413e-01 2.31077120e-01\n",
      " 1.14816427e-01 7.09056735e-01 5.54596364e-01 8.51901531e-01\n",
      " 1.06151672e-02 6.96034282e-02 1.65951312e-01 4.02479321e-02\n",
      " 2.25970335e-02 8.94152999e-01 9.60699916e-01 3.40978473e-01\n",
      " 2.00642063e-03 3.27646919e-02 4.05490071e-01 1.91476271e-01\n",
      " 3.08443364e-02 6.68493450e-01 1.03060864e-02 7.41505325e-01\n",
      " 8.40781510e-01 8.55105698e-01 9.98371542e-01 1.04994758e-03\n",
      " 1.77403126e-04 7.84483552e-03 1.03520718e-03 5.14727202e-04\n",
      " 1.14542153e-02 2.10242301e-01 5.08266967e-03 2.50189402e-03\n",
      " 1.75916851e-01 6.48559704e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 72 [0/54 (0%)]\tTrain Loss: 0.018815\n",
      "Train Epoch: 72 [8/54 (15%)]\tTrain Loss: 0.048752\n",
      "Train Epoch: 72 [16/54 (30%)]\tTrain Loss: 0.033929\n",
      "Train Epoch: 72 [24/54 (44%)]\tTrain Loss: 0.034623\n",
      "Train Epoch: 72 [32/54 (59%)]\tTrain Loss: 0.061609\n",
      "Train Epoch: 72 [40/54 (74%)]\tTrain Loss: 0.150669\n",
      "Train Epoch: 72 [48/54 (89%)]\tTrain Loss: 0.042379\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.19589522 0.99798727 0.99715662 0.95472485 0.61326849 0.28443307\n",
      " 0.99701798 0.9613688  0.03734068 0.05126699 0.70330387 0.01547489\n",
      " 0.49275842 0.99222189 0.98337054 0.46204722 0.73804384 0.10991456\n",
      " 0.28663355 0.332569   0.6821627  0.76875061 0.91400301 0.96393371\n",
      " 0.66720605 0.97354215 0.98430151 0.915573   0.58836305 0.72237331\n",
      " 0.99215829 0.98516375 0.63508928 0.01719608 0.00920699 0.37510529\n",
      " 0.42965814 0.88765275 0.2815915  0.39229044 0.46206093 0.40271074\n",
      " 0.10985602 0.87035239 0.85235214 0.88376564 0.99009025 0.98162913\n",
      " 0.99989653 0.91477716 0.99986494 0.11445938 0.78446668 0.79204273\n",
      " 0.34562722 0.59896463 0.90136582 0.84748602 0.08859065 0.83270717\n",
      " 0.99633032 0.97237408 0.97448254 0.98559618 0.98481894 0.99928099\n",
      " 0.99710637 0.99525815 0.9994548  0.78084147 0.98474497 0.94907337\n",
      " 0.99617565 0.96020335 0.95193958 0.99251056 0.99996841 0.99985254\n",
      " 0.99970967 0.99989629 0.99986303 0.99985456 0.99954468 0.58760327\n",
      " 0.75578064 0.89560556 0.95733273 0.97623944 0.80486012 0.97900486\n",
      " 0.98194605 0.93098885 0.92646033 0.99870634 0.98841584 0.98760146\n",
      " 0.29634663 0.82142401 0.76948762 0.94594765 0.3419213  0.99856514\n",
      " 0.31155592 0.9806667  0.97652131 0.98667383 0.99686962 0.07648882\n",
      " 0.00497983 0.07501939 0.01431202 0.00104152 0.80146343 0.7601288\n",
      " 0.41528693 0.22214507 0.43497187 0.83406603]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 73 [0/54 (0%)]\tTrain Loss: 0.040165\n",
      "Train Epoch: 73 [8/54 (15%)]\tTrain Loss: 0.023171\n",
      "Train Epoch: 73 [16/54 (30%)]\tTrain Loss: 0.031899\n",
      "Train Epoch: 73 [24/54 (44%)]\tTrain Loss: 0.030984\n",
      "Train Epoch: 73 [32/54 (59%)]\tTrain Loss: 0.033823\n",
      "Train Epoch: 73 [40/54 (74%)]\tTrain Loss: 0.054502\n",
      "Train Epoch: 73 [48/54 (89%)]\tTrain Loss: 0.031218\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.23956552 0.99534011 0.97079998 0.67754984 0.53868639 0.28560153\n",
      " 0.99168229 0.65691173 0.10792361 0.27095619 0.75963527 0.04340538\n",
      " 0.11140665 0.81584197 0.80550897 0.32456928 0.25569797 0.28886929\n",
      " 0.49525985 0.5315153  0.82843918 0.80794519 0.98732346 0.96112198\n",
      " 0.7926569  0.99738234 0.99597341 0.70524293 0.86363786 0.69570816\n",
      " 0.99301672 0.98961103 0.15592971 0.03812549 0.12856424 0.65470243\n",
      " 0.83773232 0.95282882 0.55983883 0.41320464 0.54606152 0.4332836\n",
      " 0.16123948 0.83948165 0.78096217 0.56422806 0.9669016  0.9075653\n",
      " 0.9999038  0.88510233 0.99991608 0.05738217 0.66404831 0.40652302\n",
      " 0.6242246  0.24660711 0.98300755 0.61437917 0.22636929 0.51292086\n",
      " 0.99869835 0.981471   0.9951638  0.99600947 0.97660261 0.99596184\n",
      " 0.99227363 0.98006403 0.99949396 0.94576681 0.96723998 0.91333175\n",
      " 0.99845982 0.86415309 0.96113217 0.99803597 0.99993563 0.99984801\n",
      " 0.99837351 0.9999367  0.99982905 0.99956173 0.99889308 0.85534233\n",
      " 0.83556557 0.99712211 0.99376523 0.99275726 0.64603561 0.94773871\n",
      " 0.97184855 0.91386193 0.86479133 0.99966908 0.9979431  0.96643639\n",
      " 0.23371932 0.94715852 0.91145498 0.97569954 0.5905239  0.99954551\n",
      " 0.33340541 0.99341267 0.99736792 0.99767119 0.99977297 0.15783826\n",
      " 0.00472274 0.12668504 0.00766685 0.00317148 0.1084213  0.90398067\n",
      " 0.43823808 0.71567392 0.91251212 0.90633458]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 74 [0/54 (0%)]\tTrain Loss: 0.048766\n",
      "Train Epoch: 74 [8/54 (15%)]\tTrain Loss: 0.014149\n",
      "Train Epoch: 74 [16/54 (30%)]\tTrain Loss: 0.069333\n",
      "Train Epoch: 74 [24/54 (44%)]\tTrain Loss: 0.091983\n",
      "Train Epoch: 74 [32/54 (59%)]\tTrain Loss: 0.050135\n",
      "Train Epoch: 74 [40/54 (74%)]\tTrain Loss: 0.044847\n",
      "Train Epoch: 74 [48/54 (89%)]\tTrain Loss: 0.042156\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.12363037 0.90882653 0.76216531 0.66523731 0.13838954 0.01449862\n",
      " 0.82418567 0.07751815 0.01388762 0.10130715 0.08395166 0.1340587\n",
      " 0.02907122 0.16546774 0.36314788 0.01834231 0.14691558 0.02401812\n",
      " 0.05064922 0.09143217 0.45630515 0.12632701 0.92868817 0.85822791\n",
      " 0.0465947  0.98329091 0.95596957 0.21760106 0.28354219 0.35141513\n",
      " 0.82969362 0.96290636 0.83217579 0.25674355 0.18543689 0.09949326\n",
      " 0.75038546 0.60045779 0.05880831 0.29012957 0.23401277 0.08804033\n",
      " 0.06558798 0.26707292 0.20136656 0.1980167  0.81551701 0.71820027\n",
      " 0.99995983 0.93993872 0.99984467 0.00298321 0.07404769 0.06833551\n",
      " 0.57460439 0.05828325 0.54674488 0.11357573 0.46757856 0.3082267\n",
      " 0.99089724 0.84984016 0.9858709  0.99476445 0.89258116 0.94224387\n",
      " 0.84659898 0.96485549 0.98437011 0.3506586  0.69465673 0.62769628\n",
      " 0.99228996 0.82133412 0.66543096 0.8326003  0.99596608 0.99008381\n",
      " 0.83120555 0.99942541 0.9914459  0.97943521 0.98407561 0.5066554\n",
      " 0.30778185 0.69977993 0.76423466 0.8801617  0.61955374 0.61976022\n",
      " 0.99682295 0.73334128 0.56323922 0.99950147 0.98766172 0.99670416\n",
      " 0.04014456 0.80455369 0.63135076 0.89662123 0.2000832  0.99257302\n",
      " 0.04318386 0.73113704 0.96711314 0.76898158 0.99967659 0.12288317\n",
      " 0.03585466 0.2160923  0.07985897 0.02287636 0.14270024 0.57194704\n",
      " 0.02318761 0.15805578 0.82048243 0.29187778]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 75 [0/54 (0%)]\tTrain Loss: 0.020182\n",
      "Train Epoch: 75 [8/54 (15%)]\tTrain Loss: 0.061794\n",
      "Train Epoch: 75 [16/54 (30%)]\tTrain Loss: 0.040500\n",
      "Train Epoch: 75 [24/54 (44%)]\tTrain Loss: 0.011884\n",
      "Train Epoch: 75 [32/54 (59%)]\tTrain Loss: 0.016193\n",
      "Train Epoch: 75 [40/54 (74%)]\tTrain Loss: 0.018777\n",
      "Train Epoch: 75 [48/54 (89%)]\tTrain Loss: 0.030378\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.49589965e-01 8.18209350e-01 2.62799054e-01 3.60259950e-01\n",
      " 2.11673796e-01 5.32119013e-02 7.63196528e-01 3.13230217e-01\n",
      " 1.18192164e-02 8.03852379e-02 6.51130736e-01 3.02591193e-02\n",
      " 1.51881024e-01 8.78388733e-02 1.94970295e-01 6.57773912e-02\n",
      " 1.11301616e-01 5.50399162e-03 4.55778129e-02 1.29840672e-01\n",
      " 4.47880000e-01 5.51491380e-01 7.40638614e-01 8.18388462e-01\n",
      " 1.51001275e-01 9.63545859e-01 9.78020072e-01 7.46218979e-01\n",
      " 2.33407468e-01 6.63393617e-01 7.72754312e-01 9.00023520e-01\n",
      " 6.06566370e-01 1.14051692e-01 8.55281129e-02 1.03275552e-01\n",
      " 4.59928781e-01 7.26171136e-01 4.12863269e-02 3.23476166e-01\n",
      " 2.18608156e-01 2.77504742e-01 1.81568433e-02 2.12160230e-01\n",
      " 4.77576256e-02 8.15209150e-02 3.20365846e-01 5.23337722e-01\n",
      " 9.98842597e-01 9.03484523e-01 9.99321461e-01 8.00931174e-03\n",
      " 5.35605289e-02 2.04542093e-02 4.15417463e-01 2.72278730e-02\n",
      " 7.04997838e-01 1.33754224e-01 2.50943005e-01 2.64003202e-02\n",
      " 9.47842300e-01 7.55942047e-01 8.63421679e-01 9.11452532e-01\n",
      " 7.64954686e-01 9.94417667e-01 9.50496972e-01 9.84733522e-01\n",
      " 9.98928249e-01 9.82316315e-01 6.07864201e-01 4.03440952e-01\n",
      " 9.80010211e-01 9.25572395e-01 7.97423363e-01 6.25817120e-01\n",
      " 9.91854906e-01 9.73034561e-01 9.42671895e-01 9.89822268e-01\n",
      " 9.92270350e-01 9.83807385e-01 9.76687729e-01 2.50905871e-01\n",
      " 2.41680279e-01 7.44210064e-01 7.09911764e-01 8.85410666e-01\n",
      " 8.03762257e-01 9.69974458e-01 9.98861790e-01 6.60880148e-01\n",
      " 3.08107823e-01 9.98387814e-01 9.58304524e-01 9.37436044e-01\n",
      " 1.33627532e-02 2.30025902e-01 7.73362041e-01 9.55904067e-01\n",
      " 8.17350522e-02 9.94189858e-01 6.89161643e-02 6.46458268e-01\n",
      " 8.86426926e-01 8.76975358e-01 9.89485621e-01 1.56168696e-02\n",
      " 4.18378273e-04 3.71065550e-02 9.40595381e-03 9.94886737e-04\n",
      " 3.29792589e-01 8.65413845e-01 1.88019753e-01 3.80261168e-02\n",
      " 7.59398460e-01 5.52111804e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 76 [0/54 (0%)]\tTrain Loss: 0.058759\n",
      "Train Epoch: 76 [8/54 (15%)]\tTrain Loss: 0.045038\n",
      "Train Epoch: 76 [16/54 (30%)]\tTrain Loss: 0.043168\n",
      "Train Epoch: 76 [24/54 (44%)]\tTrain Loss: 0.046292\n",
      "Train Epoch: 76 [32/54 (59%)]\tTrain Loss: 0.077547\n",
      "Train Epoch: 76 [40/54 (74%)]\tTrain Loss: 0.056536\n",
      "Train Epoch: 76 [48/54 (89%)]\tTrain Loss: 0.042518\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.15693566 0.67103708 0.41192502 0.3564201  0.14125721 0.05657396\n",
      " 0.49029297 0.09183311 0.13386679 0.19293869 0.19022447 0.02231715\n",
      " 0.1083802  0.15156345 0.42391896 0.07638496 0.06354002 0.02130601\n",
      " 0.03151448 0.09180926 0.32651019 0.39324731 0.71149951 0.87730026\n",
      " 0.33634683 0.94905746 0.9799903  0.58519971 0.25022507 0.29867807\n",
      " 0.53765696 0.73326862 0.5388664  0.01127624 0.0149335  0.02265381\n",
      " 0.05820918 0.2686469  0.09643679 0.40486932 0.28140819 0.21054292\n",
      " 0.07183351 0.28005686 0.04711083 0.05377388 0.44002014 0.29887769\n",
      " 0.99805605 0.96635926 0.99853432 0.00553777 0.07981739 0.06887546\n",
      " 0.65954638 0.11687253 0.51742262 0.22714035 0.05691556 0.0784061\n",
      " 0.87772149 0.85546654 0.87882805 0.9452433  0.69282389 0.93902689\n",
      " 0.70211124 0.98752582 0.98976481 0.95798761 0.50541282 0.45760429\n",
      " 0.95872808 0.88214666 0.82231086 0.75326389 0.96918082 0.96169502\n",
      " 0.81160736 0.97755355 0.97765428 0.92868716 0.98389775 0.48231184\n",
      " 0.44424549 0.83893019 0.88545114 0.92558324 0.12453334 0.69776887\n",
      " 0.99244988 0.35233846 0.19022825 0.9944641  0.97000253 0.69815505\n",
      " 0.04840165 0.78384191 0.72291648 0.89271736 0.27061516 0.97455931\n",
      " 0.07110753 0.42392403 0.5829618  0.69532382 0.95499313 0.04448986\n",
      " 0.00876877 0.16450068 0.06096034 0.01149957 0.43544906 0.2743257\n",
      " 0.08454629 0.07952434 0.60699439 0.61610097]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 77 [0/54 (0%)]\tTrain Loss: 0.010472\n",
      "Train Epoch: 77 [8/54 (15%)]\tTrain Loss: 0.102267\n",
      "Train Epoch: 77 [16/54 (30%)]\tTrain Loss: 0.059867\n",
      "Train Epoch: 77 [24/54 (44%)]\tTrain Loss: 0.021955\n",
      "Train Epoch: 77 [32/54 (59%)]\tTrain Loss: 0.020235\n",
      "Train Epoch: 77 [40/54 (74%)]\tTrain Loss: 0.018707\n",
      "Train Epoch: 77 [48/54 (89%)]\tTrain Loss: 0.036937\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.13301656 0.95409232 0.97488201 0.98656255 0.70710665 0.15230322\n",
      " 0.95237237 0.73869932 0.4064312  0.5533179  0.86466819 0.18366781\n",
      " 0.6110692  0.76436085 0.78858942 0.4342066  0.66094649 0.10577991\n",
      " 0.07331954 0.16595085 0.30729139 0.94887435 0.98989785 0.98668844\n",
      " 0.38636255 0.9976356  0.98394382 0.95352697 0.75242478 0.82215279\n",
      " 0.71994776 0.99153954 0.90242124 0.02943105 0.0169714  0.32728842\n",
      " 0.66585386 0.99976629 0.46199989 0.96740681 0.84345889 0.8970924\n",
      " 0.43623561 0.98545086 0.56472546 0.20353311 0.87889278 0.94786716\n",
      " 0.99989414 0.97537029 0.99939382 0.22252193 0.23797871 0.57860309\n",
      " 0.31958547 0.63836169 0.95834416 0.41084597 0.98272127 0.15291762\n",
      " 0.99635541 0.98404479 0.97645628 0.98372966 0.9788835  0.99923038\n",
      " 0.98734099 0.99997318 0.99977964 0.8324182  0.57591701 0.5744887\n",
      " 0.97732055 0.75980026 0.82079154 0.99128151 0.99969757 0.99926704\n",
      " 0.99875844 0.99991775 0.99566627 0.93010873 0.99162078 0.98682052\n",
      " 0.99205512 0.88003188 0.99812895 0.99766457 0.27823645 0.95075768\n",
      " 0.99128222 0.84975296 0.8158462  0.99998605 0.99050397 0.99931645\n",
      " 0.17517857 0.97042793 0.90561092 0.97676826 0.78569758 0.99979705\n",
      " 0.11189656 0.94956142 0.99173248 0.96317178 0.99965858 0.21304989\n",
      " 0.00371839 0.18398874 0.03397415 0.00309989 0.26787472 0.36028129\n",
      " 0.4100332  0.52389038 0.95698684 0.98737943]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "Train Epoch: 78 [0/54 (0%)]\tTrain Loss: 0.027219\n",
      "Train Epoch: 78 [8/54 (15%)]\tTrain Loss: 0.046347\n",
      "Train Epoch: 78 [16/54 (30%)]\tTrain Loss: 0.025749\n",
      "Train Epoch: 78 [24/54 (44%)]\tTrain Loss: 0.034411\n",
      "Train Epoch: 78 [32/54 (59%)]\tTrain Loss: 0.013289\n",
      "Train Epoch: 78 [40/54 (74%)]\tTrain Loss: 0.077166\n",
      "Train Epoch: 78 [48/54 (89%)]\tTrain Loss: 0.013845\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.13959399e-02 6.98494434e-01 6.17719710e-01 2.43912667e-01\n",
      " 1.33592561e-01 2.51876041e-02 7.46516168e-01 1.92998983e-02\n",
      " 2.86135189e-02 2.85184681e-01 7.76409447e-01 1.76293835e-01\n",
      " 8.04661661e-02 4.70552705e-02 3.24943103e-02 1.18506523e-02\n",
      " 1.08207809e-02 1.18947616e-02 7.54411593e-02 7.25636035e-02\n",
      " 3.06377202e-01 7.45213628e-01 9.71638501e-01 9.73153472e-01\n",
      " 2.19808221e-01 9.88385320e-01 9.80086446e-01 8.10520172e-01\n",
      " 7.66911030e-01 5.40430784e-01 6.65378928e-01 9.91881669e-01\n",
      " 2.96376228e-01 1.23651780e-01 3.04630455e-02 4.83646654e-02\n",
      " 3.45644802e-01 9.76155400e-01 4.84839007e-02 7.36135960e-01\n",
      " 5.85838854e-01 5.01389623e-01 4.55423743e-02 3.49048287e-01\n",
      " 8.87312517e-02 4.68314767e-01 8.98114741e-01 9.05506134e-01\n",
      " 9.99833226e-01 9.57894623e-01 9.99522328e-01 3.59247904e-03\n",
      " 1.35684796e-02 2.98390202e-02 5.60325503e-01 1.90879852e-02\n",
      " 8.11662793e-01 2.24620998e-02 7.44405389e-01 7.57139130e-03\n",
      " 9.62463200e-01 8.83799434e-01 9.11846161e-01 9.73159075e-01\n",
      " 4.92003262e-01 7.76762307e-01 6.08164966e-01 9.99678254e-01\n",
      " 9.98588264e-01 6.81660175e-01 8.29437613e-01 7.77623832e-01\n",
      " 9.86884952e-01 8.38830709e-01 7.81989217e-01 9.75183904e-01\n",
      " 9.99903560e-01 9.99714077e-01 9.83734608e-01 9.99872923e-01\n",
      " 9.98905420e-01 9.98322427e-01 9.96112823e-01 7.59826720e-01\n",
      " 7.93262422e-01 7.36131847e-01 9.74079251e-01 9.84217525e-01\n",
      " 4.83590633e-01 9.93464053e-01 9.97478306e-01 5.44945717e-01\n",
      " 2.52764761e-01 9.99975681e-01 9.93192613e-01 9.99531984e-01\n",
      " 1.85994152e-02 5.80381513e-01 6.03662848e-01 9.96054769e-01\n",
      " 3.61778259e-01 9.93003190e-01 2.87025198e-02 9.64167237e-01\n",
      " 9.86858726e-01 9.83687878e-01 9.99312162e-01 3.48758027e-02\n",
      " 8.61921231e-04 1.00261476e-02 1.84776622e-03 9.07762791e-04\n",
      " 4.39657494e-02 9.62416291e-01 4.72431153e-01 2.62229204e-01\n",
      " 8.09915185e-01 5.84643602e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 79 [0/54 (0%)]\tTrain Loss: 0.021173\n",
      "Train Epoch: 79 [8/54 (15%)]\tTrain Loss: 0.088097\n",
      "Train Epoch: 79 [16/54 (30%)]\tTrain Loss: 0.154237\n",
      "Train Epoch: 79 [24/54 (44%)]\tTrain Loss: 0.012806\n",
      "Train Epoch: 79 [32/54 (59%)]\tTrain Loss: 0.008517\n",
      "Train Epoch: 79 [40/54 (74%)]\tTrain Loss: 0.161525\n",
      "Train Epoch: 79 [48/54 (89%)]\tTrain Loss: 0.054633\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.61716675e-02 3.69573608e-02 5.75420354e-03 1.06993299e-02\n",
      " 1.44423069e-02 6.59246230e-03 9.25135892e-03 3.13343690e-03\n",
      " 8.20671115e-03 3.95094529e-02 5.19920886e-02 5.47321178e-02\n",
      " 3.42286634e-03 3.14140669e-03 1.92547520e-03 1.43614667e-03\n",
      " 6.42407220e-04 4.29341523e-03 7.05146091e-03 1.67206414e-02\n",
      " 7.48361601e-03 2.75729075e-02 3.23023975e-01 4.58802968e-01\n",
      " 5.88290067e-03 6.16891682e-01 4.12661284e-01 2.06543207e-02\n",
      " 2.93027218e-02 1.11733209e-02 2.61909254e-02 1.52902246e-01\n",
      " 3.24325375e-02 1.27276266e-02 7.93952495e-03 5.36824344e-03\n",
      " 3.70539203e-02 1.82390623e-02 1.84812322e-02 5.55122234e-02\n",
      " 2.05130763e-02 3.77685018e-02 1.16135525e-02 9.03311837e-03\n",
      " 4.47059795e-03 1.01936869e-02 5.71960062e-02 8.49832073e-02\n",
      " 9.90974009e-01 7.19461501e-01 9.57932830e-01 5.24143048e-04\n",
      " 3.68673890e-03 3.51623516e-03 8.57333615e-02 1.23093487e-03\n",
      " 2.66323596e-01 1.07060268e-03 3.10011189e-02 1.38464628e-03\n",
      " 1.76718205e-01 1.03688560e-01 4.39244866e-01 6.53682888e-01\n",
      " 1.34618962e-02 1.31509611e-02 1.74045246e-02 4.57300514e-01\n",
      " 4.03093129e-01 2.71124214e-01 2.76656747e-01 3.19516987e-01\n",
      " 7.17151165e-01 1.13075867e-01 5.66200837e-02 3.93787146e-01\n",
      " 9.08653796e-01 8.00529838e-01 3.68846804e-02 6.23969495e-01\n",
      " 1.76130846e-01 3.68354827e-01 4.77002591e-01 2.92285055e-01\n",
      " 1.15139030e-01 6.92327976e-01 6.55115664e-01 6.79290712e-01\n",
      " 6.12101033e-02 6.96525574e-02 7.70668089e-01 1.28607918e-02\n",
      " 1.56592820e-02 9.78346586e-01 4.28925008e-01 3.96272659e-01\n",
      " 3.64476582e-03 6.59528077e-02 3.74529511e-02 9.36713219e-02\n",
      " 1.25074103e-01 7.01946199e-01 5.85870259e-03 2.06639469e-01\n",
      " 7.07415402e-01 3.66750062e-01 9.91854191e-01 3.97835858e-03\n",
      " 4.82219359e-04 1.29498460e-03 3.21608211e-04 2.90780095e-04\n",
      " 1.77947106e-04 5.91880493e-02 1.18336501e-02 2.18794383e-02\n",
      " 3.64387244e-01 5.27511127e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 80 [0/54 (0%)]\tTrain Loss: 0.083147\n",
      "Train Epoch: 80 [8/54 (15%)]\tTrain Loss: 0.051844\n",
      "Train Epoch: 80 [16/54 (30%)]\tTrain Loss: 0.118181\n",
      "Train Epoch: 80 [24/54 (44%)]\tTrain Loss: 0.059353\n",
      "Train Epoch: 80 [32/54 (59%)]\tTrain Loss: 0.021256\n",
      "Train Epoch: 80 [40/54 (74%)]\tTrain Loss: 0.023696\n",
      "Train Epoch: 80 [48/54 (89%)]\tTrain Loss: 0.048400\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.12434857 0.93425995 0.95177859 0.65187603 0.0914137  0.11439657\n",
      " 0.86048979 0.15972054 0.25231421 0.15884754 0.58647233 0.05197331\n",
      " 0.03216843 0.05874587 0.05810894 0.05863957 0.05019403 0.08357242\n",
      " 0.19165824 0.23051244 0.30675051 0.79276711 0.91802907 0.95434874\n",
      " 0.35474801 0.99097377 0.94785148 0.76134783 0.367883   0.15941192\n",
      " 0.79124051 0.95481539 0.19825038 0.04011873 0.02172096 0.04528516\n",
      " 0.2279028  0.81265831 0.28566453 0.47870362 0.24679688 0.27322036\n",
      " 0.13056934 0.32552117 0.21762151 0.19767731 0.97210115 0.93822598\n",
      " 0.99950206 0.99460208 0.99926096 0.0066668  0.19720443 0.12934966\n",
      " 0.58814603 0.04348233 0.67529315 0.03639027 0.14766528 0.20435035\n",
      " 0.97158784 0.87825817 0.97372276 0.98791367 0.77116799 0.42554298\n",
      " 0.6769802  0.99754322 0.99883693 0.18075107 0.88731664 0.87699389\n",
      " 0.86190593 0.76749855 0.63576621 0.9469555  0.99995458 0.9994784\n",
      " 0.99392009 0.99968433 0.99144167 0.98947245 0.98764962 0.82127929\n",
      " 0.89022237 0.98793191 0.9921388  0.98834014 0.29466242 0.93599904\n",
      " 0.99782747 0.09862922 0.09947493 0.99984074 0.98652101 0.98889846\n",
      " 0.06702253 0.98787296 0.98175102 0.75240791 0.92012638 0.99948692\n",
      " 0.29767856 0.94459456 0.94601142 0.88807547 0.9981488  0.00671304\n",
      " 0.00413883 0.03262768 0.0136152  0.00644607 0.00344803 0.12327423\n",
      " 0.3277638  0.52569032 0.97001421 0.99211532]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "vote_pred [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 43 TN= 41 FN= 15 FP= 19\n",
      "TP+FP 62\n",
      "precision 0.6935483870967742\n",
      "recall 0.7413793103448276\n",
      "F1 0.7166666666666668\n",
      "acc 0.711864406779661\n",
      "AUCp 0.7123563218390805\n",
      "AUC 0.7416666666666667\n",
      "\n",
      " The epoch is 80, average recall: 0.7414, average precision: 0.6935,average F1: 0.7167, average accuracy: 0.7119, average AUC: 0.7417\n",
      "Train Epoch: 81 [0/54 (0%)]\tTrain Loss: 0.015448\n",
      "Train Epoch: 81 [8/54 (15%)]\tTrain Loss: 0.037257\n",
      "Train Epoch: 81 [16/54 (30%)]\tTrain Loss: 0.085131\n",
      "Train Epoch: 81 [24/54 (44%)]\tTrain Loss: 0.064125\n",
      "Train Epoch: 81 [32/54 (59%)]\tTrain Loss: 0.019504\n",
      "Train Epoch: 81 [40/54 (74%)]\tTrain Loss: 0.021868\n",
      "Train Epoch: 81 [48/54 (89%)]\tTrain Loss: 0.074675\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.59534192e-01 9.85755384e-01 8.91363561e-01 9.87670064e-01\n",
      " 8.66458654e-01 4.58946764e-01 9.68514800e-01 9.23216879e-01\n",
      " 2.24639356e-01 5.82887709e-01 9.89422858e-01 7.25082960e-03\n",
      " 7.29546726e-01 5.52506030e-01 3.78642201e-01 4.64323968e-01\n",
      " 2.67813236e-01 1.17210507e-01 1.49365187e-01 1.61509678e-01\n",
      " 3.04632962e-01 6.04513764e-01 9.07602549e-01 9.55641210e-01\n",
      " 2.32155666e-01 9.54457402e-01 9.92018521e-01 8.20851803e-01\n",
      " 8.57809126e-01 7.34718859e-01 9.31844652e-01 9.95491207e-01\n",
      " 9.67268169e-01 2.71848682e-03 8.48525017e-03 2.99558759e-01\n",
      " 1.98215306e-01 9.99193728e-01 2.57421732e-01 8.84709835e-01\n",
      " 8.08059037e-01 7.92459726e-01 4.65944767e-01 9.68777299e-01\n",
      " 8.83762956e-01 9.81159568e-01 9.99958992e-01 9.99824584e-01\n",
      " 1.00000000e+00 9.99359906e-01 9.99999881e-01 1.93849266e-01\n",
      " 4.99399096e-01 6.82689667e-01 7.35659242e-01 4.52839792e-01\n",
      " 9.24622178e-01 6.32240236e-01 2.76245642e-02 6.22207224e-01\n",
      " 9.97937202e-01 9.12014663e-01 9.82872784e-01 9.96665537e-01\n",
      " 9.71191347e-01 9.96620297e-01 9.95478988e-01 9.99931931e-01\n",
      " 9.99814689e-01 4.28761631e-01 9.95044470e-01 9.88215208e-01\n",
      " 9.99012709e-01 9.79642034e-01 9.73757029e-01 9.99156713e-01\n",
      " 9.99987721e-01 9.99977350e-01 9.99911785e-01 9.99966025e-01\n",
      " 9.99815881e-01 9.99767721e-01 9.99701023e-01 9.01289105e-01\n",
      " 9.13946927e-01 9.57751274e-01 9.96989727e-01 9.98208404e-01\n",
      " 7.07505411e-03 9.38691080e-01 9.38521266e-01 9.81846273e-01\n",
      " 9.06019509e-01 9.99897242e-01 9.78738487e-01 9.92026865e-01\n",
      " 1.25176936e-01 8.36611092e-01 9.43315208e-01 9.97895956e-01\n",
      " 7.70413578e-01 9.99637485e-01 2.63958216e-01 9.74508822e-01\n",
      " 9.95142221e-01 9.89144742e-01 9.99995828e-01 1.66702583e-01\n",
      " 4.67400649e-04 1.98934481e-01 3.21236290e-02 3.91150406e-03\n",
      " 4.69337612e-01 1.38334081e-01 7.14096367e-01 2.55168945e-01\n",
      " 3.83506685e-01 8.10612857e-01]\n",
      "predict [1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "Train Epoch: 82 [0/54 (0%)]\tTrain Loss: 0.016934\n",
      "Train Epoch: 82 [8/54 (15%)]\tTrain Loss: 0.058640\n",
      "Train Epoch: 82 [16/54 (30%)]\tTrain Loss: 0.050229\n",
      "Train Epoch: 82 [24/54 (44%)]\tTrain Loss: 0.044045\n",
      "Train Epoch: 82 [32/54 (59%)]\tTrain Loss: 0.073990\n",
      "Train Epoch: 82 [40/54 (74%)]\tTrain Loss: 0.018878\n",
      "Train Epoch: 82 [48/54 (89%)]\tTrain Loss: 0.026797\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.20741089 0.88252777 0.65249121 0.25294432 0.08310868 0.06407209\n",
      " 0.85034353 0.11769716 0.03797921 0.19694048 0.82087833 0.19585223\n",
      " 0.02828124 0.12670405 0.08923291 0.09058392 0.08693738 0.07047729\n",
      " 0.49356538 0.0598218  0.35412976 0.29486728 0.85241652 0.93014598\n",
      " 0.34558168 0.99024361 0.99598998 0.71333051 0.74320835 0.11582179\n",
      " 0.40174234 0.90917373 0.61284381 0.0595583  0.05058568 0.43364197\n",
      " 0.39440787 0.19375376 0.03750126 0.18060246 0.07947084 0.15059215\n",
      " 0.02811994 0.08834062 0.21694595 0.23804785 0.93374079 0.9015907\n",
      " 0.9999069  0.99931765 0.99990094 0.00484383 0.02256025 0.03053674\n",
      " 0.88364613 0.03449516 0.63445801 0.08467389 0.1229282  0.02964827\n",
      " 0.94976228 0.43730685 0.76683575 0.94315678 0.3247948  0.80094641\n",
      " 0.66971129 0.9149946  0.99783927 0.8893652  0.97683197 0.90636855\n",
      " 0.9971028  0.95828003 0.98352355 0.87160665 0.99465758 0.99250185\n",
      " 0.91235542 0.976044   0.98134285 0.98389626 0.98326451 0.8136124\n",
      " 0.56673735 0.95860308 0.90043527 0.86997992 0.7353189  0.85381383\n",
      " 0.99937707 0.28098136 0.16375467 0.99928278 0.97280538 0.99282736\n",
      " 0.04530572 0.55709589 0.97955966 0.9822498  0.36699131 0.98081595\n",
      " 0.07710028 0.68708557 0.98727489 0.75848013 0.99982542 0.10001165\n",
      " 0.01782792 0.65871352 0.05727717 0.01820631 0.59429348 0.98142689\n",
      " 0.33868575 0.20807791 0.90532905 0.13577913]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 83 [0/54 (0%)]\tTrain Loss: 0.059790\n",
      "Train Epoch: 83 [8/54 (15%)]\tTrain Loss: 0.025601\n",
      "Train Epoch: 83 [16/54 (30%)]\tTrain Loss: 0.170522\n",
      "Train Epoch: 83 [24/54 (44%)]\tTrain Loss: 0.053854\n",
      "Train Epoch: 83 [32/54 (59%)]\tTrain Loss: 0.040875\n",
      "Train Epoch: 83 [40/54 (74%)]\tTrain Loss: 0.033442\n",
      "Train Epoch: 83 [48/54 (89%)]\tTrain Loss: 0.073353\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.47610667 0.78239441 0.63752806 0.63990283 0.25174797 0.16559406\n",
      " 0.62394804 0.63276821 0.05603246 0.1502943  0.85081029 0.03321446\n",
      " 0.088593   0.17288892 0.21894573 0.04101394 0.02579565 0.22936302\n",
      " 0.0337692  0.21356349 0.49907389 0.77518952 0.8969115  0.96557719\n",
      " 0.18084458 0.99122298 0.98101622 0.92547613 0.58651841 0.47543705\n",
      " 0.99580175 0.99266464 0.99202091 0.00526576 0.00371846 0.05542039\n",
      " 0.09045094 0.84891123 0.23142643 0.47397324 0.24047367 0.25921655\n",
      " 0.16854946 0.75931543 0.58183801 0.84017962 0.98755437 0.96959531\n",
      " 0.99981135 0.96645129 0.99994624 0.01846609 0.23542361 0.4290033\n",
      " 0.56916791 0.15321787 0.99422604 0.20392461 0.11592905 0.3711468\n",
      " 0.9976902  0.9097333  0.96113682 0.98899126 0.9929508  0.98798507\n",
      " 0.98238474 0.99799001 0.99973136 0.83475715 0.81835449 0.82201868\n",
      " 0.9982267  0.98619407 0.99831319 0.99528486 0.99518085 0.97652721\n",
      " 0.97656107 0.99991739 0.99966323 0.9975909  0.99959332 0.69831002\n",
      " 0.7472648  0.96020114 0.98092574 0.98692709 0.15126599 0.64177299\n",
      " 0.90598124 0.79840672 0.83011299 0.99790156 0.98016077 0.95028299\n",
      " 0.07401156 0.95848072 0.90970683 0.85517907 0.37825379 0.99927169\n",
      " 0.07230951 0.8338632  0.88397872 0.86739302 0.99876535 0.02663446\n",
      " 0.00242418 0.08622612 0.00957768 0.00364601 0.03592924 0.31551471\n",
      " 0.29283583 0.20088603 0.81710523 0.3363077 ]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 84 [0/54 (0%)]\tTrain Loss: 0.028412\n",
      "Train Epoch: 84 [8/54 (15%)]\tTrain Loss: 0.021795\n",
      "Train Epoch: 84 [16/54 (30%)]\tTrain Loss: 0.022098\n",
      "Train Epoch: 84 [24/54 (44%)]\tTrain Loss: 0.049713\n",
      "Train Epoch: 84 [32/54 (59%)]\tTrain Loss: 0.056474\n",
      "Train Epoch: 84 [40/54 (74%)]\tTrain Loss: 0.080944\n",
      "Train Epoch: 84 [48/54 (89%)]\tTrain Loss: 0.110446\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.29898885 0.90030557 0.8505882  0.89686972 0.46311778 0.50481939\n",
      " 0.80937004 0.73516214 0.129668   0.440503   0.45285341 0.10292524\n",
      " 0.04404591 0.73736322 0.5772115  0.25253424 0.52197957 0.14878283\n",
      " 0.05266461 0.13519529 0.16234645 0.56796348 0.87107325 0.90628248\n",
      " 0.63872927 0.97765404 0.96647578 0.40663978 0.54579455 0.47293296\n",
      " 0.71033996 0.95872796 0.44363254 0.02895428 0.01571369 0.39042681\n",
      " 0.21976066 0.49823564 0.19034368 0.5935117  0.44441929 0.36302832\n",
      " 0.09886147 0.75175548 0.20464014 0.10817696 0.75076783 0.51817626\n",
      " 0.99936265 0.89231747 0.99881494 0.02019687 0.07808108 0.30048594\n",
      " 0.48431298 0.22959177 0.79071975 0.27673933 0.34245855 0.11660203\n",
      " 0.95997125 0.66526467 0.80540174 0.94698906 0.63221127 0.99219161\n",
      " 0.98875976 0.97628671 0.99915648 0.92590177 0.87290198 0.78862005\n",
      " 0.97562045 0.90170288 0.75576937 0.95043075 0.99565589 0.99181259\n",
      " 0.96443975 0.9983784  0.99854243 0.99547774 0.9990539  0.70311683\n",
      " 0.60765946 0.92188585 0.96405631 0.9547776  0.31765735 0.90559578\n",
      " 0.87814653 0.8550539  0.59346032 0.99802554 0.90520287 0.91500688\n",
      " 0.18106876 0.60917777 0.74926955 0.83756894 0.25958455 0.99633408\n",
      " 0.0458575  0.36950475 0.80667669 0.72088885 0.99235737 0.11307567\n",
      " 0.02437734 0.26366115 0.02709559 0.06681609 0.76090366 0.78546208\n",
      " 0.24291648 0.17771174 0.48932782 0.54052496]\n",
      "predict [0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "Train Epoch: 85 [0/54 (0%)]\tTrain Loss: 0.025237\n",
      "Train Epoch: 85 [8/54 (15%)]\tTrain Loss: 0.036200\n",
      "Train Epoch: 85 [16/54 (30%)]\tTrain Loss: 0.049079\n",
      "Train Epoch: 85 [24/54 (44%)]\tTrain Loss: 0.013894\n",
      "Train Epoch: 85 [32/54 (59%)]\tTrain Loss: 0.099586\n",
      "Train Epoch: 85 [40/54 (74%)]\tTrain Loss: 0.032915\n",
      "Train Epoch: 85 [48/54 (89%)]\tTrain Loss: 0.044100\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.36489619e-02 5.64943314e-01 6.30098641e-01 8.27443525e-02\n",
      " 3.64893605e-03 9.09034908e-03 2.61911839e-01 6.17952505e-03\n",
      " 2.06477065e-02 6.31510615e-02 1.35462545e-02 1.88739821e-02\n",
      " 1.74685847e-03 6.99341446e-02 2.19791815e-01 2.62972736e-03\n",
      " 1.54006854e-03 1.37537420e-01 1.04713015e-01 2.49428183e-01\n",
      " 5.49645424e-01 5.08348346e-01 9.42358732e-01 9.83234167e-01\n",
      " 2.95095414e-01 9.94139314e-01 9.87354696e-01 7.53599882e-01\n",
      " 4.09172028e-01 2.42994547e-01 9.89993513e-01 9.99036431e-01\n",
      " 9.99907732e-01 2.54981423e-04 3.08765768e-04 1.20744780e-02\n",
      " 2.67919563e-02 1.62419975e-01 1.01092994e-01 1.44744352e-01\n",
      " 1.08575806e-01 8.70810524e-02 1.62450206e-02 7.47736692e-02\n",
      " 1.35529548e-01 1.60962686e-01 9.97109830e-01 9.73436892e-01\n",
      " 9.99875546e-01 8.70400369e-01 9.99879837e-01 5.74989099e-05\n",
      " 2.18112543e-02 1.48105798e-02 6.76308095e-01 2.69430894e-02\n",
      " 9.66459572e-01 7.87054934e-03 7.09551945e-02 3.81266065e-02\n",
      " 9.99410629e-01 9.00853276e-01 9.94858503e-01 9.99598324e-01\n",
      " 6.69355571e-01 2.10351244e-01 3.21196049e-01 9.94344234e-01\n",
      " 9.98359859e-01 7.50809848e-01 8.96141469e-01 8.52343857e-01\n",
      " 9.95628238e-01 8.71578753e-01 9.66328621e-01 9.96929586e-01\n",
      " 9.99771893e-01 9.94555473e-01 9.89398956e-01 9.99993801e-01\n",
      " 9.99767482e-01 9.99956369e-01 9.99961019e-01 5.31485736e-01\n",
      " 7.75203764e-01 9.95722890e-01 9.96104121e-01 9.98637736e-01\n",
      " 4.05549735e-01 2.48553336e-01 9.89568293e-01 9.38282311e-02\n",
      " 2.41293550e-01 9.99334753e-01 9.78016078e-01 9.42637861e-01\n",
      " 5.55742532e-02 9.31653202e-01 4.88826334e-01 7.47189969e-02\n",
      " 3.31408083e-01 9.99889612e-01 4.28509042e-02 2.72571445e-01\n",
      " 4.16071087e-01 9.50122416e-01 9.98782694e-01 3.43586574e-03\n",
      " 3.42411594e-03 3.72107513e-02 1.95110799e-03 2.83420639e-04\n",
      " 4.99442965e-03 3.84935997e-02 3.57708372e-02 5.69834225e-02\n",
      " 6.09527349e-01 1.94189116e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 86 [0/54 (0%)]\tTrain Loss: 0.069333\n",
      "Train Epoch: 86 [8/54 (15%)]\tTrain Loss: 0.028778\n",
      "Train Epoch: 86 [16/54 (30%)]\tTrain Loss: 0.029289\n",
      "Train Epoch: 86 [24/54 (44%)]\tTrain Loss: 0.059256\n",
      "Train Epoch: 86 [32/54 (59%)]\tTrain Loss: 0.046858\n",
      "Train Epoch: 86 [40/54 (74%)]\tTrain Loss: 0.019143\n",
      "Train Epoch: 86 [48/54 (89%)]\tTrain Loss: 0.084881\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.03303263 0.12771897 0.10385563 0.17447057 0.08299682 0.05001221\n",
      " 0.06725113 0.06279379 0.02567786 0.25964165 0.23495702 0.09188338\n",
      " 0.02313351 0.03860848 0.03249731 0.02887017 0.05251509 0.04285959\n",
      " 0.11039536 0.1177969  0.26225895 0.24609683 0.56401139 0.95716876\n",
      " 0.19634126 0.92570561 0.99093783 0.37614727 0.15365623 0.13088381\n",
      " 0.58357447 0.791035   0.07305608 0.01295484 0.0086114  0.03588524\n",
      " 0.06848725 0.18349952 0.05436106 0.1931283  0.09483182 0.10408045\n",
      " 0.01219609 0.06009548 0.02163878 0.04049413 0.27825534 0.11746694\n",
      " 0.98567098 0.96147192 0.98597592 0.00160553 0.01770398 0.01613028\n",
      " 0.58658999 0.01267417 0.58755004 0.03014757 0.05532232 0.01414382\n",
      " 0.55588853 0.27936482 0.52740401 0.65689975 0.08002602 0.52023226\n",
      " 0.54882067 0.89509696 0.97014958 0.69839483 0.5273484  0.42191416\n",
      " 0.86869365 0.70479083 0.82950246 0.28728405 0.75450158 0.6651684\n",
      " 0.05752435 0.96225023 0.97044373 0.97214693 0.99471104 0.1473683\n",
      " 0.33419636 0.58025587 0.61989254 0.68123507 0.27778596 0.75765854\n",
      " 0.99062437 0.39872384 0.19041477 0.99910957 0.9386521  0.89688677\n",
      " 0.01399449 0.15220927 0.6245501  0.62875903 0.18548553 0.85934305\n",
      " 0.09513549 0.43355888 0.73994106 0.49801981 0.97245467 0.0243607\n",
      " 0.01367297 0.08504032 0.04606287 0.01086703 0.52190256 0.83131939\n",
      " 0.11172452 0.02731251 0.28022298 0.04335394]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 87 [0/54 (0%)]\tTrain Loss: 0.021603\n",
      "Train Epoch: 87 [8/54 (15%)]\tTrain Loss: 0.034988\n",
      "Train Epoch: 87 [16/54 (30%)]\tTrain Loss: 0.006402\n",
      "Train Epoch: 87 [24/54 (44%)]\tTrain Loss: 0.035662\n",
      "Train Epoch: 87 [32/54 (59%)]\tTrain Loss: 0.027660\n",
      "Train Epoch: 87 [40/54 (74%)]\tTrain Loss: 0.055165\n",
      "Train Epoch: 87 [48/54 (89%)]\tTrain Loss: 0.015318\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.20809601 0.93035841 0.74935263 0.50547045 0.1473878  0.1083988\n",
      " 0.67551351 0.3008973  0.06972368 0.06550644 0.50507116 0.00339066\n",
      " 0.01662281 0.29462588 0.47945654 0.05205303 0.01875372 0.04324903\n",
      " 0.01431294 0.08979317 0.08786291 0.22819158 0.43606505 0.64077669\n",
      " 0.11023128 0.83401376 0.94993359 0.26263529 0.17595196 0.22369999\n",
      " 0.98076129 0.97945613 0.31275812 0.00113296 0.00193648 0.02999596\n",
      " 0.04984824 0.4647657  0.10843442 0.26136899 0.11081757 0.18761712\n",
      " 0.05787105 0.20643592 0.06915664 0.49325588 0.99530679 0.81876791\n",
      " 0.99996948 0.96792322 0.99994552 0.00466928 0.11758029 0.20715997\n",
      " 0.38937229 0.03363369 0.96097189 0.03588146 0.02431896 0.26914379\n",
      " 0.99860781 0.93050557 0.99645305 0.99848759 0.67855918 0.88980329\n",
      " 0.91403359 0.95861238 0.99897695 0.97365588 0.938447   0.86389405\n",
      " 0.99256915 0.96232408 0.98406053 0.99833739 0.99968958 0.99822253\n",
      " 0.97646892 0.9999541  0.99989986 0.999668   0.9998908  0.50693536\n",
      " 0.75023764 0.87616986 0.92349315 0.98162454 0.04915033 0.36174342\n",
      " 0.96914923 0.59295869 0.4723759  0.99816388 0.95924181 0.65419906\n",
      " 0.02827894 0.24916306 0.79404402 0.93276006 0.40868634 0.99990308\n",
      " 0.03008604 0.52330178 0.94079572 0.96929103 0.9993462  0.05023756\n",
      " 0.00763763 0.23079352 0.01147034 0.00688893 0.40916148 0.43005437\n",
      " 0.24014702 0.04985287 0.69339705 0.26718506]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 88 [0/54 (0%)]\tTrain Loss: 0.027401\n",
      "Train Epoch: 88 [8/54 (15%)]\tTrain Loss: 0.023437\n",
      "Train Epoch: 88 [16/54 (30%)]\tTrain Loss: 0.020652\n",
      "Train Epoch: 88 [24/54 (44%)]\tTrain Loss: 0.009727\n",
      "Train Epoch: 88 [32/54 (59%)]\tTrain Loss: 0.184843\n",
      "Train Epoch: 88 [40/54 (74%)]\tTrain Loss: 0.111786\n",
      "Train Epoch: 88 [48/54 (89%)]\tTrain Loss: 0.054534\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.00844918 0.1030072  0.12912998 0.19468693 0.1367476  0.06948031\n",
      " 0.34930989 0.1863752  0.07919552 0.04057805 0.51626849 0.01995905\n",
      " 0.07393634 0.1502886  0.02619494 0.05392732 0.02612581 0.01479056\n",
      " 0.01199411 0.16363727 0.37211928 0.22680987 0.59699959 0.90501976\n",
      " 0.07229047 0.98753452 0.99137104 0.90824747 0.29155967 0.38342404\n",
      " 0.84495586 0.96018136 0.33666241 0.014349   0.01029229 0.05098278\n",
      " 0.05406962 0.71212757 0.02147192 0.13120511 0.05744907 0.14883152\n",
      " 0.02310082 0.57479024 0.04531829 0.03268207 0.10666381 0.05025051\n",
      " 0.99709582 0.60997373 0.87203395 0.00289382 0.26716521 0.04309041\n",
      " 0.17439584 0.04125399 0.2122508  0.39494458 0.53192091 0.13392712\n",
      " 0.44876638 0.18513615 0.228407   0.7383455  0.80657661 0.98878771\n",
      " 0.92323881 0.99049699 0.99715781 0.69751263 0.13680336 0.09640756\n",
      " 0.97661239 0.89944404 0.9577297  0.15792313 0.56689829 0.35414216\n",
      " 0.18711258 0.99168652 0.95267659 0.9442001  0.9704935  0.30981904\n",
      " 0.16214952 0.39006341 0.4305765  0.37361741 0.65442061 0.90585119\n",
      " 0.99427855 0.6507777  0.18447135 0.99991322 0.99207956 0.97235888\n",
      " 0.04566462 0.05904331 0.27102217 0.98842478 0.04477361 0.44552702\n",
      " 0.01890956 0.70124346 0.68855685 0.35898516 0.99830735 0.03491087\n",
      " 0.01920493 0.18957429 0.04971385 0.00677634 0.85677773 0.94331849\n",
      " 0.19820112 0.00380898 0.42724901 0.06304809]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 89 [0/54 (0%)]\tTrain Loss: 0.013531\n",
      "Train Epoch: 89 [8/54 (15%)]\tTrain Loss: 0.030783\n",
      "Train Epoch: 89 [16/54 (30%)]\tTrain Loss: 0.120110\n",
      "Train Epoch: 89 [24/54 (44%)]\tTrain Loss: 0.033142\n",
      "Train Epoch: 89 [32/54 (59%)]\tTrain Loss: 0.048081\n",
      "Train Epoch: 89 [40/54 (74%)]\tTrain Loss: 0.027252\n",
      "Train Epoch: 89 [48/54 (89%)]\tTrain Loss: 0.057617\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.39654419 0.89589292 0.76511097 0.16011517 0.23286039 0.03106519\n",
      " 0.40322545 0.10922346 0.0629627  0.55011207 0.51772487 0.20354454\n",
      " 0.0254027  0.11889566 0.06999428 0.05760976 0.08677695 0.17629758\n",
      " 0.29608959 0.07414337 0.26791713 0.38524386 0.91186398 0.89623737\n",
      " 0.50804383 0.99506038 0.99382991 0.41921559 0.76892787 0.17301902\n",
      " 0.92868859 0.99248284 0.81197357 0.06915354 0.11552828 0.42177683\n",
      " 0.70421416 0.86813051 0.1729324  0.48364398 0.2268997  0.49055961\n",
      " 0.01244585 0.51228166 0.24597092 0.09520004 0.99708253 0.98038208\n",
      " 0.99998868 0.91501302 0.99998391 0.00487396 0.00538004 0.02945008\n",
      " 0.60008264 0.01623658 0.9483425  0.02560302 0.35821408 0.0156342\n",
      " 0.99971372 0.99438912 0.99945635 0.99987936 0.88880169 0.97392648\n",
      " 0.98702323 0.98749524 0.99985397 0.88475412 0.9839865  0.95490539\n",
      " 0.99988425 0.98971689 0.97712201 0.98419213 0.99981529 0.99944669\n",
      " 0.97220469 0.99995899 0.99985754 0.99944907 0.99972302 0.98078728\n",
      " 0.96430832 0.99690992 0.99799156 0.99938357 0.43137935 0.99632519\n",
      " 0.9855966  0.91499847 0.16571854 0.99923146 0.99771333 0.99956065\n",
      " 0.09197032 0.97338253 0.94374633 0.99659604 0.76290339 0.99999321\n",
      " 0.50289553 0.98388112 0.98872095 0.98833829 0.9999243  0.01398764\n",
      " 0.00203465 0.21257037 0.01292197 0.00273404 0.0323046  0.81636423\n",
      " 0.42528456 0.31282985 0.9964425  0.98012322]\n",
      "predict [0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 90 [0/54 (0%)]\tTrain Loss: 0.023566\n",
      "Train Epoch: 90 [8/54 (15%)]\tTrain Loss: 0.026004\n",
      "Train Epoch: 90 [16/54 (30%)]\tTrain Loss: 0.014197\n",
      "Train Epoch: 90 [24/54 (44%)]\tTrain Loss: 0.026645\n",
      "Train Epoch: 90 [32/54 (59%)]\tTrain Loss: 0.044243\n",
      "Train Epoch: 90 [40/54 (74%)]\tTrain Loss: 0.014860\n",
      "Train Epoch: 90 [48/54 (89%)]\tTrain Loss: 0.033244\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.00428104e-01 6.30664349e-01 1.53259933e-01 2.14315534e-01\n",
      " 8.16071630e-02 1.61843002e-01 1.36170447e-01 1.20861627e-01\n",
      " 1.41690969e-01 2.45994907e-02 2.69130379e-01 3.57047515e-03\n",
      " 8.28767754e-03 1.79098938e-02 1.00047342e-01 5.70709072e-02\n",
      " 2.09034663e-02 3.11428010e-02 2.27743108e-02 1.07038841e-01\n",
      " 9.85980108e-02 2.06041619e-01 9.18580651e-01 9.65324402e-01\n",
      " 4.68839556e-02 9.88145590e-01 9.74592030e-01 4.97428447e-01\n",
      " 5.19077539e-01 2.53363669e-01 8.77166510e-01 9.87885475e-01\n",
      " 9.21201468e-01 3.35951615e-03 2.27753725e-03 4.26237565e-03\n",
      " 2.58551240e-02 5.92814445e-01 5.50470650e-02 1.45299539e-01\n",
      " 5.50384931e-02 1.83718100e-01 2.20921822e-02 3.58292907e-01\n",
      " 6.71812743e-02 9.25160348e-02 9.92047548e-01 9.78665173e-01\n",
      " 9.99976635e-01 9.53700125e-01 9.99688268e-01 4.77240479e-04\n",
      " 1.58777405e-02 1.90970376e-02 4.95797634e-01 1.22226784e-02\n",
      " 8.02152097e-01 7.73673132e-02 1.84560791e-02 2.63525806e-02\n",
      " 9.45735216e-01 6.52799428e-01 9.49965835e-01 9.92175400e-01\n",
      " 6.29582703e-01 8.88996005e-01 9.16159272e-01 9.55886245e-01\n",
      " 9.99008596e-01 9.89488661e-01 8.20452392e-01 5.77601910e-01\n",
      " 9.92632210e-01 7.91698694e-01 9.04305875e-01 8.82054269e-01\n",
      " 9.95449364e-01 9.71607566e-01 9.65590954e-01 9.98841584e-01\n",
      " 9.73236084e-01 9.77361202e-01 9.85715330e-01 3.70390207e-01\n",
      " 4.05000925e-01 9.88792956e-01 9.76612031e-01 9.90093052e-01\n",
      " 1.11448765e-01 8.71430874e-01 9.97927904e-01 7.61828497e-02\n",
      " 4.26747724e-02 9.99729812e-01 9.57449317e-01 9.95115280e-01\n",
      " 5.04001454e-02 7.66351402e-01 8.18382919e-01 9.48522925e-01\n",
      " 4.32805717e-01 9.98712897e-01 5.92615269e-02 7.85962343e-01\n",
      " 9.76345599e-01 8.54463279e-01 9.99488235e-01 4.46041394e-03\n",
      " 4.94079955e-04 7.12564960e-02 2.10804702e-03 4.71061008e-04\n",
      " 5.78433722e-02 1.57561794e-01 2.17170149e-01 1.00508563e-01\n",
      " 7.81244516e-01 3.26741457e-01]\n",
      "predict [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 43 TN= 42 FN= 15 FP= 18\n",
      "TP+FP 61\n",
      "precision 0.7049180327868853\n",
      "recall 0.7413793103448276\n",
      "F1 0.7226890756302522\n",
      "acc 0.7203389830508474\n",
      "AUCp 0.7206896551724138\n",
      "AUC 0.7405172413793104\n",
      "\n",
      " The epoch is 90, average recall: 0.7414, average precision: 0.7049,average F1: 0.7227, average accuracy: 0.7203, average AUC: 0.7405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 91 [0/54 (0%)]\tTrain Loss: 0.010112\n",
      "Train Epoch: 91 [8/54 (15%)]\tTrain Loss: 0.055986\n",
      "Train Epoch: 91 [16/54 (30%)]\tTrain Loss: 0.021621\n",
      "Train Epoch: 91 [24/54 (44%)]\tTrain Loss: 0.043366\n",
      "Train Epoch: 91 [32/54 (59%)]\tTrain Loss: 0.013769\n",
      "Train Epoch: 91 [40/54 (74%)]\tTrain Loss: 0.005992\n",
      "Train Epoch: 91 [48/54 (89%)]\tTrain Loss: 0.049765\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.52245516 0.99586201 0.99691451 0.96275437 0.14364371 0.22238573\n",
      " 0.9903447  0.73275077 0.32432634 0.05818587 0.80375516 0.00619661\n",
      " 0.08938778 0.89104313 0.54984343 0.03275173 0.28499579 0.10014907\n",
      " 0.39953649 0.6493507  0.56432128 0.89919645 0.99239993 0.97988141\n",
      " 0.7842651  0.99003893 0.98621029 0.91280591 0.96678126 0.6385811\n",
      " 0.99861813 0.99963415 0.95650578 0.0040903  0.00693877 0.47889891\n",
      " 0.76543206 0.98564178 0.33025351 0.27891243 0.18378112 0.46938425\n",
      " 0.06296766 0.94490886 0.73722142 0.83835989 0.9998827  0.99923348\n",
      " 0.99999213 0.93826765 0.99999213 0.00260601 0.24470186 0.40327647\n",
      " 0.44511354 0.12338568 0.96157432 0.66976482 0.17430745 0.68332332\n",
      " 0.99932694 0.92921591 0.99087101 0.99950933 0.98379207 0.99845016\n",
      " 0.99973506 0.9977054  0.99998736 0.74231046 0.94959581 0.93051672\n",
      " 0.99994242 0.977808   0.99859565 0.99948114 0.99999893 0.99998999\n",
      " 0.99976462 0.99999583 0.99997115 0.99987304 0.99994147 0.63349491\n",
      " 0.79014802 0.98470521 0.99913591 0.9985286  0.54046237 0.95477629\n",
      " 0.99909353 0.67082959 0.95679015 0.99991274 0.99355185 0.99594444\n",
      " 0.08771102 0.77981031 0.97368842 0.98760659 0.25202024 0.99985361\n",
      " 0.02741102 0.95043188 0.99453717 0.96748435 0.9999392  0.12872115\n",
      " 0.10963272 0.45867106 0.04061831 0.04536917 0.72977728 0.924797\n",
      " 0.07716963 0.31231582 0.71936482 0.65794396]\n",
      "predict [1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 92 [0/54 (0%)]\tTrain Loss: 0.010355\n",
      "Train Epoch: 92 [8/54 (15%)]\tTrain Loss: 0.031390\n",
      "Train Epoch: 92 [16/54 (30%)]\tTrain Loss: 0.014711\n",
      "Train Epoch: 92 [24/54 (44%)]\tTrain Loss: 0.024097\n",
      "Train Epoch: 92 [32/54 (59%)]\tTrain Loss: 0.012808\n",
      "Train Epoch: 92 [40/54 (74%)]\tTrain Loss: 0.034352\n",
      "Train Epoch: 92 [48/54 (89%)]\tTrain Loss: 0.023794\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.66960168 0.99706084 0.99509984 0.83540738 0.24710095 0.35208732\n",
      " 0.99062598 0.61432278 0.29923144 0.09371893 0.88406116 0.02488482\n",
      " 0.00936078 0.23892084 0.25236514 0.0485309  0.11691554 0.07837806\n",
      " 0.73955494 0.33238471 0.37002015 0.81762713 0.99676669 0.94595152\n",
      " 0.33073813 0.99640501 0.97130966 0.68682021 0.82323468 0.24414462\n",
      " 0.98984116 0.9969188  0.21569555 0.00706703 0.00990499 0.04933466\n",
      " 0.86703581 0.98742944 0.06152845 0.03557344 0.01725312 0.0553705\n",
      " 0.05301322 0.15365677 0.22003546 0.35047883 0.96020728 0.84409034\n",
      " 0.99998581 0.96466434 0.99986076 0.00101535 0.16409759 0.18515176\n",
      " 0.30466658 0.03639589 0.90193164 0.52942973 0.05594899 0.19387905\n",
      " 0.93383592 0.7322765  0.88594693 0.98813778 0.86911035 0.90000296\n",
      " 0.98655534 0.94412065 0.9999795  0.99456948 0.84120297 0.76367402\n",
      " 0.9990741  0.82891136 0.96361959 0.99295145 0.99999952 0.99993885\n",
      " 0.99880731 0.99793953 0.99834359 0.99190712 0.99662066 0.76273978\n",
      " 0.48559231 0.99235439 0.99706072 0.98825318 0.66567087 0.9731012\n",
      " 0.99988067 0.30782589 0.23679842 0.99998486 0.99930573 0.99710053\n",
      " 0.09563711 0.92003918 0.99345893 0.96123463 0.4235653  0.99850923\n",
      " 0.03178825 0.79617411 0.99177283 0.85379851 0.99996352 0.01068979\n",
      " 0.00846669 0.67432743 0.0129376  0.02293151 0.22754756 0.95863354\n",
      " 0.22806485 0.21805777 0.99207729 0.9631173 ]\n",
      "predict [1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 93 [0/54 (0%)]\tTrain Loss: 0.029474\n",
      "Train Epoch: 93 [8/54 (15%)]\tTrain Loss: 0.024050\n",
      "Train Epoch: 93 [16/54 (30%)]\tTrain Loss: 0.033502\n",
      "Train Epoch: 93 [24/54 (44%)]\tTrain Loss: 0.018980\n",
      "Train Epoch: 93 [32/54 (59%)]\tTrain Loss: 0.034967\n",
      "Train Epoch: 93 [40/54 (74%)]\tTrain Loss: 0.016548\n",
      "Train Epoch: 93 [48/54 (89%)]\tTrain Loss: 0.043396\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.7360208  0.96890354 0.86109346 0.80610102 0.11701155 0.0879162\n",
      " 0.88630581 0.67368239 0.07815117 0.08773658 0.70466733 0.00158537\n",
      " 0.04429416 0.29776755 0.2877059  0.08146475 0.19071013 0.04639588\n",
      " 0.21508281 0.1678185  0.2604278  0.82909656 0.9814533  0.98612332\n",
      " 0.2976895  0.99297661 0.99386472 0.89192784 0.83611381 0.25750116\n",
      " 0.99597025 0.99885404 0.95230132 0.01833237 0.00323711 0.12393723\n",
      " 0.10210718 0.93673801 0.10005396 0.30993438 0.10290635 0.36715609\n",
      " 0.02839059 0.74157524 0.60481453 0.94599414 0.99809474 0.98945355\n",
      " 0.99999666 0.98795986 0.99999344 0.00356365 0.14319266 0.33829117\n",
      " 0.53539717 0.05800315 0.99831748 0.40193033 0.01186507 0.17875077\n",
      " 0.99901736 0.97053939 0.99370944 0.99906176 0.9892652  0.97738212\n",
      " 0.99871814 0.99899226 0.99997532 0.99136907 0.9786275  0.96516275\n",
      " 0.99993885 0.97456646 0.99859363 0.99960083 0.99982458 0.99933761\n",
      " 0.99387348 0.99999261 0.99997973 0.99992657 0.99997747 0.55989116\n",
      " 0.46840343 0.99803585 0.99265468 0.99338561 0.14906567 0.98923033\n",
      " 0.99911469 0.93842328 0.85375983 0.99999714 0.9980287  0.99232846\n",
      " 0.02717175 0.89918196 0.95277011 0.99729842 0.29786134 0.99989581\n",
      " 0.14061897 0.99923849 0.99979001 0.99701571 0.99999464 0.13950682\n",
      " 0.00821603 0.45990327 0.02014502 0.00756465 0.74754286 0.79179823\n",
      " 0.24018981 0.17597216 0.80254376 0.77946496]\n",
      "predict [1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 94 [0/54 (0%)]\tTrain Loss: 0.028412\n",
      "Train Epoch: 94 [8/54 (15%)]\tTrain Loss: 0.032122\n",
      "Train Epoch: 94 [16/54 (30%)]\tTrain Loss: 0.016039\n",
      "Train Epoch: 94 [24/54 (44%)]\tTrain Loss: 0.057907\n",
      "Train Epoch: 94 [32/54 (59%)]\tTrain Loss: 0.041147\n",
      "Train Epoch: 94 [40/54 (74%)]\tTrain Loss: 0.010098\n",
      "Train Epoch: 94 [48/54 (89%)]\tTrain Loss: 0.023484\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.2478721  0.99370146 0.99563545 0.93856663 0.34872398 0.25866237\n",
      " 0.99216545 0.42716354 0.31822181 0.76287985 0.84360164 0.0795505\n",
      " 0.33691564 0.3796865  0.18599458 0.13077308 0.81769383 0.12324706\n",
      " 0.56348699 0.26632002 0.3758797  0.94590253 0.99655151 0.98668438\n",
      " 0.60273528 0.99756074 0.9927752  0.9348895  0.91173106 0.4141638\n",
      " 0.9616164  0.99379539 0.80167955 0.05954773 0.01799586 0.29938552\n",
      " 0.19671759 0.9571929  0.10725185 0.48402596 0.34769306 0.36875346\n",
      " 0.05081962 0.65873468 0.71722686 0.70615476 0.98417795 0.95717227\n",
      " 0.99999022 0.77834249 0.99965715 0.02128079 0.22987002 0.29266232\n",
      " 0.38437656 0.24528806 0.97961259 0.68219954 0.35216841 0.33085981\n",
      " 0.99848145 0.96758527 0.9926731  0.99968755 0.97686279 0.94584602\n",
      " 0.99411064 0.99866188 0.99998021 0.78068101 0.88832498 0.89491183\n",
      " 0.99992692 0.97866541 0.99615556 0.99665701 0.99999392 0.99995172\n",
      " 0.99735534 0.99980205 0.999686   0.99961722 0.99982589 0.38580641\n",
      " 0.84704381 0.98436707 0.99727792 0.99808586 0.72794908 0.98928636\n",
      " 0.99768734 0.80985463 0.45158058 0.99998331 0.99934298 0.9887898\n",
      " 0.04981574 0.86142284 0.98119831 0.99353844 0.40423283 0.99944752\n",
      " 0.18042852 0.97431755 0.99661839 0.98753834 0.99992228 0.23085497\n",
      " 0.00986722 0.36483526 0.01900895 0.05672231 0.76729989 0.941064\n",
      " 0.49295846 0.22277914 0.99154764 0.98767298]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 95 [0/54 (0%)]\tTrain Loss: 0.004096\n",
      "Train Epoch: 95 [8/54 (15%)]\tTrain Loss: 0.032208\n",
      "Train Epoch: 95 [16/54 (30%)]\tTrain Loss: 0.014577\n",
      "Train Epoch: 95 [24/54 (44%)]\tTrain Loss: 0.057224\n",
      "Train Epoch: 95 [32/54 (59%)]\tTrain Loss: 0.006625\n",
      "Train Epoch: 95 [40/54 (74%)]\tTrain Loss: 0.018840\n",
      "Train Epoch: 95 [48/54 (89%)]\tTrain Loss: 0.067961\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.73379853e-02 5.95305264e-01 6.21754050e-01 1.61798581e-01\n",
      " 7.33368099e-03 9.33061726e-03 2.28584066e-01 1.08221015e-02\n",
      " 1.56750176e-02 2.36292690e-01 3.75175834e-01 1.48619607e-01\n",
      " 1.38413310e-02 1.70681328e-02 1.43732391e-02 2.65533640e-03\n",
      " 2.55565811e-03 9.66667309e-02 4.17869017e-02 4.00777422e-02\n",
      " 2.77871378e-02 1.72974497e-01 7.93666780e-01 3.53011698e-01\n",
      " 4.01943140e-02 9.35055912e-01 8.85485768e-01 1.95907876e-01\n",
      " 2.49951586e-01 3.38548906e-02 4.18766320e-01 7.94306636e-01\n",
      " 8.43949541e-02 2.32221782e-02 1.29170734e-02 1.41937928e-02\n",
      " 7.40312412e-02 4.19969946e-01 6.64326251e-02 1.57663018e-01\n",
      " 7.57746622e-02 2.41627753e-01 3.72181810e-03 5.45391776e-02\n",
      " 4.47019823e-02 1.33278929e-02 8.23214054e-01 2.78912038e-01\n",
      " 9.99553978e-01 9.02376294e-01 9.96100903e-01 7.22677214e-04\n",
      " 1.48630282e-02 1.30254654e-02 1.62619993e-01 6.52658194e-03\n",
      " 5.98239183e-01 9.30897519e-03 7.39672929e-02 1.84065420e-02\n",
      " 9.62601066e-01 8.94576728e-01 9.54014361e-01 9.93997574e-01\n",
      " 4.43016827e-01 9.45974961e-02 2.35164821e-01 9.81716692e-01\n",
      " 9.95861709e-01 5.04467934e-02 6.62635863e-01 6.16127908e-01\n",
      " 9.04609144e-01 3.39219749e-01 6.36398554e-01 5.08590460e-01\n",
      " 9.83913243e-01 9.63273466e-01 5.44995248e-01 9.97443080e-01\n",
      " 9.59698677e-01 9.69789922e-01 9.95849490e-01 5.48079312e-01\n",
      " 4.51117516e-01 8.77224445e-01 9.61577415e-01 9.33545649e-01\n",
      " 2.62947291e-01 3.00221741e-01 9.44625080e-01 4.26536381e-01\n",
      " 6.72800839e-02 9.96445239e-01 9.81089175e-01 9.20918405e-01\n",
      " 6.04589144e-03 9.29141581e-01 6.93928003e-01 9.25148547e-01\n",
      " 2.39806384e-01 9.88150835e-01 5.55602983e-02 5.06572187e-01\n",
      " 4.90692824e-01 5.43162405e-01 9.90193427e-01 2.19675787e-02\n",
      " 3.43331182e-03 1.52824312e-01 1.17057897e-02 6.51267776e-03\n",
      " 5.05803637e-02 5.20218611e-01 7.77031854e-02 7.23704845e-02\n",
      " 7.30535924e-01 1.65506363e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 96 [0/54 (0%)]\tTrain Loss: 0.032315\n",
      "Train Epoch: 96 [8/54 (15%)]\tTrain Loss: 0.017020\n",
      "Train Epoch: 96 [16/54 (30%)]\tTrain Loss: 0.053493\n",
      "Train Epoch: 96 [24/54 (44%)]\tTrain Loss: 0.020888\n",
      "Train Epoch: 96 [32/54 (59%)]\tTrain Loss: 0.047263\n",
      "Train Epoch: 96 [40/54 (74%)]\tTrain Loss: 0.022185\n",
      "Train Epoch: 96 [48/54 (89%)]\tTrain Loss: 0.018210\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.43155886e-03 2.53865242e-01 3.97942066e-01 7.05746114e-02\n",
      " 3.54787009e-03 1.87536783e-03 2.04159036e-01 1.81402150e-03\n",
      " 5.34332683e-03 1.53637966e-02 1.40808195e-01 5.06989611e-03\n",
      " 1.08190654e-02 9.90290195e-03 2.20206268e-02 3.16919782e-03\n",
      " 2.68981414e-04 2.91918442e-02 5.39337434e-02 7.11679086e-02\n",
      " 4.76286821e-02 8.29909563e-01 9.79084611e-01 9.48708236e-01\n",
      " 1.12256110e-01 9.96762991e-01 9.92713273e-01 7.59295225e-01\n",
      " 6.38844073e-01 3.18099231e-01 4.07009900e-01 8.73149633e-01\n",
      " 1.72813445e-01 1.90070117e-04 2.91337550e-04 1.60325703e-03\n",
      " 3.00681056e-03 5.93062282e-01 5.98261319e-02 4.07215238e-01\n",
      " 1.04652517e-01 3.23379815e-01 4.89900401e-03 2.41338432e-01\n",
      " 1.19207576e-01 2.43244879e-03 2.78185129e-01 2.52074599e-02\n",
      " 9.96410906e-01 8.54992270e-01 7.21940696e-01 5.88966534e-04\n",
      " 2.64880229e-02 1.98985841e-02 1.22765154e-01 2.72957888e-02\n",
      " 4.74049121e-01 1.52078616e-02 1.44397477e-02 7.81529304e-03\n",
      " 8.96580994e-01 5.92108548e-01 7.77003884e-01 9.80362594e-01\n",
      " 6.05961800e-01 5.87570369e-01 4.01080847e-01 9.99365747e-01\n",
      " 9.93090570e-01 6.10774979e-02 6.17663115e-02 8.85147676e-02\n",
      " 9.34996665e-01 1.30832270e-01 9.23666179e-01 9.13673282e-01\n",
      " 9.94639218e-01 8.68017495e-01 2.12976620e-01 9.95879173e-01\n",
      " 9.60683763e-01 8.56899381e-01 9.85143244e-01 5.91894209e-01\n",
      " 4.76663947e-01 6.99278414e-01 9.36537325e-01 8.64891231e-01\n",
      " 1.99214950e-01 8.52427542e-01 9.91186559e-01 1.76617373e-02\n",
      " 3.19685079e-02 9.99767125e-01 9.94697928e-01 9.74063635e-01\n",
      " 1.26631381e-02 7.19688535e-01 4.10581350e-01 9.56165254e-01\n",
      " 2.32377440e-01 9.92515862e-01 3.12052630e-02 2.62561053e-01\n",
      " 4.76052672e-01 8.95421267e-01 9.67421651e-01 2.49650702e-02\n",
      " 2.17280514e-03 2.12765429e-02 4.38731816e-03 3.07784718e-03\n",
      " 6.59808144e-02 7.46562421e-01 3.47533822e-01 8.89881477e-02\n",
      " 5.73880434e-01 4.55700606e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 97 [0/54 (0%)]\tTrain Loss: 0.012384\n",
      "Train Epoch: 97 [8/54 (15%)]\tTrain Loss: 0.017995\n",
      "Train Epoch: 97 [16/54 (30%)]\tTrain Loss: 0.074018\n",
      "Train Epoch: 97 [24/54 (44%)]\tTrain Loss: 0.033116\n",
      "Train Epoch: 97 [32/54 (59%)]\tTrain Loss: 0.082350\n",
      "Train Epoch: 97 [40/54 (74%)]\tTrain Loss: 0.022570\n",
      "Train Epoch: 97 [48/54 (89%)]\tTrain Loss: 0.105586\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.04953339 0.52733105 0.7871145  0.58162022 0.18580467 0.13487983\n",
      " 0.3538239  0.4356918  0.1486267  0.51804507 0.97994071 0.25364101\n",
      " 0.38436368 0.14011708 0.13829879 0.03607544 0.08277271 0.30815971\n",
      " 0.7064473  0.71695143 0.58664602 0.99123126 0.97320551 0.95855212\n",
      " 0.79956275 0.99193114 0.99028921 0.96408492 0.96564549 0.94329107\n",
      " 0.868972   0.98979467 0.65164465 0.00809008 0.00731224 0.11046811\n",
      " 0.46258554 0.9938339  0.47965094 0.69041216 0.28645137 0.82155907\n",
      " 0.04255549 0.95967901 0.68437809 0.10612489 0.56740344 0.22192098\n",
      " 0.99920923 0.95987469 0.97585207 0.06240172 0.64839536 0.42432237\n",
      " 0.45963848 0.51147401 0.94681686 0.52519768 0.85066891 0.25242773\n",
      " 0.99335301 0.9706645  0.97566742 0.99599069 0.95032412 0.99721342\n",
      " 0.98924047 0.99692291 0.99980253 0.80815357 0.63874137 0.68874681\n",
      " 0.99469548 0.9433046  0.99827361 0.93964714 0.99319816 0.90190536\n",
      " 0.79058117 0.99892491 0.99159724 0.99094701 0.98856598 0.93993407\n",
      " 0.86906677 0.97019112 0.98748231 0.97339749 0.93583661 0.9842726\n",
      " 0.99642438 0.82798809 0.57428783 0.9997769  0.98626608 0.99698538\n",
      " 0.31309953 0.9458077  0.96506137 0.99294382 0.46159244 0.99759161\n",
      " 0.49992141 0.89188969 0.95725006 0.96961516 0.99299735 0.40779066\n",
      " 0.027645   0.61355668 0.03673088 0.00419317 0.32884675 0.98517889\n",
      " 0.63226968 0.2362435  0.6153152  0.32155448]\n",
      "predict [0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 98 [0/54 (0%)]\tTrain Loss: 0.016449\n",
      "Train Epoch: 98 [8/54 (15%)]\tTrain Loss: 0.006776\n",
      "Train Epoch: 98 [16/54 (30%)]\tTrain Loss: 0.026314\n",
      "Train Epoch: 98 [24/54 (44%)]\tTrain Loss: 0.026339\n",
      "Train Epoch: 98 [32/54 (59%)]\tTrain Loss: 0.014548\n",
      "Train Epoch: 98 [40/54 (74%)]\tTrain Loss: 0.016597\n",
      "Train Epoch: 98 [48/54 (89%)]\tTrain Loss: 0.025836\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.12170291e-01 9.99670148e-01 9.99374330e-01 9.68295038e-01\n",
      " 1.49552360e-01 1.30007446e-01 9.98084903e-01 5.48130512e-01\n",
      " 3.05858105e-02 2.71475255e-01 3.39335948e-01 3.50469500e-02\n",
      " 1.71146188e-02 1.48161836e-02 8.05867016e-02 5.28389961e-03\n",
      " 2.67277588e-04 1.91289425e-01 1.30469203e-01 7.31052309e-02\n",
      " 4.37409282e-01 8.38524640e-01 9.91328776e-01 9.50881898e-01\n",
      " 9.29966867e-02 9.90723431e-01 9.70088005e-01 7.32141852e-01\n",
      " 6.99974298e-01 3.40376735e-01 9.97427762e-01 9.99811590e-01\n",
      " 9.99985814e-01 3.32281605e-04 1.13212569e-04 1.88301736e-03\n",
      " 3.55126821e-02 8.31032872e-01 1.18089095e-01 1.32845312e-01\n",
      " 9.56406146e-02 9.47441980e-02 1.88897792e-02 2.20292389e-01\n",
      " 5.67806125e-01 9.76118684e-01 9.99998927e-01 9.99999166e-01\n",
      " 1.00000000e+00 9.81516838e-01 1.00000000e+00 8.98564467e-05\n",
      " 3.03468890e-02 6.19726852e-02 4.72121388e-01 2.56919134e-02\n",
      " 9.72103775e-01 1.34352803e-01 1.16248168e-01 3.98371279e-01\n",
      " 9.93844032e-01 9.02275980e-01 9.98090327e-01 9.99992847e-01\n",
      " 9.76093948e-01 7.80405462e-01 8.16887796e-01 9.99135673e-01\n",
      " 9.99953866e-01 8.21959078e-01 9.96585965e-01 9.96592939e-01\n",
      " 9.99940991e-01 9.82876003e-01 9.99430478e-01 9.99971867e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99996424e-01 1.00000000e+00\n",
      " 9.99999166e-01 9.99999881e-01 9.99999762e-01 8.19432735e-01\n",
      " 9.11467671e-01 9.98920679e-01 9.99995470e-01 9.99994040e-01\n",
      " 4.02802557e-01 1.38255909e-01 9.93207037e-01 2.97911644e-01\n",
      " 4.42069083e-01 9.99949574e-01 9.86425877e-01 9.92606759e-01\n",
      " 1.61491837e-02 9.85009491e-01 9.35308635e-01 9.33936894e-01\n",
      " 1.85700640e-01 9.99995351e-01 1.91276316e-02 9.68494892e-01\n",
      " 9.99190271e-01 9.94602859e-01 9.99990106e-01 4.47323173e-03\n",
      " 1.21239771e-03 6.62856624e-02 7.85938930e-04 8.99543578e-04\n",
      " 7.96139613e-02 4.99498874e-01 2.73143202e-01 6.89907447e-02\n",
      " 8.23739827e-01 8.53314325e-02]\n",
      "predict [1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 99 [0/54 (0%)]\tTrain Loss: 0.010072\n",
      "Train Epoch: 99 [8/54 (15%)]\tTrain Loss: 0.042592\n",
      "Train Epoch: 99 [16/54 (30%)]\tTrain Loss: 0.022294\n",
      "Train Epoch: 99 [24/54 (44%)]\tTrain Loss: 0.051670\n",
      "Train Epoch: 99 [32/54 (59%)]\tTrain Loss: 0.020242\n",
      "Train Epoch: 99 [40/54 (74%)]\tTrain Loss: 0.040463\n",
      "Train Epoch: 99 [48/54 (89%)]\tTrain Loss: 0.039772\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.87569205e-02 6.32217452e-02 4.34416644e-02 2.81918515e-02\n",
      " 1.10113260e-03 3.43876053e-03 2.61758845e-02 3.19845951e-03\n",
      " 1.88004337e-02 2.05141865e-02 3.54903758e-01 3.15804454e-03\n",
      " 2.77219480e-03 6.27804501e-03 8.34387820e-03 3.31350602e-03\n",
      " 2.13368752e-04 4.26219553e-02 1.72907203e-01 5.44784293e-02\n",
      " 9.57206115e-02 3.47127616e-01 9.26351666e-01 8.23721886e-01\n",
      " 1.76084973e-02 9.90311742e-01 9.94615257e-01 1.54455364e-01\n",
      " 3.67760062e-01 4.44352739e-02 6.80523455e-01 9.06065226e-01\n",
      " 4.46404219e-02 8.58373605e-05 9.60511970e-05 3.46793706e-04\n",
      " 1.83352665e-03 3.38408500e-01 3.16488594e-02 2.14664694e-02\n",
      " 1.04574291e-02 3.33090574e-02 2.14303914e-03 7.30823502e-02\n",
      " 1.16197355e-01 1.07596889e-02 6.87524557e-01 1.32741839e-01\n",
      " 9.99647737e-01 8.61503899e-01 9.95791316e-01 1.46088481e-04\n",
      " 1.04039842e-02 2.18882915e-02 1.54909164e-01 9.69425309e-03\n",
      " 7.51742542e-01 6.44673407e-03 1.94540359e-02 1.48580084e-02\n",
      " 8.58991444e-01 8.90383482e-01 9.70356166e-01 9.90827143e-01\n",
      " 5.93543231e-01 3.92883688e-01 3.01310062e-01 9.30933177e-01\n",
      " 9.88785744e-01 9.53941405e-01 5.77046454e-01 4.85909581e-01\n",
      " 9.88991737e-01 7.54835725e-01 9.10310924e-01 9.63354945e-01\n",
      " 9.75271225e-01 9.33411956e-01 4.37344104e-01 9.99328613e-01\n",
      " 9.80860472e-01 9.46843982e-01 9.95748878e-01 4.73842919e-01\n",
      " 1.05736226e-01 9.70741451e-01 9.62639272e-01 9.44723189e-01\n",
      " 1.16219729e-01 6.04856670e-01 9.81992960e-01 7.91638568e-02\n",
      " 6.59184754e-02 9.99524117e-01 9.06503081e-01 7.90319264e-01\n",
      " 1.67577565e-02 5.72150707e-01 7.16503441e-01 4.84244734e-01\n",
      " 1.47465959e-01 9.98666644e-01 2.52889097e-02 2.42753416e-01\n",
      " 7.98110247e-01 5.27634263e-01 9.97544825e-01 7.62046548e-04\n",
      " 1.78243601e-04 2.91107241e-02 4.31878259e-04 7.74258660e-05\n",
      " 3.59718665e-03 2.43817672e-01 1.06612585e-01 3.22746336e-02\n",
      " 3.01436901e-01 1.16986744e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 100 [0/54 (0%)]\tTrain Loss: 0.021884\n",
      "Train Epoch: 100 [8/54 (15%)]\tTrain Loss: 0.198532\n",
      "Train Epoch: 100 [16/54 (30%)]\tTrain Loss: 0.010481\n",
      "Train Epoch: 100 [24/54 (44%)]\tTrain Loss: 0.031783\n",
      "Train Epoch: 100 [32/54 (59%)]\tTrain Loss: 0.019305\n",
      "Train Epoch: 100 [40/54 (74%)]\tTrain Loss: 0.007537\n",
      "Train Epoch: 100 [48/54 (89%)]\tTrain Loss: 0.042932\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.02031991 0.95059305 0.97165269 0.98377466 0.29476058 0.04835153\n",
      " 0.95711952 0.79379851 0.05895494 0.27531245 0.89073128 0.05351383\n",
      " 0.51264638 0.69973236 0.33576223 0.22462595 0.50873041 0.07024486\n",
      " 0.38360307 0.20304985 0.36197329 0.96257156 0.99376208 0.96893835\n",
      " 0.59699845 0.98984736 0.96551359 0.95749575 0.88801461 0.93778312\n",
      " 0.94573897 0.99557024 0.28353339 0.06932499 0.04169821 0.2769998\n",
      " 0.71864146 0.99788696 0.04849104 0.39758575 0.3237673  0.62299448\n",
      " 0.01940744 0.81280905 0.4965291  0.04828809 0.54261112 0.46486521\n",
      " 0.99965978 0.90195924 0.97543871 0.00474052 0.34014595 0.48013356\n",
      " 0.62134743 0.36784384 0.92238528 0.58381444 0.50221449 0.09389222\n",
      " 0.81532323 0.7654649  0.75348741 0.93729389 0.85096639 0.99513763\n",
      " 0.99667311 0.99570835 0.99973851 0.92662621 0.82817709 0.77404368\n",
      " 0.98539668 0.70755535 0.97967517 0.87794745 0.99958426 0.99637586\n",
      " 0.97949481 0.99892944 0.99632049 0.9861654  0.9911986  0.7472896\n",
      " 0.68238133 0.87967151 0.97646779 0.93170565 0.93339288 0.99632734\n",
      " 0.99862421 0.80695677 0.29765996 0.99991941 0.98623151 0.99177998\n",
      " 0.09802023 0.76924837 0.87159175 0.99604332 0.29227149 0.9830361\n",
      " 0.62542099 0.95065737 0.95037055 0.63997602 0.99885666 0.20906109\n",
      " 0.06041244 0.56918466 0.0274375  0.02569886 0.61410969 0.98263782\n",
      " 0.57037425 0.1611906  0.93672901 0.8176648 ]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 42 TN= 40 FN= 16 FP= 20\n",
      "TP+FP 62\n",
      "precision 0.6774193548387096\n",
      "recall 0.7241379310344828\n",
      "F1 0.7\n",
      "acc 0.6949152542372882\n",
      "AUCp 0.6954022988505748\n",
      "AUC 0.7413793103448276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 100, average recall: 0.7241, average precision: 0.6774,average F1: 0.7000, average accuracy: 0.6949, average AUC: 0.7414\n",
      "Train Epoch: 101 [0/54 (0%)]\tTrain Loss: 0.035984\n",
      "Train Epoch: 101 [8/54 (15%)]\tTrain Loss: 0.044048\n",
      "Train Epoch: 101 [16/54 (30%)]\tTrain Loss: 0.014779\n",
      "Train Epoch: 101 [24/54 (44%)]\tTrain Loss: 0.043317\n",
      "Train Epoch: 101 [32/54 (59%)]\tTrain Loss: 0.012281\n",
      "Train Epoch: 101 [40/54 (74%)]\tTrain Loss: 0.032964\n",
      "Train Epoch: 101 [48/54 (89%)]\tTrain Loss: 0.051000\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.09155558 0.99530965 0.99772555 0.43121836 0.21558033 0.1798671\n",
      " 0.99768448 0.15592599 0.17644303 0.72023284 0.64541757 0.02491571\n",
      " 0.28299856 0.74989837 0.81790477 0.2976273  0.79737747 0.06754288\n",
      " 0.39262801 0.12902126 0.53400409 0.92610162 0.9928844  0.98583049\n",
      " 0.85963225 0.99632841 0.99527657 0.92829293 0.91464502 0.46641693\n",
      " 0.92772496 0.99728274 0.15442739 0.00857964 0.01388206 0.03796617\n",
      " 0.05380924 0.91872621 0.0699237  0.57931572 0.39721701 0.52012843\n",
      " 0.00338418 0.49410161 0.27505285 0.13936149 0.79763913 0.6613968\n",
      " 0.99996948 0.96985787 0.99940658 0.00517144 0.28092206 0.24123773\n",
      " 0.45867622 0.06225511 0.95540893 0.23170781 0.10295099 0.22129644\n",
      " 0.97847432 0.93266064 0.93410182 0.98658735 0.63807899 0.99629754\n",
      " 0.94736797 0.99175781 0.99999106 0.9915753  0.92777914 0.86824083\n",
      " 0.99912184 0.9585343  0.99677712 0.97145748 0.99986291 0.99953306\n",
      " 0.99911064 0.99992585 0.99855238 0.99883014 0.99915767 0.11647366\n",
      " 0.41266483 0.9698981  0.9926576  0.99073946 0.96766162 0.99719501\n",
      " 0.99728203 0.87491947 0.11118486 0.99964309 0.92552102 0.97964799\n",
      " 0.02501603 0.83048701 0.96344602 0.99122435 0.43259147 0.99503005\n",
      " 0.46073487 0.90636367 0.97398198 0.95989448 0.9996711  0.04638078\n",
      " 0.0211143  0.5638324  0.02991666 0.02120475 0.68681133 0.97824836\n",
      " 0.34011978 0.11768233 0.87584549 0.76168501]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 102 [0/54 (0%)]\tTrain Loss: 0.045420\n",
      "Train Epoch: 102 [8/54 (15%)]\tTrain Loss: 0.011870\n",
      "Train Epoch: 102 [16/54 (30%)]\tTrain Loss: 0.019495\n",
      "Train Epoch: 102 [24/54 (44%)]\tTrain Loss: 0.062496\n",
      "Train Epoch: 102 [32/54 (59%)]\tTrain Loss: 0.052871\n",
      "Train Epoch: 102 [40/54 (74%)]\tTrain Loss: 0.013934\n",
      "Train Epoch: 102 [48/54 (89%)]\tTrain Loss: 0.019385\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.43446201e-02 8.16125870e-01 3.55139941e-01 3.52081090e-01\n",
      " 4.18437272e-02 5.30458912e-02 7.94156253e-01 3.26327682e-02\n",
      " 2.87145078e-01 8.39491069e-01 9.51590359e-01 8.09459686e-02\n",
      " 1.38354912e-01 8.99498537e-02 7.64274132e-03 4.82316837e-02\n",
      " 2.98038960e-01 1.33247316e-01 8.30850184e-01 6.64668560e-01\n",
      " 4.02306229e-01 9.86446023e-01 9.24393654e-01 9.06034887e-01\n",
      " 9.88560975e-01 9.90759134e-01 8.51551056e-01 9.60340500e-01\n",
      " 7.06081808e-01 2.10882559e-01 5.64307511e-01 8.85111213e-01\n",
      " 1.85726047e-03 6.98781526e-03 7.88931176e-03 1.95482865e-01\n",
      " 8.58919602e-03 9.90562499e-01 1.79761454e-01 4.93661880e-01\n",
      " 2.42367297e-01 4.20035601e-01 1.57887023e-02 5.48027575e-01\n",
      " 2.17259750e-01 1.10867368e-02 4.14434150e-02 1.66375022e-02\n",
      " 9.88884568e-01 4.52990383e-01 9.54959750e-01 6.69943634e-04\n",
      " 2.87469208e-01 3.32762271e-01 5.44823289e-01 3.64810042e-02\n",
      " 9.94660556e-01 1.64398387e-01 1.23835325e-01 9.97775607e-03\n",
      " 4.32538867e-01 6.16916299e-01 4.62310344e-01 6.27890050e-01\n",
      " 5.22255182e-01 1.93610474e-01 6.99549913e-01 9.40763235e-01\n",
      " 9.98211145e-01 9.44508195e-01 9.00780618e-01 8.41374755e-01\n",
      " 8.86976421e-01 4.84218188e-02 7.92507052e-01 9.35718417e-01\n",
      " 9.84484553e-01 7.40546167e-01 7.44587839e-01 9.91060674e-01\n",
      " 9.83093858e-01 8.43538702e-01 9.25657868e-01 9.01373565e-01\n",
      " 8.90436292e-01 7.91353345e-01 8.94023478e-01 9.05726492e-01\n",
      " 8.02845359e-02 9.88110423e-01 9.77214098e-01 6.99136734e-01\n",
      " 2.46579684e-02 9.98853803e-01 9.92587626e-01 9.60823059e-01\n",
      " 1.30979950e-02 9.46617365e-01 9.96950448e-01 7.52707303e-01\n",
      " 6.71814501e-01 9.14123833e-01 6.48338616e-01 9.08270657e-01\n",
      " 9.47303236e-01 7.94918656e-01 9.98974800e-01 8.24818462e-02\n",
      " 9.94719565e-03 8.69091600e-02 7.50784483e-03 7.43491948e-02\n",
      " 1.86437920e-01 9.95592296e-01 5.34095407e-01 6.98907077e-01\n",
      " 9.92447257e-01 9.84622061e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 103 [0/54 (0%)]\tTrain Loss: 0.027800\n",
      "Train Epoch: 103 [8/54 (15%)]\tTrain Loss: 0.002575\n",
      "Train Epoch: 103 [16/54 (30%)]\tTrain Loss: 0.075445\n",
      "Train Epoch: 103 [24/54 (44%)]\tTrain Loss: 0.073595\n",
      "Train Epoch: 103 [32/54 (59%)]\tTrain Loss: 0.016271\n",
      "Train Epoch: 103 [40/54 (74%)]\tTrain Loss: 0.028229\n",
      "Train Epoch: 103 [48/54 (89%)]\tTrain Loss: 0.033487\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.56527388e-01 9.92204964e-01 9.69021380e-01 9.85554576e-01\n",
      " 1.22704484e-01 7.99397290e-01 9.83762741e-01 7.45222330e-01\n",
      " 6.78417325e-01 9.38557148e-01 8.81157875e-01 1.28701916e-02\n",
      " 1.71879351e-01 4.08102721e-01 7.56253839e-01 1.97009966e-01\n",
      " 1.91299934e-02 1.15765437e-01 2.59058969e-03 1.03463484e-02\n",
      " 2.63111871e-02 9.00053740e-01 9.79676127e-01 9.88935769e-01\n",
      " 4.77806807e-01 9.77917433e-01 9.87610757e-01 1.59382328e-01\n",
      " 1.89365342e-01 3.58890682e-01 6.07279956e-01 9.56692696e-01\n",
      " 5.13404012e-01 1.12437692e-05 2.76456354e-04 1.26089212e-02\n",
      " 2.22468586e-03 9.79746580e-01 2.26023957e-01 7.09733784e-01\n",
      " 6.37362301e-01 9.26122189e-01 2.40821987e-02 8.78707945e-01\n",
      " 9.91291478e-02 5.95655024e-01 9.98809576e-01 9.89788413e-01\n",
      " 9.99999642e-01 9.99092102e-01 9.99993920e-01 1.34415338e-02\n",
      " 2.33501121e-02 4.92165059e-01 2.62368083e-01 1.47739304e-02\n",
      " 8.43079925e-01 2.01844648e-02 3.73776853e-02 1.44313082e-01\n",
      " 9.98081326e-01 9.91794646e-01 9.96208310e-01 9.99373615e-01\n",
      " 6.64181769e-01 9.92420137e-01 9.88483727e-01 9.98613238e-01\n",
      " 9.99820530e-01 9.88356888e-01 9.96591926e-01 9.94203627e-01\n",
      " 9.99411821e-01 7.93273091e-01 9.85712886e-01 9.98910546e-01\n",
      " 9.99995351e-01 9.99975204e-01 9.99878049e-01 9.99998450e-01\n",
      " 9.99930978e-01 9.99779284e-01 9.99933243e-01 8.83834183e-01\n",
      " 7.27329910e-01 9.91636157e-01 9.99512434e-01 9.99199450e-01\n",
      " 2.67032278e-03 5.37410975e-01 9.40244138e-01 9.47226226e-01\n",
      " 9.32052672e-01 9.99550283e-01 9.68831062e-01 9.86582398e-01\n",
      " 2.94416733e-02 8.96679223e-01 2.75068015e-01 9.96304631e-01\n",
      " 3.26493442e-01 9.99972701e-01 2.77240872e-02 9.79508281e-01\n",
      " 9.94611621e-01 9.86266375e-01 9.99971151e-01 3.69558367e-03\n",
      " 1.85937082e-04 1.95817560e-01 2.33391672e-03 1.52248819e-03\n",
      " 9.48011205e-02 1.26408100e-01 4.91203249e-01 1.84350029e-01\n",
      " 7.60104477e-01 2.26803526e-01]\n",
      "predict [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 104 [0/54 (0%)]\tTrain Loss: 0.031571\n",
      "Train Epoch: 104 [8/54 (15%)]\tTrain Loss: 0.056725\n",
      "Train Epoch: 104 [16/54 (30%)]\tTrain Loss: 0.010992\n",
      "Train Epoch: 104 [24/54 (44%)]\tTrain Loss: 0.059060\n",
      "Train Epoch: 104 [32/54 (59%)]\tTrain Loss: 0.027757\n",
      "Train Epoch: 104 [40/54 (74%)]\tTrain Loss: 0.025723\n",
      "Train Epoch: 104 [48/54 (89%)]\tTrain Loss: 0.015299\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.98316458e-02 4.74329889e-01 1.46493629e-01 8.16191360e-02\n",
      " 2.91349785e-03 2.40776651e-02 3.29081625e-01 2.41815038e-02\n",
      " 5.82808889e-02 1.19274475e-01 4.55036104e-01 8.72180914e-04\n",
      " 3.68908467e-03 3.71163408e-03 1.51707130e-02 4.50272532e-03\n",
      " 1.14639371e-03 6.74981102e-02 6.23773783e-03 1.15398809e-01\n",
      " 2.24467088e-02 6.72557712e-01 8.77691150e-01 2.93308020e-01\n",
      " 7.20577016e-02 9.76288795e-01 8.14210474e-01 2.56076306e-01\n",
      " 3.64807993e-02 1.88537374e-01 6.52057052e-01 8.97170305e-01\n",
      " 2.72392124e-01 1.14037321e-05 3.42526182e-04 1.12731359e-03\n",
      " 1.14132371e-03 3.63341570e-01 9.81180295e-02 2.35244744e-02\n",
      " 1.59570780e-02 3.65070291e-02 5.91982575e-03 3.95230353e-02\n",
      " 5.41770384e-02 6.80838674e-02 6.63156509e-01 4.66467351e-01\n",
      " 9.99640942e-01 7.94681668e-01 9.97935534e-01 5.10934296e-05\n",
      " 9.16730519e-03 3.87159362e-02 1.73994601e-01 5.53177716e-03\n",
      " 9.17341590e-01 1.35951247e-02 2.79205423e-02 6.70414604e-03\n",
      " 9.86134350e-01 8.69771063e-01 9.53285873e-01 9.93799269e-01\n",
      " 2.20843866e-01 4.08431441e-01 6.62235856e-01 9.95337725e-01\n",
      " 9.96538401e-01 9.40324426e-01 8.04880261e-01 6.60028398e-01\n",
      " 9.93204832e-01 5.19599319e-01 9.01068807e-01 9.79304075e-01\n",
      " 9.88701463e-01 9.64523673e-01 9.69678342e-01 9.98492360e-01\n",
      " 9.95476305e-01 9.77652013e-01 9.94702160e-01 4.99122769e-01\n",
      " 2.59025902e-01 9.82169569e-01 9.81694043e-01 9.90471959e-01\n",
      " 1.32381367e-02 5.90539336e-01 9.34050739e-01 2.27084428e-01\n",
      " 1.17538162e-01 9.73253727e-01 9.28848982e-01 5.62175095e-01\n",
      " 1.46422215e-04 8.75730455e-01 7.84761369e-01 9.25363600e-01\n",
      " 1.59607008e-01 9.98608172e-01 2.33252384e-02 8.66673410e-01\n",
      " 9.02586401e-01 7.72463799e-01 9.99846578e-01 6.47571962e-03\n",
      " 5.56629209e-04 2.94208433e-02 3.82769690e-03 2.18329787e-05\n",
      " 8.55277404e-02 4.58521575e-01 3.81113529e-01 7.29423910e-02\n",
      " 9.03824925e-01 3.49651814e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 105 [0/54 (0%)]\tTrain Loss: 0.086791\n",
      "Train Epoch: 105 [8/54 (15%)]\tTrain Loss: 0.096451\n",
      "Train Epoch: 105 [16/54 (30%)]\tTrain Loss: 0.009341\n",
      "Train Epoch: 105 [24/54 (44%)]\tTrain Loss: 0.029566\n",
      "Train Epoch: 105 [32/54 (59%)]\tTrain Loss: 0.127261\n",
      "Train Epoch: 105 [40/54 (74%)]\tTrain Loss: 0.051089\n",
      "Train Epoch: 105 [48/54 (89%)]\tTrain Loss: 0.043655\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.28712056e-02 2.28473738e-01 2.83957213e-01 7.00395465e-01\n",
      " 5.26880696e-02 5.04675359e-02 3.02465588e-01 7.25371391e-02\n",
      " 1.26074255e-01 2.52596498e-01 2.23665252e-01 7.66869867e-04\n",
      " 8.91011301e-03 1.66227184e-02 1.30785070e-02 1.69341192e-02\n",
      " 7.09191263e-02 7.88395479e-02 1.38061959e-02 5.36591038e-02\n",
      " 4.93047506e-01 6.78373933e-01 8.83720577e-01 4.58033502e-01\n",
      " 2.89204597e-01 6.53643012e-01 4.04002517e-01 6.23965144e-01\n",
      " 4.61317487e-02 4.34451140e-02 8.03467274e-01 8.23298812e-01\n",
      " 1.15068346e-01 1.72083396e-02 1.34111019e-02 5.57354745e-03\n",
      " 1.16662476e-02 2.04955429e-01 1.70479566e-01 6.99989945e-02\n",
      " 8.46560225e-02 1.09391168e-01 1.50210466e-02 1.57486185e-01\n",
      " 7.39570558e-02 6.62654787e-02 9.51476097e-01 2.37796977e-01\n",
      " 9.98585224e-01 8.44254076e-01 9.96790111e-01 7.14659400e-04\n",
      " 1.37940021e-02 7.28379190e-02 2.18682140e-01 3.44689861e-02\n",
      " 9.13736105e-01 3.09742726e-02 1.24771288e-03 9.47653316e-03\n",
      " 9.93573606e-01 7.97151625e-01 9.36605811e-01 9.94693339e-01\n",
      " 3.46480668e-01 5.53779364e-01 6.04834497e-01 9.91272151e-01\n",
      " 9.98617172e-01 8.59770238e-01 9.42860782e-01 8.31394553e-01\n",
      " 9.97048318e-01 9.87132072e-01 9.74332809e-01 8.26573431e-01\n",
      " 9.70929086e-01 9.37365234e-01 9.25700784e-01 9.99825656e-01\n",
      " 9.99137521e-01 9.93759036e-01 9.99146223e-01 5.91377020e-02\n",
      " 7.43426859e-01 9.89007950e-01 8.25178504e-01 9.87970769e-01\n",
      " 1.38730958e-01 2.84778953e-01 9.72839475e-01 5.75311184e-01\n",
      " 1.04458719e-01 9.78900671e-01 9.51304197e-01 9.57708180e-01\n",
      " 3.66718881e-02 9.13541615e-01 9.42377508e-01 8.42715561e-01\n",
      " 4.01030153e-01 9.96120632e-01 1.54682025e-01 9.04799998e-01\n",
      " 8.44593823e-01 8.44634116e-01 9.92057145e-01 9.13723931e-02\n",
      " 4.42657173e-02 2.28940025e-01 2.45576501e-02 2.33518817e-02\n",
      " 6.27539277e-01 4.47157890e-01 6.64423034e-02 8.50406215e-02\n",
      " 8.68109643e-01 7.14448750e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 106 [0/54 (0%)]\tTrain Loss: 0.006728\n",
      "Train Epoch: 106 [8/54 (15%)]\tTrain Loss: 0.009768\n",
      "Train Epoch: 106 [16/54 (30%)]\tTrain Loss: 0.017661\n",
      "Train Epoch: 106 [24/54 (44%)]\tTrain Loss: 0.039169\n",
      "Train Epoch: 106 [32/54 (59%)]\tTrain Loss: 0.036856\n",
      "Train Epoch: 106 [40/54 (74%)]\tTrain Loss: 0.016123\n",
      "Train Epoch: 106 [48/54 (89%)]\tTrain Loss: 0.018528\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.19794354 0.97409987 0.92274791 0.85071951 0.14020358 0.22184338\n",
      " 0.88810384 0.41526586 0.3831028  0.35630858 0.7074874  0.00370645\n",
      " 0.08297538 0.25143054 0.80781764 0.09688631 0.0768822  0.124561\n",
      " 0.05236561 0.29752117 0.44484398 0.98769367 0.9933489  0.28719351\n",
      " 0.83767283 0.77056897 0.74575967 0.72633517 0.80223459 0.82511759\n",
      " 0.92367321 0.97127634 0.87008536 0.00793522 0.01192436 0.09336933\n",
      " 0.06525363 0.77510256 0.44741106 0.39565349 0.32960114 0.43716478\n",
      " 0.11626335 0.56114632 0.32057479 0.2224384  0.97382915 0.96527249\n",
      " 0.999915   0.94744343 0.99957639 0.00423995 0.14807498 0.76946217\n",
      " 0.54817158 0.10519002 0.99308056 0.30998367 0.40899819 0.05348248\n",
      " 0.99791509 0.95839596 0.98648918 0.99749595 0.99354941 0.98333931\n",
      " 0.99824238 0.99871242 0.99981529 0.99079835 0.87855661 0.82528394\n",
      " 0.99912626 0.97236878 0.99237251 0.99924552 0.99989462 0.99987531\n",
      " 0.99989343 0.99994886 0.99990737 0.99911827 0.99967051 0.7266987\n",
      " 0.90024954 0.98371178 0.9992817  0.99863559 0.43604299 0.9417187\n",
      " 0.99014485 0.70336574 0.65985006 0.99975473 0.98664516 0.99059254\n",
      " 0.07047842 0.9172284  0.93354762 0.97167563 0.3409476  0.99853837\n",
      " 0.22612326 0.98865372 0.99156719 0.99118769 0.99984145 0.02319051\n",
      " 0.01445503 0.08562405 0.01730132 0.0120924  0.63694638 0.87012529\n",
      " 0.75686514 0.79750067 0.97429878 0.99186146]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 107 [0/54 (0%)]\tTrain Loss: 0.024481\n",
      "Train Epoch: 107 [8/54 (15%)]\tTrain Loss: 0.058937\n",
      "Train Epoch: 107 [16/54 (30%)]\tTrain Loss: 0.094302\n",
      "Train Epoch: 107 [24/54 (44%)]\tTrain Loss: 0.061952\n",
      "Train Epoch: 107 [32/54 (59%)]\tTrain Loss: 0.005567\n",
      "Train Epoch: 107 [40/54 (74%)]\tTrain Loss: 0.007956\n",
      "Train Epoch: 107 [48/54 (89%)]\tTrain Loss: 0.051642\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.20854454 0.88095862 0.77915162 0.74301207 0.14636353 0.19155213\n",
      " 0.88169616 0.20773192 0.26429752 0.28380913 0.59633708 0.02347554\n",
      " 0.06484048 0.19631231 0.43847051 0.10880226 0.18456598 0.13895321\n",
      " 0.08332065 0.14931999 0.14298573 0.98062277 0.99672747 0.89906979\n",
      " 0.92586446 0.99877113 0.99251032 0.90616602 0.37322617 0.29188743\n",
      " 0.79687977 0.95075357 0.81859291 0.01059791 0.04083455 0.04889957\n",
      " 0.02479087 0.88264412 0.2717388  0.56074542 0.33837071 0.55861133\n",
      " 0.05250518 0.9407894  0.12021083 0.0781681  0.86201417 0.75300401\n",
      " 0.99989724 0.92352414 0.99685305 0.00305282 0.07282071 0.19997901\n",
      " 0.31941855 0.05336517 0.80656737 0.10986648 0.38167036 0.05213518\n",
      " 0.99630862 0.84061629 0.97939575 0.9972657  0.85760581 0.98201436\n",
      " 0.99569464 0.99937719 0.99969459 0.68238258 0.66679788 0.71962106\n",
      " 0.98718423 0.95591104 0.9310801  0.9947449  0.99686301 0.99322152\n",
      " 0.98761708 0.99977964 0.99966598 0.99219984 0.99865121 0.87267959\n",
      " 0.91342318 0.95890516 0.9942081  0.98876756 0.41916379 0.97136915\n",
      " 0.86425501 0.46118215 0.24437927 0.99997663 0.99401206 0.9959805\n",
      " 0.04594579 0.98288178 0.98411834 0.98654431 0.61965644 0.99967194\n",
      " 0.07602552 0.98766953 0.99419421 0.95776075 0.99991107 0.15822494\n",
      " 0.00348608 0.37882167 0.11484387 0.03760026 0.90569425 0.74418741\n",
      " 0.50994545 0.38662541 0.97760552 0.98734218]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 108 [0/54 (0%)]\tTrain Loss: 0.014519\n",
      "Train Epoch: 108 [8/54 (15%)]\tTrain Loss: 0.031386\n",
      "Train Epoch: 108 [16/54 (30%)]\tTrain Loss: 0.030626\n",
      "Train Epoch: 108 [24/54 (44%)]\tTrain Loss: 0.022039\n",
      "Train Epoch: 108 [32/54 (59%)]\tTrain Loss: 0.131156\n",
      "Train Epoch: 108 [40/54 (74%)]\tTrain Loss: 0.059967\n",
      "Train Epoch: 108 [48/54 (89%)]\tTrain Loss: 0.008154\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.77513796e-01 6.61644638e-01 5.44126928e-01 6.50390029e-01\n",
      " 5.53994402e-02 1.42842695e-01 5.26604772e-01 3.24887395e-01\n",
      " 1.22849427e-01 2.52672106e-01 1.25857696e-01 2.16042861e-01\n",
      " 3.13040093e-02 2.73136906e-02 6.51522726e-02 2.79156324e-02\n",
      " 1.16329156e-02 1.11606671e-02 1.19021416e-01 4.33882438e-02\n",
      " 5.97467646e-02 3.17324430e-01 9.15049195e-01 9.92406309e-01\n",
      " 1.43421188e-01 9.88896132e-01 9.96751308e-01 5.21614626e-02\n",
      " 7.42095187e-02 2.47612610e-01 6.91205338e-02 6.57006204e-01\n",
      " 2.99858481e-01 3.30354844e-04 1.34237320e-03 4.68105413e-02\n",
      " 1.23292804e-02 2.56462514e-01 1.85897034e-02 2.10512951e-02\n",
      " 2.38359887e-02 3.68364602e-02 1.92117132e-02 1.58929989e-01\n",
      " 1.55202281e-02 2.96060685e-02 4.41068977e-01 2.82137215e-01\n",
      " 9.99539852e-01 9.58427727e-01 9.97726858e-01 4.04949253e-03\n",
      " 6.69075996e-02 8.49450231e-02 4.19204272e-02 1.93415787e-02\n",
      " 2.77357936e-01 2.49841753e-02 1.80055067e-01 1.98904388e-02\n",
      " 9.59467590e-01 5.10714054e-01 7.71344543e-01 9.85431731e-01\n",
      " 6.88100398e-01 3.97419095e-01 8.79091263e-01 3.92138541e-01\n",
      " 9.72429514e-01 7.96757400e-01 7.79818654e-01 6.28336489e-01\n",
      " 9.86610115e-01 7.35779047e-01 7.89313912e-01 9.73945796e-01\n",
      " 9.97496068e-01 9.91698623e-01 9.69121456e-01 9.83589590e-01\n",
      " 9.66295004e-01 9.32053030e-01 9.92366135e-01 1.89806134e-01\n",
      " 2.96064675e-01 9.44855630e-01 9.33911324e-01 9.39472675e-01\n",
      " 7.93731287e-02 3.28855887e-02 9.84220624e-01 4.27064478e-01\n",
      " 2.36402124e-01 9.99577820e-01 5.70334315e-01 3.33454520e-01\n",
      " 1.44472895e-02 6.61182463e-01 7.84571290e-01 1.83622897e-01\n",
      " 1.75800502e-01 9.89454865e-01 2.67690141e-02 8.54321361e-01\n",
      " 9.46631610e-01 4.05912489e-01 9.99763787e-01 1.42801749e-02\n",
      " 4.07367217e-04 9.90349203e-02 7.42844422e-04 2.67587893e-04\n",
      " 4.14812118e-02 1.90414354e-01 2.21837722e-02 2.65459605e-02\n",
      " 1.87593162e-01 1.84814110e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 109 [0/54 (0%)]\tTrain Loss: 0.015962\n",
      "Train Epoch: 109 [8/54 (15%)]\tTrain Loss: 0.151059\n",
      "Train Epoch: 109 [16/54 (30%)]\tTrain Loss: 0.054735\n",
      "Train Epoch: 109 [24/54 (44%)]\tTrain Loss: 0.009668\n",
      "Train Epoch: 109 [32/54 (59%)]\tTrain Loss: 0.038513\n",
      "Train Epoch: 109 [40/54 (74%)]\tTrain Loss: 0.069963\n",
      "Train Epoch: 109 [48/54 (89%)]\tTrain Loss: 0.053493\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.99970216 0.99998963 0.99959213 0.99844873 0.94602233 0.9944095\n",
      " 0.99995959 0.99815744 0.96296394 0.91992688 0.88021398 0.64873934\n",
      " 0.50745189 0.97237474 0.9939726  0.76725    0.38384968 0.33381042\n",
      " 0.61249733 0.5299148  0.72836936 0.99967492 0.99985182 0.99751687\n",
      " 0.98034394 0.99992073 0.98626584 0.98032606 0.98768151 0.99116009\n",
      " 0.99950314 0.99994397 0.99993169 0.00496501 0.01379592 0.19440562\n",
      " 0.20743988 0.99945039 0.92573208 0.89462709 0.86961633 0.87838882\n",
      " 0.82865274 0.9932074  0.94608837 0.99858296 0.99999809 0.99999499\n",
      " 1.         0.99922466 1.         0.05512907 0.93523657 0.96076936\n",
      " 0.57323724 0.26977018 0.9990828  0.52875805 0.94945222 0.9877345\n",
      " 0.99999726 0.99825996 0.99999309 0.99999976 0.99999332 0.99313194\n",
      " 0.99997342 0.99991417 0.99999976 0.99781239 0.99949801 0.99926728\n",
      " 0.99999988 0.99995077 0.99999416 0.99999976 1.         1.\n",
      " 1.         1.         0.99999976 0.99999976 0.99999952 0.9980703\n",
      " 0.99979526 0.99999917 0.99999106 0.99999666 0.92622626 0.92006952\n",
      " 0.99980038 0.98734218 0.9797948  0.99999952 0.99974114 0.99705124\n",
      " 0.16335009 0.99994755 0.99941599 0.99918133 0.95606357 1.\n",
      " 0.43458864 0.99885654 0.99996686 0.99960631 0.99999964 0.01516972\n",
      " 0.00127943 0.80223048 0.00873956 0.01069186 0.28782687 0.53920346\n",
      " 0.86974609 0.9502635  0.9883216  0.99948174]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 110 [0/54 (0%)]\tTrain Loss: 0.017464\n",
      "Train Epoch: 110 [8/54 (15%)]\tTrain Loss: 0.029523\n",
      "Train Epoch: 110 [16/54 (30%)]\tTrain Loss: 0.057273\n",
      "Train Epoch: 110 [24/54 (44%)]\tTrain Loss: 0.012180\n",
      "Train Epoch: 110 [32/54 (59%)]\tTrain Loss: 0.048877\n",
      "Train Epoch: 110 [40/54 (74%)]\tTrain Loss: 0.030519\n",
      "Train Epoch: 110 [48/54 (89%)]\tTrain Loss: 0.025006\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.11773321 0.59590948 0.24064837 0.42578158 0.09310507 0.11608225\n",
      " 0.45622262 0.20068443 0.15629038 0.60347468 0.24160874 0.12368491\n",
      " 0.0209461  0.04323231 0.10027047 0.02369776 0.00644888 0.02809054\n",
      " 0.33589199 0.0831613  0.12161782 0.85705924 0.96871656 0.66668087\n",
      " 0.40574884 0.97792017 0.93661463 0.37742549 0.47595602 0.13207361\n",
      " 0.28207752 0.66809028 0.07229836 0.00305653 0.00303123 0.04995428\n",
      " 0.02692123 0.34971914 0.0577098  0.04538548 0.05600445 0.05174034\n",
      " 0.01952363 0.04369652 0.03886693 0.07273091 0.33300883 0.3321152\n",
      " 0.99964643 0.83642632 0.99412835 0.00143199 0.03787686 0.05453014\n",
      " 0.29663765 0.03767407 0.77839613 0.01605048 0.13676226 0.02644628\n",
      " 0.98268706 0.90567106 0.97476035 0.9882279  0.87064344 0.19411099\n",
      " 0.75363404 0.95141131 0.98138106 0.68671697 0.85605884 0.55230039\n",
      " 0.98701674 0.93346214 0.93424028 0.9356612  0.9967019  0.99572182\n",
      " 0.98869365 0.9954685  0.99924755 0.97200429 0.99631208 0.8197189\n",
      " 0.63378632 0.96928835 0.95135999 0.94688845 0.05638014 0.68909812\n",
      " 0.96156794 0.24732606 0.30678263 0.99987912 0.99796754 0.60769874\n",
      " 0.01598819 0.98330647 0.99781054 0.9846651  0.4140754  0.98424488\n",
      " 0.03843901 0.87245077 0.99018013 0.90064377 0.99989116 0.02033327\n",
      " 0.00270307 0.10707149 0.0025832  0.05110936 0.12545238 0.96882814\n",
      " 0.34174848 0.27033961 0.68989539 0.84821969]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 41 FN= 13 FP= 19\n",
      "TP+FP 64\n",
      "precision 0.703125\n",
      "recall 0.7758620689655172\n",
      "F1 0.7377049180327868\n",
      "acc 0.7288135593220338\n",
      "AUCp 0.7295977011494252\n",
      "AUC 0.7735632183908046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 110, average recall: 0.7759, average precision: 0.7031,average F1: 0.7377, average accuracy: 0.7288, average AUC: 0.7736\n",
      "Train Epoch: 111 [0/54 (0%)]\tTrain Loss: 0.041245\n",
      "Train Epoch: 111 [8/54 (15%)]\tTrain Loss: 0.023692\n",
      "Train Epoch: 111 [16/54 (30%)]\tTrain Loss: 0.050082\n",
      "Train Epoch: 111 [24/54 (44%)]\tTrain Loss: 0.027505\n",
      "Train Epoch: 111 [32/54 (59%)]\tTrain Loss: 0.054552\n",
      "Train Epoch: 111 [40/54 (74%)]\tTrain Loss: 0.021253\n",
      "Train Epoch: 111 [48/54 (89%)]\tTrain Loss: 0.019553\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.11274921 0.68112093 0.50338292 0.92297697 0.35304555 0.04653483\n",
      " 0.8315388  0.90893537 0.1539522  0.65078223 0.45681292 0.20050165\n",
      " 0.24946393 0.16623074 0.1264375  0.20965473 0.10275405 0.0272523\n",
      " 0.17916118 0.13892066 0.26601139 0.94424158 0.98505437 0.94456363\n",
      " 0.37829277 0.99723887 0.96421766 0.81853044 0.79113859 0.58920765\n",
      " 0.95553559 0.99136752 0.90020782 0.07180374 0.23343368 0.3442339\n",
      " 0.54754007 0.94907874 0.04382863 0.06576151 0.19748323 0.30546698\n",
      " 0.01631137 0.79737049 0.24872786 0.10798868 0.88948458 0.73926127\n",
      " 0.99995434 0.87938404 0.9984175  0.01950392 0.03443724 0.36854577\n",
      " 0.36364269 0.24299805 0.66615331 0.73539007 0.52297199 0.03194121\n",
      " 0.96143103 0.58126408 0.93952948 0.98127246 0.97941089 0.99899811\n",
      " 0.9996773  0.99790514 0.99989784 0.44804022 0.66409463 0.38357291\n",
      " 0.99237376 0.76908326 0.98635304 0.91017097 0.99876922 0.99479526\n",
      " 0.96493119 0.99992394 0.99981731 0.9926334  0.99905366 0.24563055\n",
      " 0.13822787 0.68543887 0.84292275 0.75991446 0.70439696 0.93492466\n",
      " 0.95954835 0.92047387 0.85180277 0.99999189 0.99734592 0.99547738\n",
      " 0.15910603 0.80690086 0.91076428 0.99228972 0.16727191 0.99351788\n",
      " 0.04563759 0.96670157 0.98095953 0.9459005  0.99943775 0.714513\n",
      " 0.03110847 0.27702126 0.02534457 0.00712048 0.82028085 0.94415557\n",
      " 0.10652737 0.11074317 0.63013995 0.62329662]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 112 [0/54 (0%)]\tTrain Loss: 0.038295\n",
      "Train Epoch: 112 [8/54 (15%)]\tTrain Loss: 0.052624\n",
      "Train Epoch: 112 [16/54 (30%)]\tTrain Loss: 0.021789\n",
      "Train Epoch: 112 [24/54 (44%)]\tTrain Loss: 0.005529\n",
      "Train Epoch: 112 [32/54 (59%)]\tTrain Loss: 0.055815\n",
      "Train Epoch: 112 [40/54 (74%)]\tTrain Loss: 0.009846\n",
      "Train Epoch: 112 [48/54 (89%)]\tTrain Loss: 0.033584\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.03574103 0.75484866 0.57180953 0.42625743 0.18764916 0.00780289\n",
      " 0.41871223 0.45958194 0.04017657 0.18111272 0.22730327 0.0913402\n",
      " 0.05965947 0.10663393 0.07539853 0.0222917  0.02432926 0.02587986\n",
      " 0.046904   0.02672611 0.09606142 0.84812444 0.79397285 0.95593327\n",
      " 0.07085049 0.93453735 0.98555589 0.23339376 0.14591946 0.08777389\n",
      " 0.53292441 0.90264273 0.54094648 0.00211725 0.00465163 0.00452112\n",
      " 0.02407712 0.75917685 0.03887186 0.06883791 0.01735693 0.05960602\n",
      " 0.03379891 0.38299707 0.12823011 0.06518695 0.84531361 0.45170745\n",
      " 0.99994195 0.98391551 0.99920183 0.00786563 0.02544804 0.14220846\n",
      " 0.17714745 0.04168141 0.94537604 0.01890625 0.0538381  0.00433259\n",
      " 0.96854711 0.70088559 0.94459581 0.97708011 0.63139498 0.87769979\n",
      " 0.98138118 0.93676543 0.9985252  0.22921531 0.65488386 0.49031353\n",
      " 0.9573096  0.8582837  0.90536934 0.9649967  0.99761498 0.99642169\n",
      " 0.99206465 0.99978119 0.99802577 0.97259033 0.99925238 0.65668607\n",
      " 0.45734227 0.44432589 0.98169726 0.96538448 0.2514334  0.28424001\n",
      " 0.98761731 0.50766474 0.25153744 0.99985945 0.99521589 0.89887434\n",
      " 0.01765391 0.85356754 0.50094938 0.79091269 0.09977688 0.99803156\n",
      " 0.16167362 0.88493752 0.97247314 0.82002509 0.99983966 0.02277756\n",
      " 0.00157165 0.1138066  0.00997701 0.00120154 0.04975313 0.13973717\n",
      " 0.06335682 0.05055858 0.67265952 0.84631157]\n",
      "predict [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 113 [0/54 (0%)]\tTrain Loss: 0.008326\n",
      "Train Epoch: 113 [8/54 (15%)]\tTrain Loss: 0.004960\n",
      "Train Epoch: 113 [16/54 (30%)]\tTrain Loss: 0.005702\n",
      "Train Epoch: 113 [24/54 (44%)]\tTrain Loss: 0.025100\n",
      "Train Epoch: 113 [32/54 (59%)]\tTrain Loss: 0.020770\n",
      "Train Epoch: 113 [40/54 (74%)]\tTrain Loss: 0.146667\n",
      "Train Epoch: 113 [48/54 (89%)]\tTrain Loss: 0.057157\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.01365463e-03 9.12670791e-01 5.91333032e-01 5.01257889e-02\n",
      " 1.52229797e-02 1.05308509e-03 6.35983765e-01 2.62602940e-02\n",
      " 7.26776719e-02 1.02627546e-01 3.94302718e-02 8.82101245e-03\n",
      " 1.53532880e-03 2.04327814e-02 1.74750723e-02 3.23295919e-03\n",
      " 1.09945154e-02 9.56735089e-02 4.71540727e-03 9.97405872e-02\n",
      " 7.12323040e-02 7.32580245e-01 8.78633022e-01 8.15384746e-01\n",
      " 2.85189133e-03 9.65556920e-01 9.67667818e-01 1.38541758e-01\n",
      " 1.12728447e-01 4.67347912e-02 2.93082967e-02 6.30283177e-01\n",
      " 5.93711948e-03 9.21333500e-04 1.51778467e-03 1.29759806e-04\n",
      " 3.84934875e-03 3.93889248e-01 4.69510555e-02 6.25581741e-02\n",
      " 9.08477232e-03 3.53400633e-02 2.44049355e-02 2.51002729e-01\n",
      " 8.25426206e-02 3.01185925e-03 6.53523803e-01 1.15435779e-01\n",
      " 9.99780476e-01 9.72488523e-01 9.77618694e-01 2.60309520e-04\n",
      " 3.44622345e-03 1.62273124e-02 7.13811964e-02 1.02830157e-02\n",
      " 9.12238717e-01 9.42019559e-03 1.17575703e-02 9.25299828e-04\n",
      " 9.70903337e-01 7.15870798e-01 9.46183980e-01 9.79886115e-01\n",
      " 4.15167302e-01 2.21964851e-01 8.74878049e-01 9.72104430e-01\n",
      " 9.91146147e-01 2.74441913e-02 5.70060372e-01 4.13395733e-01\n",
      " 9.30935144e-01 5.23092687e-01 3.27052742e-01 9.79623020e-01\n",
      " 9.98923361e-01 9.98364985e-01 9.60430443e-01 9.94429588e-01\n",
      " 9.65335011e-01 8.25309694e-01 9.96483207e-01 2.25234218e-03\n",
      " 4.65962708e-01 7.18122244e-01 9.91835594e-01 9.90474880e-01\n",
      " 1.34119615e-01 4.05800948e-03 9.21350181e-01 2.56982625e-01\n",
      " 1.44459009e-01 4.52011108e-01 9.79475677e-01 5.57268381e-01\n",
      " 1.26089333e-02 6.21036470e-01 4.12387937e-01 5.98315418e-01\n",
      " 1.29782990e-01 9.96601701e-01 1.74506661e-02 6.54715478e-01\n",
      " 6.10833824e-01 1.56625047e-01 9.97592747e-01 8.99560750e-03\n",
      " 8.24325311e-04 5.20328619e-02 5.70212957e-04 6.17517298e-06\n",
      " 5.46815321e-02 3.25513333e-02 2.61386260e-02 8.89549628e-02\n",
      " 5.08018076e-01 6.84219539e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 114 [0/54 (0%)]\tTrain Loss: 0.009060\n",
      "Train Epoch: 114 [8/54 (15%)]\tTrain Loss: 0.046010\n",
      "Train Epoch: 114 [16/54 (30%)]\tTrain Loss: 0.025826\n",
      "Train Epoch: 114 [24/54 (44%)]\tTrain Loss: 0.006921\n",
      "Train Epoch: 114 [32/54 (59%)]\tTrain Loss: 0.032646\n",
      "Train Epoch: 114 [40/54 (74%)]\tTrain Loss: 0.015392\n",
      "Train Epoch: 114 [48/54 (89%)]\tTrain Loss: 0.011176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.48582201e-03 4.70262468e-01 1.86804444e-01 5.74186087e-01\n",
      " 1.95679337e-01 2.39513302e-03 6.15965247e-01 4.29274470e-01\n",
      " 5.02813384e-02 6.01896346e-01 8.73017788e-01 2.90324390e-01\n",
      " 3.07490438e-01 5.04670218e-02 4.77503166e-02 7.64554143e-02\n",
      " 7.45865405e-02 1.00675203e-01 1.93009079e-01 1.60715654e-01\n",
      " 4.71250378e-02 6.90005720e-01 9.24252570e-01 5.92189789e-01\n",
      " 6.25729263e-02 9.71820652e-01 7.49867439e-01 5.56543469e-01\n",
      " 5.67647636e-01 5.52626133e-01 8.21247324e-02 9.95386899e-01\n",
      " 5.66965461e-01 1.58023275e-02 3.36491279e-02 4.84030321e-03\n",
      " 7.03759640e-02 8.85018468e-01 8.57476518e-02 1.78795695e-01\n",
      " 2.80141663e-02 1.91947684e-01 1.50057375e-02 7.69963086e-01\n",
      " 2.47550279e-01 3.74166667e-02 4.85819399e-01 1.18180469e-01\n",
      " 9.99740541e-01 8.91622484e-01 9.65971112e-01 8.74148309e-03\n",
      " 3.09826862e-02 4.58487868e-02 1.22103512e-01 1.55073404e-01\n",
      " 7.18916714e-01 3.81760687e-01 5.20775467e-02 1.75769329e-02\n",
      " 9.96932268e-01 9.97764468e-01 9.87913072e-01 9.76314902e-01\n",
      " 5.17095327e-01 9.80605781e-01 9.99301672e-01 9.90369141e-01\n",
      " 9.99918818e-01 7.62262404e-01 9.42033529e-01 8.75872731e-01\n",
      " 9.96279180e-01 9.66828823e-01 9.11871433e-01 9.16778743e-01\n",
      " 6.98693216e-01 7.44910121e-01 8.48742366e-01 9.99647021e-01\n",
      " 9.97139454e-01 9.64073181e-01 9.86233950e-01 9.91168976e-01\n",
      " 9.18641090e-01 9.63060677e-01 9.73066628e-01 9.88303661e-01\n",
      " 2.59057134e-01 6.55058563e-01 9.72848952e-01 7.70746946e-01\n",
      " 5.15372157e-01 9.99642253e-01 9.99852300e-01 9.84319031e-01\n",
      " 4.73603196e-02 7.64485955e-01 9.95787561e-01 9.79405940e-01\n",
      " 1.33996457e-01 9.92575526e-01 3.45221281e-01 9.97132421e-01\n",
      " 9.98945773e-01 9.85544384e-01 9.99273717e-01 3.54766957e-02\n",
      " 3.71200009e-03 1.65436164e-01 9.78064351e-03 8.82053107e-04\n",
      " 9.21193361e-01 9.38861489e-01 4.96627420e-01 3.39182675e-01\n",
      " 5.44378757e-01 8.72169554e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 115 [0/54 (0%)]\tTrain Loss: 0.041848\n",
      "Train Epoch: 115 [8/54 (15%)]\tTrain Loss: 0.010283\n",
      "Train Epoch: 115 [16/54 (30%)]\tTrain Loss: 0.007061\n",
      "Train Epoch: 115 [24/54 (44%)]\tTrain Loss: 0.011998\n",
      "Train Epoch: 115 [32/54 (59%)]\tTrain Loss: 0.018451\n",
      "Train Epoch: 115 [40/54 (74%)]\tTrain Loss: 0.023083\n",
      "Train Epoch: 115 [48/54 (89%)]\tTrain Loss: 0.012678\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.63291913e-01 3.41629505e-01 1.90312967e-01 2.32542530e-01\n",
      " 2.44532852e-03 3.09172124e-02 1.58794776e-01 8.34843703e-03\n",
      " 2.80173063e-01 1.51510969e-01 1.27608632e-03 1.56528223e-02\n",
      " 1.66381578e-04 2.72938312e-04 7.44191092e-03 9.47362205e-05\n",
      " 1.33314497e-05 1.14719430e-02 1.47936004e-03 1.20478601e-03\n",
      " 2.97236312e-02 3.62347588e-02 5.12941778e-01 8.48430336e-01\n",
      " 1.60604704e-03 9.39630032e-01 9.61190343e-01 2.28120089e-02\n",
      " 5.96478768e-03 2.19295314e-03 7.11315572e-02 4.89184290e-01\n",
      " 1.94790110e-01 1.78000300e-05 1.72351374e-05 7.41413169e-05\n",
      " 2.54050508e-04 2.88457513e-01 7.13535352e-03 5.27298823e-03\n",
      " 2.53102090e-03 5.37701184e-03 2.21948675e-03 1.35972362e-03\n",
      " 1.01509213e-03 9.03642699e-02 9.97140646e-01 9.38688338e-01\n",
      " 9.99995589e-01 9.87794757e-01 9.99973536e-01 2.75466173e-05\n",
      " 6.14062999e-04 6.88396301e-03 4.51251492e-02 5.15991589e-04\n",
      " 3.58536452e-01 1.42333587e-03 6.82918297e-04 9.75613948e-04\n",
      " 9.96893644e-01 9.16628003e-01 9.96469855e-01 9.99418497e-01\n",
      " 2.34489918e-01 1.67413980e-01 9.67371345e-01 9.75939512e-01\n",
      " 9.99602735e-01 9.36069489e-01 9.97444987e-01 9.78465378e-01\n",
      " 9.87921000e-01 9.86131668e-01 9.75033283e-01 9.88759279e-01\n",
      " 9.99935865e-01 9.99938369e-01 9.86693203e-01 9.99848962e-01\n",
      " 9.98093545e-01 9.95591938e-01 9.99861121e-01 2.84841657e-03\n",
      " 9.08873975e-02 9.86457407e-01 9.93043303e-01 9.97231781e-01\n",
      " 9.27425455e-03 3.25256865e-03 9.33265328e-01 1.15235135e-01\n",
      " 1.71697348e-01 9.64544713e-01 9.95052159e-01 5.65538466e-01\n",
      " 1.88572926e-03 6.21268272e-01 2.91064262e-01 4.48783100e-01\n",
      " 3.58488560e-02 9.99396443e-01 1.82357011e-03 3.29608589e-01\n",
      " 9.94577050e-01 8.56187642e-01 9.99659300e-01 8.45267088e-04\n",
      " 3.80869751e-05 9.61016398e-03 4.61893287e-05 3.74125411e-05\n",
      " 1.19778691e-02 1.30464688e-01 1.46281468e-02 6.02215109e-03\n",
      " 9.28139985e-02 1.95422899e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 116 [0/54 (0%)]\tTrain Loss: 0.062022\n",
      "Train Epoch: 116 [8/54 (15%)]\tTrain Loss: 0.030308\n",
      "Train Epoch: 116 [16/54 (30%)]\tTrain Loss: 0.020359\n",
      "Train Epoch: 116 [24/54 (44%)]\tTrain Loss: 0.044832\n",
      "Train Epoch: 116 [32/54 (59%)]\tTrain Loss: 0.046089\n",
      "Train Epoch: 116 [40/54 (74%)]\tTrain Loss: 0.020642\n",
      "Train Epoch: 116 [48/54 (89%)]\tTrain Loss: 0.027413\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.06308429 0.83576256 0.74087352 0.98919886 0.56061435 0.00505367\n",
      " 0.7992655  0.97919923 0.28561077 0.14911552 0.63085479 0.2526702\n",
      " 0.1994203  0.14531121 0.10214092 0.08866343 0.073035   0.17368962\n",
      " 0.85001701 0.91792208 0.60273355 0.95194542 0.99804026 0.99445784\n",
      " 0.52066237 0.99991429 0.99832743 0.93985921 0.7420938  0.54424787\n",
      " 0.99640673 0.99507385 0.59758681 0.01672241 0.03821968 0.21175444\n",
      " 0.38340932 0.99928892 0.4870736  0.7212199  0.13659318 0.21071117\n",
      " 0.07565692 0.95590627 0.86081952 0.11447869 0.99891198 0.95044464\n",
      " 0.99994814 0.99322504 0.99969316 0.02674814 0.39440873 0.86593503\n",
      " 0.39122501 0.31715977 0.97493809 0.95989722 0.67836279 0.34077814\n",
      " 0.9980306  0.93889666 0.99162322 0.99314123 0.99367011 0.99975008\n",
      " 0.99997473 0.99978656 0.99999535 0.87984151 0.97267318 0.93995744\n",
      " 0.99940383 0.98285002 0.99875116 0.99691379 0.99955493 0.99843973\n",
      " 0.99870729 0.99998224 0.99979502 0.99362141 0.99975103 0.99653959\n",
      " 0.88824123 0.98574531 0.9877401  0.9749186  0.91252542 0.99026239\n",
      " 0.99876404 0.90740794 0.97417206 0.99999976 0.99998116 0.99999118\n",
      " 0.51530892 0.95255208 0.95609826 0.98695081 0.15232067 0.9999336\n",
      " 0.09761032 0.99549085 0.99851888 0.98480922 0.99989712 0.16556418\n",
      " 0.01254021 0.89885998 0.22340709 0.68327832 0.96374798 0.88773316\n",
      " 0.58254069 0.58142567 0.97750187 0.99663132]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 117 [0/54 (0%)]\tTrain Loss: 0.025433\n",
      "Train Epoch: 117 [8/54 (15%)]\tTrain Loss: 0.013775\n",
      "Train Epoch: 117 [16/54 (30%)]\tTrain Loss: 0.094532\n",
      "Train Epoch: 117 [24/54 (44%)]\tTrain Loss: 0.074831\n",
      "Train Epoch: 117 [32/54 (59%)]\tTrain Loss: 0.008852\n",
      "Train Epoch: 117 [40/54 (74%)]\tTrain Loss: 0.042787\n",
      "Train Epoch: 117 [48/54 (89%)]\tTrain Loss: 0.054857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.10371983e-01 9.93461370e-01 9.83354270e-01 9.51136768e-01\n",
      " 1.53496847e-01 2.63010085e-01 9.34516609e-01 8.99099648e-01\n",
      " 4.43186730e-01 5.67081392e-01 3.19675535e-01 1.26444129e-02\n",
      " 3.04605756e-02 4.06480767e-02 7.73070827e-02 5.36612123e-02\n",
      " 4.89737280e-03 8.99718404e-02 2.87342281e-03 1.08506335e-02\n",
      " 2.52604112e-02 7.41978765e-01 9.45615053e-01 7.80757368e-01\n",
      " 1.12857215e-01 9.87022221e-01 8.61027420e-01 4.95102435e-01\n",
      " 1.23994604e-01 3.56932521e-01 9.28853214e-01 9.84917939e-01\n",
      " 9.63398874e-01 4.96909313e-04 1.51426706e-03 1.65617187e-03\n",
      " 5.08282334e-03 9.45687532e-01 1.67722642e-01 4.39106673e-01\n",
      " 1.09190255e-01 9.38595235e-02 2.69868132e-02 3.81675392e-01\n",
      " 3.20805997e-01 3.21219027e-01 9.99729574e-01 9.99705493e-01\n",
      " 9.99999523e-01 9.40192282e-01 9.99994993e-01 2.82631256e-03\n",
      " 3.36610489e-02 2.28378639e-01 1.41602932e-02 2.36893073e-02\n",
      " 8.30908000e-01 1.03758246e-01 4.33330327e-01 3.17202330e-01\n",
      " 9.71534073e-01 7.43944764e-01 9.70241249e-01 9.98663902e-01\n",
      " 9.70853925e-01 9.98099267e-01 9.99731600e-01 9.99383211e-01\n",
      " 9.99996662e-01 6.65808856e-01 9.86895204e-01 9.70783472e-01\n",
      " 9.97635603e-01 9.86509383e-01 9.95826662e-01 9.84079659e-01\n",
      " 9.99997854e-01 9.99991417e-01 9.99976397e-01 9.99973536e-01\n",
      " 9.99536395e-01 9.99256432e-01 9.99893069e-01 2.24951208e-01\n",
      " 8.57865989e-01 9.93602455e-01 9.98309016e-01 9.99400973e-01\n",
      " 3.36389512e-01 2.19112694e-01 9.87130105e-01 1.62653163e-01\n",
      " 1.09779567e-01 9.99490142e-01 9.87744391e-01 9.42132771e-01\n",
      " 8.23678356e-03 8.27808976e-01 5.06766200e-01 8.29923689e-01\n",
      " 2.11588398e-01 9.99913096e-01 1.46105736e-02 3.82318258e-01\n",
      " 7.57737994e-01 6.69498444e-01 9.98816252e-01 1.37631856e-02\n",
      " 1.27554045e-03 7.88300186e-02 8.13333597e-03 5.16632397e-04\n",
      " 9.48612094e-02 1.02140866e-01 6.99034035e-02 2.77036745e-02\n",
      " 7.59358108e-01 6.18385732e-01]\n",
      "predict [1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 118 [0/54 (0%)]\tTrain Loss: 0.090786\n",
      "Train Epoch: 118 [8/54 (15%)]\tTrain Loss: 0.019924\n",
      "Train Epoch: 118 [16/54 (30%)]\tTrain Loss: 0.169672\n",
      "Train Epoch: 118 [24/54 (44%)]\tTrain Loss: 0.020443\n",
      "Train Epoch: 118 [32/54 (59%)]\tTrain Loss: 0.016664\n",
      "Train Epoch: 118 [40/54 (74%)]\tTrain Loss: 0.013440\n",
      "Train Epoch: 118 [48/54 (89%)]\tTrain Loss: 0.005550\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.02442311 0.84413153 0.77227962 0.9962579  0.41230455 0.07145531\n",
      " 0.75423205 0.62406385 0.42586884 0.42207736 0.52500081 0.0518229\n",
      " 0.05496461 0.13049328 0.08695567 0.03370683 0.031606   0.1248527\n",
      " 0.0357479  0.2252741  0.3458418  0.97486091 0.99872893 0.99679428\n",
      " 0.62697518 0.99917042 0.99510336 0.80508846 0.4967441  0.72903985\n",
      " 0.28231591 0.94147635 0.29713497 0.00281414 0.00505193 0.00552127\n",
      " 0.01096812 0.88521564 0.23518571 0.42188504 0.04540382 0.09739203\n",
      " 0.01484987 0.90369523 0.3472867  0.01047819 0.91852444 0.38231823\n",
      " 0.99974388 0.98806119 0.99680811 0.00592567 0.05320417 0.54964435\n",
      " 0.09916951 0.11455871 0.90993893 0.07113678 0.41652122 0.08211733\n",
      " 0.98810172 0.93661594 0.94707423 0.984429   0.99460226 0.99196893\n",
      " 0.99963474 0.99986827 0.99995911 0.54602003 0.93156481 0.92693019\n",
      " 0.9698258  0.94531465 0.97878796 0.95541328 0.99880886 0.99774975\n",
      " 0.99955922 0.99990892 0.99847585 0.96935534 0.99984992 0.68368018\n",
      " 0.96578693 0.9264468  0.99916756 0.9972927  0.57488012 0.76076162\n",
      " 0.99506336 0.78014725 0.3981562  0.99995649 0.99948162 0.99543804\n",
      " 0.01322195 0.96899647 0.80694538 0.98251086 0.23733914 0.9975338\n",
      " 0.0495767  0.90880388 0.93390715 0.90392983 0.99941301 0.0441099\n",
      " 0.00975509 0.21935396 0.08612477 0.00368139 0.58243024 0.61741149\n",
      " 0.65293854 0.39461741 0.30515614 0.86671913]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      "Train Epoch: 119 [0/54 (0%)]\tTrain Loss: 0.023796\n",
      "Train Epoch: 119 [8/54 (15%)]\tTrain Loss: 0.030238\n",
      "Train Epoch: 119 [16/54 (30%)]\tTrain Loss: 0.019511\n",
      "Train Epoch: 119 [24/54 (44%)]\tTrain Loss: 0.009926\n",
      "Train Epoch: 119 [32/54 (59%)]\tTrain Loss: 0.083293\n",
      "Train Epoch: 119 [40/54 (74%)]\tTrain Loss: 0.019723\n",
      "Train Epoch: 119 [48/54 (89%)]\tTrain Loss: 0.027600\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.13148229 0.83633047 0.92090625 0.98720646 0.29188409 0.25682324\n",
      " 0.87020099 0.67136967 0.41488314 0.76861745 0.80729467 0.07850926\n",
      " 0.09318163 0.03763445 0.03202237 0.11991414 0.04780585 0.08292902\n",
      " 0.02748556 0.06414224 0.08271921 0.96397835 0.96889371 0.92050177\n",
      " 0.76228237 0.98931062 0.98187757 0.35160995 0.41820389 0.25018975\n",
      " 0.83219367 0.96995103 0.26647666 0.00201186 0.04840271 0.02817316\n",
      " 0.03056366 0.94446301 0.25024965 0.33472094 0.15067151 0.22905785\n",
      " 0.09065244 0.72080779 0.15558004 0.3327086  0.9835397  0.95041293\n",
      " 0.99983621 0.97895724 0.99857938 0.01408511 0.03441657 0.31331918\n",
      " 0.12226351 0.10244197 0.91958803 0.09693171 0.34975615 0.18793197\n",
      " 0.99857962 0.96303058 0.99504256 0.99878639 0.95592785 0.99453777\n",
      " 0.9994092  0.99780923 0.99997032 0.11625899 0.98648238 0.99115247\n",
      " 0.9985984  0.90086788 0.99539751 0.98724616 0.99884927 0.99898881\n",
      " 0.99982953 0.99991727 0.999569   0.9966799  0.99853766 0.60558754\n",
      " 0.96557969 0.99864751 0.99917006 0.99956125 0.1696797  0.7376852\n",
      " 0.91694868 0.93713015 0.74649441 0.99971598 0.94843835 0.92966455\n",
      " 0.02849268 0.90828454 0.69183087 0.94689584 0.25441611 0.99868017\n",
      " 0.0204712  0.83167535 0.93132883 0.87609279 0.9988324  0.37111738\n",
      " 0.05370678 0.75209206 0.04991253 0.04395362 0.60911477 0.78399014\n",
      " 0.07224239 0.14319053 0.515481   0.39802676]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 120 [0/54 (0%)]\tTrain Loss: 0.012042\n",
      "Train Epoch: 120 [8/54 (15%)]\tTrain Loss: 0.026821\n",
      "Train Epoch: 120 [16/54 (30%)]\tTrain Loss: 0.068139\n",
      "Train Epoch: 120 [24/54 (44%)]\tTrain Loss: 0.011594\n",
      "Train Epoch: 120 [32/54 (59%)]\tTrain Loss: 0.022919\n",
      "Train Epoch: 120 [40/54 (74%)]\tTrain Loss: 0.031363\n",
      "Train Epoch: 120 [48/54 (89%)]\tTrain Loss: 0.154791\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.00146604 0.49479714 0.39093608 0.87059695 0.31802446 0.01995048\n",
      " 0.70803064 0.09393944 0.11288863 0.08622953 0.3218503  0.00279718\n",
      " 0.02095387 0.00122763 0.00574961 0.03405431 0.00981013 0.03721842\n",
      " 0.10320583 0.14348736 0.15026961 0.7323789  0.83323449 0.83263946\n",
      " 0.16428766 0.98891056 0.93562645 0.19885406 0.27227879 0.27984589\n",
      " 0.51299912 0.90910143 0.0338729  0.0011913  0.00575416 0.00220334\n",
      " 0.00284433 0.84062749 0.0435611  0.09042533 0.01517116 0.00639173\n",
      " 0.03744035 0.20540448 0.04631363 0.43488708 0.62686056 0.08582705\n",
      " 0.99299228 0.86387694 0.96223986 0.00124969 0.0239506  0.05724225\n",
      " 0.12560478 0.02824572 0.87020057 0.07443249 0.02823769 0.0272152\n",
      " 0.97063792 0.82399642 0.97443885 0.99185669 0.81768489 0.96652323\n",
      " 0.98433429 0.96499276 0.99953091 0.64043683 0.85290354 0.87224758\n",
      " 0.99780387 0.936656   0.96762073 0.66169304 0.9575749  0.9358868\n",
      " 0.93354183 0.99973685 0.99770504 0.99241465 0.99395823 0.25411189\n",
      " 0.5347997  0.99936944 0.9547137  0.96355116 0.35370347 0.60147715\n",
      " 0.98895603 0.42482066 0.42328304 0.99987853 0.99732023 0.98923767\n",
      " 0.0295835  0.82483852 0.63121164 0.97704077 0.10534365 0.99004316\n",
      " 0.01067607 0.83957618 0.96125996 0.866629   0.99863029 0.01606178\n",
      " 0.0134559  0.47940725 0.01362778 0.01561605 0.74035311 0.82841974\n",
      " 0.30179709 0.06475861 0.57188749 0.20660536]\n",
      "predict [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 43 FN= 13 FP= 17\n",
      "TP+FP 62\n",
      "precision 0.7258064516129032\n",
      "recall 0.7758620689655172\n",
      "F1 0.7500000000000001\n",
      "acc 0.7457627118644068\n",
      "AUCp 0.746264367816092\n",
      "AUC 0.7689655172413794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 120, average recall: 0.7759, average precision: 0.7258,average F1: 0.7500, average accuracy: 0.7458, average AUC: 0.7690\n",
      "Train Epoch: 121 [0/54 (0%)]\tTrain Loss: 0.022113\n",
      "Train Epoch: 121 [8/54 (15%)]\tTrain Loss: 0.054791\n",
      "Train Epoch: 121 [16/54 (30%)]\tTrain Loss: 0.054090\n",
      "Train Epoch: 121 [24/54 (44%)]\tTrain Loss: 0.019998\n",
      "Train Epoch: 121 [32/54 (59%)]\tTrain Loss: 0.020060\n",
      "Train Epoch: 121 [40/54 (74%)]\tTrain Loss: 0.049466\n",
      "Train Epoch: 121 [48/54 (89%)]\tTrain Loss: 0.026876\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.02348374 0.94979882 0.41329417 0.67567903 0.19212241 0.07074875\n",
      " 0.96339947 0.12814957 0.55110931 0.5919891  0.49397993 0.33436498\n",
      " 0.03650539 0.04813889 0.02245937 0.0249546  0.01864011 0.22291484\n",
      " 0.02634383 0.0804085  0.12465364 0.9409377  0.99829358 0.9782905\n",
      " 0.30602282 0.99989486 0.99691284 0.73616898 0.66204971 0.87250102\n",
      " 0.60065401 0.77400565 0.32055494 0.00364475 0.00427387 0.00279835\n",
      " 0.00255075 0.8161934  0.0459009  0.10452169 0.01745845 0.02484686\n",
      " 0.02154175 0.22243372 0.01697294 0.01466075 0.61495447 0.07180186\n",
      " 0.99569356 0.77751684 0.86130387 0.00156697 0.09053945 0.74206811\n",
      " 0.4015545  0.04571516 0.99830121 0.11829464 0.74954706 0.01400222\n",
      " 0.99008757 0.92708498 0.96418756 0.96158576 0.78859991 0.95111209\n",
      " 0.98742735 0.99962997 0.99997079 0.49442428 0.76555663 0.82198209\n",
      " 0.99701798 0.87442279 0.97294497 0.62447578 0.96307546 0.97371364\n",
      " 0.63782221 0.99783641 0.99465275 0.95111865 0.9899323  0.93522131\n",
      " 0.75067478 0.9856813  0.96055913 0.97508198 0.70141333 0.99115503\n",
      " 0.99979991 0.16596006 0.38224038 0.99999952 0.99469334 0.99918348\n",
      " 0.08428138 0.61367327 0.7332623  0.94938529 0.09807543 0.9791975\n",
      " 0.03499405 0.9590202  0.96483362 0.70615411 0.99946994 0.03115755\n",
      " 0.07711168 0.78301799 0.19805095 0.29243809 0.51617801 0.4784272\n",
      " 0.4390288  0.21170412 0.74226981 0.97681022]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 122 [0/54 (0%)]\tTrain Loss: 0.018243\n",
      "Train Epoch: 122 [8/54 (15%)]\tTrain Loss: 0.034679\n",
      "Train Epoch: 122 [16/54 (30%)]\tTrain Loss: 0.005549\n",
      "Train Epoch: 122 [24/54 (44%)]\tTrain Loss: 0.027927\n",
      "Train Epoch: 122 [32/54 (59%)]\tTrain Loss: 0.033757\n",
      "Train Epoch: 122 [40/54 (74%)]\tTrain Loss: 0.009185\n",
      "Train Epoch: 122 [48/54 (89%)]\tTrain Loss: 0.012172\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.54798639e-01 9.99711454e-01 9.65681553e-01 9.93742764e-01\n",
      " 8.59453857e-01 7.25334227e-01 9.99269664e-01 5.87360859e-01\n",
      " 7.61533380e-01 9.67372358e-01 2.79602468e-01 1.09558783e-01\n",
      " 1.14540001e-02 1.47817895e-01 1.02892473e-01 3.77130024e-02\n",
      " 1.17210322e-03 1.55934989e-01 1.59529284e-01 1.71276666e-02\n",
      " 1.87679783e-01 8.78773987e-01 9.99328613e-01 9.78165925e-01\n",
      " 5.23706317e-01 9.99679685e-01 9.44215536e-01 3.25960875e-01\n",
      " 7.73259878e-01 5.60870409e-01 3.70249540e-01 9.95370924e-01\n",
      " 8.83264840e-01 2.12977733e-03 8.98051728e-03 4.03902903e-02\n",
      " 8.44363496e-02 9.22692716e-01 1.72711313e-01 7.90413097e-02\n",
      " 3.58940512e-02 1.99123193e-02 2.42323615e-02 6.83780015e-01\n",
      " 3.37095633e-02 7.35888183e-01 9.99900103e-01 9.99917984e-01\n",
      " 9.99997377e-01 9.73360538e-01 9.99963164e-01 3.34727578e-04\n",
      " 1.86571886e-03 2.66099244e-01 1.98835343e-01 3.30778733e-02\n",
      " 8.70847762e-01 5.60232066e-02 3.56923163e-01 1.25916228e-02\n",
      " 9.75665927e-01 9.17546391e-01 9.86429214e-01 9.99149919e-01\n",
      " 9.74734366e-01 9.88231122e-01 9.99644041e-01 9.99156117e-01\n",
      " 9.99997258e-01 6.98670924e-01 9.96740639e-01 9.97520030e-01\n",
      " 9.98559773e-01 9.86870706e-01 9.73560512e-01 9.70953822e-01\n",
      " 9.99999881e-01 1.00000000e+00 9.99998569e-01 9.99997973e-01\n",
      " 9.99998808e-01 9.99470174e-01 9.99982119e-01 4.47258443e-01\n",
      " 9.69838023e-01 9.90776598e-01 9.99319553e-01 9.99583662e-01\n",
      " 8.28185260e-01 9.51080799e-01 9.92389023e-01 6.98315561e-01\n",
      " 4.89237636e-01 9.99997258e-01 9.98759270e-01 9.98930156e-01\n",
      " 2.11664140e-02 8.08239222e-01 9.33867037e-01 9.99229908e-01\n",
      " 1.57675922e-01 9.99240398e-01 1.10271135e-02 9.87754643e-01\n",
      " 9.98070538e-01 9.94077802e-01 9.99989867e-01 6.85238615e-02\n",
      " 1.38220266e-02 7.04547346e-01 3.87253165e-02 3.07845380e-02\n",
      " 9.25131917e-01 8.02584052e-01 6.90318525e-01 6.01265967e-01\n",
      " 8.96122396e-01 9.01256502e-01]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 123 [0/54 (0%)]\tTrain Loss: 0.027721\n",
      "Train Epoch: 123 [8/54 (15%)]\tTrain Loss: 0.073020\n",
      "Train Epoch: 123 [16/54 (30%)]\tTrain Loss: 0.043512\n",
      "Train Epoch: 123 [24/54 (44%)]\tTrain Loss: 0.002036\n",
      "Train Epoch: 123 [32/54 (59%)]\tTrain Loss: 0.054435\n",
      "Train Epoch: 123 [40/54 (74%)]\tTrain Loss: 0.037841\n",
      "Train Epoch: 123 [48/54 (89%)]\tTrain Loss: 0.010395\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.95120335 0.99916697 0.98786283 0.99986136 0.97905684 0.77406037\n",
      " 0.99730718 0.9993819  0.71744961 0.24912585 0.50796896 0.03351716\n",
      " 0.30895239 0.75819796 0.94990754 0.65472054 0.38735455 0.27028263\n",
      " 0.04107138 0.25743231 0.03564185 0.80553651 0.99555051 0.96562248\n",
      " 0.43439284 0.99831897 0.99676692 0.48908252 0.82557434 0.93462086\n",
      " 0.93441051 0.99368697 0.97676098 0.02033231 0.03559069 0.05008458\n",
      " 0.11784735 0.94634354 0.22572361 0.4964622  0.18678099 0.0447703\n",
      " 0.58444262 0.98682624 0.61739373 0.88200313 0.9996568  0.99956423\n",
      " 0.99999988 0.99326199 0.99996543 0.01655599 0.11930428 0.98530585\n",
      " 0.01432357 0.29127431 0.99524975 0.14705899 0.16607672 0.6365962\n",
      " 0.99922073 0.94620234 0.99738616 0.99897939 0.99965858 0.99985003\n",
      " 0.99999583 0.99977452 0.99998152 0.62793261 0.97608745 0.9836458\n",
      " 0.99883002 0.99007809 0.98168015 0.99937373 0.99999785 0.99999523\n",
      " 0.99999678 0.9999938  0.99998379 0.99929118 0.9999336  0.99959892\n",
      " 0.98977697 0.99692458 0.99924445 0.99938202 0.12107782 0.86528307\n",
      " 0.99365693 0.96559364 0.95335352 0.99994671 0.98177254 0.96010101\n",
      " 0.0098441  0.90228617 0.65366405 0.98613399 0.0798464  0.9998982\n",
      " 0.20757359 0.98498869 0.9881478  0.92937475 0.99998629 0.10843372\n",
      " 0.00890748 0.43295398 0.20522857 0.02877612 0.73632079 0.18165047\n",
      " 0.56207484 0.23204441 0.72418219 0.99270624]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
      "Train Epoch: 124 [0/54 (0%)]\tTrain Loss: 0.032552\n",
      "Train Epoch: 124 [8/54 (15%)]\tTrain Loss: 0.014496\n",
      "Train Epoch: 124 [16/54 (30%)]\tTrain Loss: 0.016018\n",
      "Train Epoch: 124 [24/54 (44%)]\tTrain Loss: 0.006588\n",
      "Train Epoch: 124 [32/54 (59%)]\tTrain Loss: 0.005566\n",
      "Train Epoch: 124 [40/54 (74%)]\tTrain Loss: 0.026601\n",
      "Train Epoch: 124 [48/54 (89%)]\tTrain Loss: 0.021680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.45569553e-03 3.02166522e-01 5.79462899e-03 1.47334740e-01\n",
      " 1.14451041e-02 1.87050924e-02 2.56333441e-01 3.98520846e-03\n",
      " 9.83795300e-02 3.09036337e-02 5.80572546e-01 2.48623034e-03\n",
      " 3.34545760e-03 1.29473291e-03 2.71494640e-03 3.39949806e-03\n",
      " 1.73323497e-03 1.06091034e-02 3.83552521e-01 1.10083111e-01\n",
      " 9.00148004e-02 2.59402454e-01 9.64852929e-01 1.00000000e+00\n",
      " 2.43227766e-03 9.99401689e-01 1.00000000e+00 1.66039839e-01\n",
      " 3.90895694e-01 1.00854918e-01 1.70633927e-01 6.19005144e-01\n",
      " 4.48606722e-02 2.16980628e-03 7.40468968e-04 2.56602361e-05\n",
      " 4.24953265e-04 7.12162852e-02 7.92618189e-03 2.45273975e-03\n",
      " 3.11702752e-04 2.47806340e-04 5.50502446e-04 1.49762779e-02\n",
      " 5.88351674e-03 3.17673292e-03 1.31846234e-01 1.40933190e-02\n",
      " 9.99999762e-01 8.77984107e-01 9.86962974e-01 5.87340328e-04\n",
      " 2.53777974e-03 7.29825441e-03 2.22034320e-01 1.70159005e-02\n",
      " 8.96366298e-01 7.52583053e-03 1.47448480e-03 3.60787351e-04\n",
      " 9.90000844e-01 8.82915616e-01 8.39795470e-01 9.80642855e-01\n",
      " 1.56183466e-01 6.65259600e-01 9.75774586e-01 7.52083123e-01\n",
      " 9.88057017e-01 5.46380281e-01 8.48731399e-01 9.22623575e-01\n",
      " 9.64000940e-01 6.15263879e-01 4.14356321e-01 7.87776038e-02\n",
      " 8.66875172e-01 9.03467119e-01 4.78959709e-01 9.87343431e-01\n",
      " 8.77835631e-01 7.82053292e-01 9.99578178e-01 3.94802690e-02\n",
      " 1.38549253e-01 9.99927282e-01 9.99723852e-01 9.99997139e-01\n",
      " 6.04665577e-01 6.03196263e-01 1.00000000e+00 6.59571141e-02\n",
      " 2.43495312e-02 1.00000000e+00 9.99146819e-01 9.34705734e-01\n",
      " 1.10223675e-02 1.70223862e-02 4.40919399e-01 9.97366369e-01\n",
      " 1.76510531e-02 9.98660445e-01 9.04264208e-03 9.44231153e-01\n",
      " 9.58662987e-01 8.02342296e-01 1.00000000e+00 6.62313483e-04\n",
      " 5.47141477e-04 5.14571331e-02 4.29336587e-03 1.19245728e-03\n",
      " 1.74726620e-01 7.49044120e-01 7.36074746e-02 2.71311146e-03\n",
      " 7.21128359e-02 7.54605353e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "Train Epoch: 125 [0/54 (0%)]\tTrain Loss: 0.063964\n",
      "Train Epoch: 125 [8/54 (15%)]\tTrain Loss: 0.096720\n",
      "Train Epoch: 125 [16/54 (30%)]\tTrain Loss: 0.035364\n",
      "Train Epoch: 125 [24/54 (44%)]\tTrain Loss: 0.011453\n",
      "Train Epoch: 125 [32/54 (59%)]\tTrain Loss: 0.022407\n",
      "Train Epoch: 125 [40/54 (74%)]\tTrain Loss: 0.006345\n",
      "Train Epoch: 125 [48/54 (89%)]\tTrain Loss: 0.013839\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.42637388e-04 1.08178616e-01 1.17446736e-01 2.59262055e-01\n",
      " 1.29917054e-04 3.33477714e-04 1.01513505e-01 9.85994702e-04\n",
      " 4.34149290e-03 1.21457856e-02 7.64643494e-03 1.25155093e-05\n",
      " 1.97752728e-03 1.27087143e-04 1.32993923e-03 7.33857960e-05\n",
      " 1.24327262e-05 8.12729541e-03 1.07468860e-02 4.70615551e-02\n",
      " 1.63327873e-01 1.26126826e-01 5.78795969e-01 9.99997854e-01\n",
      " 6.73226826e-03 9.73321319e-01 1.00000000e+00 6.65106595e-01\n",
      " 2.20070705e-02 2.14803335e-03 4.24562544e-01 9.23003376e-01\n",
      " 8.37557316e-02 1.84983932e-04 2.29822923e-04 1.03115883e-04\n",
      " 1.81805156e-02 7.61969462e-02 8.15259200e-03 5.26541248e-02\n",
      " 1.20308492e-02 6.93087513e-03 4.87188203e-03 2.18249415e-03\n",
      " 2.37406100e-04 2.39090688e-04 4.02779669e-01 3.76064330e-02\n",
      " 9.99932170e-01 1.00000000e+00 9.99782503e-01 2.89640667e-07\n",
      " 1.32826201e-04 1.17172580e-03 9.99905109e-01 9.91667854e-04\n",
      " 7.03824878e-01 4.69460472e-04 1.11574751e-04 2.23518218e-04\n",
      " 9.99316454e-01 8.61773133e-01 9.61511731e-01 9.96602297e-01\n",
      " 2.81222105e-01 4.58896697e-01 9.66917276e-01 9.81149793e-01\n",
      " 9.99794185e-01 4.52016443e-02 8.23849916e-01 4.27322745e-01\n",
      " 9.93382454e-01 9.65237617e-01 9.66442645e-01 5.53066313e-01\n",
      " 9.74540949e-01 9.71027553e-01 5.65813780e-01 9.93316770e-01\n",
      " 9.64846194e-01 7.44129181e-01 9.98874366e-01 3.06349427e-01\n",
      " 1.22810207e-01 9.99999642e-01 1.00000000e+00 1.00000000e+00\n",
      " 7.05872774e-02 1.88445553e-01 1.00000000e+00 2.22891476e-02\n",
      " 4.71860282e-02 9.99936342e-01 9.81628239e-01 9.00025547e-01\n",
      " 4.32236586e-04 9.51750576e-01 8.72703433e-01 9.70695853e-01\n",
      " 5.07090569e-01 9.93431985e-01 4.23014909e-03 2.52776861e-01\n",
      " 7.80084550e-01 4.80199724e-01 1.00000000e+00 1.23117985e-02\n",
      " 1.26138458e-03 2.62666732e-01 3.13019310e-03 2.52511445e-02\n",
      " 4.74322230e-01 2.41147075e-02 3.85515541e-02 2.31350446e-03\n",
      " 9.87582445e-01 6.22832775e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 126 [0/54 (0%)]\tTrain Loss: 0.009026\n",
      "Train Epoch: 126 [8/54 (15%)]\tTrain Loss: 0.034218\n",
      "Train Epoch: 126 [16/54 (30%)]\tTrain Loss: 0.045531\n",
      "Train Epoch: 126 [24/54 (44%)]\tTrain Loss: 0.008397\n",
      "Train Epoch: 126 [32/54 (59%)]\tTrain Loss: 0.035038\n",
      "Train Epoch: 126 [40/54 (74%)]\tTrain Loss: 0.004492\n",
      "Train Epoch: 126 [48/54 (89%)]\tTrain Loss: 0.005805\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.14001524e-01 9.96146441e-01 9.76383209e-01 9.99269545e-01\n",
      " 9.27236259e-01 5.49918413e-01 9.70096886e-01 9.85127509e-01\n",
      " 1.27289727e-01 1.70349982e-02 9.75296497e-01 3.77808861e-03\n",
      " 2.14819506e-01 4.12241876e-01 7.65460968e-01 2.53958069e-02\n",
      " 5.31328656e-02 3.48407440e-02 6.77263379e-01 2.97961920e-01\n",
      " 6.15755081e-01 9.99952912e-01 9.97616768e-01 9.82106209e-01\n",
      " 7.91072607e-01 9.99803126e-01 9.99998331e-01 9.93530214e-01\n",
      " 9.21725512e-01 6.47216976e-01 9.81292367e-01 9.99534965e-01\n",
      " 9.92111087e-01 8.52397550e-03 6.28433190e-03 7.37117752e-02\n",
      " 2.44089454e-01 1.00000000e+00 5.81127882e-01 1.59107164e-01\n",
      " 1.73688412e-01 2.01794803e-01 1.34260267e-01 9.97934699e-01\n",
      " 7.09035814e-01 9.31184709e-01 9.99986410e-01 9.99961019e-01\n",
      " 1.00000000e+00 9.98854160e-01 9.99999881e-01 1.05681400e-04\n",
      " 1.69434831e-01 7.43314505e-01 6.19274735e-01 1.58264413e-01\n",
      " 9.96738255e-01 1.68733418e-01 5.19036986e-02 5.61591089e-02\n",
      " 9.99971509e-01 9.99210358e-01 9.99924660e-01 9.99985933e-01\n",
      " 9.99818504e-01 9.99999881e-01 1.00000000e+00 9.99995947e-01\n",
      " 1.00000000e+00 9.21807349e-01 9.99676824e-01 9.99551356e-01\n",
      " 9.99893904e-01 9.99673247e-01 9.97790933e-01 9.99995708e-01\n",
      " 1.00000000e+00 9.99999762e-01 9.99999404e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99965072e-01 9.99995351e-01 9.69612479e-01\n",
      " 9.91236925e-01 9.99619961e-01 9.99947190e-01 9.99976397e-01\n",
      " 3.46635222e-01 9.67975438e-01 9.99997616e-01 9.51010406e-01\n",
      " 9.54809427e-01 9.99984026e-01 9.98926103e-01 9.92187738e-01\n",
      " 1.10015869e-01 1.00000000e+00 9.93674397e-01 9.99511957e-01\n",
      " 9.50521708e-01 1.00000000e+00 4.32920575e-01 9.99655366e-01\n",
      " 9.99931097e-01 9.97380555e-01 9.99998689e-01 1.09178700e-01\n",
      " 1.20125562e-02 6.79445207e-01 4.10402194e-03 3.28350849e-02\n",
      " 5.85485578e-01 3.95830870e-01 7.05195844e-01 7.47392952e-01\n",
      " 9.99999762e-01 9.99468267e-01]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 127 [0/54 (0%)]\tTrain Loss: 0.004845\n",
      "Train Epoch: 127 [8/54 (15%)]\tTrain Loss: 0.006695\n",
      "Train Epoch: 127 [16/54 (30%)]\tTrain Loss: 0.023754\n",
      "Train Epoch: 127 [24/54 (44%)]\tTrain Loss: 0.030365\n",
      "Train Epoch: 127 [32/54 (59%)]\tTrain Loss: 0.034167\n",
      "Train Epoch: 127 [40/54 (74%)]\tTrain Loss: 0.041814\n",
      "Train Epoch: 127 [48/54 (89%)]\tTrain Loss: 0.013793\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.24781719e-02 4.84005272e-01 1.04246430e-01 9.00954187e-01\n",
      " 2.23012671e-01 1.80183947e-02 2.88711578e-01 8.18243772e-02\n",
      " 1.37851074e-01 1.54816508e-01 9.42073822e-01 2.85363309e-02\n",
      " 1.44433662e-01 5.22167422e-02 2.82485336e-01 3.19016241e-02\n",
      " 7.12285237e-03 4.61388528e-02 2.54700959e-01 1.68648258e-01\n",
      " 9.05494168e-02 9.10394728e-01 8.52756798e-01 9.63040531e-01\n",
      " 1.80005625e-01 9.81379271e-01 9.84681010e-01 4.61837053e-01\n",
      " 3.86337012e-01 6.64866209e-01 8.19242299e-02 9.04243469e-01\n",
      " 7.02284098e-01 3.20027419e-03 3.37231462e-03 2.79024709e-03\n",
      " 7.50972107e-02 8.90066504e-01 3.12054027e-02 1.62867159e-01\n",
      " 5.39904609e-02 5.40978201e-02 3.07722930e-02 7.47184038e-01\n",
      " 1.39735311e-01 1.44820111e-02 8.67021322e-01 5.88032663e-01\n",
      " 9.99807298e-01 9.72477555e-01 9.96794760e-01 4.30822052e-04\n",
      " 4.36361460e-03 2.09672078e-02 1.23908632e-01 3.18845361e-02\n",
      " 8.66019785e-01 3.17559913e-02 2.77641654e-01 1.82867143e-03\n",
      " 9.47655678e-01 8.72449160e-01 9.08387780e-01 9.84910190e-01\n",
      " 2.55220592e-01 9.92464304e-01 9.95720446e-01 9.94485557e-01\n",
      " 9.99940395e-01 1.11886494e-01 8.69746447e-01 6.12666249e-01\n",
      " 9.74340260e-01 9.44068670e-01 7.02662289e-01 9.39285755e-01\n",
      " 9.92422044e-01 9.73220170e-01 9.41359103e-01 9.99736249e-01\n",
      " 9.85918522e-01 9.11794305e-01 9.91246879e-01 8.96192789e-01\n",
      " 8.75604510e-01 9.89835203e-01 9.90792811e-01 9.94231582e-01\n",
      " 5.44738591e-01 8.20983768e-01 9.97916758e-01 6.08212411e-01\n",
      " 2.65837789e-01 9.99663591e-01 9.72098231e-01 9.83055234e-01\n",
      " 2.35668514e-02 8.49195004e-01 8.95107388e-01 9.59320486e-01\n",
      " 6.01557195e-01 9.98436511e-01 2.47241870e-01 7.66513765e-01\n",
      " 8.37928951e-01 5.98933518e-01 9.71554875e-01 3.73395413e-01\n",
      " 1.22062182e-02 5.80677748e-01 8.67121071e-02 1.38544198e-02\n",
      " 3.96322340e-01 9.03719366e-01 4.83038664e-01 1.73825622e-01\n",
      " 6.55185878e-01 3.55997533e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 128 [0/54 (0%)]\tTrain Loss: 0.041287\n",
      "Train Epoch: 128 [8/54 (15%)]\tTrain Loss: 0.089717\n",
      "Train Epoch: 128 [16/54 (30%)]\tTrain Loss: 0.008899\n",
      "Train Epoch: 128 [24/54 (44%)]\tTrain Loss: 0.012699\n",
      "Train Epoch: 128 [32/54 (59%)]\tTrain Loss: 0.008905\n",
      "Train Epoch: 128 [40/54 (74%)]\tTrain Loss: 0.051267\n",
      "Train Epoch: 128 [48/54 (89%)]\tTrain Loss: 0.005659\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.68849766 0.99795985 0.99934095 0.99940896 0.99800795 0.82665217\n",
      " 0.99901617 0.99961543 0.37526727 0.39642715 0.87072474 0.09953596\n",
      " 0.73591655 0.99902701 0.98817098 0.98867488 0.99917454 0.32972547\n",
      " 0.92810529 0.23240773 0.09278553 0.97564858 0.99661225 0.98966986\n",
      " 0.87223297 0.99956948 0.99968064 0.97978115 0.95335621 0.91206217\n",
      " 0.82287377 0.99787736 0.93784207 0.08464929 0.07428368 0.73423463\n",
      " 0.94945484 0.98872942 0.27678815 0.63569033 0.21280479 0.19773117\n",
      " 0.15157557 0.99456406 0.94024527 0.30516738 0.99436778 0.98810005\n",
      " 0.99999857 0.99140173 0.99997997 0.78385913 0.30164284 0.79907686\n",
      " 0.21995892 0.83702219 0.98653805 0.88318187 0.60516381 0.92391431\n",
      " 0.99932885 0.98368293 0.99642342 0.99970311 0.99584997 0.99999976\n",
      " 1.         0.99995196 1.         0.99506444 0.98648483 0.98314559\n",
      " 0.99969256 0.99924386 0.92760885 0.99926168 0.99999905 0.99998593\n",
      " 0.99999607 0.99999976 0.99998271 0.99981123 0.99996603 0.90161717\n",
      " 0.95941043 0.99753809 0.99593449 0.9988845  0.98588723 0.99998987\n",
      " 0.99977201 0.99857485 0.97173923 0.99999356 0.99788338 0.99866056\n",
      " 0.21007942 0.99758089 0.99194288 0.99909973 0.52084845 0.99999762\n",
      " 0.90449923 0.99395174 0.9981395  0.98782992 0.99997795 0.71702528\n",
      " 0.06060524 0.87628555 0.64516252 0.27683729 0.99986231 0.99801862\n",
      " 0.95711398 0.10769209 0.93645883 0.97835177]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 129 [0/54 (0%)]\tTrain Loss: 0.034085\n",
      "Train Epoch: 129 [8/54 (15%)]\tTrain Loss: 0.005630\n",
      "Train Epoch: 129 [16/54 (30%)]\tTrain Loss: 0.006068\n",
      "Train Epoch: 129 [24/54 (44%)]\tTrain Loss: 0.009147\n",
      "Train Epoch: 129 [32/54 (59%)]\tTrain Loss: 0.050362\n",
      "Train Epoch: 129 [40/54 (74%)]\tTrain Loss: 0.012476\n",
      "Train Epoch: 129 [48/54 (89%)]\tTrain Loss: 0.040308\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.98801892e-04 1.00000000e+00 9.99964237e-01 5.05593792e-02\n",
      " 6.59397477e-03 5.18277346e-04 9.99980330e-01 1.05926841e-02\n",
      " 1.46041792e-02 1.09198596e-02 7.70429432e-01 1.12303905e-03\n",
      " 4.20522578e-02 1.56200712e-03 3.60920746e-03 1.14790897e-03\n",
      " 1.16780950e-02 1.55554451e-02 5.07261574e-01 4.55428325e-02\n",
      " 7.81901740e-03 1.62346035e-01 9.59297121e-01 8.12263191e-01\n",
      " 1.55385556e-02 9.98771846e-01 8.53878915e-01 2.83972919e-01\n",
      " 2.72317588e-01 2.89526097e-02 9.49824303e-02 8.27829778e-01\n",
      " 9.58859921e-01 4.07751417e-03 1.66506751e-03 1.01748016e-03\n",
      " 3.12607698e-02 6.45334840e-01 9.59443301e-03 4.53205034e-02\n",
      " 2.72256806e-02 1.89952459e-02 5.12797502e-04 1.52566629e-02\n",
      " 3.91839817e-02 5.08885086e-03 6.53392851e-01 2.45267004e-01\n",
      " 9.97941554e-01 4.78541404e-01 7.72676647e-01 1.63517543e-04\n",
      " 2.06106510e-02 7.98982382e-03 5.17442264e-03 2.12303782e-03\n",
      " 9.24658477e-01 9.81733762e-03 1.73119511e-02 3.03828856e-03\n",
      " 9.36257839e-01 3.10059816e-01 6.55603349e-01 9.11540270e-01\n",
      " 1.14608392e-01 3.04579735e-01 5.04747212e-01 9.49648082e-01\n",
      " 9.99989271e-01 1.70888733e-02 4.34102893e-01 4.12236005e-01\n",
      " 9.16470826e-01 4.78062510e-01 3.22582960e-01 8.35007250e-01\n",
      " 1.00000000e+00 1.00000000e+00 5.72115421e-01 9.87155080e-01\n",
      " 9.15733933e-01 7.12984204e-01 8.79509330e-01 6.50134325e-01\n",
      " 7.77092934e-01 8.70263278e-01 6.79480076e-01 7.92029440e-01\n",
      " 1.41926751e-01 1.31996140e-01 9.67509031e-01 2.88532108e-01\n",
      " 1.48861662e-01 9.99874353e-01 9.94052589e-01 9.82262135e-01\n",
      " 3.94797698e-03 3.98048222e-01 5.78298509e-01 9.25147772e-01\n",
      " 3.01180154e-01 9.85440671e-01 3.93464677e-02 9.38528895e-01\n",
      " 8.77541065e-01 3.05334538e-01 9.98088181e-01 9.43895616e-03\n",
      " 5.05009433e-04 9.85550880e-02 1.87162869e-02 7.55200104e-04\n",
      " 2.06164092e-01 2.18330756e-01 3.30179138e-03 5.45570918e-04\n",
      " 9.42881584e-01 7.49277472e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 130 [0/54 (0%)]\tTrain Loss: 0.062252\n",
      "Train Epoch: 130 [8/54 (15%)]\tTrain Loss: 0.016020\n",
      "Train Epoch: 130 [16/54 (30%)]\tTrain Loss: 0.019179\n",
      "Train Epoch: 130 [24/54 (44%)]\tTrain Loss: 0.019839\n",
      "Train Epoch: 130 [32/54 (59%)]\tTrain Loss: 0.045326\n",
      "Train Epoch: 130 [40/54 (74%)]\tTrain Loss: 0.010052\n",
      "Train Epoch: 130 [48/54 (89%)]\tTrain Loss: 0.055644\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.70001674e-01 9.88896847e-01 9.89936113e-01 7.74272025e-01\n",
      " 4.35158968e-01 1.94179043e-01 9.70634282e-01 8.59373808e-01\n",
      " 2.65956044e-01 2.55965739e-02 7.90732741e-01 8.46578565e-04\n",
      " 5.90831712e-02 2.87277773e-02 3.89710933e-01 3.31904413e-03\n",
      " 2.77177594e-03 2.15164982e-02 6.27222955e-01 6.40128851e-02\n",
      " 4.17160876e-02 9.57132101e-01 9.95424449e-01 9.83325958e-01\n",
      " 2.55244642e-01 9.99580204e-01 9.79399562e-01 8.65454376e-01\n",
      " 8.86913300e-01 2.94500500e-01 9.55470860e-01 9.93965685e-01\n",
      " 7.49637187e-01 6.48953486e-04 1.20125704e-04 2.32467940e-03\n",
      " 1.12004288e-01 9.72881317e-01 4.82519111e-03 1.10059522e-01\n",
      " 2.46008076e-02 6.24900870e-02 1.06601659e-02 5.05837083e-01\n",
      " 6.34764075e-01 4.02020037e-01 9.99796569e-01 9.92564499e-01\n",
      " 9.99998093e-01 9.29270029e-01 9.99780715e-01 1.47316419e-03\n",
      " 1.04183238e-02 2.96286810e-02 1.01049012e-02 2.02157889e-02\n",
      " 8.90406609e-01 9.74351764e-02 2.83752590e-01 7.67658278e-03\n",
      " 9.92319643e-01 7.08907485e-01 9.83002603e-01 9.98336554e-01\n",
      " 9.78027940e-01 9.97220159e-01 9.98669744e-01 9.98800278e-01\n",
      " 9.99991655e-01 1.55146539e-01 9.87869442e-01 9.85181332e-01\n",
      " 9.96729851e-01 9.42974865e-01 9.87924933e-01 9.85457778e-01\n",
      " 9.99999404e-01 9.99986649e-01 9.99968886e-01 9.99977827e-01\n",
      " 9.99711573e-01 9.99552190e-01 9.99751270e-01 4.46621925e-01\n",
      " 9.60597873e-01 9.89575744e-01 9.97297585e-01 9.93404448e-01\n",
      " 5.31049073e-01 8.22281539e-01 9.91329074e-01 4.60637361e-01\n",
      " 4.42954414e-02 9.99983788e-01 9.94956315e-01 9.97887075e-01\n",
      " 1.29260868e-01 1.96252719e-01 5.79056561e-01 9.86730099e-01\n",
      " 4.76909764e-02 9.99749124e-01 2.71882080e-02 9.46491778e-01\n",
      " 9.90866661e-01 8.91872168e-01 9.99586523e-01 2.57210489e-02\n",
      " 1.03227940e-04 3.59464675e-01 5.79697220e-03 1.79694776e-04\n",
      " 3.78571868e-01 6.81058943e-01 8.00278187e-01 2.88055092e-01\n",
      " 7.41887748e-01 3.84405524e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 43 TN= 38 FN= 15 FP= 22\n",
      "TP+FP 65\n",
      "precision 0.6615384615384615\n",
      "recall 0.7413793103448276\n",
      "F1 0.6991869918699186\n",
      "acc 0.6864406779661016\n",
      "AUCp 0.6873563218390805\n",
      "AUC 0.7632183908045977\n",
      "\n",
      " The epoch is 130, average recall: 0.7414, average precision: 0.6615,average F1: 0.6992, average accuracy: 0.6864, average AUC: 0.7632\n",
      "Train Epoch: 131 [0/54 (0%)]\tTrain Loss: 0.055347\n",
      "Train Epoch: 131 [8/54 (15%)]\tTrain Loss: 0.039203\n",
      "Train Epoch: 131 [16/54 (30%)]\tTrain Loss: 0.007507\n",
      "Train Epoch: 131 [24/54 (44%)]\tTrain Loss: 0.042791\n",
      "Train Epoch: 131 [32/54 (59%)]\tTrain Loss: 0.008544\n",
      "Train Epoch: 131 [40/54 (74%)]\tTrain Loss: 0.047394\n",
      "Train Epoch: 131 [48/54 (89%)]\tTrain Loss: 0.022317\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.07929847 0.97711098 0.99374795 0.95691872 0.30806264 0.35603759\n",
      " 0.98047799 0.87914026 0.35774124 0.24866734 0.46192494 0.01332667\n",
      " 0.15195432 0.52490741 0.5856567  0.29020119 0.48576042 0.08346429\n",
      " 0.57309818 0.00492793 0.37846965 0.85772222 0.9938305  0.95705748\n",
      " 0.2944614  0.99740076 0.98968118 0.86733747 0.95815504 0.79613966\n",
      " 0.98758614 0.99366546 0.33395931 0.00928366 0.00461488 0.08112241\n",
      " 0.20390975 0.93543041 0.02174905 0.10705619 0.0776697  0.13702196\n",
      " 0.01024997 0.5549314  0.36317167 0.0953499  0.99603868 0.85935366\n",
      " 0.99998486 0.92312217 0.99942964 0.00141755 0.02732386 0.18028118\n",
      " 0.03234354 0.28725252 0.55005223 0.52009696 0.55202645 0.2312479\n",
      " 0.98936033 0.89391518 0.93172199 0.99499524 0.98424441 0.99984467\n",
      " 0.99985397 0.99845326 0.99999917 0.63340789 0.93620402 0.93114573\n",
      " 0.99996054 0.9924798  0.99936301 0.69100207 0.99952829 0.99930942\n",
      " 0.99880779 0.99998188 0.99976546 0.99986708 0.99974698 0.11976009\n",
      " 0.90711689 0.94408214 0.98116714 0.97990924 0.97271085 0.98251456\n",
      " 0.99298334 0.81356084 0.14385083 0.99988365 0.99059427 0.99734688\n",
      " 0.0222435  0.33844325 0.64033115 0.99081379 0.19836386 0.99831402\n",
      " 0.07587484 0.94163889 0.9616012  0.94362837 0.99953771 0.65642256\n",
      " 0.01295028 0.69424623 0.04316619 0.01117455 0.87879866 0.81997216\n",
      " 0.34837043 0.0908543  0.68562943 0.58503675]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 132 [0/54 (0%)]\tTrain Loss: 0.014621\n",
      "Train Epoch: 132 [8/54 (15%)]\tTrain Loss: 0.054306\n",
      "Train Epoch: 132 [16/54 (30%)]\tTrain Loss: 0.065271\n",
      "Train Epoch: 132 [24/54 (44%)]\tTrain Loss: 0.017543\n",
      "Train Epoch: 132 [32/54 (59%)]\tTrain Loss: 0.056276\n",
      "Train Epoch: 132 [40/54 (74%)]\tTrain Loss: 0.034238\n",
      "Train Epoch: 132 [48/54 (89%)]\tTrain Loss: 0.025135\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.22437063 0.9721275  0.88185561 0.99609816 0.51106459 0.06077959\n",
      " 0.79484528 0.9426952  0.57390308 0.1518034  0.92069787 0.01308291\n",
      " 0.26541436 0.14182159 0.70989186 0.21456368 0.90360123 0.19886921\n",
      " 0.31463397 0.15196142 0.34411597 0.89274931 0.99740618 0.990991\n",
      " 0.1188977  0.99987769 0.99359304 0.90187186 0.80391717 0.71365881\n",
      " 0.86635911 0.99731147 0.98966295 0.00677842 0.00385554 0.02586995\n",
      " 0.10286909 0.98264253 0.15931022 0.36507362 0.18729287 0.22681056\n",
      " 0.0348803  0.3286044  0.77818251 0.27977464 0.99606943 0.97470039\n",
      " 0.99999964 0.98623705 0.999816   0.02684748 0.1283679  0.52898288\n",
      " 0.01048942 0.41223258 0.9411943  0.72258127 0.78882104 0.43585712\n",
      " 0.97925949 0.8915028  0.93958139 0.99433386 0.99552554 0.9999609\n",
      " 0.99997079 0.99955386 0.99999738 0.69403368 0.91753745 0.94240397\n",
      " 0.99940193 0.96366894 0.9926489  0.94602919 0.99997211 0.99486828\n",
      " 0.99849379 0.99998069 0.99972123 0.99855429 0.99959797 0.8306058\n",
      " 0.98310971 0.98607254 0.99511045 0.98454791 0.9935782  0.94146514\n",
      " 0.9996264  0.9372521  0.51508319 0.99999738 0.99914765 0.99798512\n",
      " 0.07531495 0.4875825  0.82433873 0.99753088 0.42094573 0.9994337\n",
      " 0.04920729 0.97578967 0.98295343 0.78421569 0.99990618 0.01152429\n",
      " 0.00237667 0.45967546 0.03670549 0.00209496 0.92758936 0.68996257\n",
      " 0.32056841 0.0549088  0.93745345 0.98938888]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 133 [0/54 (0%)]\tTrain Loss: 0.014421\n",
      "Train Epoch: 133 [8/54 (15%)]\tTrain Loss: 0.009795\n",
      "Train Epoch: 133 [16/54 (30%)]\tTrain Loss: 0.079941\n",
      "Train Epoch: 133 [24/54 (44%)]\tTrain Loss: 0.023449\n",
      "Train Epoch: 133 [32/54 (59%)]\tTrain Loss: 0.011619\n",
      "Train Epoch: 133 [40/54 (74%)]\tTrain Loss: 0.017652\n",
      "Train Epoch: 133 [48/54 (89%)]\tTrain Loss: 0.008371\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.77761738e-05 6.04250789e-01 1.73977882e-01 6.68457210e-01\n",
      " 6.47346443e-03 8.07150733e-03 3.49999368e-01 7.31149036e-03\n",
      " 1.02941237e-01 1.82484180e-01 8.79767179e-01 1.72198168e-03\n",
      " 1.48523569e-01 6.95636118e-05 6.18900347e-04 8.11515376e-03\n",
      " 8.67412332e-03 2.76377350e-02 1.46242529e-01 1.34273335e-01\n",
      " 4.19544250e-01 9.72879052e-01 9.89625156e-01 7.53965557e-01\n",
      " 8.54298949e-01 9.96874928e-01 9.54240620e-01 9.56702113e-01\n",
      " 8.70863259e-01 4.06227171e-01 9.28643763e-01 9.65496838e-01\n",
      " 8.30141082e-03 1.03348888e-04 3.64102219e-04 7.75213586e-03\n",
      " 8.55687819e-03 5.17869473e-01 1.05037196e-02 1.78655963e-02\n",
      " 1.61092472e-03 4.58993576e-03 5.98252052e-04 7.13623345e-01\n",
      " 5.81249893e-02 3.36970645e-03 8.73717308e-01 1.37120590e-01\n",
      " 9.83614624e-01 6.13129616e-01 9.38401580e-01 3.45045955e-05\n",
      " 3.99155600e-04 1.99188478e-02 4.28084917e-02 7.77388364e-02\n",
      " 8.33166301e-01 1.18740983e-01 8.25006783e-01 3.83916922e-04\n",
      " 9.92913842e-01 8.87924016e-01 8.68334413e-01 9.38646197e-01\n",
      " 8.20566118e-01 9.89715874e-01 9.98509705e-01 9.99166131e-01\n",
      " 9.99973416e-01 4.90968853e-01 5.81142128e-01 7.42702365e-01\n",
      " 9.96573091e-01 9.58872080e-01 9.95282590e-01 6.71178222e-01\n",
      " 9.93932664e-01 9.93333280e-01 8.65148425e-01 9.99798000e-01\n",
      " 9.98176813e-01 8.12564611e-01 9.85454440e-01 6.83604777e-02\n",
      " 5.79429984e-01 7.77313948e-01 9.71153140e-01 9.28883851e-01\n",
      " 9.03369486e-01 9.56004858e-01 2.12871149e-01 6.76092625e-01\n",
      " 8.63575563e-02 9.98718619e-01 9.81315851e-01 8.21758032e-01\n",
      " 7.45386723e-03 6.00304976e-02 8.75003695e-01 9.52920854e-01\n",
      " 1.15114801e-01 9.81224835e-01 4.92143892e-02 8.08515489e-01\n",
      " 6.61769748e-01 8.78531992e-01 9.18072641e-01 6.72121271e-02\n",
      " 1.14476997e-02 5.46500027e-01 8.41531029e-04 6.17818034e-04\n",
      " 9.68893945e-01 9.54862595e-01 4.56856072e-01 1.60799459e-01\n",
      " 1.04677923e-01 5.18094301e-02]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 134 [0/54 (0%)]\tTrain Loss: 0.001483\n",
      "Train Epoch: 134 [8/54 (15%)]\tTrain Loss: 0.038861\n",
      "Train Epoch: 134 [16/54 (30%)]\tTrain Loss: 0.008230\n",
      "Train Epoch: 134 [24/54 (44%)]\tTrain Loss: 0.007676\n",
      "Train Epoch: 134 [32/54 (59%)]\tTrain Loss: 0.031844\n",
      "Train Epoch: 134 [40/54 (74%)]\tTrain Loss: 0.033596\n",
      "Train Epoch: 134 [48/54 (89%)]\tTrain Loss: 0.077027\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.08972483e-03 1.21244662e-01 2.00787947e-01 9.86516401e-02\n",
      " 7.50324782e-03 3.86798684e-03 6.35195151e-02 3.52735333e-02\n",
      " 3.70258279e-02 7.79125467e-02 2.49027714e-01 4.15600510e-03\n",
      " 7.48715084e-03 8.94718338e-04 4.83991532e-03 6.69674948e-04\n",
      " 5.27065771e-04 1.11541159e-01 3.40811610e-01 3.17988902e-01\n",
      " 4.28797394e-01 8.81715536e-01 9.47084963e-01 9.40461516e-01\n",
      " 1.84528574e-01 9.86391664e-01 9.64461446e-01 2.37517640e-01\n",
      " 4.88455713e-01 5.10555468e-02 6.43051565e-02 9.50508714e-01\n",
      " 5.13654994e-03 4.45973594e-03 1.30051072e-03 1.72253989e-03\n",
      " 5.21042058e-03 7.62560308e-01 1.67446788e-02 1.30930766e-01\n",
      " 1.90767050e-02 6.81695864e-02 2.24650223e-02 7.62960166e-02\n",
      " 1.20461062e-01 3.07807382e-02 5.98477781e-01 6.17361628e-02\n",
      " 9.96443450e-01 8.24602604e-01 9.75726068e-01 1.02857601e-04\n",
      " 1.91646069e-02 1.53645054e-02 4.91751023e-02 5.99230407e-03\n",
      " 9.42641914e-01 7.94015732e-03 2.78393291e-02 2.88982945e-03\n",
      " 9.94861186e-01 8.54926646e-01 8.28500748e-01 9.67869580e-01\n",
      " 2.23563328e-01 3.62194389e-01 7.50820816e-01 9.61091995e-01\n",
      " 9.80968535e-01 2.28711650e-01 8.52598131e-01 8.88019264e-01\n",
      " 9.80480313e-01 5.44269025e-01 4.72269803e-01 9.43811417e-01\n",
      " 8.81489933e-01 6.64456725e-01 7.96600044e-01 9.99972105e-01\n",
      " 9.93194103e-01 9.80356991e-01 9.99250710e-01 5.34569919e-01\n",
      " 9.44248140e-01 9.31907356e-01 9.96892273e-01 9.89581227e-01\n",
      " 2.26037160e-01 4.54945028e-01 9.76854503e-01 3.45075220e-01\n",
      " 1.68912828e-01 9.99907136e-01 9.98287976e-01 8.92654836e-01\n",
      " 3.64275202e-02 3.52744102e-01 3.28334898e-01 9.09592748e-01\n",
      " 1.58908740e-01 9.97977197e-01 1.08343102e-02 9.91538346e-01\n",
      " 9.86867547e-01 9.62119579e-01 9.99990702e-01 7.72389844e-02\n",
      " 6.38829079e-03 2.37934530e-01 8.24216101e-03 1.76623110e-02\n",
      " 1.62334859e-01 6.33236885e-01 2.39673406e-01 8.92723203e-02\n",
      " 3.46552171e-02 1.04824498e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 135 [0/54 (0%)]\tTrain Loss: 0.026210\n",
      "Train Epoch: 135 [8/54 (15%)]\tTrain Loss: 0.008804\n",
      "Train Epoch: 135 [16/54 (30%)]\tTrain Loss: 0.041913\n",
      "Train Epoch: 135 [24/54 (44%)]\tTrain Loss: 0.006984\n",
      "Train Epoch: 135 [32/54 (59%)]\tTrain Loss: 0.028673\n",
      "Train Epoch: 135 [40/54 (74%)]\tTrain Loss: 0.030691\n",
      "Train Epoch: 135 [48/54 (89%)]\tTrain Loss: 0.043977\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.32460473e-03 8.13014686e-01 8.60076547e-01 7.02911437e-01\n",
      " 1.46576360e-01 1.16512142e-02 7.78463304e-01 7.68570840e-01\n",
      " 7.01385438e-02 3.50386300e-03 8.77587795e-01 2.63786642e-03\n",
      " 5.41814387e-01 1.68210722e-03 2.27648299e-02 1.78169850e-02\n",
      " 7.55610839e-02 1.23548009e-01 7.98699796e-01 4.60897744e-01\n",
      " 3.63443375e-01 9.52621758e-01 9.63145137e-01 9.20853794e-01\n",
      " 4.97951269e-01 9.98690784e-01 9.86208439e-01 9.81224179e-01\n",
      " 7.58698046e-01 3.95938128e-01 6.42970264e-01 9.62415159e-01\n",
      " 5.89157999e-01 6.10187941e-04 5.99461840e-03 2.49365135e-03\n",
      " 1.34282917e-01 9.84736979e-01 1.40682766e-02 2.84905732e-01\n",
      " 1.53025892e-02 2.01992188e-02 4.19787802e-02 7.87200630e-01\n",
      " 4.16235059e-01 1.97643265e-01 9.62677479e-01 3.76022607e-01\n",
      " 9.99434531e-01 9.04466927e-01 9.93040800e-01 1.43092894e-03\n",
      " 9.13756266e-02 1.32742180e-02 3.96907283e-03 3.62344906e-02\n",
      " 6.92164779e-01 8.23794827e-02 9.20586381e-03 4.44443263e-02\n",
      " 9.09174919e-01 3.42695475e-01 5.21334887e-01 8.44519436e-01\n",
      " 9.68910158e-01 9.97712612e-01 9.99639988e-01 9.98560369e-01\n",
      " 9.99979973e-01 7.21966505e-01 5.59238195e-01 7.94719636e-01\n",
      " 9.94084179e-01 9.80765402e-01 9.93962705e-01 9.90394175e-01\n",
      " 9.98790443e-01 9.97723162e-01 9.85477924e-01 9.99977350e-01\n",
      " 9.99178946e-01 9.78944421e-01 9.97293293e-01 8.40350807e-01\n",
      " 8.66328001e-01 9.78737891e-01 9.76015449e-01 9.05680776e-01\n",
      " 8.43305588e-01 9.40358400e-01 9.98659849e-01 9.02697861e-01\n",
      " 3.05168778e-01 9.99997854e-01 9.97195005e-01 9.90299702e-01\n",
      " 1.59321070e-01 1.44936889e-01 8.12972963e-01 9.96828258e-01\n",
      " 5.26274405e-02 9.96380746e-01 6.05754219e-02 9.94496644e-01\n",
      " 9.83653724e-01 9.07219529e-01 9.99897242e-01 4.26400751e-02\n",
      " 2.49862745e-02 5.37290931e-01 2.30483301e-02 2.76153255e-03\n",
      " 9.23767209e-01 9.97558355e-01 8.00176740e-01 2.37139627e-01\n",
      " 7.76430607e-01 1.73875555e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 136 [0/54 (0%)]\tTrain Loss: 0.005407\n",
      "Train Epoch: 136 [8/54 (15%)]\tTrain Loss: 0.012401\n",
      "Train Epoch: 136 [16/54 (30%)]\tTrain Loss: 0.110998\n",
      "Train Epoch: 136 [24/54 (44%)]\tTrain Loss: 0.033051\n",
      "Train Epoch: 136 [32/54 (59%)]\tTrain Loss: 0.018205\n",
      "Train Epoch: 136 [40/54 (74%)]\tTrain Loss: 0.032794\n",
      "Train Epoch: 136 [48/54 (89%)]\tTrain Loss: 0.070700\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.45516967e-05 4.52621907e-01 3.96352522e-02 1.24935294e-02\n",
      " 2.63382448e-04 1.21494049e-05 9.32016000e-02 1.29453570e-03\n",
      " 2.68305819e-02 2.13534869e-02 2.81074792e-01 5.37915230e-02\n",
      " 4.53849137e-02 2.84675352e-05 1.47231010e-04 2.43214759e-04\n",
      " 7.89861009e-03 2.23095082e-02 1.81140706e-01 2.25895294e-03\n",
      " 3.13523442e-01 4.18429166e-01 4.88235801e-01 3.14464897e-01\n",
      " 9.52119157e-02 8.88325036e-01 8.85350823e-01 1.60730511e-01\n",
      " 1.49653658e-01 3.74974720e-02 8.58443882e-03 1.05129138e-01\n",
      " 9.22258361e-04 1.41498211e-04 1.70345127e-03 3.37885669e-03\n",
      " 4.65895608e-03 4.20488045e-02 3.54941096e-03 3.40346154e-03\n",
      " 4.47257981e-03 5.15736733e-03 1.07501005e-03 1.48253459e-02\n",
      " 2.07494833e-02 7.03853322e-04 8.57288241e-02 3.87825184e-02\n",
      " 7.42691219e-01 9.04509187e-01 5.23196399e-01 2.60549973e-06\n",
      " 1.62202254e-04 1.23425741e-02 4.86183278e-02 2.37094611e-03\n",
      " 1.48349702e-01 3.33964522e-03 4.42065438e-03 4.26176630e-05\n",
      " 2.59205788e-01 2.56778747e-01 1.94256783e-01 4.39020514e-01\n",
      " 1.70050506e-02 2.36416847e-01 4.37406272e-01 5.09285152e-01\n",
      " 9.98293817e-01 6.84319288e-02 5.75952351e-01 5.45753002e-01\n",
      " 8.45872939e-01 1.36751294e-01 1.40089855e-01 1.93626061e-01\n",
      " 9.68549907e-01 9.55813885e-01 4.96957265e-03 6.03706479e-01\n",
      " 8.31859648e-01 5.56346834e-01 7.02526629e-01 8.68493617e-02\n",
      " 7.79855549e-02 2.17511266e-01 1.85874969e-01 1.73576757e-01\n",
      " 2.67357439e-01 5.67504585e-01 8.65950882e-01 3.02664757e-01\n",
      " 1.82480156e-01 9.94942605e-01 9.46593344e-01 9.28134561e-01\n",
      " 1.57213639e-02 1.08583737e-02 1.38504073e-01 6.82674110e-01\n",
      " 6.12424687e-03 4.39913496e-02 1.37057994e-03 6.86084569e-01\n",
      " 9.20073867e-01 1.68573394e-01 8.69120419e-01 1.93469059e-02\n",
      " 6.59050234e-03 5.98147325e-02 2.97535764e-04 4.94708568e-02\n",
      " 8.23841035e-01 9.10716832e-01 2.36654412e-02 1.05099762e-02\n",
      " 1.96824804e-01 2.47118273e-03]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 137 [0/54 (0%)]\tTrain Loss: 0.049233\n",
      "Train Epoch: 137 [8/54 (15%)]\tTrain Loss: 0.066003\n",
      "Train Epoch: 137 [16/54 (30%)]\tTrain Loss: 0.009637\n",
      "Train Epoch: 137 [24/54 (44%)]\tTrain Loss: 0.009020\n",
      "Train Epoch: 137 [32/54 (59%)]\tTrain Loss: 0.077830\n",
      "Train Epoch: 137 [40/54 (74%)]\tTrain Loss: 0.022253\n",
      "Train Epoch: 137 [48/54 (89%)]\tTrain Loss: 0.025329\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.73008296e-02 9.26517606e-01 8.06066751e-01 4.29260850e-01\n",
      " 3.31405252e-02 2.42647752e-02 8.07953298e-01 2.28368476e-01\n",
      " 3.97193655e-02 1.14679588e-02 6.97837174e-02 2.39446759e-02\n",
      " 2.98813153e-02 2.01740442e-03 1.51176099e-02 1.45264843e-03\n",
      " 3.97443818e-03 5.11307567e-02 5.14433309e-02 1.89732872e-02\n",
      " 7.44275525e-02 5.70198238e-01 9.55210745e-01 4.47655141e-01\n",
      " 4.23369035e-02 9.29848194e-01 7.46996522e-01 1.76438391e-01\n",
      " 3.09256196e-01 9.40965936e-02 2.01820388e-01 8.29208136e-01\n",
      " 8.09786022e-01 6.87880602e-05 7.27092207e-04 3.92276794e-03\n",
      " 4.81128227e-03 3.72017622e-01 1.48129109e-02 1.78891327e-02\n",
      " 1.70388781e-02 4.42970265e-03 9.43179801e-03 6.68675378e-02\n",
      " 8.98796692e-02 1.67052016e-01 9.97149289e-01 9.91525471e-01\n",
      " 9.99992728e-01 8.06386113e-01 9.99923944e-01 1.21892866e-04\n",
      " 1.04765990e-03 2.78806500e-02 3.27343270e-02 1.89977314e-03\n",
      " 7.76246846e-01 4.39785933e-03 3.19455825e-02 8.51224363e-03\n",
      " 9.97844577e-01 9.52758610e-01 9.94783461e-01 9.99229431e-01\n",
      " 7.69815564e-01 2.69718319e-01 5.89612186e-01 8.87922823e-01\n",
      " 9.98795509e-01 6.48756847e-02 9.44025517e-01 9.55387950e-01\n",
      " 9.45741177e-01 5.79418898e-01 4.94657487e-01 9.62637603e-01\n",
      " 9.99961138e-01 9.99963880e-01 9.63803709e-01 9.97278750e-01\n",
      " 9.99012232e-01 9.82289851e-01 9.95638430e-01 6.16973817e-01\n",
      " 5.03737390e-01 9.79609549e-01 9.63182628e-01 9.47640359e-01\n",
      " 4.44584265e-02 1.18200883e-01 4.15160209e-01 3.57207805e-01\n",
      " 3.02999228e-01 9.32177424e-01 4.81329113e-01 1.99598223e-01\n",
      " 3.61377187e-03 2.45029896e-01 4.33433771e-01 6.55710921e-02\n",
      " 5.44837900e-02 9.78585958e-01 1.10716475e-02 6.04070604e-01\n",
      " 6.14592254e-01 1.05360024e-01 9.82959390e-01 1.54555058e-02\n",
      " 2.45874369e-04 1.09372236e-01 1.08099659e-03 1.30796398e-03\n",
      " 4.51794360e-03 6.15874268e-02 2.55183782e-02 1.23839937e-01\n",
      " 8.61231446e-01 2.88197428e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 138 [0/54 (0%)]\tTrain Loss: 0.021158\n",
      "Train Epoch: 138 [8/54 (15%)]\tTrain Loss: 0.094392\n",
      "Train Epoch: 138 [16/54 (30%)]\tTrain Loss: 0.006536\n",
      "Train Epoch: 138 [24/54 (44%)]\tTrain Loss: 0.007164\n",
      "Train Epoch: 138 [32/54 (59%)]\tTrain Loss: 0.016137\n",
      "Train Epoch: 138 [40/54 (74%)]\tTrain Loss: 0.010878\n",
      "Train Epoch: 138 [48/54 (89%)]\tTrain Loss: 0.025483\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.03030451 0.99141228 0.85061574 0.93278193 0.20801604 0.29439187\n",
      " 0.97580647 0.48493946 0.26305044 0.62398458 0.61822504 0.0210372\n",
      " 0.13155416 0.03362077 0.07039008 0.02563148 0.1003304  0.05952183\n",
      " 0.58363491 0.03985387 0.44253021 0.94740456 0.99547237 0.91201103\n",
      " 0.23385777 0.99967384 0.99152815 0.45004413 0.88383007 0.61341184\n",
      " 0.64418602 0.9931919  0.53032893 0.00539051 0.00745224 0.01162163\n",
      " 0.07026618 0.98278749 0.09194931 0.42696929 0.27029714 0.06659716\n",
      " 0.07079916 0.35457948 0.72593629 0.28973725 0.99958652 0.98830903\n",
      " 0.99999988 0.98370034 0.99999058 0.00557733 0.01548493 0.15211347\n",
      " 0.02595434 0.0124723  0.75514728 0.22131082 0.37177306 0.22970347\n",
      " 0.99964774 0.96025717 0.99927503 0.9996506  0.9947108  0.99376535\n",
      " 0.99959308 0.99797469 0.99999714 0.83681494 0.94865608 0.95350188\n",
      " 0.99971372 0.9914493  0.96648586 0.99949336 0.99999762 0.9999876\n",
      " 0.99978536 0.99999797 0.99998808 0.99930632 0.99988055 0.90286481\n",
      " 0.98651671 0.99133754 0.9878692  0.99406415 0.55984175 0.92002517\n",
      " 0.99929166 0.5610351  0.74590945 0.99998796 0.99981385 0.99540615\n",
      " 0.02204977 0.49264285 0.69438475 0.98846239 0.164946   0.99945372\n",
      " 0.02197406 0.99715096 0.99917537 0.96067673 0.99997282 0.12877317\n",
      " 0.0060609  0.72415644 0.01776117 0.0509544  0.9423005  0.96219784\n",
      " 0.88868368 0.40686774 0.84769315 0.68424666]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 139 [0/54 (0%)]\tTrain Loss: 0.014459\n",
      "Train Epoch: 139 [8/54 (15%)]\tTrain Loss: 0.004078\n",
      "Train Epoch: 139 [16/54 (30%)]\tTrain Loss: 0.008968\n",
      "Train Epoch: 139 [24/54 (44%)]\tTrain Loss: 0.008293\n",
      "Train Epoch: 139 [32/54 (59%)]\tTrain Loss: 0.037751\n",
      "Train Epoch: 139 [40/54 (74%)]\tTrain Loss: 0.028008\n",
      "Train Epoch: 139 [48/54 (89%)]\tTrain Loss: 0.022648\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.74673774e-04 8.52432728e-01 3.21158201e-01 9.47502553e-01\n",
      " 1.15166076e-01 3.81452637e-03 7.08850086e-01 7.42726684e-01\n",
      " 6.82259426e-02 6.83174372e-01 9.36196685e-01 8.68109763e-02\n",
      " 9.47569668e-01 1.41675875e-03 8.13266728e-03 9.04463418e-03\n",
      " 7.65784979e-01 1.19187087e-01 4.90492642e-01 1.21034898e-01\n",
      " 2.89165199e-01 9.70284224e-01 9.08236563e-01 9.55151439e-01\n",
      " 5.07023871e-01 9.96620059e-01 9.97503221e-01 4.74803776e-01\n",
      " 5.77050149e-01 5.19758105e-01 1.08454406e-01 3.44259202e-01\n",
      " 3.60328667e-02 2.73421267e-03 4.04992476e-02 1.40531324e-02\n",
      " 6.58236742e-02 6.18561208e-01 2.56883306e-03 1.19214147e-01\n",
      " 3.17814015e-02 3.21391248e-03 5.41472156e-03 3.78430396e-01\n",
      " 1.48805782e-01 2.45112963e-02 3.76072109e-01 7.38264769e-02\n",
      " 9.99370396e-01 9.70365763e-01 9.96560156e-01 4.98376961e-04\n",
      " 4.23076563e-03 2.66310498e-02 2.58961902e-03 2.17894632e-02\n",
      " 4.84805286e-01 5.21356948e-02 5.29722869e-01 1.16869593e-02\n",
      " 9.96759593e-01 6.09408081e-01 8.49614084e-01 9.74379241e-01\n",
      " 6.89826727e-01 9.80043888e-01 9.93379712e-01 9.92684186e-01\n",
      " 9.99975681e-01 4.01158154e-01 8.24874163e-01 8.31119120e-01\n",
      " 9.96768832e-01 9.80505645e-01 9.78490651e-01 7.81506062e-01\n",
      " 9.85480368e-01 9.81326342e-01 6.56242251e-01 9.98094141e-01\n",
      " 9.99367774e-01 9.97519314e-01 9.98759151e-01 8.85909796e-01\n",
      " 8.49513948e-01 9.88416433e-01 9.88560140e-01 9.57831383e-01\n",
      " 9.86132622e-01 9.88498032e-01 9.99940515e-01 9.88601625e-01\n",
      " 8.81514907e-01 9.99999642e-01 9.99411941e-01 9.99217033e-01\n",
      " 6.93898201e-02 4.67346042e-01 9.53167200e-01 9.71217871e-01\n",
      " 8.81225020e-02 8.94020915e-01 4.23552655e-02 9.99353588e-01\n",
      " 9.98732507e-01 5.54715693e-01 9.99902725e-01 2.78556675e-01\n",
      " 4.78398660e-03 9.69516873e-01 1.62088405e-02 5.39491735e-02\n",
      " 9.96072650e-01 9.99553263e-01 3.74382198e-01 1.83895957e-02\n",
      " 9.22458231e-01 1.72903016e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 140 [0/54 (0%)]\tTrain Loss: 0.075813\n",
      "Train Epoch: 140 [8/54 (15%)]\tTrain Loss: 0.047043\n",
      "Train Epoch: 140 [16/54 (30%)]\tTrain Loss: 0.017599\n",
      "Train Epoch: 140 [24/54 (44%)]\tTrain Loss: 0.068651\n",
      "Train Epoch: 140 [32/54 (59%)]\tTrain Loss: 0.014719\n",
      "Train Epoch: 140 [40/54 (74%)]\tTrain Loss: 0.011250\n",
      "Train Epoch: 140 [48/54 (89%)]\tTrain Loss: 0.009350\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.70869139e-03 9.68347788e-01 8.88606906e-01 8.94841194e-01\n",
      " 4.11516093e-02 2.18944270e-02 9.63851094e-01 8.66563737e-01\n",
      " 1.40319958e-01 1.33313566e-01 8.62711847e-01 6.41662478e-02\n",
      " 4.71226454e-01 4.01879586e-02 4.09850717e-01 2.66052298e-02\n",
      " 6.81927707e-03 2.44140193e-01 4.14660215e-01 1.32157251e-01\n",
      " 2.27819040e-01 9.79180396e-01 9.91974056e-01 9.42462683e-01\n",
      " 4.04557824e-01 9.98592913e-01 9.94507015e-01 6.16012394e-01\n",
      " 7.99613655e-01 5.44145346e-01 8.38351429e-01 9.42601144e-01\n",
      " 3.81430537e-01 3.68477922e-04 3.09733278e-03 6.99986443e-02\n",
      " 1.46820888e-01 6.48565233e-01 2.55432818e-02 1.89297214e-01\n",
      " 7.93067813e-02 5.90507910e-02 1.18019320e-02 6.47697330e-01\n",
      " 3.15695405e-01 1.65441595e-02 9.89684939e-01 9.15569782e-01\n",
      " 9.99989033e-01 9.31842387e-01 9.99906182e-01 2.39023869e-03\n",
      " 1.46548236e-02 2.78483480e-01 3.21156606e-02 1.93813145e-02\n",
      " 9.68333721e-01 1.78915560e-01 5.03749430e-01 7.44623244e-02\n",
      " 9.96915221e-01 7.33388782e-01 8.87058318e-01 9.71446991e-01\n",
      " 9.60359633e-01 9.99069512e-01 9.98355329e-01 9.99891400e-01\n",
      " 9.99936461e-01 8.80623460e-01 9.37473238e-01 9.20633078e-01\n",
      " 9.99781072e-01 9.95360434e-01 9.98010695e-01 9.86932218e-01\n",
      " 9.99898672e-01 9.99622941e-01 9.97996747e-01 9.99995828e-01\n",
      " 9.99966621e-01 9.98812437e-01 9.99903083e-01 8.82939339e-01\n",
      " 9.08670187e-01 9.97220993e-01 9.93034005e-01 9.89232421e-01\n",
      " 2.96032101e-01 8.73054862e-01 9.47477639e-01 9.07432377e-01\n",
      " 8.20780694e-01 9.99986529e-01 9.92953479e-01 9.69302118e-01\n",
      " 5.62390685e-02 5.95806539e-01 5.39427638e-01 8.28963399e-01\n",
      " 9.90449637e-02 9.97869372e-01 8.73382203e-03 9.97105062e-01\n",
      " 9.55596685e-01 7.86458015e-01 9.99815524e-01 2.74833236e-02\n",
      " 1.35225346e-02 2.85142124e-01 2.82545132e-03 5.46209980e-03\n",
      " 3.69943410e-01 9.94144857e-01 5.64936064e-02 3.37539196e-01\n",
      " 8.88248086e-01 1.13712445e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 44 TN= 41 FN= 14 FP= 19\n",
      "TP+FP 63\n",
      "precision 0.6984126984126984\n",
      "recall 0.7586206896551724\n",
      "F1 0.7272727272727273\n",
      "acc 0.7203389830508474\n",
      "AUCp 0.7209770114942529\n",
      "AUC 0.7563218390804597\n",
      "\n",
      " The epoch is 140, average recall: 0.7586, average precision: 0.6984,average F1: 0.7273, average accuracy: 0.7203, average AUC: 0.7563\n",
      "Train Epoch: 141 [0/54 (0%)]\tTrain Loss: 0.023302\n",
      "Train Epoch: 141 [8/54 (15%)]\tTrain Loss: 0.031718\n",
      "Train Epoch: 141 [16/54 (30%)]\tTrain Loss: 0.012194\n",
      "Train Epoch: 141 [24/54 (44%)]\tTrain Loss: 0.001693\n",
      "Train Epoch: 141 [32/54 (59%)]\tTrain Loss: 0.014710\n",
      "Train Epoch: 141 [40/54 (74%)]\tTrain Loss: 0.004672\n",
      "Train Epoch: 141 [48/54 (89%)]\tTrain Loss: 0.010540\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.95027781e-03 7.24424794e-02 8.34877938e-02 2.44800314e-01\n",
      " 2.31387117e-03 6.81022415e-03 6.74481466e-02 3.44722010e-02\n",
      " 1.77890837e-01 3.57479423e-01 1.95368193e-02 3.22426744e-02\n",
      " 4.38746158e-03 5.99657884e-04 1.87629443e-02 3.55028850e-03\n",
      " 4.07791184e-03 1.33302435e-01 6.97530210e-02 9.66167077e-03\n",
      " 2.39072740e-01 9.20478642e-01 8.27031672e-01 9.48453784e-01\n",
      " 6.05658703e-02 9.88579512e-01 9.98886645e-01 1.22447416e-01\n",
      " 8.12647566e-02 9.95782167e-02 1.68565646e-01 7.58476317e-01\n",
      " 9.17695649e-03 5.39094544e-05 3.79528734e-04 3.71373445e-03\n",
      " 1.19417291e-02 7.90349066e-01 6.85493636e-04 4.23257798e-03\n",
      " 1.29737344e-03 3.14123323e-03 2.42170948e-03 7.64965918e-03\n",
      " 1.47539889e-02 1.95737276e-03 9.80650365e-01 9.33990359e-01\n",
      " 9.99995112e-01 9.73183692e-01 9.99928951e-01 7.27990555e-05\n",
      " 8.93422548e-05 5.13308507e-04 2.17143837e-02 3.32128620e-05\n",
      " 9.17308867e-01 1.00460195e-04 2.35037550e-01 1.35519053e-03\n",
      " 9.86864030e-01 7.72193968e-01 7.01587737e-01 9.33367193e-01\n",
      " 9.12341774e-02 9.63422596e-01 9.52919245e-01 9.83283997e-01\n",
      " 9.99990463e-01 8.51551235e-01 8.80465448e-01 8.20627928e-01\n",
      " 9.96288896e-01 9.90026832e-01 9.38728273e-01 8.67152154e-01\n",
      " 9.98941839e-01 9.96625662e-01 9.87503231e-01 9.99986649e-01\n",
      " 9.99055803e-01 9.84898865e-01 9.97635841e-01 4.92080569e-01\n",
      " 8.92004192e-01 9.97352600e-01 9.85686839e-01 9.93888319e-01\n",
      " 2.91983992e-01 9.89154637e-01 9.99531984e-01 7.13242814e-02\n",
      " 1.98817942e-02 9.99361813e-01 9.75244999e-01 9.37124610e-01\n",
      " 1.38033822e-03 8.00447941e-01 3.35816175e-01 9.16230738e-01\n",
      " 1.02344826e-01 9.99094486e-01 2.38211174e-03 9.51825738e-01\n",
      " 9.71873641e-01 6.29019797e-01 9.99403954e-01 1.56122074e-03\n",
      " 1.34704006e-03 3.20252955e-01 5.08650718e-03 5.35157416e-03\n",
      " 4.65908237e-02 8.79742265e-01 2.74291366e-01 2.70628095e-01\n",
      " 9.32453573e-01 1.84193607e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 142 [0/54 (0%)]\tTrain Loss: 0.005045\n",
      "Train Epoch: 142 [8/54 (15%)]\tTrain Loss: 0.024017\n",
      "Train Epoch: 142 [16/54 (30%)]\tTrain Loss: 0.003246\n",
      "Train Epoch: 142 [24/54 (44%)]\tTrain Loss: 0.005755\n",
      "Train Epoch: 142 [32/54 (59%)]\tTrain Loss: 0.020833\n",
      "Train Epoch: 142 [40/54 (74%)]\tTrain Loss: 0.025432\n",
      "Train Epoch: 142 [48/54 (89%)]\tTrain Loss: 0.013659\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.02221275 0.6953674  0.07779197 0.90741175 0.05942351 0.23073962\n",
      " 0.28359219 0.23317038 0.78294116 0.93935537 0.41209421 0.74159503\n",
      " 0.12028623 0.03256935 0.08753808 0.07930011 0.60194248 0.11236033\n",
      " 0.12163961 0.04933549 0.25033727 0.92013168 0.98184341 0.99531806\n",
      " 0.13816735 0.99929476 0.99987793 0.64999211 0.55573964 0.4480319\n",
      " 0.52347636 0.57128173 0.02185968 0.0015299  0.02558102 0.02128486\n",
      " 0.02231841 0.92286152 0.00922051 0.12053665 0.02044785 0.01788551\n",
      " 0.13962577 0.04121283 0.12804417 0.00561184 0.75638318 0.32978112\n",
      " 0.99961215 0.99712223 0.99924111 0.00291727 0.02491106 0.23920999\n",
      " 0.17204997 0.0832506  0.96256649 0.04616933 0.91124797 0.04261202\n",
      " 0.99546981 0.92457706 0.89784104 0.98973197 0.27529261 0.9755829\n",
      " 0.96252972 0.99914265 0.99991643 0.50961185 0.79153621 0.62902421\n",
      " 0.99086422 0.98719054 0.83662182 0.36313415 0.99689615 0.99468046\n",
      " 0.98827481 0.99878973 0.9997974  0.89056212 0.99975318 0.93982309\n",
      " 0.95940459 0.91033918 0.97895986 0.98621386 0.92641008 0.97832948\n",
      " 0.99855798 0.62291181 0.42965847 0.99999988 0.99484879 0.96148527\n",
      " 0.09943442 0.69890183 0.71687615 0.95769507 0.36106905 0.98832744\n",
      " 0.01750191 0.97210062 0.68869054 0.6221478  0.99987686 0.01517967\n",
      " 0.00426805 0.79017669 0.08945385 0.04922506 0.69985485 0.58240175\n",
      " 0.51912171 0.17207116 0.9677037  0.42755339]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0.]\n",
      "Train Epoch: 143 [0/54 (0%)]\tTrain Loss: 0.042497\n",
      "Train Epoch: 143 [8/54 (15%)]\tTrain Loss: 0.003160\n",
      "Train Epoch: 143 [16/54 (30%)]\tTrain Loss: 0.001730\n",
      "Train Epoch: 143 [24/54 (44%)]\tTrain Loss: 0.003142\n",
      "Train Epoch: 143 [32/54 (59%)]\tTrain Loss: 0.053459\n",
      "Train Epoch: 143 [40/54 (74%)]\tTrain Loss: 0.012088\n",
      "Train Epoch: 143 [48/54 (89%)]\tTrain Loss: 0.019277\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.01356689e-04 7.68444955e-01 3.87562998e-02 8.58266428e-02\n",
      " 3.73316085e-04 3.27963033e-04 2.94574294e-02 2.26772018e-03\n",
      " 2.14375164e-02 7.49718025e-02 6.20691013e-03 4.49721180e-02\n",
      " 4.48200852e-04 7.95017811e-04 3.24809998e-02 3.11806507e-04\n",
      " 6.44748390e-04 7.54304081e-02 2.84955114e-01 4.34980452e-01\n",
      " 2.68432170e-01 7.85452962e-01 9.60783541e-01 8.78337324e-01\n",
      " 2.68757075e-01 9.95987952e-01 9.94194329e-01 8.11501443e-01\n",
      " 5.73304355e-01 2.74992317e-01 7.15729654e-01 6.95529342e-01\n",
      " 5.95834255e-02 4.12848167e-05 3.82055645e-04 3.91126471e-03\n",
      " 3.81245418e-03 2.09559023e-01 6.78746914e-03 5.38073573e-03\n",
      " 3.65697849e-03 1.48769552e-02 5.26033621e-03 1.24692963e-02\n",
      " 2.05057207e-02 8.33571982e-03 8.74512732e-01 1.66719824e-01\n",
      " 9.99848485e-01 8.23595405e-01 9.96164799e-01 5.34084393e-06\n",
      " 8.50494311e-04 5.94746904e-04 2.93771744e-01 2.17070366e-04\n",
      " 7.56856263e-01 1.20287505e-03 1.43904358e-01 1.56175840e-04\n",
      " 9.75714266e-01 7.32547581e-01 8.14078748e-01 9.95127201e-01\n",
      " 5.32006025e-02 1.58130914e-01 3.46325755e-01 9.89766538e-01\n",
      " 9.95734155e-01 8.23448002e-01 7.75392294e-01 8.37966621e-01\n",
      " 9.65277195e-01 8.63217890e-01 9.82819617e-01 9.61420596e-01\n",
      " 9.99969363e-01 9.99750912e-01 7.86085308e-01 9.99922514e-01\n",
      " 9.98068869e-01 9.80420232e-01 9.98973370e-01 4.77162153e-01\n",
      " 3.25695366e-01 9.68089640e-01 9.57411528e-01 9.80824590e-01\n",
      " 3.76554072e-01 8.70775938e-01 9.63086665e-01 6.57788143e-02\n",
      " 2.23071948e-01 9.99996781e-01 9.54565704e-01 7.27896512e-01\n",
      " 4.20918362e-03 3.42316747e-01 1.99687436e-01 3.14422816e-01\n",
      " 1.57046095e-01 9.88276660e-01 4.86710342e-03 5.19579828e-01\n",
      " 7.89612353e-01 4.56444085e-01 9.95516479e-01 2.12009922e-02\n",
      " 1.51647385e-02 2.34469980e-01 2.51843967e-03 2.16437057e-02\n",
      " 8.44669342e-02 4.94733900e-01 1.28038088e-02 1.10739745e-01\n",
      " 8.37204158e-01 4.42840979e-02]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 144 [0/54 (0%)]\tTrain Loss: 0.180561\n",
      "Train Epoch: 144 [8/54 (15%)]\tTrain Loss: 0.037355\n",
      "Train Epoch: 144 [16/54 (30%)]\tTrain Loss: 0.119611\n",
      "Train Epoch: 144 [24/54 (44%)]\tTrain Loss: 0.009747\n",
      "Train Epoch: 144 [32/54 (59%)]\tTrain Loss: 0.007348\n",
      "Train Epoch: 144 [40/54 (74%)]\tTrain Loss: 0.013997\n",
      "Train Epoch: 144 [48/54 (89%)]\tTrain Loss: 0.022392\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.03853003 0.43081006 0.01306364 0.99850875 0.64764363 0.08423562\n",
      " 0.03106772 0.98851007 0.5091576  0.30074233 0.6888243  0.0505251\n",
      " 0.79753256 0.0438551  0.44509956 0.06280765 0.12783997 0.26319706\n",
      " 0.97121865 0.72265041 0.86834699 0.99959248 0.99958009 0.99999356\n",
      " 0.96858394 0.99997866 0.99992883 0.99630773 0.89554238 0.95201826\n",
      " 0.99999452 0.99731064 0.83966696 0.6089766  0.18392146 0.00573848\n",
      " 0.20099537 0.99993384 0.32109746 0.51777381 0.31954619 0.18161075\n",
      " 0.4131262  0.97544801 0.94906402 0.83435214 0.99105585 0.95291698\n",
      " 0.99999952 0.99650025 0.99999368 0.00183105 0.64505315 0.63592452\n",
      " 0.68688512 0.2947717  0.99996781 0.44442269 0.75284725 0.66883099\n",
      " 0.99988949 0.9958936  0.99942988 0.9998318  0.99976498 0.99955851\n",
      " 0.99986684 0.99999785 0.9999994  0.98835677 0.9963308  0.9991892\n",
      " 0.99998629 0.9987281  0.99982882 0.99991393 0.99985707 0.99952757\n",
      " 0.99858606 1.         1.         1.         1.         0.91689992\n",
      " 0.92866403 0.99810094 0.99987411 0.99979633 0.99541414 0.98775893\n",
      " 0.99985218 0.9784773  0.98322403 1.         0.99999261 0.99999964\n",
      " 0.60760146 0.96323276 0.68249518 0.99946433 0.43339768 0.9999975\n",
      " 0.0808012  0.99998045 0.99994707 0.99953187 1.         0.37417117\n",
      " 0.02479481 0.58828038 0.56928849 0.03202826 0.87652159 0.99836856\n",
      " 0.6199097  0.66454506 0.40643382 0.86718595]\n",
      "predict [0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "Train Epoch: 145 [0/54 (0%)]\tTrain Loss: 0.003816\n",
      "Train Epoch: 145 [8/54 (15%)]\tTrain Loss: 0.002978\n",
      "Train Epoch: 145 [16/54 (30%)]\tTrain Loss: 0.002921\n",
      "Train Epoch: 145 [24/54 (44%)]\tTrain Loss: 0.025833\n",
      "Train Epoch: 145 [32/54 (59%)]\tTrain Loss: 0.013149\n",
      "Train Epoch: 145 [40/54 (74%)]\tTrain Loss: 0.004944\n",
      "Train Epoch: 145 [48/54 (89%)]\tTrain Loss: 0.028887\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.02605955e-03 8.00762653e-01 1.91392481e-01 9.89732921e-01\n",
      " 4.33439225e-01 2.55263434e-03 3.96649539e-01 9.58864391e-01\n",
      " 1.44689217e-01 7.00116605e-02 4.95770782e-01 1.67711731e-02\n",
      " 1.83529764e-01 2.05375366e-02 6.08842731e-01 4.42684963e-02\n",
      " 1.68747410e-01 3.30920890e-02 7.81682953e-02 1.16434895e-01\n",
      " 1.84226349e-01 9.82091725e-01 9.70246315e-01 9.99291897e-01\n",
      " 4.30845022e-01 9.98900890e-01 9.99760687e-01 7.24146903e-01\n",
      " 1.14473373e-01 7.37669468e-01 9.91827369e-01 9.28586781e-01\n",
      " 9.32221711e-01 2.82922084e-03 1.53001875e-03 3.99454683e-03\n",
      " 9.53902528e-02 9.63852167e-01 4.83683124e-02 1.62835121e-01\n",
      " 5.80594204e-02 3.99453118e-02 2.06103306e-02 5.22910833e-01\n",
      " 1.43440083e-01 7.67121557e-03 9.59482312e-01 9.19635832e-01\n",
      " 9.99996543e-01 9.92221057e-01 9.99815047e-01 4.50650114e-04\n",
      " 1.50438938e-02 4.62333560e-02 1.10481471e-01 1.42815849e-02\n",
      " 9.07256603e-01 3.28864232e-02 7.97482491e-01 8.22589099e-02\n",
      " 9.81187224e-01 9.14701045e-01 9.24271047e-01 9.89124656e-01\n",
      " 9.37432587e-01 9.82484400e-01 9.88746822e-01 9.99891639e-01\n",
      " 9.99981880e-01 7.93789506e-01 6.56520128e-01 7.27357328e-01\n",
      " 9.98504639e-01 9.31115746e-01 9.57275927e-01 9.78598475e-01\n",
      " 9.98648107e-01 9.97958302e-01 9.90426660e-01 9.99957323e-01\n",
      " 9.99984384e-01 9.99775112e-01 9.99973416e-01 4.25945073e-01\n",
      " 6.07150912e-01 9.95854914e-01 9.98609006e-01 9.97693479e-01\n",
      " 8.49388301e-01 8.59976470e-01 9.99801934e-01 5.13653994e-01\n",
      " 7.54386604e-01 9.99999285e-01 9.98970985e-01 9.99522328e-01\n",
      " 1.17172152e-02 9.50464666e-01 4.12152737e-01 9.96130824e-01\n",
      " 2.51822144e-01 9.99499083e-01 3.55880186e-02 9.69694495e-01\n",
      " 9.73225236e-01 6.74491167e-01 9.99930501e-01 4.58440557e-03\n",
      " 7.83746771e-04 8.40742365e-02 1.73164792e-02 3.16173327e-03\n",
      " 2.66144961e-01 9.24426019e-01 7.94647411e-02 1.65824685e-02\n",
      " 6.31302714e-01 9.81295645e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 146 [0/54 (0%)]\tTrain Loss: 0.066370\n",
      "Train Epoch: 146 [8/54 (15%)]\tTrain Loss: 0.010642\n",
      "Train Epoch: 146 [16/54 (30%)]\tTrain Loss: 0.009063\n",
      "Train Epoch: 146 [24/54 (44%)]\tTrain Loss: 0.007082\n",
      "Train Epoch: 146 [32/54 (59%)]\tTrain Loss: 0.039322\n",
      "Train Epoch: 146 [40/54 (74%)]\tTrain Loss: 0.003948\n",
      "Train Epoch: 146 [48/54 (89%)]\tTrain Loss: 0.043346\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.07452155 0.9221679  0.98785454 0.99430931 0.12493101 0.01399554\n",
      " 0.96237987 0.68754119 0.2126815  0.55536032 0.44865224 0.14676215\n",
      " 0.38781559 0.13146102 0.57783031 0.24792187 0.38051903 0.17594624\n",
      " 0.98731089 0.16655609 0.50249565 0.99971563 0.99968719 0.99989188\n",
      " 0.88397199 0.99998426 0.99967349 0.97930545 0.94885427 0.99275875\n",
      " 0.99998224 0.99946803 0.97344911 0.03706985 0.03848182 0.21534339\n",
      " 0.94714206 0.99996603 0.7343173  0.18901876 0.24547464 0.39276797\n",
      " 0.04619694 0.99312532 0.52924895 0.29231817 0.99183297 0.96122217\n",
      " 0.9999994  0.98008496 0.99999082 0.0227388  0.55130786 0.69500405\n",
      " 0.15650642 0.4175818  0.95512402 0.65416914 0.14145592 0.17704996\n",
      " 0.99923849 0.99292892 0.99603951 0.99937361 0.98823869 0.99733448\n",
      " 0.99989188 0.99999011 0.99999976 0.99518085 0.98845726 0.99544299\n",
      " 0.99984097 0.99401265 0.97513402 0.99985754 0.9998042  0.9992736\n",
      " 0.99850816 0.99999928 0.99999905 0.99997437 0.99994934 0.86113763\n",
      " 0.86706138 0.99925691 0.97166508 0.99524081 0.98018128 0.98761463\n",
      " 0.99992549 0.97366738 0.98748583 1.         0.99992669 0.99989927\n",
      " 0.73912114 0.9884029  0.4418675  0.99920124 0.68514699 0.99993777\n",
      " 0.93644536 0.99982697 0.99968946 0.98384744 0.99999917 0.80431467\n",
      " 0.17538472 0.6587804  0.4196423  0.42143041 0.83354431 0.99966288\n",
      " 0.8050102  0.29818186 0.98605913 0.9927901 ]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 147 [0/54 (0%)]\tTrain Loss: 0.038296\n",
      "Train Epoch: 147 [8/54 (15%)]\tTrain Loss: 0.019904\n",
      "Train Epoch: 147 [16/54 (30%)]\tTrain Loss: 0.032530\n",
      "Train Epoch: 147 [24/54 (44%)]\tTrain Loss: 0.015959\n",
      "Train Epoch: 147 [32/54 (59%)]\tTrain Loss: 0.003689\n",
      "Train Epoch: 147 [40/54 (74%)]\tTrain Loss: 0.014913\n",
      "Train Epoch: 147 [48/54 (89%)]\tTrain Loss: 0.005114\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.58314686e-03 5.84679127e-01 3.99878085e-01 7.21018434e-01\n",
      " 1.96648091e-02 4.75733960e-03 3.27789038e-01 1.62924692e-01\n",
      " 3.80318984e-02 6.76634610e-02 4.30870242e-02 3.57319713e-02\n",
      " 7.55550619e-03 7.84870179e-04 1.66457668e-02 1.61054137e-03\n",
      " 4.41136351e-03 9.01326258e-03 2.22212359e-01 3.58229391e-02\n",
      " 1.38198018e-01 9.11118925e-01 9.66173947e-01 9.90808964e-01\n",
      " 1.55873355e-02 9.93834376e-01 9.82276380e-01 5.27313128e-02\n",
      " 8.81028548e-02 4.47769105e-01 7.23794699e-02 6.38959587e-01\n",
      " 1.39940321e-01 6.50846268e-05 9.71843328e-05 3.91841168e-04\n",
      " 4.29512374e-02 9.66411233e-01 3.89329158e-03 1.16260035e-03\n",
      " 4.85821773e-04 2.93783168e-03 5.50120696e-03 3.84112924e-01\n",
      " 7.15012057e-03 1.07805186e-03 4.69258964e-01 1.15977190e-01\n",
      " 9.99993205e-01 8.67610097e-01 9.99805868e-01 4.46031045e-04\n",
      " 1.27918809e-03 2.52915602e-02 2.06448766e-03 1.61821432e-02\n",
      " 2.33798817e-01 6.30153567e-02 4.45619464e-01 1.61881617e-03\n",
      " 9.84950185e-01 7.19345450e-01 4.66532856e-01 9.26493883e-01\n",
      " 4.08562332e-01 9.75672781e-01 9.93777990e-01 9.96451378e-01\n",
      " 9.99994993e-01 8.85841787e-01 8.37174654e-01 8.61314654e-01\n",
      " 9.96098280e-01 9.24228251e-01 4.75960761e-01 4.54622954e-01\n",
      " 9.98197258e-01 9.97887790e-01 9.16203380e-01 9.99908209e-01\n",
      " 9.99940157e-01 9.95408833e-01 9.99702632e-01 1.03013732e-01\n",
      " 1.88131198e-01 9.38363254e-01 9.15538013e-01 9.54264581e-01\n",
      " 7.04960227e-01 2.07014769e-01 9.94832635e-01 6.20931327e-01\n",
      " 1.59458578e-01 9.99998212e-01 9.88048851e-01 9.76893187e-01\n",
      " 9.23667327e-02 3.56580988e-02 2.67507397e-02 7.68081188e-01\n",
      " 1.19519560e-02 9.90772963e-01 2.99731232e-02 8.65333140e-01\n",
      " 9.48116422e-01 4.08531904e-01 9.99703825e-01 1.48608524e-03\n",
      " 1.26725543e-04 4.56044525e-02 9.27590008e-04 1.43080484e-04\n",
      " 5.95396496e-02 8.52871358e-01 3.01525015e-02 2.34448374e-03\n",
      " 3.07071656e-01 7.89203309e-03]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 148 [0/54 (0%)]\tTrain Loss: 0.002318\n",
      "Train Epoch: 148 [8/54 (15%)]\tTrain Loss: 0.021787\n",
      "Train Epoch: 148 [16/54 (30%)]\tTrain Loss: 0.001110\n",
      "Train Epoch: 148 [24/54 (44%)]\tTrain Loss: 0.030854\n",
      "Train Epoch: 148 [32/54 (59%)]\tTrain Loss: 0.007706\n",
      "Train Epoch: 148 [40/54 (74%)]\tTrain Loss: 0.020247\n",
      "Train Epoch: 148 [48/54 (89%)]\tTrain Loss: 0.007492\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.32163507e-03 9.67973232e-01 6.90161526e-01 9.91559684e-01\n",
      " 1.59436882e-01 2.62059830e-02 9.39948380e-01 9.48546529e-01\n",
      " 1.16506204e-01 5.32415649e-03 1.69381753e-01 6.63004210e-03\n",
      " 7.92268366e-02 2.04631284e-01 9.48966205e-01 2.59955432e-02\n",
      " 7.71489590e-02 1.16145797e-01 6.89475894e-01 3.52289468e-01\n",
      " 6.67675912e-01 9.95819032e-01 9.97768641e-01 9.93919015e-01\n",
      " 2.94896871e-01 9.99784172e-01 9.92815256e-01 5.99412084e-01\n",
      " 7.03214586e-01 9.05613363e-01 9.79193866e-01 9.98222768e-01\n",
      " 6.82622433e-01 1.21893315e-03 6.96203089e-04 1.47584733e-03\n",
      " 3.83642763e-02 9.84434783e-01 5.87681821e-03 5.54721951e-02\n",
      " 2.51926500e-02 4.96454351e-02 1.65730435e-02 9.26387072e-01\n",
      " 3.26803029e-01 3.20361741e-02 9.71781015e-01 4.03713375e-01\n",
      " 9.99999642e-01 9.15498555e-01 9.99894381e-01 2.45811231e-03\n",
      " 3.99325281e-01 3.89665306e-01 3.59988734e-02 4.00179952e-01\n",
      " 9.94286597e-01 2.93295890e-01 2.22055912e-01 7.44881868e-01\n",
      " 9.95112956e-01 9.00582314e-01 9.50053632e-01 9.90956485e-01\n",
      " 9.96437788e-01 9.99977112e-01 9.99650598e-01 9.99882221e-01\n",
      " 9.99999881e-01 9.09320414e-01 8.79720747e-01 9.10900056e-01\n",
      " 9.99902964e-01 9.96961653e-01 9.98715401e-01 9.98855591e-01\n",
      " 9.99917507e-01 9.99622345e-01 9.99036312e-01 9.99999166e-01\n",
      " 9.99998212e-01 9.99982357e-01 9.99997020e-01 1.51285499e-01\n",
      " 2.84282207e-01 9.81015086e-01 9.90559220e-01 9.95581329e-01\n",
      " 9.97672498e-01 9.45378244e-01 9.99829531e-01 7.62675941e-01\n",
      " 4.97800291e-01 1.00000000e+00 9.97687697e-01 9.91545379e-01\n",
      " 4.76668030e-01 7.53622890e-01 4.82798219e-01 9.87456143e-01\n",
      " 2.87659932e-02 9.99969482e-01 2.23631620e-01 9.62800384e-01\n",
      " 9.79663730e-01 7.46069908e-01 9.99584019e-01 3.64945531e-02\n",
      " 1.60910394e-02 6.10290051e-01 6.98105618e-02 1.25161335e-02\n",
      " 7.30060637e-01 9.52918351e-01 4.32141982e-02 8.56928304e-02\n",
      " 8.13139856e-01 1.32801399e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 149 [0/54 (0%)]\tTrain Loss: 0.093696\n",
      "Train Epoch: 149 [8/54 (15%)]\tTrain Loss: 0.017709\n",
      "Train Epoch: 149 [16/54 (30%)]\tTrain Loss: 0.063677\n",
      "Train Epoch: 149 [24/54 (44%)]\tTrain Loss: 0.009979\n",
      "Train Epoch: 149 [32/54 (59%)]\tTrain Loss: 0.009442\n",
      "Train Epoch: 149 [40/54 (74%)]\tTrain Loss: 0.024197\n",
      "Train Epoch: 149 [48/54 (89%)]\tTrain Loss: 0.011741\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.33330184e-02 9.09941316e-01 8.27512562e-01 8.95870030e-01\n",
      " 3.07153706e-02 4.79977205e-02 8.63797605e-01 5.32259643e-01\n",
      " 2.59373337e-01 2.67855197e-01 5.62777638e-01 4.53569233e-01\n",
      " 3.97414602e-02 3.77676450e-04 2.18536016e-02 2.74084299e-03\n",
      " 4.85440157e-03 7.50921890e-02 8.36580098e-02 6.35297224e-02\n",
      " 5.10870516e-02 8.48806262e-01 9.65265632e-01 9.85475481e-01\n",
      " 2.56698102e-01 9.92575526e-01 9.97578204e-01 1.66311767e-02\n",
      " 3.18359762e-01 3.04108024e-01 5.75148128e-03 3.56306881e-01\n",
      " 2.56740171e-02 1.57357324e-04 9.57869575e-04 5.67680504e-03\n",
      " 7.31474767e-03 1.19899556e-01 5.15730074e-03 8.96200258e-03\n",
      " 8.56134947e-03 2.41642147e-02 5.14775561e-03 1.35917082e-01\n",
      " 3.10508963e-02 6.58636242e-02 9.86527860e-01 8.17289889e-01\n",
      " 9.99999046e-01 9.88761365e-01 9.99823630e-01 2.09283593e-04\n",
      " 6.22176565e-04 1.80424731e-02 3.41540836e-02 1.32148471e-02\n",
      " 7.14129150e-01 5.09771612e-03 2.81974465e-01 3.81539110e-03\n",
      " 9.93800819e-01 9.67388511e-01 7.03664422e-01 9.56760466e-01\n",
      " 2.53088057e-01 4.25234646e-01 1.51378691e-01 8.85646582e-01\n",
      " 9.99416709e-01 6.79117322e-01 9.88205433e-01 9.93103266e-01\n",
      " 8.07872891e-01 7.90338695e-01 2.39061654e-01 7.37435281e-01\n",
      " 9.95825410e-01 9.95791554e-01 9.88021970e-01 9.96984899e-01\n",
      " 9.99895334e-01 9.93108869e-01 9.99442041e-01 4.85784739e-01\n",
      " 8.78986537e-01 9.90201175e-01 9.94409263e-01 9.96427000e-01\n",
      " 2.42409170e-01 7.28488863e-01 9.87816036e-01 5.31555116e-01\n",
      " 1.80380121e-01 9.99982834e-01 9.94900405e-01 8.38927925e-01\n",
      " 5.47219552e-02 8.82855237e-01 4.10076320e-01 4.87971276e-01\n",
      " 1.28853649e-01 9.94120181e-01 3.23683247e-02 7.87556827e-01\n",
      " 8.58394086e-01 1.13947086e-01 9.98457551e-01 9.66483355e-03\n",
      " 5.30221150e-04 2.87340492e-01 4.54945170e-04 6.56968681e-03\n",
      " 5.05389422e-02 5.40683389e-01 1.67679531e-03 1.20550739e-02\n",
      " 8.03926587e-01 6.38714656e-02]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 150 [0/54 (0%)]\tTrain Loss: 0.008052\n",
      "Train Epoch: 150 [8/54 (15%)]\tTrain Loss: 0.008670\n",
      "Train Epoch: 150 [16/54 (30%)]\tTrain Loss: 0.002922\n",
      "Train Epoch: 150 [24/54 (44%)]\tTrain Loss: 0.005757\n",
      "Train Epoch: 150 [32/54 (59%)]\tTrain Loss: 0.078027\n",
      "Train Epoch: 150 [40/54 (74%)]\tTrain Loss: 0.021532\n",
      "Train Epoch: 150 [48/54 (89%)]\tTrain Loss: 0.006016\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.01600811 0.92430514 0.66001618 0.98999316 0.24806122 0.03514445\n",
      " 0.79571503 0.83352077 0.32049951 0.26228556 0.98799163 0.13372736\n",
      " 0.51273239 0.03357712 0.13349307 0.08148591 0.13574652 0.05672818\n",
      " 0.00420275 0.01477289 0.08706212 0.99540234 0.99428767 0.99787498\n",
      " 0.51813096 0.9996171  0.99996352 0.34061384 0.85332841 0.93554789\n",
      " 0.91145295 0.99300885 0.96951395 0.00106553 0.00385905 0.01272543\n",
      " 0.16106139 0.93181938 0.01945437 0.08274117 0.07544143 0.25827092\n",
      " 0.00273816 0.65606344 0.01737972 0.35509935 0.99962139 0.98826027\n",
      " 0.99999905 0.99899119 0.99996424 0.03046837 0.00838343 0.05051996\n",
      " 0.21908909 0.08197634 0.98728055 0.31470391 0.57046044 0.02445673\n",
      " 0.99933416 0.99273443 0.99635941 0.99743736 0.44651118 0.99577039\n",
      " 0.99775177 0.99971658 0.99998176 0.93114078 0.98715031 0.99867529\n",
      " 0.99840063 0.99830568 0.99326444 0.96845502 0.9972589  0.99447411\n",
      " 0.98124874 0.99998426 0.99999702 0.99942672 0.99999082 0.84559411\n",
      " 0.9588325  0.98711306 0.99003041 0.99899322 0.76724452 0.99872476\n",
      " 0.99945718 0.91586196 0.45975065 0.99999654 0.997832   0.98432678\n",
      " 0.03263703 0.94357753 0.86795759 0.99942505 0.32661918 0.99991512\n",
      " 0.38278982 0.992607   0.99155933 0.97267646 0.99999499 0.02094487\n",
      " 0.01393441 0.88106078 0.07567005 0.00733386 0.93411273 0.97991532\n",
      " 0.10738049 0.01786031 0.98472875 0.8357057 ]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 42 TN= 41 FN= 16 FP= 19\n",
      "TP+FP 61\n",
      "precision 0.6885245901639344\n",
      "recall 0.7241379310344828\n",
      "F1 0.7058823529411765\n",
      "acc 0.7033898305084746\n",
      "AUCp 0.703735632183908\n",
      "AUC 0.7637931034482759\n",
      "\n",
      " The epoch is 150, average recall: 0.7241, average precision: 0.6885,average F1: 0.7059, average accuracy: 0.7034, average AUC: 0.7638\n",
      "Train Epoch: 151 [0/54 (0%)]\tTrain Loss: 0.001833\n",
      "Train Epoch: 151 [8/54 (15%)]\tTrain Loss: 0.009149\n",
      "Train Epoch: 151 [16/54 (30%)]\tTrain Loss: 0.052720\n",
      "Train Epoch: 151 [24/54 (44%)]\tTrain Loss: 0.041950\n",
      "Train Epoch: 151 [32/54 (59%)]\tTrain Loss: 0.018871\n",
      "Train Epoch: 151 [40/54 (74%)]\tTrain Loss: 0.029588\n",
      "Train Epoch: 151 [48/54 (89%)]\tTrain Loss: 0.023338\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.99518305 0.99950206 0.96263421 0.99994719 0.99544156 0.83728802\n",
      " 0.99166542 0.99983478 0.89999694 0.92348731 0.99570811 0.43486363\n",
      " 0.96806294 0.08848649 0.52663952 0.94051737 0.85239083 0.42924845\n",
      " 0.1351756  0.31582829 0.18305987 0.99842513 0.99925762 0.99926001\n",
      " 0.96198708 0.99995673 0.99995804 0.91993225 0.9720937  0.9777534\n",
      " 0.99838758 0.99955291 0.99532688 0.74355108 0.02308357 0.24655637\n",
      " 0.71063304 0.99476492 0.20324658 0.69301134 0.63366622 0.73238963\n",
      " 0.1007577  0.97641027 0.89995718 0.98381996 0.99998653 0.99997616\n",
      " 1.         0.99995208 1.         0.47811776 0.14920685 0.7923429\n",
      " 0.23489378 0.03223688 0.99974412 0.73509055 0.34068426 0.81518698\n",
      " 0.99970621 0.98602194 0.99978632 0.99991012 0.98892128 0.99959379\n",
      " 0.99986792 0.9998908  0.99999738 0.9959268  0.99991453 0.99998212\n",
      " 0.99994671 0.99966156 0.98244447 0.99997771 0.99999881 0.99999249\n",
      " 0.9999069  0.99999952 0.99999988 0.99999559 0.99999857 0.85528231\n",
      " 0.97478414 0.99976522 0.99973351 0.99982738 0.69771302 0.99789953\n",
      " 0.99935728 0.99906713 0.98783422 0.99999833 0.99975413 0.99829942\n",
      " 0.02670757 0.99897897 0.99499869 0.99996102 0.84579104 0.99999893\n",
      " 0.55020314 0.99998796 0.9999193  0.99380141 0.99999988 0.27639711\n",
      " 0.20221777 0.92103076 0.88367778 0.52405399 0.99732095 0.99831843\n",
      " 0.97269541 0.39196143 0.99731857 0.97465831]\n",
      "predict [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 152 [0/54 (0%)]\tTrain Loss: 0.007363\n",
      "Train Epoch: 152 [8/54 (15%)]\tTrain Loss: 0.033054\n",
      "Train Epoch: 152 [16/54 (30%)]\tTrain Loss: 0.009799\n",
      "Train Epoch: 152 [24/54 (44%)]\tTrain Loss: 0.020376\n",
      "Train Epoch: 152 [32/54 (59%)]\tTrain Loss: 0.016264\n",
      "Train Epoch: 152 [40/54 (74%)]\tTrain Loss: 0.015941\n",
      "Train Epoch: 152 [48/54 (89%)]\tTrain Loss: 0.011221\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.43076126e-03 3.51371855e-01 4.80903611e-02 8.03628266e-01\n",
      " 1.41545348e-02 9.08113143e-04 8.28720778e-02 3.54397088e-01\n",
      " 6.89426735e-02 2.94110477e-02 1.73448741e-01 1.32236667e-02\n",
      " 2.94548203e-03 5.66812290e-04 4.28361120e-03 1.62477198e-03\n",
      " 7.41464552e-04 1.06743068e-01 7.07924604e-01 1.14904955e-01\n",
      " 7.61569440e-02 8.73620331e-01 9.77897584e-01 9.73654509e-01\n",
      " 9.11342427e-02 9.98915195e-01 9.96821642e-01 9.91188064e-02\n",
      " 2.83853441e-01 3.37252878e-02 5.65206468e-01 9.05250251e-01\n",
      " 3.76825213e-01 3.92814800e-02 3.63394298e-04 1.58240844e-04\n",
      " 2.85275234e-03 9.35401738e-01 1.19198840e-02 1.82631407e-02\n",
      " 8.63354001e-03 1.49297891e-02 4.73243371e-02 1.78782959e-02\n",
      " 3.44431750e-03 3.02373264e-02 9.73103225e-01 9.13620830e-01\n",
      " 9.99949336e-01 9.92429912e-01 9.97460246e-01 2.18141871e-03\n",
      " 1.77823618e-04 1.16073596e-03 1.92712992e-01 1.07344647e-03\n",
      " 9.14307952e-01 4.23765741e-03 1.12273963e-02 3.76814464e-03\n",
      " 3.40948850e-01 1.56898960e-01 5.23489416e-01 9.01915014e-01\n",
      " 3.07579283e-02 3.24916422e-01 8.45497131e-01 6.36544466e-01\n",
      " 9.90910828e-01 9.46415007e-01 9.34994996e-01 9.56197202e-01\n",
      " 6.82253122e-01 9.07227278e-01 2.54906952e-01 7.40014434e-01\n",
      " 2.83687990e-02 5.86702943e-01 1.96866482e-01 9.98220742e-01\n",
      " 9.54563558e-01 9.93643999e-01 9.89596307e-01 4.54250365e-01\n",
      " 8.13044190e-01 9.63530600e-01 9.43491757e-01 9.52358842e-01\n",
      " 3.25193763e-01 2.31178522e-01 9.96339560e-01 8.35825562e-01\n",
      " 4.33392227e-01 9.99792755e-01 9.94263947e-01 8.55488420e-01\n",
      " 1.93119235e-02 8.21973443e-01 3.68532419e-01 9.88517523e-01\n",
      " 2.56118804e-01 9.99928117e-01 4.69997339e-02 9.98635113e-01\n",
      " 9.91378903e-01 8.46327186e-01 9.99871850e-01 3.69367911e-03\n",
      " 3.86002660e-03 1.36557072e-01 3.38041671e-02 5.09690940e-02\n",
      " 3.46003979e-01 9.25814390e-01 1.17287159e-01 3.05608939e-02\n",
      " 2.60656561e-05 4.14789468e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 153 [0/54 (0%)]\tTrain Loss: 0.002568\n",
      "Train Epoch: 153 [8/54 (15%)]\tTrain Loss: 0.023405\n",
      "Train Epoch: 153 [16/54 (30%)]\tTrain Loss: 0.028593\n",
      "Train Epoch: 153 [24/54 (44%)]\tTrain Loss: 0.021636\n",
      "Train Epoch: 153 [32/54 (59%)]\tTrain Loss: 0.009841\n",
      "Train Epoch: 153 [40/54 (74%)]\tTrain Loss: 0.010638\n",
      "Train Epoch: 153 [48/54 (89%)]\tTrain Loss: 0.041281\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.48893455e-01 9.77445126e-01 6.82089865e-01 9.66106355e-01\n",
      " 5.28171003e-01 7.40077496e-02 9.38601911e-01 9.14625525e-01\n",
      " 1.04634173e-01 7.87448943e-01 8.23334754e-01 7.72709906e-01\n",
      " 1.55961990e-01 8.25563818e-03 2.31495321e-01 1.10170878e-02\n",
      " 1.67891718e-02 1.80278674e-01 6.49243832e-01 6.65491521e-01\n",
      " 4.13946539e-01 9.38342273e-01 9.98862267e-01 9.96369004e-01\n",
      " 5.14345169e-01 9.98506367e-01 9.99248326e-01 9.56934154e-01\n",
      " 9.59541440e-01 6.59976840e-01 9.63652134e-01 9.92392898e-01\n",
      " 9.73760426e-01 3.65071860e-03 7.80283764e-04 4.64979671e-02\n",
      " 5.97351417e-03 8.91111970e-01 5.26668131e-02 2.16610767e-02\n",
      " 2.94058607e-03 8.51479173e-03 3.59729826e-02 7.88178980e-01\n",
      " 4.17181700e-01 8.11924696e-01 9.99708116e-01 9.95089114e-01\n",
      " 9.99997377e-01 9.99620914e-01 9.99982119e-01 8.01743183e-04\n",
      " 3.03195208e-01 2.28272472e-02 7.48932421e-01 2.06862673e-01\n",
      " 9.98903394e-01 1.97307263e-02 1.97824940e-01 8.67522955e-01\n",
      " 9.99891043e-01 9.88799036e-01 9.96383548e-01 9.99828577e-01\n",
      " 9.96811092e-01 9.54314947e-01 9.94430006e-01 9.98447239e-01\n",
      " 9.99787152e-01 9.99613345e-01 9.97502625e-01 9.98311639e-01\n",
      " 9.99855638e-01 9.99896407e-01 9.99634027e-01 9.99810278e-01\n",
      " 9.99662519e-01 9.99345481e-01 9.98849511e-01 9.99985456e-01\n",
      " 9.99987602e-01 9.99980927e-01 9.99994159e-01 8.58791530e-01\n",
      " 9.03180242e-01 9.99562681e-01 9.99497175e-01 9.99748528e-01\n",
      " 3.27553511e-01 1.56946763e-01 9.31628048e-01 9.96098399e-01\n",
      " 9.97785330e-01 9.99939322e-01 9.89633441e-01 7.35392392e-01\n",
      " 1.01314284e-01 5.68477929e-01 8.91288042e-01 9.95020628e-01\n",
      " 1.09690174e-01 9.99868751e-01 8.00474286e-02 9.99362051e-01\n",
      " 9.99074697e-01 9.96773303e-01 9.99999285e-01 5.18653775e-03\n",
      " 1.19390730e-02 1.68505624e-01 1.12980232e-03 1.27294600e-01\n",
      " 6.22682750e-01 6.65637016e-01 3.76595825e-01 6.79696798e-01\n",
      " 3.20898205e-01 6.84409440e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1.]\n",
      "Train Epoch: 154 [0/54 (0%)]\tTrain Loss: 0.020027\n",
      "Train Epoch: 154 [8/54 (15%)]\tTrain Loss: 0.079835\n",
      "Train Epoch: 154 [16/54 (30%)]\tTrain Loss: 0.042719\n",
      "Train Epoch: 154 [24/54 (44%)]\tTrain Loss: 0.134691\n",
      "Train Epoch: 154 [32/54 (59%)]\tTrain Loss: 0.082920\n",
      "Train Epoch: 154 [40/54 (74%)]\tTrain Loss: 0.068647\n",
      "Train Epoch: 154 [48/54 (89%)]\tTrain Loss: 0.031823\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.48049378 0.93348759 0.85782361 0.9598456  0.75370407 0.93042362\n",
      " 0.83539993 0.797562   0.86745012 0.54976809 0.51430058 0.13896568\n",
      " 0.2506918  0.76910675 0.88768274 0.7640295  0.58668596 0.36734676\n",
      " 0.38054392 0.80376136 0.84990299 0.8965534  0.99093854 0.98928469\n",
      " 0.5725596  0.99464476 0.99277836 0.95590585 0.60505217 0.4864305\n",
      " 0.94246906 0.99258476 0.99533528 0.15196031 0.01030936 0.35397822\n",
      " 0.37655729 0.86919266 0.70282227 0.78436047 0.50916636 0.49002165\n",
      " 0.45800942 0.94674718 0.75667882 0.894916   0.99838471 0.99552238\n",
      " 0.99994195 0.99181706 0.99936765 0.0409028  0.50666285 0.02654618\n",
      " 0.60300535 0.22980715 0.99947435 0.06254698 0.21738136 0.8977809\n",
      " 0.99988544 0.97397703 0.99964118 0.999964   0.99880576 0.98885077\n",
      " 0.9897328  0.99201715 0.99969947 0.99102801 0.96535814 0.91909522\n",
      " 0.99965656 0.99614429 0.99955899 0.99994469 0.99962723 0.99897552\n",
      " 0.99630177 0.99980158 0.99858439 0.99961543 0.9998098  0.89620721\n",
      " 0.98463166 0.9947142  0.99749607 0.99825495 0.70781338 0.69630641\n",
      " 0.98787016 0.9896276  0.97734034 0.99811089 0.71245831 0.93519545\n",
      " 0.11039859 0.90943348 0.94514596 0.956388   0.77825093 0.99998236\n",
      " 0.62373579 0.95787758 0.78669834 0.99524659 0.9998709  0.31522277\n",
      " 0.16390069 0.82247728 0.35557285 0.30840373 0.70888048 0.74962169\n",
      " 0.74389488 0.68770528 0.53437054 0.58604109]\n",
      "predict [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 155 [0/54 (0%)]\tTrain Loss: 0.011783\n",
      "Train Epoch: 155 [8/54 (15%)]\tTrain Loss: 0.027108\n",
      "Train Epoch: 155 [16/54 (30%)]\tTrain Loss: 0.098569\n",
      "Train Epoch: 155 [24/54 (44%)]\tTrain Loss: 0.092488\n",
      "Train Epoch: 155 [32/54 (59%)]\tTrain Loss: 0.106914\n",
      "Train Epoch: 155 [40/54 (74%)]\tTrain Loss: 0.033589\n",
      "Train Epoch: 155 [48/54 (89%)]\tTrain Loss: 0.026299\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.34999624e-03 1.60124168e-01 6.49370700e-02 1.65529400e-01\n",
      " 1.38677023e-02 1.35659042e-03 2.35044673e-01 8.12033489e-02\n",
      " 3.82267423e-02 1.22351117e-01 3.38443339e-01 3.60767096e-02\n",
      " 2.42794156e-02 9.49176843e-04 2.41589244e-03 4.20509391e-02\n",
      " 4.20022346e-02 4.73315232e-02 2.42488459e-01 1.94706917e-01\n",
      " 3.80735993e-01 2.90896416e-01 9.13071036e-01 5.91606379e-01\n",
      " 3.01476359e-01 9.46005464e-01 8.20791066e-01 4.25311983e-01\n",
      " 2.82964170e-01 5.69354296e-02 6.76941350e-02 5.55420399e-01\n",
      " 1.31978974e-01 3.00960504e-02 4.87771071e-03 8.03529620e-02\n",
      " 6.33976385e-02 3.09547037e-01 3.48607227e-02 2.14720845e-01\n",
      " 5.04861288e-02 6.25051111e-02 4.16583829e-02 1.39467958e-02\n",
      " 5.15562296e-02 4.90352092e-03 8.16517994e-02 6.02266863e-02\n",
      " 8.57488275e-01 4.90480632e-01 5.08628726e-01 5.45436284e-03\n",
      " 1.47128934e-02 4.20735311e-03 7.46261626e-02 6.60079494e-02\n",
      " 4.36520725e-01 1.91418920e-02 1.66388795e-01 8.23502801e-03\n",
      " 1.87131852e-01 7.20540881e-02 1.29557326e-01 4.31161493e-01\n",
      " 5.83754107e-02 9.71557871e-02 7.18415007e-02 7.40414619e-01\n",
      " 9.61147726e-01 4.39208806e-01 6.25651330e-02 4.91525307e-02\n",
      " 3.80162895e-01 2.67361611e-01 3.25966090e-01 1.59539923e-01\n",
      " 7.44163275e-01 6.37158811e-01 3.86773329e-03 2.82604516e-01\n",
      " 1.94005042e-01 1.63384169e-01 2.62953490e-01 2.15910241e-01\n",
      " 5.14642715e-01 2.89170504e-01 1.44864812e-01 1.23408981e-01\n",
      " 2.00370282e-01 2.98503637e-01 9.51226175e-01 1.48622289e-01\n",
      " 1.44487470e-01 9.98660684e-01 9.10403013e-01 8.73872578e-01\n",
      " 2.37781014e-02 3.03467840e-01 8.54881465e-01 5.83795130e-01\n",
      " 9.47226733e-02 4.04490262e-01 6.67456314e-02 4.31206703e-01\n",
      " 4.65129972e-01 3.41562420e-01 9.68711317e-01 2.51211654e-02\n",
      " 4.99744117e-02 2.55007237e-01 1.29834875e-01 7.51188323e-02\n",
      " 4.76462126e-01 7.66560018e-01 2.26027705e-02 5.03552072e-02\n",
      " 7.25694180e-01 2.53831804e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 156 [0/54 (0%)]\tTrain Loss: 0.051811\n",
      "Train Epoch: 156 [8/54 (15%)]\tTrain Loss: 0.034392\n",
      "Train Epoch: 156 [16/54 (30%)]\tTrain Loss: 0.033665\n",
      "Train Epoch: 156 [24/54 (44%)]\tTrain Loss: 0.067187\n",
      "Train Epoch: 156 [32/54 (59%)]\tTrain Loss: 0.095461\n",
      "Train Epoch: 156 [40/54 (74%)]\tTrain Loss: 0.051188\n",
      "Train Epoch: 156 [48/54 (89%)]\tTrain Loss: 0.085633\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.70531368e-01 9.99170899e-01 9.95277286e-01 9.49643314e-01\n",
      " 2.39744082e-01 8.03775072e-01 9.98035967e-01 9.65164542e-01\n",
      " 4.40717906e-01 1.50669724e-01 7.87064970e-01 1.06525511e-01\n",
      " 5.44243529e-02 9.58264545e-02 1.81950137e-01 3.30080092e-02\n",
      " 2.09762971e-03 2.34954283e-01 3.96322533e-02 7.44615555e-01\n",
      " 6.55083299e-01 8.01626325e-01 8.43468487e-01 7.34773755e-01\n",
      " 3.69259536e-01 7.72780299e-01 8.52771699e-01 6.42657757e-01\n",
      " 8.39399621e-02 2.57312149e-01 2.17198029e-01 5.72842121e-01\n",
      " 9.04965341e-01 4.41994593e-02 2.60110013e-04 3.09945717e-02\n",
      " 5.62141761e-02 5.08295834e-01 3.77850719e-02 7.83589184e-02\n",
      " 2.41900794e-02 3.30294445e-02 2.21903890e-01 3.00529212e-01\n",
      " 5.17646372e-01 6.47849143e-01 9.99916315e-01 9.99783576e-01\n",
      " 9.99999642e-01 9.74882543e-01 9.99999285e-01 2.32937951e-02\n",
      " 2.47588322e-01 8.16580057e-01 1.79117680e-01 1.67637080e-01\n",
      " 3.53823036e-01 3.72830555e-02 1.65388454e-02 4.73941594e-01\n",
      " 9.61012602e-01 9.49864209e-01 9.79029059e-01 9.91149187e-01\n",
      " 9.75560069e-01 9.45824265e-01 8.31619978e-01 9.92587864e-01\n",
      " 9.99826491e-01 9.90626812e-01 9.57249582e-01 9.31937575e-01\n",
      " 9.96040344e-01 9.82846797e-01 9.92721140e-01 9.96141493e-01\n",
      " 9.99985814e-01 9.99948859e-01 9.97956514e-01 9.83844459e-01\n",
      " 9.97630239e-01 9.96455312e-01 9.98113751e-01 9.27956820e-01\n",
      " 8.71841431e-01 8.42652678e-01 9.54398811e-01 9.50558782e-01\n",
      " 8.56321584e-03 2.61038214e-01 4.30914491e-01 8.05073142e-01\n",
      " 9.03879166e-01 9.95203972e-01 8.20087433e-01 8.88196945e-01\n",
      " 4.88526821e-02 9.67802703e-01 5.34387290e-01 9.26362574e-01\n",
      " 1.51926996e-02 9.98452425e-01 3.54430415e-02 9.85412061e-01\n",
      " 9.88525867e-01 9.78967726e-01 9.99848485e-01 7.89241344e-02\n",
      " 6.69323280e-02 1.93416238e-01 6.53724149e-02 6.31069839e-01\n",
      " 9.18115079e-01 7.31481373e-01 1.83657274e-01 1.17332608e-01\n",
      " 3.51493388e-01 5.82144819e-02]\n",
      "predict [1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 157 [0/54 (0%)]\tTrain Loss: 0.029840\n",
      "Train Epoch: 157 [8/54 (15%)]\tTrain Loss: 0.131957\n",
      "Train Epoch: 157 [16/54 (30%)]\tTrain Loss: 0.035353\n",
      "Train Epoch: 157 [24/54 (44%)]\tTrain Loss: 0.042521\n",
      "Train Epoch: 157 [32/54 (59%)]\tTrain Loss: 0.071385\n",
      "Train Epoch: 157 [40/54 (74%)]\tTrain Loss: 0.036889\n",
      "Train Epoch: 157 [48/54 (89%)]\tTrain Loss: 0.019241\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.70628687e-02 9.70678091e-01 9.53510761e-01 9.66648102e-01\n",
      " 2.51202017e-01 4.04850952e-02 9.70804393e-01 8.25992525e-01\n",
      " 1.71959519e-01 3.39559406e-01 9.17575598e-01 2.55942494e-01\n",
      " 1.04953879e-02 1.09329792e-02 1.53816547e-02 1.30353514e-02\n",
      " 2.96755135e-03 6.43970132e-01 6.06711805e-01 8.45412672e-01\n",
      " 9.46766853e-01 9.75957990e-01 9.93083715e-01 9.84166384e-01\n",
      " 9.37367976e-01 9.88047719e-01 9.92509842e-01 9.64359581e-01\n",
      " 2.68736482e-01 3.79681826e-01 7.77543187e-01 7.58101046e-01\n",
      " 8.99227977e-01 1.30692840e-01 8.87061236e-04 2.18707293e-01\n",
      " 4.57639992e-01 5.57835817e-01 3.67376238e-01 4.06285435e-01\n",
      " 1.44580558e-01 8.50423500e-02 5.29104292e-01 4.22862142e-01\n",
      " 3.51591617e-01 1.01926781e-01 9.74255502e-01 8.56045127e-01\n",
      " 9.99780834e-01 8.13329518e-01 9.99464452e-01 2.82128565e-02\n",
      " 3.46121699e-01 9.17519778e-02 1.21417403e-01 3.93635362e-01\n",
      " 8.75508010e-01 2.28974491e-01 5.35565376e-01 5.63759319e-02\n",
      " 9.91935134e-01 9.36609983e-01 9.74101663e-01 9.95975912e-01\n",
      " 9.29322660e-01 9.35734928e-01 9.28236008e-01 9.99235511e-01\n",
      " 9.99957323e-01 5.87633193e-01 9.20429051e-01 9.07269180e-01\n",
      " 9.93991911e-01 9.71172571e-01 9.97744083e-01 9.97360289e-01\n",
      " 9.99898672e-01 9.97936964e-01 9.31394994e-01 9.98487711e-01\n",
      " 9.98854637e-01 9.97583389e-01 9.97112513e-01 9.06040430e-01\n",
      " 9.74654913e-01 9.40008938e-01 9.81450200e-01 9.24784482e-01\n",
      " 2.37308875e-01 8.44542384e-01 9.81552422e-01 7.38185048e-01\n",
      " 8.46723139e-01 9.99848485e-01 9.92900848e-01 9.97651994e-01\n",
      " 2.45681610e-02 8.68190169e-01 9.91137147e-01 9.31931674e-01\n",
      " 7.89455354e-01 9.98606145e-01 2.87421077e-01 9.93059158e-01\n",
      " 9.53027368e-01 9.33317482e-01 9.99332726e-01 1.88236609e-01\n",
      " 1.61339909e-01 4.90948528e-01 1.76214688e-02 1.86686255e-02\n",
      " 7.97603428e-01 9.61336076e-01 2.31205776e-01 5.16659141e-01\n",
      " 9.87723589e-01 9.21039462e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 158 [0/54 (0%)]\tTrain Loss: 0.011588\n",
      "Train Epoch: 158 [8/54 (15%)]\tTrain Loss: 0.025328\n",
      "Train Epoch: 158 [16/54 (30%)]\tTrain Loss: 0.079340\n",
      "Train Epoch: 158 [24/54 (44%)]\tTrain Loss: 0.087874\n",
      "Train Epoch: 158 [32/54 (59%)]\tTrain Loss: 0.027171\n",
      "Train Epoch: 158 [40/54 (74%)]\tTrain Loss: 0.007783\n",
      "Train Epoch: 158 [48/54 (89%)]\tTrain Loss: 0.075118\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.71040723e-02 9.47083890e-01 6.85218036e-01 5.40104210e-02\n",
      " 8.64038616e-03 2.14275366e-04 8.42725694e-01 2.11130634e-01\n",
      " 1.03563862e-02 9.70824957e-02 3.97666901e-01 2.10653767e-02\n",
      " 1.18258793e-03 1.52125198e-03 2.76432373e-04 3.12404241e-03\n",
      " 1.13096740e-03 6.92150071e-02 3.24602835e-02 4.95441407e-01\n",
      " 3.29700887e-01 3.73178124e-01 8.57300103e-01 9.14336026e-01\n",
      " 9.03647095e-02 9.47863042e-01 9.77442741e-01 2.62169510e-01\n",
      " 3.53344455e-02 1.44820381e-02 7.47974813e-02 2.25105017e-01\n",
      " 5.17071664e-01 3.80576309e-03 2.37130749e-04 2.76252031e-02\n",
      " 3.92536959e-03 3.06117292e-02 1.00870393e-02 1.02781847e-01\n",
      " 1.45569406e-02 9.50940698e-03 1.66382529e-02 8.55057780e-03\n",
      " 3.68509702e-02 1.19351316e-02 9.38265085e-01 5.54544151e-01\n",
      " 9.99887586e-01 5.97185671e-01 9.99717653e-01 2.14351946e-03\n",
      " 5.05501218e-03 3.23091168e-03 1.17301261e-02 2.91229994e-03\n",
      " 6.27475858e-01 2.73801223e-03 9.85199958e-03 2.15447173e-04\n",
      " 9.82719898e-01 6.75738394e-01 9.53592896e-01 9.89116132e-01\n",
      " 1.24278784e-01 6.31532192e-01 4.29271698e-01 9.52545404e-01\n",
      " 9.99799788e-01 4.02236819e-01 7.57531941e-01 8.09798896e-01\n",
      " 9.92722452e-01 9.29934204e-01 9.21160400e-01 9.61929917e-01\n",
      " 9.99657512e-01 9.95845258e-01 7.31353223e-01 9.52713490e-01\n",
      " 9.94003356e-01 9.81355488e-01 9.92899299e-01 4.76684272e-01\n",
      " 5.78243613e-01 8.86262536e-01 8.13478708e-01 8.37404370e-01\n",
      " 1.30055090e-02 2.38496661e-01 8.03533912e-01 4.93802518e-01\n",
      " 4.04898405e-01 9.98035371e-01 9.55000639e-01 9.84679759e-01\n",
      " 2.08857027e-03 1.56721815e-01 7.89759278e-01 4.86389548e-01\n",
      " 8.24010149e-02 9.95952129e-01 8.62815883e-03 9.35484350e-01\n",
      " 7.09396183e-01 7.84850359e-01 9.99823391e-01 5.87438792e-02\n",
      " 1.76644546e-03 2.65858054e-01 2.97025009e-03 1.60657614e-02\n",
      " 7.07203925e-01 6.82757318e-01 3.36843617e-02 7.35449642e-02\n",
      " 8.98512304e-01 3.12013924e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 159 [0/54 (0%)]\tTrain Loss: 0.044402\n",
      "Train Epoch: 159 [8/54 (15%)]\tTrain Loss: 0.020697\n",
      "Train Epoch: 159 [16/54 (30%)]\tTrain Loss: 0.046402\n",
      "Train Epoch: 159 [24/54 (44%)]\tTrain Loss: 0.097107\n",
      "Train Epoch: 159 [32/54 (59%)]\tTrain Loss: 0.041549\n",
      "Train Epoch: 159 [40/54 (74%)]\tTrain Loss: 0.068781\n",
      "Train Epoch: 159 [48/54 (89%)]\tTrain Loss: 0.035703\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.81534330e-03 7.94880688e-01 3.24749023e-01 1.40803292e-01\n",
      " 7.73160858e-03 1.40293327e-03 6.04376078e-01 1.65120482e-01\n",
      " 9.63745546e-03 4.65270802e-02 4.59060580e-01 1.01254163e-02\n",
      " 7.92350527e-03 2.32101954e-03 2.12363899e-03 1.14919301e-02\n",
      " 1.41705503e-03 4.53859009e-02 2.71795690e-02 3.52136195e-01\n",
      " 1.53951511e-01 5.63199043e-01 9.63496685e-01 9.78888333e-01\n",
      " 1.27022430e-01 9.69665110e-01 9.29658115e-01 5.24623930e-01\n",
      " 1.07555278e-01 2.88769528e-02 6.75653815e-01 6.69250488e-01\n",
      " 3.57603908e-01 7.36669230e-04 2.17022971e-04 3.00139072e-03\n",
      " 6.67732581e-03 3.57858747e-01 1.36201316e-03 6.99707195e-02\n",
      " 1.81429237e-02 1.18740108e-02 2.80252043e-02 8.73415023e-02\n",
      " 5.77937961e-02 5.27424067e-02 8.03676188e-01 1.64889812e-01\n",
      " 9.97662663e-01 5.13517559e-02 9.69442666e-01 7.94182532e-03\n",
      " 6.63763098e-03 5.92323020e-02 5.13614947e-03 4.67331335e-02\n",
      " 7.31525064e-01 7.76518555e-03 1.86579689e-01 5.96945174e-04\n",
      " 7.24333465e-01 1.17590234e-01 3.42152774e-01 6.25693619e-01\n",
      " 1.25891745e-01 9.62934852e-01 5.07246196e-01 9.95413840e-01\n",
      " 9.97707129e-01 5.74424267e-01 7.80802295e-02 1.48597986e-01\n",
      " 9.64203477e-01 4.25953001e-01 9.62902367e-01 7.96081364e-01\n",
      " 9.77387846e-01 9.22091246e-01 4.61304456e-01 9.66225445e-01\n",
      " 8.99062395e-01 7.59333313e-01 9.48492825e-01 2.39441872e-01\n",
      " 1.82254642e-01 1.22847728e-01 4.44191664e-01 2.23810062e-01\n",
      " 1.21859508e-02 7.32091904e-01 9.80615675e-01 3.87525082e-01\n",
      " 3.76763403e-01 9.99205530e-01 7.27983117e-01 9.73997712e-01\n",
      " 3.81707144e-03 2.61430498e-02 3.49082351e-01 5.62848151e-01\n",
      " 2.40282156e-02 9.84353602e-01 3.16161336e-03 9.90247011e-01\n",
      " 8.48265707e-01 7.88001299e-01 9.99491811e-01 6.52271658e-02\n",
      " 3.14701279e-03 2.74426341e-01 7.76550174e-03 1.60916708e-04\n",
      " 1.59353539e-01 6.77448392e-01 3.93619016e-02 3.97731252e-02\n",
      " 7.12357938e-01 6.83781058e-02]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 160 [0/54 (0%)]\tTrain Loss: 0.004310\n",
      "Train Epoch: 160 [8/54 (15%)]\tTrain Loss: 0.037993\n",
      "Train Epoch: 160 [16/54 (30%)]\tTrain Loss: 0.047221\n",
      "Train Epoch: 160 [24/54 (44%)]\tTrain Loss: 0.040329\n",
      "Train Epoch: 160 [32/54 (59%)]\tTrain Loss: 0.066787\n",
      "Train Epoch: 160 [40/54 (74%)]\tTrain Loss: 0.077161\n",
      "Train Epoch: 160 [48/54 (89%)]\tTrain Loss: 0.028580\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.01846938 0.98214781 0.9114241  0.76949531 0.02569493 0.01101806\n",
      " 0.95633084 0.74614191 0.09339061 0.16559331 0.55875969 0.08995967\n",
      " 0.01966206 0.00380615 0.01784697 0.0180295  0.02551695 0.54366344\n",
      " 0.32991076 0.82852608 0.32344013 0.92222071 0.9903971  0.99064577\n",
      " 0.17328751 0.98555577 0.99007052 0.68264425 0.57468307 0.14995348\n",
      " 0.31105515 0.77265036 0.32891026 0.0034409  0.00159484 0.01929217\n",
      " 0.02582314 0.53031611 0.08465324 0.16554359 0.12887412 0.02653099\n",
      " 0.08344912 0.3182652  0.27790663 0.01825415 0.91040361 0.48969671\n",
      " 0.99852967 0.6113466  0.99061906 0.08609322 0.01368226 0.20793323\n",
      " 0.02826095 0.10457534 0.93643165 0.05989799 0.13766767 0.00322893\n",
      " 0.93189514 0.51139635 0.86920428 0.96738863 0.52474701 0.94574118\n",
      " 0.94446534 0.99325103 0.9997856  0.44574684 0.55282301 0.55165952\n",
      " 0.99632519 0.86185604 0.96073109 0.90739048 0.99976236 0.99909306\n",
      " 0.92005551 0.99576437 0.99597895 0.98293704 0.99881411 0.42428428\n",
      " 0.62026465 0.84571207 0.94279915 0.93486083 0.0502858  0.85960972\n",
      " 0.89946669 0.90167516 0.83087087 0.99830025 0.97011167 0.97509456\n",
      " 0.01388691 0.16112956 0.49721169 0.7899543  0.02043248 0.99909616\n",
      " 0.00878474 0.93996114 0.94863868 0.8347488  0.99916005 0.05923011\n",
      " 0.01369536 0.67484957 0.01612399 0.00236468 0.20431414 0.7877211\n",
      " 0.14440553 0.13432306 0.78227949 0.38126484]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 44 TN= 38 FN= 14 FP= 22\n",
      "TP+FP 66\n",
      "precision 0.6666666666666666\n",
      "recall 0.7586206896551724\n",
      "F1 0.7096774193548386\n",
      "acc 0.6949152542372882\n",
      "AUCp 0.6959770114942528\n",
      "AUC 0.7336206896551725\n",
      "\n",
      " The epoch is 160, average recall: 0.7586, average precision: 0.6667,average F1: 0.7097, average accuracy: 0.6949, average AUC: 0.7336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 161 [0/54 (0%)]\tTrain Loss: 0.034002\n",
      "Train Epoch: 161 [8/54 (15%)]\tTrain Loss: 0.015050\n",
      "Train Epoch: 161 [16/54 (30%)]\tTrain Loss: 0.008676\n",
      "Train Epoch: 161 [24/54 (44%)]\tTrain Loss: 0.019266\n",
      "Train Epoch: 161 [32/54 (59%)]\tTrain Loss: 0.012059\n",
      "Train Epoch: 161 [40/54 (74%)]\tTrain Loss: 0.057146\n",
      "Train Epoch: 161 [48/54 (89%)]\tTrain Loss: 0.021432\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.01487744e-05 4.15774107e-01 1.05401296e-02 1.39102014e-03\n",
      " 2.57830543e-05 5.89500596e-05 3.92545527e-03 3.41962768e-05\n",
      " 7.79758324e-04 2.05697119e-02 1.21989904e-03 2.07589520e-03\n",
      " 5.07860350e-05 7.92488481e-06 2.52447899e-05 1.66812370e-05\n",
      " 4.01983016e-06 4.87196958e-03 2.44392641e-03 2.58980412e-03\n",
      " 7.60262739e-03 4.57115285e-02 6.64116681e-01 6.89252317e-01\n",
      " 1.35728822e-03 8.10524285e-01 8.77340794e-01 4.59059235e-03\n",
      " 1.15539995e-03 7.21123163e-03 6.58704340e-03 4.11204807e-02\n",
      " 1.87760312e-03 1.93746546e-05 2.68622830e-06 3.23613240e-05\n",
      " 2.10604794e-05 4.51162318e-03 1.67175109e-04 1.58407271e-03\n",
      " 1.96104098e-04 4.07879794e-04 2.76181614e-04 1.44004240e-04\n",
      " 2.73764221e-04 1.75574142e-03 4.85135764e-01 4.31780629e-02\n",
      " 9.80166376e-01 5.15822053e-01 8.57208550e-01 1.86473358e-06\n",
      " 2.09264617e-05 6.33712567e-04 4.17064242e-02 2.12981213e-05\n",
      " 2.58895159e-01 6.30458671e-05 1.19247838e-04 7.69883991e-06\n",
      " 9.66835856e-01 6.21635497e-01 9.39458370e-01 9.88985538e-01\n",
      " 3.17613804e-03 3.85063444e-03 7.07412288e-02 8.33910882e-01\n",
      " 9.96185958e-01 1.61182776e-01 8.10131431e-01 8.26847851e-01\n",
      " 9.35847223e-01 5.52890480e-01 5.97957075e-01 8.53739798e-01\n",
      " 9.87860978e-01 9.75435078e-01 1.35748014e-01 9.58761394e-01\n",
      " 9.67462599e-01 9.75786388e-01 9.95247781e-01 1.40070975e-01\n",
      " 1.55223042e-01 8.03036511e-01 4.99724746e-01 6.23221934e-01\n",
      " 1.73977402e-03 4.09067385e-02 9.80505824e-01 1.68282166e-03\n",
      " 1.51722664e-02 9.68022287e-01 5.97191393e-01 5.24442017e-01\n",
      " 2.64691713e-04 7.82502815e-03 2.73751542e-02 6.14037037e-01\n",
      " 1.00742290e-02 9.88502264e-01 2.21985203e-04 1.20461725e-01\n",
      " 6.31173849e-01 7.47521460e-01 9.92558718e-01 4.82173578e-04\n",
      " 9.03227250e-04 6.65625557e-02 1.78263639e-04 6.98751028e-05\n",
      " 5.61568653e-03 3.70550454e-02 2.73987539e-02 1.98506434e-02\n",
      " 2.18810707e-01 1.82916666e-03]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 162 [0/54 (0%)]\tTrain Loss: 0.114728\n",
      "Train Epoch: 162 [8/54 (15%)]\tTrain Loss: 0.015547\n",
      "Train Epoch: 162 [16/54 (30%)]\tTrain Loss: 0.020844\n",
      "Train Epoch: 162 [24/54 (44%)]\tTrain Loss: 0.059583\n",
      "Train Epoch: 162 [32/54 (59%)]\tTrain Loss: 0.029709\n",
      "Train Epoch: 162 [40/54 (74%)]\tTrain Loss: 0.033279\n",
      "Train Epoch: 162 [48/54 (89%)]\tTrain Loss: 0.027079\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.0309936  0.84516215 0.62952161 0.61832863 0.02910804 0.00527089\n",
      " 0.75623178 0.15325539 0.0280818  0.35468498 0.1654146  0.13161775\n",
      " 0.01179562 0.00538064 0.00484908 0.03764864 0.03163584 0.0931488\n",
      " 0.06376749 0.27874658 0.14411628 0.54911792 0.93682665 0.93522531\n",
      " 0.09647553 0.9622283  0.95754761 0.32947597 0.18570083 0.15271552\n",
      " 0.22520162 0.89914459 0.67353517 0.00741223 0.00375162 0.02200856\n",
      " 0.00872189 0.35986742 0.0305149  0.23101667 0.07323802 0.07577587\n",
      " 0.04086562 0.05990162 0.12051968 0.10246743 0.97306484 0.90799737\n",
      " 0.99984348 0.86561471 0.99920541 0.00738275 0.00876691 0.13720465\n",
      " 0.11666518 0.01714648 0.60545027 0.06754874 0.02503874 0.02363703\n",
      " 0.87855554 0.30855528 0.58279109 0.91095269 0.3339794  0.86891508\n",
      " 0.88296229 0.98713779 0.99982077 0.87230426 0.86001784 0.82976502\n",
      " 0.99612504 0.93282956 0.8745864  0.72104931 0.97610438 0.97534865\n",
      " 0.90952575 0.99838626 0.99802089 0.99582493 0.99836046 0.41086987\n",
      " 0.59366292 0.90974146 0.90694922 0.94159597 0.30706155 0.34406909\n",
      " 0.9888469  0.74264318 0.52349436 0.99954504 0.94109201 0.98862284\n",
      " 0.0091812  0.11123504 0.20610996 0.83594936 0.05570085 0.99010289\n",
      " 0.01462878 0.86588168 0.95502335 0.70980656 0.99911648 0.14240406\n",
      " 0.03765148 0.80502087 0.11760633 0.06119669 0.78470677 0.66649026\n",
      " 0.02286799 0.04974213 0.84057969 0.4641526 ]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 163 [0/54 (0%)]\tTrain Loss: 0.016141\n",
      "Train Epoch: 163 [8/54 (15%)]\tTrain Loss: 0.015544\n",
      "Train Epoch: 163 [16/54 (30%)]\tTrain Loss: 0.015103\n",
      "Train Epoch: 163 [24/54 (44%)]\tTrain Loss: 0.026697\n",
      "Train Epoch: 163 [32/54 (59%)]\tTrain Loss: 0.021405\n",
      "Train Epoch: 163 [40/54 (74%)]\tTrain Loss: 0.004859\n",
      "Train Epoch: 163 [48/54 (89%)]\tTrain Loss: 0.041336\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.01299999 0.95566136 0.72508222 0.99624062 0.49667659 0.10846169\n",
      " 0.86532629 0.82781625 0.02046344 0.39046976 0.16523877 0.07075755\n",
      " 0.07053222 0.00439294 0.00251877 0.10328557 0.02550014 0.12072917\n",
      " 0.14996526 0.29893714 0.01974446 0.58851457 0.99584752 0.96069586\n",
      " 0.07185674 0.99656373 0.97149795 0.3833963  0.18640713 0.06133089\n",
      " 0.11905801 0.66832823 0.69723952 0.11299444 0.00221789 0.00600659\n",
      " 0.00677756 0.88272965 0.03029706 0.27294242 0.0375632  0.00768525\n",
      " 0.050595   0.03786756 0.1799233  0.04926239 0.97549522 0.66377538\n",
      " 0.99857724 0.5268749  0.99117517 0.07519217 0.01653053 0.15783812\n",
      " 0.0327773  0.11193431 0.71369678 0.1678526  0.01846724 0.01280864\n",
      " 0.98512346 0.80343419 0.96120226 0.99522555 0.83758301 0.96013409\n",
      " 0.98300505 0.99924183 0.99998045 0.45063409 0.90576428 0.93316507\n",
      " 0.9996506  0.97916496 0.96877903 0.89000964 0.99975556 0.99949837\n",
      " 0.99321562 0.9977181  0.99977964 0.99517977 0.99935549 0.88495392\n",
      " 0.89437652 0.89232093 0.98303473 0.98294961 0.16189782 0.82239658\n",
      " 0.99708825 0.1850643  0.69572425 0.99998868 0.99535251 0.99915421\n",
      " 0.01623151 0.07252317 0.4323557  0.98230481 0.21287853 0.99956781\n",
      " 0.05956069 0.95980465 0.95419478 0.83149242 0.99976188 0.01775736\n",
      " 0.00991161 0.30745816 0.28722948 0.03060135 0.57956177 0.84517545\n",
      " 0.29665309 0.11140537 0.94367993 0.99712843]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 164 [0/54 (0%)]\tTrain Loss: 0.002114\n",
      "Train Epoch: 164 [8/54 (15%)]\tTrain Loss: 0.010850\n",
      "Train Epoch: 164 [16/54 (30%)]\tTrain Loss: 0.060215\n",
      "Train Epoch: 164 [24/54 (44%)]\tTrain Loss: 0.001584\n",
      "Train Epoch: 164 [32/54 (59%)]\tTrain Loss: 0.017676\n",
      "Train Epoch: 164 [40/54 (74%)]\tTrain Loss: 0.026048\n",
      "Train Epoch: 164 [48/54 (89%)]\tTrain Loss: 0.013760\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.56681848e-03 6.60591245e-01 2.96885133e-01 9.94735003e-01\n",
      " 1.63309023e-01 9.83240921e-03 1.03737764e-01 6.52609527e-01\n",
      " 1.21341599e-02 2.69964635e-01 8.45103323e-01 1.83620304e-02\n",
      " 9.84974355e-02 3.15249991e-03 1.05741341e-03 1.21818762e-02\n",
      " 2.85551138e-02 1.99833378e-01 6.04395151e-01 7.96406448e-01\n",
      " 6.09610200e-01 9.52639043e-01 9.99180019e-01 9.94940758e-01\n",
      " 2.63551027e-01 9.99476612e-01 9.98223364e-01 9.41376090e-01\n",
      " 9.54763889e-02 2.90182419e-02 9.48502123e-01 7.15324879e-01\n",
      " 9.43173945e-01 1.53705448e-01 6.60711550e-04 3.06176953e-02\n",
      " 1.33676454e-01 9.19703901e-01 1.34503320e-02 1.81578338e-01\n",
      " 1.43996431e-02 1.53696835e-02 9.44493152e-03 1.06940940e-01\n",
      " 2.43151322e-01 1.50449891e-02 9.60825264e-01 1.35800228e-01\n",
      " 9.99920249e-01 9.39092040e-01 9.92568374e-01 3.25094089e-02\n",
      " 7.54173696e-02 2.53093522e-02 1.49420202e-01 1.37304500e-01\n",
      " 8.59707952e-01 9.70518962e-02 9.02641639e-02 4.95676277e-03\n",
      " 9.18587267e-01 2.87034631e-01 8.00160408e-01 9.77553785e-01\n",
      " 9.61482525e-01 9.97245431e-01 9.96809185e-01 9.99878168e-01\n",
      " 9.99998927e-01 6.77660644e-01 8.03213000e-01 7.42678583e-01\n",
      " 9.99816000e-01 9.96993184e-01 9.99109447e-01 6.78576171e-01\n",
      " 9.95417356e-01 9.90050197e-01 8.56934726e-01 9.98182535e-01\n",
      " 9.99859214e-01 9.95606720e-01 9.99554694e-01 8.79459023e-01\n",
      " 9.18023705e-01 9.31890488e-01 9.79090810e-01 9.44366574e-01\n",
      " 7.92948544e-01 9.94106531e-01 9.99978662e-01 6.85116470e-01\n",
      " 9.43045318e-01 9.99999762e-01 9.99930620e-01 9.99994755e-01\n",
      " 3.78028788e-02 8.18067789e-01 9.95031595e-01 9.99309063e-01\n",
      " 1.12996019e-01 9.99972224e-01 7.88887665e-02 9.96908128e-01\n",
      " 9.98938024e-01 8.81762326e-01 9.99922395e-01 4.89912033e-01\n",
      " 5.22165969e-02 9.27153230e-01 9.47821856e-01 1.99046090e-01\n",
      " 9.99549448e-01 9.91033375e-01 7.85333991e-01 1.99788034e-01\n",
      " 9.92547214e-01 9.82403994e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 165 [0/54 (0%)]\tTrain Loss: 0.016263\n",
      "Train Epoch: 165 [8/54 (15%)]\tTrain Loss: 0.009662\n",
      "Train Epoch: 165 [16/54 (30%)]\tTrain Loss: 0.003148\n",
      "Train Epoch: 165 [24/54 (44%)]\tTrain Loss: 0.007305\n",
      "Train Epoch: 165 [32/54 (59%)]\tTrain Loss: 0.006420\n",
      "Train Epoch: 165 [40/54 (74%)]\tTrain Loss: 0.029266\n",
      "Train Epoch: 165 [48/54 (89%)]\tTrain Loss: 0.003339\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.46565497e-01 9.91398096e-01 8.65110159e-01 9.39560950e-01\n",
      " 2.42669672e-01 6.47768304e-02 8.50004613e-01 8.65115404e-01\n",
      " 6.38447627e-02 3.96067411e-01 9.67142284e-02 9.33439657e-02\n",
      " 7.33098062e-03 5.63424453e-03 4.35901387e-03 1.17850043e-02\n",
      " 1.37053058e-02 2.65433460e-01 1.46661937e-01 8.92614201e-02\n",
      " 3.33869867e-02 7.98298061e-01 9.77839828e-01 7.97605395e-01\n",
      " 6.84754848e-02 9.91816461e-01 9.78151858e-01 2.32047990e-01\n",
      " 2.62651145e-01 2.43331771e-02 9.97812629e-01 9.86532152e-01\n",
      " 9.79477048e-01 9.57894977e-03 5.00048161e-04 1.60232201e-01\n",
      " 1.93473026e-02 9.56537485e-01 9.79652256e-02 1.46654487e-01\n",
      " 1.68314606e-01 3.59294899e-02 1.26207367e-01 7.12851062e-02\n",
      " 1.61984354e-01 1.83358997e-01 9.99997735e-01 9.99796927e-01\n",
      " 1.00000000e+00 9.85977769e-01 9.99999166e-01 8.29022191e-03\n",
      " 7.78458267e-03 1.85900122e-01 8.95075575e-02 1.03584100e-02\n",
      " 9.87557411e-01 1.98700987e-02 2.23186258e-02 3.48498859e-02\n",
      " 9.98951197e-01 9.44813728e-01 9.98523891e-01 9.99200523e-01\n",
      " 9.47312355e-01 9.96644020e-01 9.98255074e-01 9.99957323e-01\n",
      " 9.99999881e-01 9.67190564e-01 9.95692909e-01 9.89726245e-01\n",
      " 9.98508751e-01 9.97932911e-01 9.82505322e-01 9.93019283e-01\n",
      " 9.99993086e-01 9.99983191e-01 9.98302341e-01 9.99997377e-01\n",
      " 9.99998808e-01 9.99889135e-01 9.99980330e-01 8.95236611e-01\n",
      " 8.99484038e-01 9.93911266e-01 9.81117308e-01 9.91525829e-01\n",
      " 4.23078947e-02 9.49308991e-01 9.53373313e-01 9.78227496e-01\n",
      " 9.10696149e-01 9.99807298e-01 9.93489027e-01 9.68951762e-01\n",
      " 8.87958519e-03 1.87104583e-01 6.91436291e-01 8.99874032e-01\n",
      " 1.38343990e-01 9.99987483e-01 5.17665558e-02 9.61735845e-01\n",
      " 9.97677267e-01 9.53638852e-01 9.99964476e-01 1.29855365e-01\n",
      " 5.29922731e-03 7.09523022e-01 5.75399101e-02 7.25821704e-02\n",
      " 3.91905695e-01 5.90704918e-01 8.49692896e-02 3.10524911e-01\n",
      " 7.98955142e-01 9.43125606e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 166 [0/54 (0%)]\tTrain Loss: 0.015647\n",
      "Train Epoch: 166 [8/54 (15%)]\tTrain Loss: 0.017349\n",
      "Train Epoch: 166 [16/54 (30%)]\tTrain Loss: 0.028785\n",
      "Train Epoch: 166 [24/54 (44%)]\tTrain Loss: 0.007733\n",
      "Train Epoch: 166 [32/54 (59%)]\tTrain Loss: 0.038286\n",
      "Train Epoch: 166 [40/54 (74%)]\tTrain Loss: 0.068644\n",
      "Train Epoch: 166 [48/54 (89%)]\tTrain Loss: 0.025267\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.16611490e-01 9.48166370e-01 5.97447634e-01 9.51964021e-01\n",
      " 1.08933337e-01 1.59753442e-01 4.25186962e-01 1.01388313e-01\n",
      " 3.44009995e-02 2.96937048e-01 9.61229391e-03 1.02475323e-01\n",
      " 1.24356977e-03 1.05465949e-03 7.56512600e-05 5.15428511e-03\n",
      " 2.17025075e-02 1.24537826e-01 1.55208617e-01 7.35845836e-03\n",
      " 1.24594709e-02 7.23450243e-01 9.90194857e-01 9.85493481e-01\n",
      " 2.66234782e-02 9.95570600e-01 9.04537439e-01 4.83161807e-02\n",
      " 2.06562951e-01 1.32692782e-02 7.39616156e-02 9.48892772e-01\n",
      " 5.38293004e-01 5.19948602e-02 8.01228744e-04 2.62398645e-03\n",
      " 7.39342952e-03 8.23233664e-01 2.79443450e-02 3.01745906e-02\n",
      " 2.35639513e-02 2.21629045e-03 2.33526137e-02 3.27045202e-01\n",
      " 4.27844785e-02 2.97031879e-01 9.99434292e-01 9.90170062e-01\n",
      " 9.99994636e-01 7.34536946e-01 9.99943137e-01 4.84069984e-04\n",
      " 3.56182631e-04 1.21400366e-02 2.47352663e-02 2.62003997e-03\n",
      " 9.91725326e-01 3.88303772e-03 5.59410360e-03 1.71275853e-04\n",
      " 9.95842874e-01 8.92693162e-01 9.97708917e-01 9.99890447e-01\n",
      " 6.83754086e-01 8.72578084e-01 9.79406655e-01 9.99694824e-01\n",
      " 9.99968648e-01 7.59095788e-01 9.95471001e-01 9.95844066e-01\n",
      " 9.98433053e-01 9.67294157e-01 6.55064821e-01 9.71278608e-01\n",
      " 9.99943495e-01 9.99865055e-01 9.96568918e-01 9.99980330e-01\n",
      " 9.99999166e-01 9.99363244e-01 9.99895334e-01 8.35897386e-01\n",
      " 9.37551200e-01 9.99168515e-01 9.88042355e-01 9.94356215e-01\n",
      " 8.16870295e-03 4.07118857e-01 9.83661473e-01 2.98654854e-01\n",
      " 2.37330720e-01 9.99998569e-01 9.88446891e-01 9.87273812e-01\n",
      " 6.79494999e-03 4.45028722e-01 2.28456140e-01 9.96815264e-01\n",
      " 1.84932664e-01 9.99827206e-01 1.33908512e-02 9.99378800e-01\n",
      " 9.99575198e-01 9.76290464e-01 9.99999285e-01 3.13842157e-03\n",
      " 1.80307834e-04 1.78106185e-02 1.30813837e-03 2.08192505e-04\n",
      " 3.59368101e-02 8.90421927e-01 1.83829397e-01 6.26340926e-01\n",
      " 7.99924791e-01 9.75786448e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 167 [0/54 (0%)]\tTrain Loss: 0.049120\n",
      "Train Epoch: 167 [8/54 (15%)]\tTrain Loss: 0.034446\n",
      "Train Epoch: 167 [16/54 (30%)]\tTrain Loss: 0.011074\n",
      "Train Epoch: 167 [24/54 (44%)]\tTrain Loss: 0.008950\n",
      "Train Epoch: 167 [32/54 (59%)]\tTrain Loss: 0.011875\n",
      "Train Epoch: 167 [40/54 (74%)]\tTrain Loss: 0.043501\n",
      "Train Epoch: 167 [48/54 (89%)]\tTrain Loss: 0.023090\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.82592162e-03 9.58413363e-01 2.39185452e-01 4.69218910e-01\n",
      " 2.14600423e-03 1.38025207e-03 4.72104579e-01 3.94020528e-02\n",
      " 1.19316727e-02 1.92864075e-01 1.22259170e-01 3.17905913e-03\n",
      " 5.16483188e-03 1.03693944e-03 5.57638763e-04 2.59460718e-03\n",
      " 1.47288144e-02 9.13166702e-02 3.78734261e-01 1.62530646e-01\n",
      " 6.51120907e-03 6.02678120e-01 9.57022250e-01 8.53779137e-01\n",
      " 4.52874415e-02 9.93896425e-01 8.14776123e-01 5.22976778e-02\n",
      " 1.79177716e-01 1.03146322e-02 3.87438834e-02 5.36395609e-01\n",
      " 4.30756450e-01 1.70135492e-04 3.50719201e-05 5.04745694e-04\n",
      " 9.76793235e-04 6.86575949e-01 1.45082630e-03 6.55258447e-02\n",
      " 1.54315196e-02 9.24544875e-03 5.64879552e-03 7.14994781e-03\n",
      " 6.64285868e-02 8.46765761e-04 8.47048998e-01 2.92230248e-01\n",
      " 9.94090497e-01 6.14754677e-01 9.73799944e-01 1.72130635e-03\n",
      " 3.31936491e-04 6.42112689e-03 5.24029769e-02 1.59411470e-03\n",
      " 9.91146386e-01 3.53704416e-03 1.42340781e-03 5.68997639e-04\n",
      " 8.50106359e-01 4.56709296e-01 9.78639126e-01 9.84401882e-01\n",
      " 1.52881786e-01 2.69859821e-01 8.22748423e-01 8.74757409e-01\n",
      " 9.99406576e-01 1.43668637e-01 6.65617764e-01 6.24575913e-01\n",
      " 9.96011496e-01 9.39813614e-01 5.64712882e-01 7.34921038e-01\n",
      " 9.99174178e-01 9.97960925e-01 6.38269126e-01 9.86360133e-01\n",
      " 9.91968811e-01 5.25540113e-01 9.57298100e-01 1.83793962e-01\n",
      " 5.24933755e-01 9.42326665e-01 9.24110234e-01 8.48381579e-01\n",
      " 7.65093341e-02 1.91368848e-01 9.40546393e-01 6.78654969e-01\n",
      " 1.38486326e-01 9.97459471e-01 8.76772523e-01 9.49715376e-01\n",
      " 3.88471689e-03 1.97382662e-02 6.55814230e-01 5.86802959e-01\n",
      " 1.37120500e-01 9.98908877e-01 2.52696406e-02 9.28264558e-01\n",
      " 9.71679449e-01 6.77991331e-01 9.99484062e-01 2.91781174e-03\n",
      " 9.42427141e-05 7.21029341e-01 2.86672101e-03 3.80225101e-04\n",
      " 4.72998479e-03 1.34407684e-01 1.64822549e-01 6.46470562e-02\n",
      " 8.41567934e-01 8.25023830e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 168 [0/54 (0%)]\tTrain Loss: 0.013701\n",
      "Train Epoch: 168 [8/54 (15%)]\tTrain Loss: 0.004650\n",
      "Train Epoch: 168 [16/54 (30%)]\tTrain Loss: 0.012385\n",
      "Train Epoch: 168 [24/54 (44%)]\tTrain Loss: 0.035103\n",
      "Train Epoch: 168 [32/54 (59%)]\tTrain Loss: 0.008336\n",
      "Train Epoch: 168 [40/54 (74%)]\tTrain Loss: 0.034079\n",
      "Train Epoch: 168 [48/54 (89%)]\tTrain Loss: 0.026548\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.23955186e-03 7.03921080e-01 3.50519657e-01 7.26845205e-01\n",
      " 2.48960536e-02 4.08750866e-03 1.34688616e-01 1.96422078e-02\n",
      " 2.01461464e-02 2.60369211e-01 7.21459184e-03 6.32213578e-02\n",
      " 2.44053244e-03 4.15312452e-03 6.88234111e-04 1.17470575e-02\n",
      " 3.77052929e-03 5.94420135e-02 5.40928602e-01 4.06640619e-01\n",
      " 2.01894403e-01 3.47725809e-01 9.93746042e-01 9.93519604e-01\n",
      " 6.65040761e-02 9.95938420e-01 9.96857882e-01 4.18322325e-01\n",
      " 6.23033419e-02 3.26429754e-02 2.83559114e-01 6.44462347e-01\n",
      " 7.95770362e-02 1.57032104e-03 1.82610718e-04 8.50934535e-04\n",
      " 9.19070188e-03 3.58892530e-01 1.87949110e-02 1.55043781e-01\n",
      " 2.78000031e-02 2.79453490e-02 3.29329423e-03 6.65153237e-03\n",
      " 8.62130802e-03 4.71226219e-03 9.92546141e-01 2.88372874e-01\n",
      " 9.91231024e-01 6.43181503e-01 9.60820735e-01 6.91300607e-04\n",
      " 3.19110369e-03 4.40996932e-03 2.92408288e-01 2.80880928e-03\n",
      " 5.82237899e-01 2.12877151e-02 9.03488602e-03 5.10972785e-03\n",
      " 8.99771750e-01 5.43737650e-01 7.65485644e-01 9.53801811e-01\n",
      " 4.94690448e-01 5.81001759e-01 8.50880682e-01 9.97540116e-01\n",
      " 9.99889493e-01 6.19204938e-02 8.77255023e-01 8.32465053e-01\n",
      " 9.97142136e-01 9.21115100e-01 7.83475697e-01 3.35440487e-01\n",
      " 9.96889412e-01 9.91435111e-01 4.68347371e-01 9.96943772e-01\n",
      " 9.99359190e-01 8.92703891e-01 9.96611655e-01 1.71636730e-01\n",
      " 6.87218964e-01 9.55078781e-01 8.88247371e-01 7.50827432e-01\n",
      " 2.09736437e-01 9.49578941e-01 9.99721110e-01 6.07160516e-02\n",
      " 1.08264722e-01 9.99918222e-01 9.89392161e-01 9.92377639e-01\n",
      " 7.00772600e-03 3.65364552e-01 9.19636011e-01 9.68168378e-01\n",
      " 1.36926636e-01 9.98777926e-01 2.21195593e-02 7.56708324e-01\n",
      " 8.99854064e-01 9.21575129e-01 9.98600900e-01 2.82312203e-02\n",
      " 1.32066933e-02 9.18165326e-01 1.61797591e-02 3.29426713e-02\n",
      " 4.90401983e-01 8.26737046e-01 3.76657456e-01 8.55373293e-02\n",
      " 8.17207754e-01 9.07919645e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 169 [0/54 (0%)]\tTrain Loss: 0.052672\n",
      "Train Epoch: 169 [8/54 (15%)]\tTrain Loss: 0.016387\n",
      "Train Epoch: 169 [16/54 (30%)]\tTrain Loss: 0.012190\n",
      "Train Epoch: 169 [24/54 (44%)]\tTrain Loss: 0.005455\n",
      "Train Epoch: 169 [32/54 (59%)]\tTrain Loss: 0.054609\n",
      "Train Epoch: 169 [40/54 (74%)]\tTrain Loss: 0.019230\n",
      "Train Epoch: 169 [48/54 (89%)]\tTrain Loss: 0.036109\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.55304496e-02 8.80265772e-01 1.76535055e-01 9.58707929e-01\n",
      " 2.43102431e-01 1.30398860e-02 3.71680140e-01 6.82701766e-01\n",
      " 5.13754897e-02 4.09213066e-01 3.99677008e-01 5.91347776e-02\n",
      " 9.18675959e-02 8.44809040e-03 1.55375926e-02 7.01660290e-02\n",
      " 2.93356441e-02 6.80387467e-02 1.47213843e-02 4.09191519e-01\n",
      " 2.22981289e-01 9.85225618e-01 9.98228252e-01 9.95582879e-01\n",
      " 5.62395513e-01 9.98413086e-01 9.91110325e-01 4.40952271e-01\n",
      " 7.04660267e-02 4.29209560e-01 5.78206740e-02 6.09657884e-01\n",
      " 9.65900242e-01 3.74284713e-03 2.72980455e-04 4.70052008e-03\n",
      " 1.04930652e-02 7.88461387e-01 1.31850794e-01 3.80413622e-01\n",
      " 6.97364509e-02 2.41172984e-01 7.10421335e-03 6.34937435e-02\n",
      " 7.76076540e-02 1.13105692e-01 9.67694402e-01 8.17148328e-01\n",
      " 9.99982357e-01 9.92151856e-01 9.99532580e-01 1.49574713e-03\n",
      " 7.19549740e-03 2.26042904e-02 8.59006047e-02 7.35208392e-03\n",
      " 6.61399424e-01 6.59354776e-02 2.47503277e-02 1.66110229e-02\n",
      " 3.78387570e-01 3.01780224e-01 3.21020037e-01 9.27195430e-01\n",
      " 6.60250962e-01 9.22005117e-01 9.57027912e-01 9.98651087e-01\n",
      " 9.99999285e-01 7.30171323e-01 8.25597227e-01 7.89737701e-01\n",
      " 9.99625087e-01 9.90684152e-01 9.89843369e-01 9.01587307e-01\n",
      " 9.99497414e-01 9.97398019e-01 9.88132536e-01 9.97836769e-01\n",
      " 9.98755813e-01 9.78233337e-01 9.97479141e-01 9.76390481e-01\n",
      " 9.91271436e-01 9.47538972e-01 9.70013261e-01 9.26512480e-01\n",
      " 1.20808326e-01 9.32452977e-01 9.99898195e-01 1.76371530e-01\n",
      " 4.22968328e-01 9.99994159e-01 9.79702652e-01 9.99595463e-01\n",
      " 1.26442816e-02 9.47564662e-01 7.36642718e-01 9.95076597e-01\n",
      " 1.67849869e-01 9.95343864e-01 1.52455857e-02 7.01897204e-01\n",
      " 8.97739947e-01 3.40662897e-01 9.99827743e-01 5.48171215e-02\n",
      " 1.36892451e-02 9.32736039e-01 4.50661451e-01 6.26107082e-02\n",
      " 8.48268688e-01 9.81032431e-01 8.88423085e-01 1.33086368e-01\n",
      " 9.75320637e-01 9.90198374e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 170 [0/54 (0%)]\tTrain Loss: 0.001965\n",
      "Train Epoch: 170 [8/54 (15%)]\tTrain Loss: 0.010732\n",
      "Train Epoch: 170 [16/54 (30%)]\tTrain Loss: 0.034231\n",
      "Train Epoch: 170 [24/54 (44%)]\tTrain Loss: 0.002902\n",
      "Train Epoch: 170 [32/54 (59%)]\tTrain Loss: 0.008949\n",
      "Train Epoch: 170 [40/54 (74%)]\tTrain Loss: 0.023117\n",
      "Train Epoch: 170 [48/54 (89%)]\tTrain Loss: 0.040197\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.17021678e-02 9.85694110e-01 8.22411239e-01 9.98912930e-01\n",
      " 6.66388392e-01 4.39429767e-02 8.27757895e-01 9.90017354e-01\n",
      " 1.99458510e-01 4.40515190e-01 6.61096871e-02 1.27158210e-01\n",
      " 3.32498215e-02 1.34517755e-02 5.64782172e-02 1.75733447e-01\n",
      " 2.81801134e-01 4.34036672e-01 4.74914372e-01 4.46995437e-01\n",
      " 7.15639740e-02 9.99465764e-01 9.99847531e-01 9.97695863e-01\n",
      " 9.85385120e-01 9.99447286e-01 9.94067430e-01 8.06058049e-01\n",
      " 8.26636851e-01 7.44675159e-01 5.18774629e-01 9.92799401e-01\n",
      " 7.42653787e-01 1.17510161e-03 1.77374706e-04 3.39092570e-03\n",
      " 2.31355373e-02 9.98212457e-01 3.40101659e-01 3.87618363e-01\n",
      " 1.13180026e-01 1.90523177e-01 1.11447703e-02 8.68943453e-01\n",
      " 3.04095387e-01 2.35321313e-01 9.94087815e-01 9.77013230e-01\n",
      " 9.99974608e-01 9.69752550e-01 9.99146461e-01 5.90297952e-03\n",
      " 1.07781095e-02 2.03565046e-01 5.95122427e-02 5.51872104e-02\n",
      " 9.94250298e-01 4.41734120e-02 1.51803613e-01 3.86081487e-02\n",
      " 9.75294888e-01 9.53822315e-01 8.71184826e-01 9.68417227e-01\n",
      " 8.94957244e-01 9.64532435e-01 9.91094410e-01 9.99349773e-01\n",
      " 9.99993563e-01 9.29872155e-01 9.94786263e-01 9.94632840e-01\n",
      " 9.99169350e-01 9.79863882e-01 9.23223257e-01 9.92543101e-01\n",
      " 9.99964118e-01 9.99945998e-01 9.98845577e-01 9.99983311e-01\n",
      " 9.99988794e-01 9.99012351e-01 9.99872208e-01 8.30540359e-01\n",
      " 9.90593731e-01 9.87897456e-01 9.96501088e-01 9.97230947e-01\n",
      " 1.31733492e-01 9.74202096e-01 9.62243378e-01 7.90639043e-01\n",
      " 8.69779468e-01 9.99680042e-01 8.50818515e-01 9.96656299e-01\n",
      " 9.12485179e-03 9.95049894e-01 4.52482522e-01 9.44262683e-01\n",
      " 7.04724848e-01 9.99899745e-01 6.35149240e-01 9.80706215e-01\n",
      " 9.91107762e-01 8.14489484e-01 9.99934673e-01 6.94317445e-02\n",
      " 6.48015644e-03 8.65564764e-01 1.14904344e-01 8.85229632e-02\n",
      " 1.76594213e-01 6.73277676e-01 9.01863754e-01 6.86852336e-01\n",
      " 6.32611275e-01 9.88692641e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "vote_pred [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 43 TN= 44 FN= 15 FP= 16\n",
      "TP+FP 59\n",
      "precision 0.7288135593220338\n",
      "recall 0.7413793103448276\n",
      "F1 0.735042735042735\n",
      "acc 0.7372881355932204\n",
      "AUCp 0.7373563218390805\n",
      "AUC 0.7945402298850575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 170, average recall: 0.7414, average precision: 0.7288,average F1: 0.7350, average accuracy: 0.7373, average AUC: 0.7945\n",
      "Train Epoch: 171 [0/54 (0%)]\tTrain Loss: 0.001420\n",
      "Train Epoch: 171 [8/54 (15%)]\tTrain Loss: 0.007298\n",
      "Train Epoch: 171 [16/54 (30%)]\tTrain Loss: 0.024411\n",
      "Train Epoch: 171 [24/54 (44%)]\tTrain Loss: 0.005699\n",
      "Train Epoch: 171 [32/54 (59%)]\tTrain Loss: 0.141396\n",
      "Train Epoch: 171 [40/54 (74%)]\tTrain Loss: 0.022954\n",
      "Train Epoch: 171 [48/54 (89%)]\tTrain Loss: 0.007645\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.18650720e-03 3.42935681e-01 2.72618890e-01 9.40129817e-01\n",
      " 1.05705410e-01 5.16349217e-03 1.20155975e-01 3.46005976e-01\n",
      " 1.07777350e-01 5.43603480e-01 1.65695965e-01 5.79255261e-02\n",
      " 9.30061378e-03 8.07281351e-04 2.27127690e-03 8.94524064e-03\n",
      " 3.01593263e-03 2.32602924e-01 6.59263134e-01 7.42195964e-01\n",
      " 1.69517487e-01 9.69997048e-01 9.89152193e-01 9.93146837e-01\n",
      " 4.72596079e-01 9.97717857e-01 9.93308067e-01 8.95000696e-01\n",
      " 1.27439573e-01 1.47157833e-01 9.19886649e-01 9.83362675e-01\n",
      " 4.45505559e-01 5.41385845e-04 1.93118511e-04 2.51249559e-02\n",
      " 8.51572379e-02 9.80909526e-01 5.09208031e-02 2.88733959e-01\n",
      " 3.12557071e-02 3.64713892e-02 1.18129782e-01 4.00442958e-01\n",
      " 6.36945888e-02 6.44383430e-01 9.99881148e-01 9.90432978e-01\n",
      " 9.99990702e-01 9.31971252e-01 9.99905467e-01 1.81177203e-02\n",
      " 2.82041971e-02 3.09555560e-01 2.06331357e-01 1.27239721e-02\n",
      " 9.10614908e-01 5.51910065e-02 1.50087729e-01 7.37333819e-02\n",
      " 9.93112266e-01 9.27678406e-01 8.86975706e-01 9.86603260e-01\n",
      " 8.53969812e-01 9.65656281e-01 9.80098605e-01 9.98686731e-01\n",
      " 9.99976397e-01 9.43108976e-01 9.81635928e-01 9.61443603e-01\n",
      " 9.98789847e-01 9.94994402e-01 9.93575394e-01 9.77858841e-01\n",
      " 9.99079108e-01 9.99281585e-01 9.75190163e-01 9.99959707e-01\n",
      " 9.99940157e-01 9.97276008e-01 9.99586284e-01 7.19249964e-01\n",
      " 8.84785950e-01 9.96985257e-01 9.80310023e-01 9.83292758e-01\n",
      " 1.62087873e-01 6.29004061e-01 9.83478427e-01 9.49450076e-01\n",
      " 8.70652139e-01 9.99739587e-01 9.91067588e-01 9.95020270e-01\n",
      " 1.68392695e-02 5.39729059e-01 8.82901251e-01 8.60462606e-01\n",
      " 1.17999017e-01 9.98846889e-01 1.33172467e-01 9.74871457e-01\n",
      " 9.79729295e-01 9.59544003e-01 9.99898791e-01 4.29444164e-02\n",
      " 8.28600023e-03 8.89931381e-01 1.27100227e-02 2.59561893e-02\n",
      " 3.02462935e-01 8.60615849e-01 2.05943376e-01 4.01769370e-01\n",
      " 3.48608792e-01 6.75067827e-02]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 172 [0/54 (0%)]\tTrain Loss: 0.012748\n",
      "Train Epoch: 172 [8/54 (15%)]\tTrain Loss: 0.003751\n",
      "Train Epoch: 172 [16/54 (30%)]\tTrain Loss: 0.019969\n",
      "Train Epoch: 172 [24/54 (44%)]\tTrain Loss: 0.001505\n",
      "Train Epoch: 172 [32/54 (59%)]\tTrain Loss: 0.011670\n",
      "Train Epoch: 172 [40/54 (74%)]\tTrain Loss: 0.007292\n",
      "Train Epoch: 172 [48/54 (89%)]\tTrain Loss: 0.004206\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.61526653e-03 8.33687007e-01 1.47639126e-01 9.71626997e-01\n",
      " 4.25985157e-02 8.39284621e-03 4.70485270e-01 1.33840501e-01\n",
      " 4.20987271e-02 8.21823403e-02 2.50312276e-02 6.19352981e-03\n",
      " 5.19698532e-03 3.84047627e-04 2.67257402e-03 3.66055593e-03\n",
      " 9.70234396e-04 4.21743393e-02 1.94312520e-02 4.33342636e-01\n",
      " 6.75626285e-03 8.48293841e-01 9.94961143e-01 9.90216374e-01\n",
      " 4.88837324e-02 9.98982966e-01 9.93828237e-01 4.34277594e-01\n",
      " 1.69553123e-02 1.47372127e-01 1.18934318e-01 7.35094666e-01\n",
      " 3.69123995e-01 2.53624276e-05 2.18954901e-05 4.21978580e-03\n",
      " 1.37999980e-03 8.65550578e-01 1.67344394e-03 2.01881714e-02\n",
      " 2.29779934e-03 2.62795179e-03 6.32932363e-03 3.30152847e-02\n",
      " 2.38409583e-02 1.45015255e-01 9.98835385e-01 6.27687812e-01\n",
      " 9.99938250e-01 8.71045470e-01 9.97643292e-01 2.53184699e-03\n",
      " 9.85847786e-03 1.25974521e-01 2.71172430e-02 1.75495837e-02\n",
      " 3.51456851e-01 4.35896628e-02 9.60765779e-02 2.38349829e-02\n",
      " 8.78697634e-01 5.17329931e-01 7.83606708e-01 9.43947792e-01\n",
      " 9.02940691e-01 9.83306885e-01 9.92682278e-01 9.99463856e-01\n",
      " 9.99997377e-01 7.77696550e-01 5.58543742e-01 6.70296729e-01\n",
      " 9.99892473e-01 9.96713758e-01 9.94920433e-01 9.66796160e-01\n",
      " 9.99927402e-01 9.99919415e-01 9.53879356e-01 9.99788344e-01\n",
      " 9.99810636e-01 9.94631648e-01 9.99854207e-01 6.31146431e-01\n",
      " 8.28112245e-01 9.62509930e-01 9.33518887e-01 9.81123030e-01\n",
      " 1.34717733e-01 1.65514231e-01 9.91760194e-01 2.78184116e-01\n",
      " 6.30274415e-01 9.99948025e-01 9.85635996e-01 9.96620417e-01\n",
      " 5.89292822e-03 8.19538459e-02 1.44722760e-01 8.29554498e-01\n",
      " 6.37399638e-03 9.97622550e-01 4.74497257e-03 8.00705135e-01\n",
      " 7.40593851e-01 7.00675964e-01 9.99475777e-01 2.09960295e-03\n",
      " 4.74720087e-04 6.10056877e-01 7.37669365e-03 4.61748685e-04\n",
      " 3.76757026e-01 4.95705605e-01 8.01587570e-03 2.52783727e-02\n",
      " 2.39715815e-01 2.67045735e-03]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 173 [0/54 (0%)]\tTrain Loss: 0.063290\n",
      "Train Epoch: 173 [8/54 (15%)]\tTrain Loss: 0.003478\n",
      "Train Epoch: 173 [16/54 (30%)]\tTrain Loss: 0.030844\n",
      "Train Epoch: 173 [24/54 (44%)]\tTrain Loss: 0.014767\n",
      "Train Epoch: 173 [32/54 (59%)]\tTrain Loss: 0.002408\n",
      "Train Epoch: 173 [40/54 (74%)]\tTrain Loss: 0.002372\n",
      "Train Epoch: 173 [48/54 (89%)]\tTrain Loss: 0.080155\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.23807471e-02 9.31420863e-01 8.87936056e-01 9.95007038e-01\n",
      " 4.93893981e-01 1.93002038e-02 9.82294321e-01 9.64891315e-01\n",
      " 8.79003704e-02 3.02696228e-01 1.48019239e-01 6.84404597e-02\n",
      " 1.90745387e-02 5.22273630e-02 4.35054839e-01 5.97517118e-02\n",
      " 2.29498997e-01 2.59437948e-01 6.80381358e-01 7.85300314e-01\n",
      " 3.42504382e-02 9.95618641e-01 9.99899626e-01 9.97995377e-01\n",
      " 9.14512694e-01 9.99838233e-01 9.99059975e-01 9.45241928e-01\n",
      " 7.77696550e-01 4.03357387e-01 9.58181322e-01 9.95927632e-01\n",
      " 3.75237316e-01 2.00939411e-03 2.20777001e-04 4.85010408e-02\n",
      " 2.99843922e-02 9.92307007e-01 3.65841947e-02 3.70127648e-01\n",
      " 7.93073550e-02 3.33320573e-02 8.35126359e-03 6.88219190e-01\n",
      " 4.03361797e-01 3.92904252e-01 9.99785125e-01 9.80496466e-01\n",
      " 9.99591887e-01 9.60028172e-01 9.99350369e-01 4.94702831e-02\n",
      " 5.75220957e-02 5.49038470e-01 8.50419253e-02 1.36045799e-01\n",
      " 8.13131154e-01 2.88064152e-01 4.93308783e-01 3.06853175e-01\n",
      " 9.79876399e-01 8.42247248e-01 9.19118524e-01 9.76388633e-01\n",
      " 9.94478822e-01 9.99820292e-01 9.99362051e-01 9.99952912e-01\n",
      " 9.99999642e-01 9.40019608e-01 8.72486532e-01 8.38653386e-01\n",
      " 9.99957561e-01 9.97522414e-01 9.92671967e-01 9.96512115e-01\n",
      " 9.99984384e-01 9.99980450e-01 9.99914646e-01 9.99993682e-01\n",
      " 9.99979734e-01 9.95304823e-01 9.99932528e-01 2.33831853e-01\n",
      " 7.48522520e-01 9.38905478e-01 9.94871497e-01 9.97613311e-01\n",
      " 2.33388409e-01 9.88985419e-01 9.99486327e-01 9.05851305e-01\n",
      " 8.68548930e-01 9.99983668e-01 9.91274416e-01 9.97812390e-01\n",
      " 4.81251115e-03 7.69953787e-01 8.53769481e-01 9.86430168e-01\n",
      " 3.53910923e-02 9.99519467e-01 9.95194688e-02 9.91578221e-01\n",
      " 9.87026870e-01 8.85203302e-01 9.99976754e-01 3.46351080e-02\n",
      " 7.91282300e-03 9.34271693e-01 8.75257142e-03 1.77051071e-02\n",
      " 9.54738319e-01 9.27288294e-01 9.15147811e-02 2.10111439e-01\n",
      " 7.18732476e-01 6.98712289e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 174 [0/54 (0%)]\tTrain Loss: 0.009355\n",
      "Train Epoch: 174 [8/54 (15%)]\tTrain Loss: 0.008034\n",
      "Train Epoch: 174 [16/54 (30%)]\tTrain Loss: 0.001794\n",
      "Train Epoch: 174 [24/54 (44%)]\tTrain Loss: 0.021876\n",
      "Train Epoch: 174 [32/54 (59%)]\tTrain Loss: 0.075280\n",
      "Train Epoch: 174 [40/54 (74%)]\tTrain Loss: 0.019851\n",
      "Train Epoch: 174 [48/54 (89%)]\tTrain Loss: 0.002807\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.64640262e-03 6.32354558e-01 1.83281109e-01 8.51841092e-01\n",
      " 5.16138136e-01 5.42076258e-03 7.20854223e-01 6.27362370e-01\n",
      " 1.65658891e-02 3.46508414e-01 8.08383003e-02 4.42695804e-02\n",
      " 3.45618301e-03 6.32047700e-03 3.57044339e-02 1.74612645e-02\n",
      " 3.85773405e-02 6.17325976e-02 3.00372660e-01 2.36153722e-01\n",
      " 5.71052805e-02 8.58568966e-01 9.91944551e-01 9.95450675e-01\n",
      " 2.13705942e-01 9.97428119e-01 9.99037027e-01 5.87290406e-01\n",
      " 4.07092690e-01 1.65656935e-02 7.89932609e-01 9.27448988e-01\n",
      " 2.17345923e-01 6.04576489e-04 8.00902926e-05 2.91189328e-02\n",
      " 1.30188717e-02 8.03445160e-01 1.69132333e-02 1.24402143e-01\n",
      " 3.12437527e-02 1.02771493e-02 2.23461981e-03 1.20016888e-01\n",
      " 1.35851130e-01 6.58334419e-02 9.99516964e-01 8.94535363e-01\n",
      " 9.99895096e-01 9.77311790e-01 9.99774158e-01 6.56441087e-03\n",
      " 2.53290813e-02 5.34970313e-02 9.90767255e-02 8.81850570e-02\n",
      " 7.80785382e-01 3.76406729e-01 2.14516416e-01 1.48029462e-01\n",
      " 9.75924313e-01 4.24905986e-01 6.92296326e-01 9.70558405e-01\n",
      " 9.73982573e-01 9.99456704e-01 9.94869828e-01 9.99571383e-01\n",
      " 9.99992967e-01 2.70062327e-01 5.73703468e-01 5.89845300e-01\n",
      " 9.99825776e-01 9.97372389e-01 9.90834296e-01 8.91745865e-01\n",
      " 9.98807311e-01 9.99714911e-01 9.89441037e-01 9.99881506e-01\n",
      " 9.99797404e-01 9.75453317e-01 9.99817193e-01 2.93459222e-02\n",
      " 1.22419655e-01 6.19458318e-01 9.84965324e-01 9.92020071e-01\n",
      " 2.37515241e-01 7.94160247e-01 9.81031120e-01 9.52238083e-01\n",
      " 7.81818986e-01 9.99981523e-01 9.82259035e-01 9.97826993e-01\n",
      " 4.37642401e-03 3.78323644e-01 2.86760926e-01 9.50231969e-01\n",
      " 1.12448372e-02 9.98550713e-01 2.02428643e-02 9.53934729e-01\n",
      " 9.04227793e-01 5.82479537e-01 9.99979854e-01 1.57389045e-02\n",
      " 4.51739179e-03 6.25247598e-01 4.35813610e-03 1.13978283e-02\n",
      " 9.25044894e-01 9.17562246e-01 2.52215862e-02 4.46324563e-03\n",
      " 3.14501166e-01 3.15992475e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 175 [0/54 (0%)]\tTrain Loss: 0.016682\n",
      "Train Epoch: 175 [8/54 (15%)]\tTrain Loss: 0.019082\n",
      "Train Epoch: 175 [16/54 (30%)]\tTrain Loss: 0.005953\n",
      "Train Epoch: 175 [24/54 (44%)]\tTrain Loss: 0.054371\n",
      "Train Epoch: 175 [32/54 (59%)]\tTrain Loss: 0.007482\n",
      "Train Epoch: 175 [40/54 (74%)]\tTrain Loss: 0.020254\n",
      "Train Epoch: 175 [48/54 (89%)]\tTrain Loss: 0.010951\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.91028479e-03 2.40275055e-01 1.25903904e-01 9.83222425e-01\n",
      " 3.22708696e-01 4.70248749e-03 2.25804731e-01 5.01339376e-01\n",
      " 5.27876802e-02 4.81544793e-01 1.69219404e-01 6.09655529e-02\n",
      " 2.10007671e-02 2.58068065e-03 4.85572545e-03 2.78232750e-02\n",
      " 9.06573981e-03 6.65218830e-02 4.90190983e-01 3.92907143e-01\n",
      " 2.49612164e-02 9.92052555e-01 9.98765469e-01 9.99832988e-01\n",
      " 1.67915463e-01 9.99976039e-01 9.99949455e-01 7.71363080e-01\n",
      " 3.26386422e-01 1.83851838e-01 7.08491206e-01 9.56158817e-01\n",
      " 1.47127837e-01 2.42515747e-03 3.51129478e-04 3.30139278e-03\n",
      " 7.06978049e-03 9.30075347e-01 1.28869154e-02 2.56636947e-01\n",
      " 4.75746319e-02 4.76324596e-02 2.37734225e-02 4.95068356e-02\n",
      " 2.70261616e-01 3.48595083e-02 9.74220574e-01 3.90254140e-01\n",
      " 9.99748290e-01 9.96141136e-01 9.98846889e-01 1.97770447e-03\n",
      " 6.38697296e-02 1.63326547e-01 1.14266768e-01 2.62268305e-01\n",
      " 8.91315818e-01 2.70564765e-01 3.04285735e-01 7.62780234e-02\n",
      " 7.76852727e-01 4.59220499e-01 4.47682649e-01 9.16745067e-01\n",
      " 7.48401403e-01 9.88407433e-01 9.89403605e-01 9.99704778e-01\n",
      " 9.99992013e-01 5.14496326e-01 5.73970318e-01 7.51202881e-01\n",
      " 9.99911666e-01 9.84362483e-01 9.94026184e-01 6.21896684e-01\n",
      " 9.99038696e-01 9.97791171e-01 9.11595047e-01 9.99515891e-01\n",
      " 9.99674082e-01 9.65278387e-01 9.99444067e-01 8.56938720e-01\n",
      " 9.80334222e-01 9.36523616e-01 9.15159166e-01 9.30211246e-01\n",
      " 4.16242421e-01 9.98715281e-01 9.99967694e-01 5.82070410e-01\n",
      " 7.57274449e-01 9.99999642e-01 9.96955395e-01 9.99845147e-01\n",
      " 5.07855276e-03 9.52321410e-01 6.93889976e-01 9.99630570e-01\n",
      " 9.12342593e-02 9.93964255e-01 2.22837105e-02 9.62750614e-01\n",
      " 9.84148502e-01 7.56114364e-01 9.99997139e-01 1.17392885e-02\n",
      " 5.34976274e-03 7.05490947e-01 1.36736959e-01 2.29673199e-02\n",
      " 9.75146592e-01 9.99732673e-01 7.35557616e-01 3.04910000e-02\n",
      " 8.45132113e-01 9.73778963e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 176 [0/54 (0%)]\tTrain Loss: 0.002044\n",
      "Train Epoch: 176 [8/54 (15%)]\tTrain Loss: 0.030344\n",
      "Train Epoch: 176 [16/54 (30%)]\tTrain Loss: 0.007223\n",
      "Train Epoch: 176 [24/54 (44%)]\tTrain Loss: 0.010773\n",
      "Train Epoch: 176 [32/54 (59%)]\tTrain Loss: 0.003709\n",
      "Train Epoch: 176 [40/54 (74%)]\tTrain Loss: 0.011074\n",
      "Train Epoch: 176 [48/54 (89%)]\tTrain Loss: 0.004936\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.99750460e-03 8.84376466e-01 4.43999648e-01 5.92427611e-01\n",
      " 7.91567340e-02 7.06034759e-03 6.83907211e-01 7.98348561e-02\n",
      " 6.20695800e-02 9.81196295e-03 1.66527983e-02 9.04386456e-04\n",
      " 2.33133901e-02 3.16972658e-02 1.16714574e-01 5.92272244e-02\n",
      " 3.48668639e-03 1.48550123e-01 4.73960266e-02 2.17523739e-01\n",
      " 5.53792389e-03 9.29835975e-01 9.94887888e-01 9.82055247e-01\n",
      " 1.52351201e-01 9.99210715e-01 9.98647153e-01 6.26050770e-01\n",
      " 1.98153645e-01 4.24283504e-01 9.95359004e-01 9.88862097e-01\n",
      " 9.83517110e-01 1.65377837e-03 4.88159945e-04 7.70961458e-04\n",
      " 5.59154758e-03 7.94685125e-01 5.19796349e-02 9.79796946e-02\n",
      " 3.71240601e-02 3.91930016e-03 1.06424391e-02 1.86572909e-01\n",
      " 2.18106672e-01 4.30721879e-01 9.95584071e-01 9.12813365e-01\n",
      " 9.99267280e-01 9.77956176e-01 9.99617338e-01 1.07145461e-03\n",
      " 1.28421001e-02 5.99374846e-02 2.08068509e-02 9.93368868e-03\n",
      " 9.71634209e-01 4.57379706e-02 2.93851760e-03 1.93744078e-02\n",
      " 9.27077889e-01 5.82752645e-01 9.54381645e-01 9.92097735e-01\n",
      " 8.49632859e-01 9.90467608e-01 9.72047865e-01 9.99893785e-01\n",
      " 9.99993205e-01 8.58455360e-01 9.08405483e-01 9.19608593e-01\n",
      " 9.99987483e-01 9.96638894e-01 9.96258378e-01 9.64109719e-01\n",
      " 9.99825418e-01 9.99859691e-01 9.91952479e-01 9.99941587e-01\n",
      " 9.99996901e-01 9.99907613e-01 9.99973774e-01 4.80796456e-01\n",
      " 8.93349469e-01 9.99418736e-01 9.92383301e-01 9.98388886e-01\n",
      " 1.45277113e-01 9.99280155e-01 9.95322526e-01 2.74099261e-01\n",
      " 7.03729033e-01 9.99972343e-01 9.85484779e-01 9.97799814e-01\n",
      " 3.58532998e-04 7.99047530e-01 5.41425645e-01 9.99326944e-01\n",
      " 2.81973798e-02 9.99887705e-01 3.05466931e-02 9.00892496e-01\n",
      " 9.85118628e-01 7.00275540e-01 9.99994874e-01 2.03866512e-02\n",
      " 3.06351203e-02 9.36489999e-01 9.76377845e-01 4.72864136e-02\n",
      " 9.67717648e-01 9.97883141e-01 2.24134251e-01 6.67239651e-02\n",
      " 8.44768107e-01 9.99817193e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 177 [0/54 (0%)]\tTrain Loss: 0.007823\n",
      "Train Epoch: 177 [8/54 (15%)]\tTrain Loss: 0.013600\n",
      "Train Epoch: 177 [16/54 (30%)]\tTrain Loss: 0.014468\n",
      "Train Epoch: 177 [24/54 (44%)]\tTrain Loss: 0.002510\n",
      "Train Epoch: 177 [32/54 (59%)]\tTrain Loss: 0.002727\n",
      "Train Epoch: 177 [40/54 (74%)]\tTrain Loss: 0.013689\n",
      "Train Epoch: 177 [48/54 (89%)]\tTrain Loss: 0.001543\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.13858012e-04 8.84969294e-01 5.94330907e-01 9.97399569e-01\n",
      " 2.95022130e-02 3.04145366e-03 9.59928393e-01 3.81369263e-01\n",
      " 4.31698970e-02 1.11126252e-01 1.97833702e-02 7.02724373e-03\n",
      " 5.35614938e-02 8.36354680e-03 4.66331951e-02 7.05145299e-02\n",
      " 1.67088630e-03 2.22756714e-01 7.25159049e-01 7.91321218e-01\n",
      " 1.64327145e-01 9.93999362e-01 9.98651564e-01 9.99919891e-01\n",
      " 6.10090017e-01 9.99990821e-01 9.99962211e-01 9.53954339e-01\n",
      " 7.28203177e-01 6.28242344e-02 8.44723761e-01 9.64178920e-01\n",
      " 9.59165275e-01 3.34299286e-04 2.59626686e-04 2.93600373e-02\n",
      " 1.48008699e-02 9.79992926e-01 1.39154587e-02 1.85235649e-01\n",
      " 2.25275885e-02 5.92052378e-03 2.42165886e-02 2.13393226e-01\n",
      " 3.59259874e-01 9.06063095e-02 9.99356687e-01 7.80371249e-01\n",
      " 1.00000000e+00 9.98568416e-01 9.99999762e-01 3.05415993e-03\n",
      " 1.05604373e-01 5.69581874e-02 1.20770298e-01 1.53129786e-01\n",
      " 9.15182233e-01 6.56831861e-02 5.58898039e-02 3.57421160e-01\n",
      " 9.88566875e-01 6.97938323e-01 8.97912145e-01 9.98532176e-01\n",
      " 9.95912373e-01 9.99026537e-01 9.96602774e-01 9.99654531e-01\n",
      " 9.99999523e-01 8.98506343e-01 9.85359073e-01 9.80407536e-01\n",
      " 9.99996424e-01 9.94473398e-01 9.98598874e-01 9.85182226e-01\n",
      " 9.99839306e-01 9.99899387e-01 9.95912373e-01 9.99996424e-01\n",
      " 9.99944091e-01 9.99807537e-01 9.99990940e-01 3.18811625e-01\n",
      " 6.02692902e-01 9.99891043e-01 9.98711586e-01 9.99588788e-01\n",
      " 4.37119603e-01 9.84723210e-01 9.99178588e-01 9.83659148e-01\n",
      " 9.60011005e-01 9.99997139e-01 9.80676413e-01 9.99578297e-01\n",
      " 3.59954592e-03 9.83705640e-01 9.69310939e-01 9.92718458e-01\n",
      " 2.00286970e-01 9.99934793e-01 5.09600937e-02 9.92353141e-01\n",
      " 9.92766619e-01 6.17052615e-01 9.99999762e-01 1.88965321e-01\n",
      " 1.58676393e-02 9.08672452e-01 2.48534437e-02 2.01578513e-02\n",
      " 9.73902941e-01 9.95100319e-01 7.04919081e-03 4.69207801e-02\n",
      " 6.74765706e-01 6.88424051e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 178 [0/54 (0%)]\tTrain Loss: 0.001787\n",
      "Train Epoch: 178 [8/54 (15%)]\tTrain Loss: 0.002258\n",
      "Train Epoch: 178 [16/54 (30%)]\tTrain Loss: 0.002840\n",
      "Train Epoch: 178 [24/54 (44%)]\tTrain Loss: 0.008209\n",
      "Train Epoch: 178 [32/54 (59%)]\tTrain Loss: 0.010289\n",
      "Train Epoch: 178 [40/54 (74%)]\tTrain Loss: 0.009192\n",
      "Train Epoch: 178 [48/54 (89%)]\tTrain Loss: 0.036753\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.29689549e-03 4.10702020e-01 1.83163136e-02 3.46607774e-01\n",
      " 3.73439654e-03 1.36652053e-03 9.83975455e-02 7.19590634e-02\n",
      " 3.12411804e-02 3.91909527e-03 3.86632251e-04 2.10673432e-04\n",
      " 3.83942213e-04 2.79009854e-03 1.97863672e-02 3.22409929e-03\n",
      " 3.13472061e-04 3.07961088e-02 5.23476070e-03 8.02655984e-03\n",
      " 6.29585981e-03 7.67002821e-01 9.79758739e-01 9.61859882e-01\n",
      " 6.48736507e-02 9.94688511e-01 9.96874332e-01 5.14373295e-02\n",
      " 2.10983716e-02 7.25466907e-02 4.74689715e-02 4.88801211e-01\n",
      " 4.47716594e-01 1.76565263e-05 2.28152203e-05 2.78651161e-04\n",
      " 2.83928122e-03 8.51242244e-02 5.09143844e-02 1.35972723e-01\n",
      " 3.90129127e-02 1.81727111e-02 3.06732487e-03 3.25354747e-03\n",
      " 9.87447891e-03 1.60630122e-02 9.78617132e-01 5.63397884e-01\n",
      " 9.99984384e-01 9.94381368e-01 9.99807537e-01 1.22956364e-04\n",
      " 3.27189424e-04 9.47841257e-03 1.07662790e-02 5.18079498e-04\n",
      " 1.26618907e-01 5.34537423e-04 2.04981188e-03 9.08002909e-03\n",
      " 5.00985682e-01 1.48940191e-01 6.80399656e-01 9.50155318e-01\n",
      " 5.58712006e-01 7.09442556e-01 8.92965376e-01 9.97360408e-01\n",
      " 9.99946475e-01 7.20244586e-01 7.17902064e-01 7.71482766e-01\n",
      " 9.99443352e-01 9.85425711e-01 9.68575954e-01 7.67076254e-01\n",
      " 9.99082088e-01 9.99316931e-01 7.81183422e-01 9.99666333e-01\n",
      " 9.99104798e-01 9.70460057e-01 9.99783695e-01 1.16572633e-01\n",
      " 1.94206595e-01 9.57789540e-01 9.65263188e-01 9.79465663e-01\n",
      " 5.72007848e-03 2.19017252e-01 9.93934572e-01 1.55550301e-01\n",
      " 4.29158807e-01 9.97385561e-01 9.64394808e-01 9.75938261e-01\n",
      " 1.03977480e-04 7.18588293e-01 6.58838376e-02 9.76311266e-01\n",
      " 1.65555049e-02 9.98082876e-01 1.04749284e-03 1.00379445e-01\n",
      " 8.93586516e-01 1.37180686e-01 9.99983191e-01 2.70736311e-03\n",
      " 4.36824933e-03 6.64931685e-02 1.60639323e-02 1.97959915e-02\n",
      " 7.75059462e-01 2.11373523e-01 4.47366722e-02 1.94608141e-02\n",
      " 1.39971614e-01 1.58985078e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 179 [0/54 (0%)]\tTrain Loss: 0.042008\n",
      "Train Epoch: 179 [8/54 (15%)]\tTrain Loss: 0.004051\n",
      "Train Epoch: 179 [16/54 (30%)]\tTrain Loss: 0.061363\n",
      "Train Epoch: 179 [24/54 (44%)]\tTrain Loss: 0.004994\n",
      "Train Epoch: 179 [32/54 (59%)]\tTrain Loss: 0.039111\n",
      "Train Epoch: 179 [40/54 (74%)]\tTrain Loss: 0.004461\n",
      "Train Epoch: 179 [48/54 (89%)]\tTrain Loss: 0.006083\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.08545552 0.96733207 0.60490996 0.99911052 0.18339537 0.01853628\n",
      " 0.9550063  0.87815195 0.09259231 0.50450718 0.37115934 0.394016\n",
      " 0.1461293  0.05383015 0.32691273 0.14841187 0.16044047 0.52558511\n",
      " 0.48897684 0.89350468 0.52702874 0.99571699 0.99970275 0.99354595\n",
      " 0.77090663 0.9998647  0.99754542 0.98586351 0.9600786  0.99094427\n",
      " 0.40635198 0.99827731 0.98573697 0.00144767 0.00302289 0.02688551\n",
      " 0.55434483 0.85646212 0.42702326 0.63308239 0.14391446 0.26544863\n",
      " 0.01868719 0.38646466 0.15820378 0.38830271 0.96583217 0.71507174\n",
      " 0.9975732  0.98436272 0.99598974 0.0074722  0.05391102 0.81627387\n",
      " 0.47371966 0.05647946 0.41965249 0.85576272 0.53242892 0.1715893\n",
      " 0.97682118 0.90858281 0.96609235 0.99747688 0.77801996 0.99239665\n",
      " 0.99890172 0.99999869 0.99999952 0.65421218 0.88376361 0.9497354\n",
      " 0.99865252 0.9975248  0.99499559 0.96684361 0.99998629 0.99999905\n",
      " 0.98540014 0.99993253 0.99999571 0.99339926 0.99905509 0.66658938\n",
      " 0.52469748 0.95611775 0.99156684 0.98978919 0.16279422 0.98402816\n",
      " 0.98964578 0.81184977 0.9737128  0.99991727 0.99786299 0.99985826\n",
      " 0.02247384 0.99628013 0.95059991 0.99032682 0.16167897 0.99604791\n",
      " 0.04967282 0.83396757 0.99758565 0.5197897  0.99952888 0.1074509\n",
      " 0.11839435 0.96005583 0.04088515 0.4690496  0.97231573 0.90068102\n",
      " 0.27456269 0.49488303 0.99217755 0.99365777]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 180 [0/54 (0%)]\tTrain Loss: 0.014086\n",
      "Train Epoch: 180 [8/54 (15%)]\tTrain Loss: 0.017761\n",
      "Train Epoch: 180 [16/54 (30%)]\tTrain Loss: 0.002086\n",
      "Train Epoch: 180 [24/54 (44%)]\tTrain Loss: 0.007240\n",
      "Train Epoch: 180 [32/54 (59%)]\tTrain Loss: 0.016072\n",
      "Train Epoch: 180 [40/54 (74%)]\tTrain Loss: 0.009671\n",
      "Train Epoch: 180 [48/54 (89%)]\tTrain Loss: 0.009141\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.30748343e-01 8.92494917e-01 1.05288513e-01 9.14713323e-01\n",
      " 4.09132652e-02 3.09281647e-02 8.80426049e-01 5.14836311e-01\n",
      " 4.82448377e-02 3.18659633e-01 1.51624337e-01 2.42804244e-01\n",
      " 1.76872220e-03 7.45510915e-03 8.64583030e-02 1.61694847e-02\n",
      " 1.30586168e-02 4.91698124e-02 1.46951720e-01 3.57625097e-01\n",
      " 1.21531107e-01 8.62775385e-01 9.99398470e-01 9.98390555e-01\n",
      " 3.80047232e-01 9.99915004e-01 9.99302268e-01 7.69216955e-01\n",
      " 8.81148160e-01 5.10463715e-01 1.35049745e-01 9.81996179e-01\n",
      " 8.88733804e-01 6.35277320e-06 3.72707036e-05 7.98906013e-03\n",
      " 3.64999031e-03 4.07202721e-01 1.44571839e-02 1.25527710e-01\n",
      " 2.46461928e-02 1.83408447e-02 8.36241897e-03 1.26372159e-01\n",
      " 4.56830412e-02 5.70928454e-01 9.53129470e-01 8.82179141e-01\n",
      " 9.99970555e-01 9.82083082e-01 9.99814451e-01 9.88731626e-04\n",
      " 9.48304310e-03 1.53898671e-01 1.60105273e-01 1.26352534e-02\n",
      " 7.52616286e-01 3.37772556e-02 1.22587562e-01 5.34168519e-02\n",
      " 9.93375242e-01 8.77010465e-01 9.95056868e-01 9.98864770e-01\n",
      " 6.28717482e-01 9.05871153e-01 9.07891035e-01 9.96884763e-01\n",
      " 9.99954224e-01 3.51772279e-01 9.81864333e-01 9.82665420e-01\n",
      " 9.97114062e-01 9.65059519e-01 7.65347540e-01 9.45154905e-01\n",
      " 9.99912500e-01 9.99983430e-01 9.90647614e-01 9.99803126e-01\n",
      " 9.99840736e-01 9.94169235e-01 9.99566138e-01 1.02472708e-01\n",
      " 4.39729869e-01 9.98748660e-01 9.96013999e-01 9.96221662e-01\n",
      " 7.89436027e-02 4.77040142e-01 9.66472030e-01 4.39366817e-01\n",
      " 6.40542567e-01 9.98041093e-01 9.60384250e-01 9.26906109e-01\n",
      " 1.35839370e-03 7.31733024e-01 2.51255661e-01 7.81463683e-01\n",
      " 2.12056637e-02 9.98841465e-01 7.38991331e-03 6.18434787e-01\n",
      " 9.34555352e-01 7.19759703e-01 9.99882102e-01 1.21354805e-02\n",
      " 1.60741294e-03 8.01118135e-01 1.10495754e-03 1.03941408e-03\n",
      " 3.51969361e-01 4.06175017e-01 1.67477503e-02 4.37254012e-02\n",
      " 6.05464935e-01 3.23803335e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 46 TN= 42 FN= 12 FP= 18\n",
      "TP+FP 64\n",
      "precision 0.71875\n",
      "recall 0.7931034482758621\n",
      "F1 0.7540983606557378\n",
      "acc 0.7457627118644068\n",
      "AUCp 0.7465517241379309\n",
      "AUC 0.750287356321839\n",
      "\n",
      " The epoch is 180, average recall: 0.7931, average precision: 0.7188,average F1: 0.7541, average accuracy: 0.7458, average AUC: 0.7503\n",
      "Train Epoch: 181 [0/54 (0%)]\tTrain Loss: 0.031958\n",
      "Train Epoch: 181 [8/54 (15%)]\tTrain Loss: 0.003850\n",
      "Train Epoch: 181 [16/54 (30%)]\tTrain Loss: 0.003862\n",
      "Train Epoch: 181 [24/54 (44%)]\tTrain Loss: 0.017795\n",
      "Train Epoch: 181 [32/54 (59%)]\tTrain Loss: 0.054516\n",
      "Train Epoch: 181 [40/54 (74%)]\tTrain Loss: 0.003507\n",
      "Train Epoch: 181 [48/54 (89%)]\tTrain Loss: 0.002636\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.35296406e-02 4.24525380e-01 4.74139117e-03 3.62537354e-01\n",
      " 2.19906252e-02 4.76336019e-04 1.67505264e-01 1.25740871e-01\n",
      " 3.53471842e-03 4.27240282e-02 5.61414510e-02 3.58412834e-03\n",
      " 2.48134881e-03 1.03672617e-03 5.68571314e-03 3.53927305e-03\n",
      " 2.14955257e-03 4.14020196e-02 7.64978454e-02 4.64991555e-02\n",
      " 2.35932283e-02 6.54450655e-01 9.40527260e-01 9.85081375e-01\n",
      " 3.65993232e-02 9.98040378e-01 9.98600185e-01 8.14779758e-01\n",
      " 1.50455728e-01 6.41328916e-02 5.26933074e-02 8.76938164e-01\n",
      " 8.75795066e-01 5.30793332e-05 5.76423590e-05 4.99182264e-04\n",
      " 1.01846224e-03 1.61392286e-01 9.47080180e-03 1.84196413e-01\n",
      " 5.42217679e-02 3.96662429e-02 2.32184445e-03 1.73758417e-02\n",
      " 2.90036108e-03 3.53407115e-02 9.35665727e-01 4.48722452e-01\n",
      " 9.99884605e-01 9.68915045e-01 9.97343123e-01 1.48835912e-04\n",
      " 8.49421951e-04 1.26592803e-03 3.30621563e-02 1.10332074e-03\n",
      " 4.08194028e-02 1.33888740e-02 5.03962440e-03 4.12256457e-03\n",
      " 9.08429205e-01 1.50986522e-01 4.57414836e-01 9.39455450e-01\n",
      " 2.34502539e-01 8.78388166e-01 9.35595274e-01 9.97256219e-01\n",
      " 9.99678612e-01 9.12967771e-02 6.22931242e-01 4.33970481e-01\n",
      " 9.95404601e-01 8.10638607e-01 7.83978820e-01 3.09670925e-01\n",
      " 9.95514810e-01 9.96558964e-01 9.27196085e-01 9.99619126e-01\n",
      " 9.98284876e-01 9.80071902e-01 9.97670472e-01 1.48108592e-02\n",
      " 9.05823708e-02 9.95095015e-01 9.63780224e-01 9.74762797e-01\n",
      " 7.67080113e-02 5.80357194e-01 9.93706286e-01 1.10028066e-01\n",
      " 3.09410393e-01 9.99848485e-01 9.50720489e-01 9.80930448e-01\n",
      " 7.74436281e-04 2.34013379e-01 3.71162832e-01 8.66005123e-01\n",
      " 1.07682645e-02 9.96237040e-01 2.95219314e-03 2.27552503e-01\n",
      " 7.82157779e-01 1.82169542e-01 9.99606907e-01 7.65876146e-03\n",
      " 1.50361704e-03 3.55326235e-01 2.04681121e-02 1.88356789e-03\n",
      " 5.20290434e-01 7.65564620e-01 2.73893982e-01 4.32176925e-02\n",
      " 5.12566268e-01 2.37038761e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 182 [0/54 (0%)]\tTrain Loss: 0.047817\n",
      "Train Epoch: 182 [8/54 (15%)]\tTrain Loss: 0.004379\n",
      "Train Epoch: 182 [16/54 (30%)]\tTrain Loss: 0.004698\n",
      "Train Epoch: 182 [24/54 (44%)]\tTrain Loss: 0.001039\n",
      "Train Epoch: 182 [32/54 (59%)]\tTrain Loss: 0.019914\n",
      "Train Epoch: 182 [40/54 (74%)]\tTrain Loss: 0.012446\n",
      "Train Epoch: 182 [48/54 (89%)]\tTrain Loss: 0.028943\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.46122156e-02 8.47277999e-01 6.62415773e-02 9.96740878e-01\n",
      " 1.23163134e-01 3.43059818e-03 8.78573135e-02 2.93480963e-01\n",
      " 1.79046709e-02 1.30065545e-01 6.30881935e-02 2.05621105e-02\n",
      " 3.76728526e-03 3.48603091e-04 9.06318659e-04 9.69797256e-04\n",
      " 3.31211425e-02 1.12785585e-01 9.21822429e-01 3.58802021e-01\n",
      " 9.46028065e-03 9.98433650e-01 9.99153852e-01 9.99488831e-01\n",
      " 7.21187174e-01 9.99998808e-01 9.99898195e-01 8.93377721e-01\n",
      " 8.26100707e-01 7.96408877e-02 2.96383630e-02 8.96003127e-01\n",
      " 9.15559709e-01 4.65136545e-04 3.53297619e-05 2.07465468e-03\n",
      " 3.04329884e-03 5.37440181e-01 2.40197289e-03 4.98493426e-02\n",
      " 9.30735748e-03 3.05624306e-03 2.41999608e-03 5.38141467e-03\n",
      " 4.61819815e-03 4.13478650e-02 9.86182332e-01 4.35836077e-01\n",
      " 9.99956965e-01 9.97891843e-01 9.99214172e-01 3.05248221e-04\n",
      " 4.48929437e-04 6.66032592e-03 1.58224236e-02 2.13297922e-03\n",
      " 1.92568362e-01 7.78406719e-03 2.02854443e-03 2.90482189e-04\n",
      " 9.99825060e-01 9.85150754e-01 9.86166775e-01 9.97860610e-01\n",
      " 7.53595293e-01 8.75656664e-01 9.99693155e-01 9.99771774e-01\n",
      " 1.00000000e+00 2.25538582e-01 9.85104620e-01 9.77477133e-01\n",
      " 9.99919653e-01 9.98527765e-01 9.82176125e-01 7.71265686e-01\n",
      " 9.99989152e-01 9.99972820e-01 9.87636805e-01 9.99996662e-01\n",
      " 9.99996901e-01 9.99825299e-01 9.99934912e-01 4.64927852e-02\n",
      " 7.20566988e-01 9.98465776e-01 9.79137540e-01 9.86800671e-01\n",
      " 4.72981334e-02 9.98153746e-01 9.99566972e-01 2.71957338e-01\n",
      " 7.94281900e-01 9.99999881e-01 9.99968767e-01 9.99927998e-01\n",
      " 2.22129119e-03 9.99812782e-01 9.94940281e-01 9.88059223e-01\n",
      " 1.10986000e-02 9.99814689e-01 8.74927789e-02 9.85180378e-01\n",
      " 9.96970415e-01 9.11147535e-01 9.99999523e-01 4.75737192e-02\n",
      " 4.30147251e-04 8.54359210e-01 4.77884077e-02 3.72630922e-04\n",
      " 9.59237397e-01 9.99872208e-01 9.75870848e-01 2.35544860e-01\n",
      " 4.44123745e-01 2.47748360e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 183 [0/54 (0%)]\tTrain Loss: 0.002353\n",
      "Train Epoch: 183 [8/54 (15%)]\tTrain Loss: 0.004042\n",
      "Train Epoch: 183 [16/54 (30%)]\tTrain Loss: 0.005896\n",
      "Train Epoch: 183 [24/54 (44%)]\tTrain Loss: 0.008253\n",
      "Train Epoch: 183 [32/54 (59%)]\tTrain Loss: 0.014584\n",
      "Train Epoch: 183 [40/54 (74%)]\tTrain Loss: 0.005967\n",
      "Train Epoch: 183 [48/54 (89%)]\tTrain Loss: 0.009094\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.09399889 0.99324292 0.30660287 0.98947501 0.89603603 0.5461064\n",
      " 0.89972466 0.85837072 0.08686552 0.97086233 0.89356381 0.67872816\n",
      " 0.77430493 0.40144274 0.67738509 0.15475847 0.10096791 0.1891454\n",
      " 0.23458914 0.20204964 0.04232876 0.99452591 0.99927205 0.99964201\n",
      " 0.60996693 0.99996865 0.99977058 0.4967429  0.8478092  0.32078961\n",
      " 0.02438347 0.9536587  0.98642933 0.04606752 0.00114647 0.01112237\n",
      " 0.01597465 0.95048058 0.47105885 0.25092548 0.30260438 0.10365936\n",
      " 0.02844722 0.816679   0.8465395  0.91634429 0.99244261 0.96589357\n",
      " 0.99996185 0.99855238 0.99994171 0.05990579 0.0152988  0.95198226\n",
      " 0.38823125 0.02346345 0.98716438 0.13264902 0.13038164 0.01157066\n",
      " 0.99998724 0.9967339  0.99916756 0.99949908 0.99875569 0.99344122\n",
      " 0.99616963 0.99998653 0.9999994  0.91445386 0.99694949 0.99698371\n",
      " 0.99996161 0.99987543 0.99942362 0.99991584 1.         0.99999976\n",
      " 0.99996376 0.99999952 0.9999975  0.99991298 0.99999404 0.98857993\n",
      " 0.9907003  0.99900204 0.99970204 0.99967182 0.08001307 0.99870157\n",
      " 0.98524231 0.93478328 0.97523457 0.99999988 0.9999789  0.99820638\n",
      " 0.03939398 0.81899446 0.74196833 0.96314037 0.4244937  0.99980956\n",
      " 0.04047779 0.99727231 0.99785221 0.99792981 0.99999797 0.06017625\n",
      " 0.01592473 0.91186965 0.2041671  0.07555104 0.88278705 0.81662548\n",
      " 0.81266439 0.88395476 0.96588689 0.98643363]\n",
      "predict [0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 184 [0/54 (0%)]\tTrain Loss: 0.015819\n",
      "Train Epoch: 184 [8/54 (15%)]\tTrain Loss: 0.003267\n",
      "Train Epoch: 184 [16/54 (30%)]\tTrain Loss: 0.006944\n",
      "Train Epoch: 184 [24/54 (44%)]\tTrain Loss: 0.013849\n",
      "Train Epoch: 184 [32/54 (59%)]\tTrain Loss: 0.056851\n",
      "Train Epoch: 184 [40/54 (74%)]\tTrain Loss: 0.010930\n",
      "Train Epoch: 184 [48/54 (89%)]\tTrain Loss: 0.006733\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.56066234e-03 9.90629256e-01 7.14701951e-01 3.18720788e-01\n",
      " 7.06825927e-02 3.09069082e-03 3.74725223e-01 3.07583988e-01\n",
      " 2.05054991e-02 3.89018327e-01 1.36968404e-01 2.27215990e-01\n",
      " 3.46796028e-03 7.00594066e-03 3.07883136e-02 3.16486374e-04\n",
      " 7.26278406e-04 5.17438166e-02 2.83476375e-02 2.11561665e-01\n",
      " 3.77117544e-02 9.94578600e-01 9.99550402e-01 9.99619246e-01\n",
      " 9.84781012e-02 9.99968886e-01 9.98661518e-01 5.52649081e-01\n",
      " 9.06953737e-02 4.39016730e-01 8.75005592e-03 7.60827214e-02\n",
      " 1.62512943e-01 1.39266282e-04 9.65836371e-05 2.82109919e-04\n",
      " 1.92356086e-03 7.45335519e-01 5.18710399e-03 1.06647596e-01\n",
      " 3.17885540e-02 1.70693975e-02 1.11704599e-03 8.35386943e-03\n",
      " 3.05714831e-02 4.88426071e-03 9.06019986e-01 2.74981111e-01\n",
      " 9.99897838e-01 9.49617982e-01 9.98073816e-01 5.34365536e-04\n",
      " 5.23784140e-04 8.90508518e-02 3.43700917e-03 5.29752113e-03\n",
      " 3.26567829e-01 1.23802396e-02 8.38397369e-02 6.28372480e-04\n",
      " 9.79032159e-01 4.64038521e-01 7.59806752e-01 9.96161461e-01\n",
      " 7.38244176e-01 8.68257105e-01 8.54415178e-01 9.98945892e-01\n",
      " 9.99936819e-01 9.83998403e-02 9.07794535e-01 9.07559037e-01\n",
      " 9.99705851e-01 9.84860361e-01 9.51253831e-01 9.67473626e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99227881e-01 9.99782979e-01\n",
      " 9.93053496e-01 9.92648661e-01 9.99684811e-01 5.45823351e-02\n",
      " 8.41336787e-01 9.57011521e-01 9.91669774e-01 9.84379351e-01\n",
      " 1.60796456e-02 9.88483489e-01 9.99635339e-01 1.14934772e-01\n",
      " 4.43849534e-01 9.99987841e-01 9.98355091e-01 9.99458849e-01\n",
      " 3.08374199e-03 3.25950235e-01 4.26732689e-01 5.29429138e-01\n",
      " 1.16405725e-01 9.98295605e-01 1.40377041e-03 7.10285366e-01\n",
      " 9.75266337e-01 7.90744543e-01 9.99986172e-01 1.25818315e-03\n",
      " 4.23114252e-04 3.91746432e-01 7.63487210e-03 1.42604252e-03\n",
      " 4.12600726e-01 1.59424201e-01 1.36151850e-01 2.04909835e-02\n",
      " 9.57245767e-01 9.81360435e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "Train Epoch: 185 [0/54 (0%)]\tTrain Loss: 0.017188\n",
      "Train Epoch: 185 [8/54 (15%)]\tTrain Loss: 0.090325\n",
      "Train Epoch: 185 [16/54 (30%)]\tTrain Loss: 0.001580\n",
      "Train Epoch: 185 [24/54 (44%)]\tTrain Loss: 0.017078\n",
      "Train Epoch: 185 [32/54 (59%)]\tTrain Loss: 0.001889\n",
      "Train Epoch: 185 [40/54 (74%)]\tTrain Loss: 0.007734\n",
      "Train Epoch: 185 [48/54 (89%)]\tTrain Loss: 0.060766\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.48017956e-02 8.63120914e-01 3.79429907e-01 7.01997399e-01\n",
      " 1.04007222e-01 3.27945058e-03 6.83889806e-01 6.95000112e-01\n",
      " 9.07362159e-03 2.19002478e-02 2.62442231e-03 6.10488933e-03\n",
      " 1.16318639e-03 1.06030898e-02 2.33235717e-01 2.85114278e-04\n",
      " 1.74920511e-04 1.17948890e-01 6.39091790e-01 1.54185425e-02\n",
      " 4.30137245e-03 8.86785686e-01 9.99285519e-01 9.97280121e-01\n",
      " 8.15903619e-02 9.99906659e-01 9.98599112e-01 5.14870346e-01\n",
      " 5.07786751e-01 1.48668036e-01 8.33392814e-02 9.03403103e-01\n",
      " 3.43737483e-01 8.93593642e-06 5.64856873e-06 1.61993339e-05\n",
      " 1.61769145e-04 8.50979507e-01 1.02978095e-03 6.72255382e-02\n",
      " 1.37700988e-02 6.19548000e-03 1.29234293e-04 1.48693407e-02\n",
      " 3.18168029e-02 3.20378765e-02 9.75989699e-01 3.97553235e-01\n",
      " 9.99927998e-01 8.12092900e-01 9.99829054e-01 4.07454470e-04\n",
      " 3.81233753e-04 1.17754946e-02 2.89158057e-03 1.99025366e-02\n",
      " 9.70579267e-01 7.64244143e-03 8.77279881e-03 2.40902285e-04\n",
      " 9.57726896e-01 4.31510150e-01 5.63123167e-01 8.97650182e-01\n",
      " 8.56800556e-01 9.99683619e-01 9.88491297e-01 9.98455286e-01\n",
      " 1.00000000e+00 9.05084670e-01 9.81345594e-01 9.81185913e-01\n",
      " 9.99983430e-01 9.95650113e-01 9.77843881e-01 9.70590174e-01\n",
      " 9.99999762e-01 9.99990821e-01 9.87923801e-01 9.99999642e-01\n",
      " 9.99946594e-01 9.99126375e-01 9.99970078e-01 2.58076563e-02\n",
      " 2.06389651e-01 9.95534658e-01 9.78040218e-01 9.46807981e-01\n",
      " 4.65787016e-02 9.99991655e-01 9.99996901e-01 4.39655244e-01\n",
      " 6.25846148e-01 1.00000000e+00 9.98714566e-01 9.95559573e-01\n",
      " 1.15597458e-03 1.20925210e-01 1.79959819e-01 6.73115730e-01\n",
      " 1.19385519e-03 9.99331653e-01 3.98378616e-04 9.50963080e-01\n",
      " 9.99726951e-01 9.48760450e-01 9.99999762e-01 1.27338583e-03\n",
      " 3.90515284e-04 6.56348467e-01 5.09273028e-04 1.35043508e-03\n",
      " 6.56187117e-01 9.16192234e-02 6.01769127e-02 1.17523959e-02\n",
      " 8.46325994e-01 6.78866625e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 186 [0/54 (0%)]\tTrain Loss: 0.013929\n",
      "Train Epoch: 186 [8/54 (15%)]\tTrain Loss: 0.002921\n",
      "Train Epoch: 186 [16/54 (30%)]\tTrain Loss: 0.023191\n",
      "Train Epoch: 186 [24/54 (44%)]\tTrain Loss: 0.002248\n",
      "Train Epoch: 186 [32/54 (59%)]\tTrain Loss: 0.010810\n",
      "Train Epoch: 186 [40/54 (74%)]\tTrain Loss: 0.024920\n",
      "Train Epoch: 186 [48/54 (89%)]\tTrain Loss: 0.016090\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.53656856e-03 9.83542204e-01 7.22621322e-01 9.02707577e-01\n",
      " 6.04339957e-01 1.21741369e-02 9.66549337e-01 8.97699535e-01\n",
      " 8.85340571e-02 2.43270069e-01 1.45310998e-01 8.58565867e-02\n",
      " 9.68412682e-03 4.41428833e-02 7.56334364e-01 2.20155828e-02\n",
      " 2.64865719e-02 1.13182545e-01 9.32687581e-01 3.53905886e-01\n",
      " 3.74171324e-02 9.63372648e-01 9.97148097e-01 9.99909639e-01\n",
      " 5.68888783e-01 9.99801576e-01 9.99937296e-01 8.72984886e-01\n",
      " 4.07095581e-01 3.72351617e-01 9.87428367e-01 9.88646448e-01\n",
      " 7.86394894e-01 2.93567628e-02 9.75642295e-04 3.38292634e-03\n",
      " 8.72147828e-03 9.76033986e-01 5.19033149e-02 3.20942521e-01\n",
      " 7.82895237e-02 1.74749903e-02 3.07632308e-03 2.15005130e-01\n",
      " 4.71238703e-01 1.51589409e-01 9.86926198e-01 7.91571021e-01\n",
      " 9.99995589e-01 9.67313886e-01 9.99976516e-01 5.98124275e-03\n",
      " 5.98875061e-02 1.77558348e-01 1.37914130e-02 2.51469780e-02\n",
      " 9.63777542e-01 4.66368720e-02 2.40398496e-01 1.35713235e-01\n",
      " 9.97784197e-01 9.53260779e-01 9.78869021e-01 9.93741095e-01\n",
      " 9.97735977e-01 9.99424458e-01 9.79768693e-01 9.99993563e-01\n",
      " 9.99999881e-01 9.04011846e-01 9.80780959e-01 9.57280278e-01\n",
      " 9.99995470e-01 9.99385476e-01 9.96074438e-01 9.89248753e-01\n",
      " 9.99997854e-01 9.99993920e-01 9.81953621e-01 9.99991059e-01\n",
      " 9.99970675e-01 9.99902129e-01 9.99984503e-01 2.93255746e-01\n",
      " 2.94124246e-01 9.99769628e-01 9.88939047e-01 9.86694932e-01\n",
      " 2.63861775e-01 9.99375403e-01 9.99999285e-01 8.78238559e-01\n",
      " 9.56070006e-01 1.00000000e+00 9.97016788e-01 9.99772608e-01\n",
      " 9.71012108e-04 6.45770133e-01 9.37459707e-01 9.84422565e-01\n",
      " 4.86806370e-02 9.99747813e-01 6.04088381e-02 6.60825849e-01\n",
      " 9.83464360e-01 4.10488665e-01 9.99991775e-01 5.61736859e-02\n",
      " 2.20571049e-02 8.71248245e-01 9.84820053e-02 9.98817831e-02\n",
      " 9.87233520e-01 9.99033689e-01 5.54574728e-01 1.30304685e-02\n",
      " 9.73365307e-01 9.99994516e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 187 [0/54 (0%)]\tTrain Loss: 0.002415\n",
      "Train Epoch: 187 [8/54 (15%)]\tTrain Loss: 0.005819\n",
      "Train Epoch: 187 [16/54 (30%)]\tTrain Loss: 0.001672\n",
      "Train Epoch: 187 [24/54 (44%)]\tTrain Loss: 0.005481\n",
      "Train Epoch: 187 [32/54 (59%)]\tTrain Loss: 0.028422\n",
      "Train Epoch: 187 [40/54 (74%)]\tTrain Loss: 0.015420\n",
      "Train Epoch: 187 [48/54 (89%)]\tTrain Loss: 0.070453\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.69500286e-04 5.21547616e-01 3.45763803e-01 4.40825999e-01\n",
      " 1.56532913e-01 2.04866612e-03 4.83848602e-01 1.21640697e-01\n",
      " 3.86687033e-02 2.33350590e-01 1.10379411e-02 1.29816771e-01\n",
      " 7.33833644e-04 8.61053169e-03 6.70358986e-02 8.58491287e-03\n",
      " 1.07741021e-02 1.24768011e-01 8.68110836e-01 9.75380018e-02\n",
      " 1.46301821e-01 9.93267179e-01 9.99246359e-01 9.98127162e-01\n",
      " 5.19005299e-01 9.99723375e-01 9.99991298e-01 9.24166977e-01\n",
      " 6.81986988e-01 3.31447199e-02 9.78011489e-01 9.93821979e-01\n",
      " 3.56474221e-02 6.59158267e-03 6.54046744e-05 4.34016110e-04\n",
      " 2.09086947e-03 9.71046209e-01 8.42007548e-02 1.10570759e-01\n",
      " 4.06112224e-02 3.14088375e-03 7.02272751e-04 1.13354199e-01\n",
      " 1.23429224e-02 1.67638659e-01 9.67778027e-01 7.45434046e-01\n",
      " 9.99913692e-01 9.25107658e-01 9.99694943e-01 1.81247611e-04\n",
      " 6.11811294e-04 2.48818640e-02 1.88494194e-02 6.93882210e-03\n",
      " 9.54631209e-01 5.67525849e-02 4.51150119e-01 2.21244083e-03\n",
      " 9.99240398e-01 9.41891670e-01 9.10008848e-01 9.95405793e-01\n",
      " 8.60773623e-01 9.97685432e-01 9.94460464e-01 9.99974132e-01\n",
      " 9.99999881e-01 8.60492349e-01 9.92774367e-01 9.88285840e-01\n",
      " 9.99895453e-01 9.95045304e-01 7.18628407e-01 9.97007787e-01\n",
      " 9.99979734e-01 9.99984622e-01 9.99881268e-01 9.99997973e-01\n",
      " 1.00000000e+00 9.99981284e-01 9.99981642e-01 5.75321913e-02\n",
      " 1.64455459e-01 9.99187768e-01 9.99819219e-01 9.99060929e-01\n",
      " 1.22680992e-01 9.99999166e-01 9.99997616e-01 6.82067513e-01\n",
      " 8.35982084e-01 9.99981761e-01 9.99585330e-01 9.63966608e-01\n",
      " 1.80109739e-04 9.96452332e-01 9.36005235e-01 9.71713245e-01\n",
      " 4.41364050e-02 9.98356283e-01 1.46075621e-01 5.08099139e-01\n",
      " 9.36004519e-01 9.27588761e-01 9.99998212e-01 1.88413691e-02\n",
      " 2.00838260e-02 9.78834987e-01 3.77461948e-02 2.29091361e-01\n",
      " 9.73062038e-01 6.94072366e-01 3.97040784e-01 1.24187090e-01\n",
      " 8.84488940e-01 9.80109930e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 188 [0/54 (0%)]\tTrain Loss: 0.001344\n",
      "Train Epoch: 188 [8/54 (15%)]\tTrain Loss: 0.014546\n",
      "Train Epoch: 188 [16/54 (30%)]\tTrain Loss: 0.006709\n",
      "Train Epoch: 188 [24/54 (44%)]\tTrain Loss: 0.056177\n",
      "Train Epoch: 188 [32/54 (59%)]\tTrain Loss: 0.002275\n",
      "Train Epoch: 188 [40/54 (74%)]\tTrain Loss: 0.007161\n",
      "Train Epoch: 188 [48/54 (89%)]\tTrain Loss: 0.014792\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.10053823e-03 9.70748067e-01 7.28293359e-01 9.99689341e-01\n",
      " 6.52217209e-01 1.85261555e-02 9.76395369e-01 6.47974551e-01\n",
      " 1.21011771e-02 3.16509306e-01 6.98956370e-01 5.76080084e-01\n",
      " 3.00740689e-01 7.12989151e-01 8.00562203e-01 3.38519439e-02\n",
      " 1.82368997e-02 1.51528865e-02 1.22370962e-02 3.42050544e-03\n",
      " 2.09724046e-02 8.64742696e-01 9.99684572e-01 9.99234319e-01\n",
      " 2.24616081e-02 9.99998569e-01 9.96683776e-01 8.63790691e-01\n",
      " 1.07786842e-01 1.15772478e-01 9.51211989e-01 7.74065137e-01\n",
      " 9.99668956e-01 1.55558009e-04 2.62992980e-04 3.77235265e-04\n",
      " 1.36633236e-02 5.65240979e-01 2.57663410e-02 3.41732979e-01\n",
      " 2.62295246e-01 5.28508052e-02 4.42758988e-04 1.55748740e-01\n",
      " 7.02393129e-02 8.17042962e-03 8.42105865e-01 5.29862642e-01\n",
      " 9.99895573e-01 5.58033943e-01 8.90757084e-01 2.32789083e-03\n",
      " 6.62330762e-02 1.67257145e-01 3.90617468e-04 1.15864649e-01\n",
      " 6.94223791e-02 7.14159906e-02 2.32799321e-01 1.63888648e-01\n",
      " 9.47700083e-01 1.95060581e-01 5.77793896e-01 9.73982453e-01\n",
      " 8.97762537e-01 9.99985218e-01 9.97366726e-01 9.99999166e-01\n",
      " 1.00000000e+00 1.89464301e-01 7.30684042e-01 8.83747101e-01\n",
      " 9.99991655e-01 9.99793231e-01 9.99981284e-01 9.74701226e-01\n",
      " 1.00000000e+00 9.99903560e-01 9.99569595e-01 1.00000000e+00\n",
      " 9.99849200e-01 9.51113701e-01 9.99955058e-01 6.37562275e-01\n",
      " 9.25802052e-01 9.72747862e-01 9.21565831e-01 9.75756764e-01\n",
      " 6.26094759e-01 6.45396113e-01 1.00000000e+00 5.23695834e-02\n",
      " 1.63164288e-01 1.00000000e+00 9.99892592e-01 9.99954104e-01\n",
      " 6.50959322e-03 7.30086207e-01 5.84197879e-01 9.74143863e-01\n",
      " 3.65074351e-02 9.98716831e-01 3.70866358e-02 2.03784451e-01\n",
      " 8.69450212e-01 5.01692779e-02 9.92565274e-01 1.85997542e-02\n",
      " 1.81270007e-03 6.13429129e-01 9.68174115e-02 1.31532340e-03\n",
      " 9.88434136e-01 5.12712896e-01 1.06069185e-01 1.23135652e-03\n",
      " 5.01588464e-01 9.98150647e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 189 [0/54 (0%)]\tTrain Loss: 0.001134\n",
      "Train Epoch: 189 [8/54 (15%)]\tTrain Loss: 0.120099\n",
      "Train Epoch: 189 [16/54 (30%)]\tTrain Loss: 0.002009\n",
      "Train Epoch: 189 [24/54 (44%)]\tTrain Loss: 0.025731\n",
      "Train Epoch: 189 [32/54 (59%)]\tTrain Loss: 0.065304\n",
      "Train Epoch: 189 [40/54 (74%)]\tTrain Loss: 0.010188\n",
      "Train Epoch: 189 [48/54 (89%)]\tTrain Loss: 0.005677\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.98493174e-03 8.37363780e-01 6.63349628e-01 9.50545549e-01\n",
      " 3.11582774e-01 2.97828042e-03 5.91124177e-01 5.20936668e-01\n",
      " 2.57941708e-02 7.70454764e-01 6.37692451e-01 5.95736444e-01\n",
      " 3.48467752e-02 2.88490020e-02 3.58625874e-02 4.64038588e-02\n",
      " 1.75101444e-01 1.10251177e-02 2.22534984e-02 4.91462275e-02\n",
      " 8.52263346e-03 9.07102168e-01 9.99400854e-01 9.98538017e-01\n",
      " 1.45263284e-01 9.99953866e-01 9.98966813e-01 6.88451946e-01\n",
      " 8.26346800e-02 1.35872945e-01 2.52480000e-01 5.63372612e-01\n",
      " 7.99273551e-01 5.31036872e-03 4.08661971e-03 7.27371871e-03\n",
      " 9.13572609e-02 4.03570265e-01 4.93090264e-02 1.40772983e-01\n",
      " 6.28382787e-02 2.05790121e-02 9.95978480e-04 2.73141395e-02\n",
      " 1.43907676e-02 4.81735682e-03 3.96010697e-01 3.19795966e-01\n",
      " 9.99365509e-01 9.90853131e-01 9.95419502e-01 1.55638270e-02\n",
      " 7.39347190e-03 4.06797975e-02 6.24464033e-03 2.46437639e-02\n",
      " 2.13919938e-01 3.87082130e-01 6.86143994e-01 1.23229893e-02\n",
      " 5.25332451e-01 1.45535126e-01 3.55228990e-01 8.44858766e-01\n",
      " 7.56483138e-01 9.91148591e-01 7.87684977e-01 9.99998927e-01\n",
      " 1.00000000e+00 5.53548574e-01 3.63836110e-01 4.26388472e-01\n",
      " 9.94372368e-01 9.75548863e-01 9.87368643e-01 4.90211636e-01\n",
      " 1.00000000e+00 1.00000000e+00 5.16992807e-01 9.96670425e-01\n",
      " 9.96182024e-01 6.75704718e-01 9.97964859e-01 3.09644248e-02\n",
      " 3.14136863e-01 8.31779301e-01 8.43814075e-01 9.50633764e-01\n",
      " 6.20570064e-01 9.90607142e-01 9.98130739e-01 6.77145600e-01\n",
      " 6.72031879e-01 1.00000000e+00 9.99942780e-01 9.99253452e-01\n",
      " 6.84601720e-03 1.89073011e-01 8.12553704e-01 9.99095440e-01\n",
      " 1.53126456e-02 9.73343730e-01 7.57466480e-02 6.50192320e-01\n",
      " 7.68031478e-01 3.83170359e-02 9.99750435e-01 1.27067342e-01\n",
      " 2.51140483e-02 8.88690114e-01 6.44468307e-01 9.81731862e-02\n",
      " 9.95877624e-01 9.78518009e-01 1.06310941e-01 1.74885616e-02\n",
      " 9.94591653e-01 9.84658360e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 190 [0/54 (0%)]\tTrain Loss: 0.029042\n",
      "Train Epoch: 190 [8/54 (15%)]\tTrain Loss: 0.009932\n",
      "Train Epoch: 190 [16/54 (30%)]\tTrain Loss: 0.002178\n",
      "Train Epoch: 190 [24/54 (44%)]\tTrain Loss: 0.020219\n",
      "Train Epoch: 190 [32/54 (59%)]\tTrain Loss: 0.012454\n",
      "Train Epoch: 190 [40/54 (74%)]\tTrain Loss: 0.075185\n",
      "Train Epoch: 190 [48/54 (89%)]\tTrain Loss: 0.024098\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.31969066e-03 7.32933700e-01 5.47650516e-01 9.86652911e-01\n",
      " 4.68265623e-01 6.47830544e-03 5.64675748e-01 9.93973792e-01\n",
      " 1.41572366e-02 8.44719291e-01 9.14722860e-01 8.27131510e-01\n",
      " 4.24131185e-01 2.00414620e-02 1.73430461e-02 7.88754597e-03\n",
      " 5.53428056e-03 1.46692574e-01 9.29673016e-01 7.56369710e-01\n",
      " 4.86357398e-02 9.95755970e-01 9.99500632e-01 9.99047101e-01\n",
      " 6.06579363e-01 9.99902368e-01 9.98308182e-01 8.94313693e-01\n",
      " 6.93207145e-01 1.27228096e-01 9.95486557e-01 9.98088419e-01\n",
      " 6.26915753e-01 5.98491286e-04 2.68232601e-04 9.97238327e-03\n",
      " 8.43927264e-02 9.91623700e-01 1.14766926e-01 6.13707639e-02\n",
      " 2.64383052e-02 1.59029290e-02 3.96629386e-02 4.18802172e-01\n",
      " 2.00522747e-02 1.02204993e-01 9.86851394e-01 9.91300285e-01\n",
      " 9.99961019e-01 9.16310549e-01 9.99978304e-01 3.40425670e-02\n",
      " 6.73321784e-02 4.55733508e-01 6.05418868e-02 3.33833754e-01\n",
      " 9.80413973e-01 5.67826293e-02 9.68946755e-01 2.12175548e-01\n",
      " 9.95610058e-01 8.77055049e-01 9.77587819e-01 9.98056591e-01\n",
      " 9.96459782e-01 9.97885048e-01 9.92918551e-01 9.99999285e-01\n",
      " 1.00000000e+00 9.67421234e-01 9.06111121e-01 9.35279191e-01\n",
      " 9.89268720e-01 9.88864303e-01 9.95984316e-01 9.90309536e-01\n",
      " 9.99999762e-01 9.99999285e-01 9.91242051e-01 9.99996781e-01\n",
      " 9.99998689e-01 9.95899022e-01 9.99940872e-01 5.57097912e-01\n",
      " 2.35674590e-01 9.16513503e-01 9.85309422e-01 9.84078944e-01\n",
      " 3.73299479e-01 9.99615550e-01 8.87680173e-01 9.68674660e-01\n",
      " 9.67677355e-01 9.99999046e-01 9.98352051e-01 9.98872340e-01\n",
      " 3.38007323e-02 2.13586107e-01 2.21126527e-01 9.45383489e-01\n",
      " 3.58304828e-02 9.98643219e-01 3.30618590e-01 9.86788273e-01\n",
      " 9.92336452e-01 6.43330932e-01 9.99992251e-01 1.13963835e-01\n",
      " 2.24620141e-02 7.58136272e-01 3.62326056e-02 2.78295577e-03\n",
      " 5.22925138e-01 9.91017818e-01 1.05077334e-01 1.02372080e-01\n",
      " 2.72955686e-01 1.42318845e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "vote_pred [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 43 TN= 43 FN= 15 FP= 17\n",
      "TP+FP 60\n",
      "precision 0.7166666666666667\n",
      "recall 0.7413793103448276\n",
      "F1 0.728813559322034\n",
      "acc 0.7288135593220338\n",
      "AUCp 0.7290229885057472\n",
      "AUC 0.7591954022988506\n",
      "\n",
      " The epoch is 190, average recall: 0.7414, average precision: 0.7167,average F1: 0.7288, average accuracy: 0.7288, average AUC: 0.7592\n",
      "Train Epoch: 191 [0/54 (0%)]\tTrain Loss: 0.024687\n",
      "Train Epoch: 191 [8/54 (15%)]\tTrain Loss: 0.009669\n",
      "Train Epoch: 191 [16/54 (30%)]\tTrain Loss: 0.007879\n",
      "Train Epoch: 191 [24/54 (44%)]\tTrain Loss: 0.030817\n",
      "Train Epoch: 191 [32/54 (59%)]\tTrain Loss: 0.016669\n",
      "Train Epoch: 191 [40/54 (74%)]\tTrain Loss: 0.002408\n",
      "Train Epoch: 191 [48/54 (89%)]\tTrain Loss: 0.000907\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.57231782e-02 6.71577215e-01 7.88973391e-01 9.99357879e-01\n",
      " 9.11042511e-01 3.32204811e-02 7.61414945e-01 9.99933720e-01\n",
      " 3.34598720e-01 5.94952404e-01 9.98395145e-01 7.79536739e-02\n",
      " 8.62991750e-01 4.95824404e-03 1.90406963e-02 2.38957461e-02\n",
      " 1.94894239e-01 3.55902128e-02 9.88869667e-01 3.80597711e-01\n",
      " 1.44917602e-02 9.99992967e-01 9.99987841e-01 9.99987960e-01\n",
      " 9.69519198e-01 1.00000000e+00 9.99927640e-01 9.39728618e-01\n",
      " 9.49787855e-01 9.31643248e-01 9.77622509e-01 9.99708831e-01\n",
      " 9.17369187e-01 5.65617438e-03 2.12081824e-04 2.19393848e-03\n",
      " 1.76377539e-02 9.99951839e-01 1.56090790e-02 3.40158403e-01\n",
      " 1.17274143e-01 1.11703854e-02 1.28410915e-02 5.28357863e-01\n",
      " 8.90243232e-01 9.16700810e-02 9.96338487e-01 9.97357011e-01\n",
      " 9.99950051e-01 9.90389526e-01 9.99976039e-01 8.08655564e-03\n",
      " 4.54098657e-02 4.38177019e-01 1.58972514e-03 2.63906628e-01\n",
      " 9.99444902e-01 1.62856057e-01 9.04759228e-01 5.33275232e-02\n",
      " 9.87976491e-01 6.81476235e-01 6.43993795e-01 9.65870321e-01\n",
      " 9.97025311e-01 9.99625444e-01 9.97112513e-01 9.99997854e-01\n",
      " 1.00000000e+00 8.05594265e-01 9.87425268e-01 9.87758815e-01\n",
      " 9.99999285e-01 9.95588183e-01 9.72946346e-01 9.67004597e-01\n",
      " 1.00000000e+00 9.99998927e-01 9.99955297e-01 1.00000000e+00\n",
      " 9.99997854e-01 9.99921203e-01 9.99704659e-01 6.54140413e-01\n",
      " 8.88314068e-01 9.98374820e-01 9.98828948e-01 9.97883141e-01\n",
      " 9.83275890e-01 1.00000000e+00 9.99999642e-01 9.83477056e-01\n",
      " 8.00988674e-01 1.00000000e+00 9.99995112e-01 9.99998927e-01\n",
      " 1.74516961e-02 5.78808367e-01 9.81374860e-01 9.99999523e-01\n",
      " 1.07363738e-01 9.99737322e-01 5.13335943e-01 9.99844551e-01\n",
      " 9.98857379e-01 7.08434224e-01 9.99999762e-01 2.57830977e-01\n",
      " 1.34199634e-02 9.99909282e-01 9.34952319e-01 2.79813143e-03\n",
      " 9.96376455e-01 9.99999642e-01 9.95483041e-01 1.71059117e-01\n",
      " 9.66134667e-01 9.26472306e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 192 [0/54 (0%)]\tTrain Loss: 0.014371\n",
      "Train Epoch: 192 [8/54 (15%)]\tTrain Loss: 0.004784\n",
      "Train Epoch: 192 [16/54 (30%)]\tTrain Loss: 0.029434\n",
      "Train Epoch: 192 [24/54 (44%)]\tTrain Loss: 0.058588\n",
      "Train Epoch: 192 [32/54 (59%)]\tTrain Loss: 0.018369\n",
      "Train Epoch: 192 [40/54 (74%)]\tTrain Loss: 0.003411\n",
      "Train Epoch: 192 [48/54 (89%)]\tTrain Loss: 0.035189\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.02960328e-03 2.41789132e-01 1.85739025e-02 7.58453913e-04\n",
      " 2.28491859e-04 9.11468815e-04 1.89513087e-01 1.30888569e-04\n",
      " 4.67190240e-03 5.18023729e-01 9.78265405e-02 5.98754501e-03\n",
      " 5.31639531e-02 2.52853915e-05 3.26486508e-04 1.62671233e-04\n",
      " 2.68266129e-04 1.17134266e-02 5.26236184e-02 4.74489341e-03\n",
      " 2.60721194e-03 9.19376493e-01 9.80435967e-01 9.98142362e-01\n",
      " 1.02190703e-01 9.99434769e-01 9.99517679e-01 3.85027975e-01\n",
      " 5.77604063e-02 2.03132890e-02 9.38508868e-01 9.22472715e-01\n",
      " 9.78044569e-01 1.21086987e-06 1.00095201e-06 6.76015334e-05\n",
      " 2.14255688e-05 6.21108651e-01 1.33524300e-03 3.06562539e-02\n",
      " 1.39956148e-02 1.73604526e-02 1.09535176e-03 1.56420935e-02\n",
      " 1.50516173e-02 8.67744610e-02 4.80654120e-01 2.12617710e-01\n",
      " 9.99846220e-01 9.90307093e-01 9.99202192e-01 5.29991894e-06\n",
      " 9.61605474e-06 8.40747380e-05 1.35141969e-01 6.06618705e-05\n",
      " 6.36360228e-01 1.57091374e-04 1.83453299e-02 3.17355443e-06\n",
      " 7.46274829e-01 1.36677902e-02 1.24463238e-01 9.63556945e-01\n",
      " 8.20085853e-02 9.91846621e-02 3.92170340e-01 9.98960257e-01\n",
      " 9.99789298e-01 8.82761419e-01 5.94576001e-01 6.75524712e-01\n",
      " 9.99861360e-01 9.92866397e-01 6.09064460e-01 9.78957653e-01\n",
      " 9.99571979e-01 9.99284327e-01 5.74667633e-01 9.99939203e-01\n",
      " 9.99046147e-01 9.99716580e-01 9.99909520e-01 4.04585958e-01\n",
      " 3.31213355e-01 9.96981800e-01 9.76145267e-01 9.94982719e-01\n",
      " 3.34390759e-01 3.80483329e-01 9.96901751e-01 2.33660623e-01\n",
      " 2.22078145e-01 9.99999642e-01 9.97839332e-01 9.98827279e-01\n",
      " 6.59220168e-05 3.60805392e-02 1.49178714e-01 7.82589614e-01\n",
      " 4.79851291e-02 9.97015119e-01 1.05661806e-02 6.65864766e-01\n",
      " 3.80026817e-01 4.56132777e-02 9.99353349e-01 7.20899226e-03\n",
      " 8.08322802e-04 5.08736193e-01 1.10879075e-02 1.12731978e-02\n",
      " 9.43691969e-01 5.84213495e-01 3.60353701e-02 3.52053810e-03\n",
      " 5.77981651e-01 9.07771215e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 193 [0/54 (0%)]\tTrain Loss: 0.010514\n",
      "Train Epoch: 193 [8/54 (15%)]\tTrain Loss: 0.011408\n",
      "Train Epoch: 193 [16/54 (30%)]\tTrain Loss: 0.004937\n",
      "Train Epoch: 193 [24/54 (44%)]\tTrain Loss: 0.015500\n",
      "Train Epoch: 193 [32/54 (59%)]\tTrain Loss: 0.120486\n",
      "Train Epoch: 193 [40/54 (74%)]\tTrain Loss: 0.002999\n",
      "Train Epoch: 193 [48/54 (89%)]\tTrain Loss: 0.017370\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.74936057e-04 4.23344433e-01 1.73517521e-02 1.37907758e-01\n",
      " 5.41691631e-02 5.13297971e-04 3.03080142e-01 6.56888902e-01\n",
      " 2.22197752e-02 4.84249353e-01 9.84671891e-01 4.37670089e-02\n",
      " 9.53040779e-01 7.48306746e-04 7.41867058e-04 1.13074882e-02\n",
      " 5.19894920e-02 2.03798013e-03 2.90927351e-01 2.88632154e-01\n",
      " 4.75880317e-03 9.82097924e-01 9.99041736e-01 9.99928832e-01\n",
      " 9.99007151e-02 9.99967456e-01 9.99996424e-01 1.30475774e-01\n",
      " 5.10024488e-01 5.26294231e-01 1.42296534e-02 4.46045846e-01\n",
      " 9.34204161e-01 2.85342423e-04 1.91792133e-04 3.67361028e-03\n",
      " 6.03994541e-03 8.69860172e-01 1.85260072e-03 9.28958058e-02\n",
      " 5.67111522e-02 1.13639332e-01 3.47570196e-04 1.20381219e-02\n",
      " 3.67955603e-02 5.10310940e-03 1.86075181e-01 3.71650457e-02\n",
      " 9.99889612e-01 9.24734414e-01 9.92681086e-01 1.09497141e-02\n",
      " 4.47859173e-04 1.02038505e-02 4.47409647e-03 3.88727523e-02\n",
      " 1.22196497e-02 3.36785048e-01 1.28113627e-01 2.12308769e-05\n",
      " 5.46942651e-01 1.19903341e-01 1.75945267e-01 7.41002619e-01\n",
      " 1.42453715e-01 8.98167253e-01 9.96941984e-01 9.98490930e-01\n",
      " 9.99999762e-01 5.89285530e-02 5.13616145e-01 6.75449967e-01\n",
      " 9.99562562e-01 9.91227984e-01 2.95159101e-01 6.66111782e-02\n",
      " 9.96933103e-01 9.99706328e-01 8.49687532e-02 9.87729609e-01\n",
      " 9.68896151e-01 9.89726484e-01 9.91841316e-01 4.87288833e-02\n",
      " 1.11371674e-01 9.80162024e-01 4.06855613e-01 3.71309400e-01\n",
      " 8.99259388e-01 9.99025106e-01 1.00000000e+00 8.46134186e-01\n",
      " 2.53982991e-01 1.00000000e+00 9.99952674e-01 9.99999881e-01\n",
      " 1.26736388e-02 2.58234073e-03 4.56769168e-01 1.00000000e+00\n",
      " 6.51391782e-03 9.32039917e-01 2.91539617e-02 9.38732028e-01\n",
      " 8.81412327e-01 3.00415643e-02 9.99915719e-01 2.25508474e-02\n",
      " 9.92493471e-04 9.99001682e-01 1.19516425e-01 7.03073107e-03\n",
      " 9.99987483e-01 9.99549568e-01 2.98280329e-01 2.90350826e-03\n",
      " 5.44005394e-01 2.01416105e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 194 [0/54 (0%)]\tTrain Loss: 0.007007\n",
      "Train Epoch: 194 [8/54 (15%)]\tTrain Loss: 0.006687\n",
      "Train Epoch: 194 [16/54 (30%)]\tTrain Loss: 0.010208\n",
      "Train Epoch: 194 [24/54 (44%)]\tTrain Loss: 0.007574\n",
      "Train Epoch: 194 [32/54 (59%)]\tTrain Loss: 0.002813\n",
      "Train Epoch: 194 [40/54 (74%)]\tTrain Loss: 0.008886\n",
      "Train Epoch: 194 [48/54 (89%)]\tTrain Loss: 0.043124\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.69119039e-02 9.91322279e-01 6.78028703e-01 9.29038763e-01\n",
      " 3.05522799e-01 6.53373897e-02 9.81437206e-01 9.19257820e-01\n",
      " 5.32216549e-01 5.06448686e-01 5.20360410e-01 5.93505148e-03\n",
      " 3.73456240e-01 1.19811326e-01 2.81778783e-01 1.36726141e-01\n",
      " 4.49273251e-02 1.25039145e-01 9.83451605e-01 3.82784396e-01\n",
      " 4.10497114e-02 9.96381760e-01 9.96930420e-01 9.99954224e-01\n",
      " 9.22272503e-01 9.99636412e-01 1.00000000e+00 5.02569973e-01\n",
      " 7.52734005e-01 8.37008178e-01 7.09754109e-01 9.99783218e-01\n",
      " 5.32233000e-01 1.30264016e-04 1.80818490e-04 2.74395826e-03\n",
      " 7.13158352e-03 9.91060793e-01 9.36453938e-02 5.40466547e-01\n",
      " 3.28325838e-01 1.57407105e-01 4.48855013e-02 1.49744034e-01\n",
      " 3.87895554e-01 3.12303841e-01 9.98226106e-01 9.94411647e-01\n",
      " 9.99999881e-01 9.99390602e-01 9.99936819e-01 1.89746022e-02\n",
      " 6.73739053e-03 7.19349146e-01 5.73890917e-02 1.63455084e-02\n",
      " 9.31924641e-01 1.03075271e-02 4.25517038e-02 2.09014919e-02\n",
      " 9.88421321e-01 6.85375571e-01 9.52428162e-01 9.97583628e-01\n",
      " 9.73169029e-01 9.89482164e-01 9.99791205e-01 9.99733984e-01\n",
      " 9.99998212e-01 9.33665454e-01 9.95810390e-01 9.92223084e-01\n",
      " 9.99989033e-01 9.96874332e-01 8.95951331e-01 9.99199569e-01\n",
      " 9.99998331e-01 9.99996424e-01 9.99146938e-01 9.99928713e-01\n",
      " 9.99865294e-01 9.99655128e-01 9.99803364e-01 5.78152597e-01\n",
      " 9.58752096e-01 9.99956727e-01 9.95000243e-01 9.96209145e-01\n",
      " 6.27466023e-01 9.87431288e-01 1.00000000e+00 9.67946649e-01\n",
      " 7.77089775e-01 1.00000000e+00 9.93112147e-01 9.99949694e-01\n",
      " 3.72768240e-03 4.12371844e-01 3.87731850e-01 9.99604642e-01\n",
      " 1.80573642e-01 9.99977112e-01 6.11455083e-01 9.55077469e-01\n",
      " 9.69736099e-01 8.27394545e-01 9.99966145e-01 1.01221293e-01\n",
      " 4.20307443e-02 9.93689537e-01 7.90789485e-01 3.02411646e-01\n",
      " 9.80041087e-01 9.98577356e-01 9.84279633e-01 3.62731606e-01\n",
      " 8.32498074e-01 9.05535460e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 195 [0/54 (0%)]\tTrain Loss: 0.018273\n",
      "Train Epoch: 195 [8/54 (15%)]\tTrain Loss: 0.001352\n",
      "Train Epoch: 195 [16/54 (30%)]\tTrain Loss: 0.005774\n",
      "Train Epoch: 195 [24/54 (44%)]\tTrain Loss: 0.001098\n",
      "Train Epoch: 195 [32/54 (59%)]\tTrain Loss: 0.003130\n",
      "Train Epoch: 195 [40/54 (74%)]\tTrain Loss: 0.001862\n",
      "Train Epoch: 195 [48/54 (89%)]\tTrain Loss: 0.008382\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.06136999 0.98276168 0.98348331 0.94986677 0.32398769 0.02972152\n",
      " 0.98418909 0.83120269 0.334806   0.53878993 0.73122388 0.17018819\n",
      " 0.04204394 0.06251519 0.10880674 0.04451432 0.06681287 0.1398686\n",
      " 0.98425102 0.31616765 0.19254449 0.97475684 0.99997509 0.99900812\n",
      " 0.85401767 0.9999975  0.99999714 0.9059273  0.99604589 0.44051787\n",
      " 0.63192576 0.9977811  0.35019195 0.00215127 0.00101932 0.0163039\n",
      " 0.40160143 0.99901462 0.06817767 0.10473515 0.04987709 0.0171077\n",
      " 0.00563936 0.10025578 0.16003792 0.32905817 0.97621858 0.95304137\n",
      " 0.9999361  0.99620616 0.99989486 0.01359906 0.00718536 0.51480192\n",
      " 0.44631603 0.0828877  0.99870992 0.03156852 0.43532759 0.02764835\n",
      " 0.99182701 0.92904961 0.98836374 0.99806434 0.97702968 0.99305034\n",
      " 0.99994707 0.99999797 1.         0.93977958 0.98839033 0.98885453\n",
      " 0.99995577 0.99885273 0.99998558 0.95920372 0.99998713 0.99999928\n",
      " 0.98871839 0.99999619 0.99999905 0.99724704 0.99994445 0.06451984\n",
      " 0.77386135 0.99140745 0.99455345 0.98667914 0.90250093 0.94345474\n",
      " 1.         0.90817398 0.58032298 1.         0.99998748 0.999982\n",
      " 0.00208052 0.30617335 0.84658283 0.99997139 0.03626037 0.99766612\n",
      " 0.76707178 0.9977265  0.99832278 0.99660444 0.99999964 0.10923452\n",
      " 0.04678772 0.99921703 0.96342379 0.11255378 0.99706227 0.9999429\n",
      " 0.75171739 0.38289842 0.38128391 0.92447543]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "Train Epoch: 196 [0/54 (0%)]\tTrain Loss: 0.013826\n",
      "Train Epoch: 196 [8/54 (15%)]\tTrain Loss: 0.037917\n",
      "Train Epoch: 196 [16/54 (30%)]\tTrain Loss: 0.104108\n",
      "Train Epoch: 196 [24/54 (44%)]\tTrain Loss: 0.008801\n",
      "Train Epoch: 196 [32/54 (59%)]\tTrain Loss: 0.002233\n",
      "Train Epoch: 196 [40/54 (74%)]\tTrain Loss: 0.007353\n",
      "Train Epoch: 196 [48/54 (89%)]\tTrain Loss: 0.007429\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.47105372e-02 5.79161532e-02 5.21729933e-03 1.00347742e-01\n",
      " 1.32562490e-02 2.74704979e-03 1.68162547e-02 2.58344859e-02\n",
      " 1.08390905e-01 1.45106288e-02 3.19623351e-02 8.45929049e-03\n",
      " 7.64529104e-04 5.44534196e-05 1.61531754e-03 4.95230965e-03\n",
      " 3.57781956e-03 4.34422605e-02 3.82228941e-03 3.47656280e-01\n",
      " 3.81619744e-02 8.18013668e-01 9.60357130e-01 9.87774670e-01\n",
      " 2.46453121e-01 9.99000251e-01 8.99064481e-01 3.55958521e-01\n",
      " 8.68553855e-03 2.07274593e-02 5.09854825e-03 7.41878822e-02\n",
      " 5.60970493e-02 7.82597851e-07 7.41003578e-06 5.37225453e-04\n",
      " 8.03037328e-05 9.30996060e-01 3.77399521e-03 6.58188611e-02\n",
      " 1.32901650e-02 1.12530515e-02 4.70156875e-03 2.32565850e-02\n",
      " 3.43765761e-03 1.38696283e-01 1.00694485e-01 1.47192404e-01\n",
      " 9.96482491e-01 9.77538645e-01 9.48079228e-01 1.12224458e-04\n",
      " 4.68224939e-03 1.08563360e-02 1.76108722e-02 1.01857047e-04\n",
      " 8.20855200e-01 4.91805724e-04 2.47544646e-01 2.03947071e-04\n",
      " 5.61018109e-01 5.79039343e-02 4.50137705e-01 6.09658539e-01\n",
      " 6.64377153e-01 5.30431926e-01 4.50719506e-01 8.58749866e-01\n",
      " 9.98533010e-01 5.16447365e-01 7.71299660e-01 7.73932517e-01\n",
      " 9.84571218e-01 7.63338923e-01 8.36848736e-01 6.72825933e-01\n",
      " 9.66513455e-01 9.95633423e-01 8.21590245e-01 9.82036173e-01\n",
      " 9.11585271e-01 8.73349845e-01 9.96228337e-01 4.17436123e-01\n",
      " 4.66078848e-01 8.29627454e-01 8.57366264e-01 9.10279095e-01\n",
      " 2.30945036e-01 1.38068035e-01 8.36484253e-01 1.98724046e-01\n",
      " 1.22554943e-01 9.99994159e-01 9.79617894e-01 9.79936242e-01\n",
      " 1.54763472e-03 9.62736905e-02 1.15207471e-01 9.10814881e-01\n",
      " 1.79678500e-02 9.95557487e-01 6.41561821e-02 7.68109798e-01\n",
      " 5.57143509e-01 1.83300033e-01 9.99678850e-01 4.65562707e-03\n",
      " 9.98279732e-03 4.60360646e-01 3.67090367e-02 1.25132571e-03\n",
      " 2.08009467e-01 8.23491991e-01 1.74895197e-01 5.03238142e-02\n",
      " 5.83562404e-02 4.14999425e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 197 [0/54 (0%)]\tTrain Loss: 0.061659\n",
      "Train Epoch: 197 [8/54 (15%)]\tTrain Loss: 0.024970\n",
      "Train Epoch: 197 [16/54 (30%)]\tTrain Loss: 0.010887\n",
      "Train Epoch: 197 [24/54 (44%)]\tTrain Loss: 0.025523\n",
      "Train Epoch: 197 [32/54 (59%)]\tTrain Loss: 0.005863\n",
      "Train Epoch: 197 [40/54 (74%)]\tTrain Loss: 0.024098\n",
      "Train Epoch: 197 [48/54 (89%)]\tTrain Loss: 0.013813\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.62733735e-02 6.49118602e-01 6.25957847e-02 8.17853034e-01\n",
      " 1.83790341e-01 1.57126226e-02 3.64907920e-01 7.61174679e-01\n",
      " 2.69831210e-01 7.31012225e-01 3.31955492e-01 4.45663363e-01\n",
      " 4.99062873e-02 6.42278639e-04 1.98481977e-02 1.32858530e-02\n",
      " 2.29654685e-02 2.53692001e-01 2.98385997e-03 4.03013155e-02\n",
      " 3.42072323e-02 9.00756061e-01 8.53037775e-01 9.88873839e-01\n",
      " 5.58869503e-02 9.92294908e-01 9.99634743e-01 5.62030435e-01\n",
      " 2.38821190e-02 1.63638860e-01 2.07584770e-03 5.80629051e-01\n",
      " 3.98389161e-01 4.89013928e-06 2.81483681e-05 1.92347681e-03\n",
      " 1.68545614e-03 9.91503239e-01 1.12444587e-01 5.47499716e-01\n",
      " 1.15560800e-01 3.22067201e-01 7.15137692e-03 3.77555229e-02\n",
      " 6.32679313e-02 1.62880849e-02 5.66524744e-01 6.16224110e-01\n",
      " 9.99935031e-01 9.92029011e-01 9.59203184e-01 1.01191796e-01\n",
      " 5.11513231e-03 4.22788486e-02 4.72718701e-02 1.46226902e-02\n",
      " 1.84679270e-01 1.67882126e-02 9.03584063e-01 1.63903169e-03\n",
      " 6.18491411e-01 2.80187130e-01 6.79663956e-01 8.67135763e-01\n",
      " 4.95739371e-01 9.85383034e-01 9.72689450e-01 9.96726274e-01\n",
      " 9.99562800e-01 8.41512144e-01 8.53843093e-01 8.33932161e-01\n",
      " 9.95111287e-01 9.50891078e-01 5.89241266e-01 3.71576995e-01\n",
      " 9.97020662e-01 9.99084949e-01 4.44237083e-01 9.74697113e-01\n",
      " 7.62942970e-01 4.29673880e-01 9.94276345e-01 3.71229291e-01\n",
      " 5.35072088e-01 8.84064913e-01 8.49019825e-01 9.06111121e-01\n",
      " 7.98887238e-02 5.18952310e-01 9.95174587e-01 9.12666678e-01\n",
      " 7.57672668e-01 9.99966621e-01 7.31900871e-01 9.14441705e-01\n",
      " 7.58962939e-03 8.82034078e-02 3.59627977e-02 8.75577331e-01\n",
      " 3.25935148e-02 9.97844219e-01 4.39761914e-02 7.89052188e-01\n",
      " 3.45702559e-01 1.65592819e-01 9.92129982e-01 5.42063359e-03\n",
      " 3.45276203e-03 4.50019985e-01 5.78485196e-03 1.62401665e-02\n",
      " 3.68762106e-01 1.24266110e-01 7.00374320e-02 4.18259716e-03\n",
      " 3.16090018e-01 5.45711040e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 198 [0/54 (0%)]\tTrain Loss: 0.026631\n",
      "Train Epoch: 198 [8/54 (15%)]\tTrain Loss: 0.007407\n",
      "Train Epoch: 198 [16/54 (30%)]\tTrain Loss: 0.008931\n",
      "Train Epoch: 198 [24/54 (44%)]\tTrain Loss: 0.003648\n",
      "Train Epoch: 198 [32/54 (59%)]\tTrain Loss: 0.007807\n",
      "Train Epoch: 198 [40/54 (74%)]\tTrain Loss: 0.001856\n",
      "Train Epoch: 198 [48/54 (89%)]\tTrain Loss: 0.028791\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.38224137e-01 9.25868988e-01 3.26366484e-01 9.91382897e-01\n",
      " 5.56584656e-01 2.96890438e-02 6.89154387e-01 9.96241570e-01\n",
      " 3.59544843e-01 9.34338927e-01 9.94594991e-01 2.28961691e-01\n",
      " 5.35225868e-01 3.78118735e-03 3.19310464e-02 4.04259600e-02\n",
      " 1.57240946e-02 9.73290727e-02 4.12304997e-02 7.44516850e-01\n",
      " 9.01241899e-02 9.98112440e-01 9.99773324e-01 9.99304414e-01\n",
      " 3.39488894e-01 9.99997735e-01 9.99999523e-01 9.96853650e-01\n",
      " 4.02922809e-01 3.75036240e-01 3.04037124e-01 9.33224559e-01\n",
      " 9.45843577e-01 1.94627646e-04 9.82677448e-05 1.19466418e-02\n",
      " 2.71534431e-03 9.99721825e-01 6.43519163e-02 4.26989496e-01\n",
      " 6.64282441e-02 1.97754890e-01 5.65592758e-03 2.32699230e-01\n",
      " 1.63984373e-01 6.07140541e-01 9.99048173e-01 9.97774780e-01\n",
      " 1.00000000e+00 9.99935031e-01 9.99998331e-01 1.18237026e-01\n",
      " 1.29885897e-02 6.73716128e-01 2.67268211e-01 1.74321249e-01\n",
      " 9.84947741e-01 4.86411810e-01 5.25458634e-01 3.90873179e-02\n",
      " 9.97951686e-01 9.92356181e-01 9.99663472e-01 9.98083472e-01\n",
      " 9.96201456e-01 9.99938130e-01 9.99980092e-01 1.00000000e+00\n",
      " 9.99999762e-01 9.97729242e-01 9.95979667e-01 9.99165058e-01\n",
      " 9.99943495e-01 9.99993801e-01 9.99041855e-01 9.25329328e-01\n",
      " 9.99998808e-01 1.00000000e+00 9.98179793e-01 9.99973536e-01\n",
      " 9.99990702e-01 9.99917626e-01 9.99969482e-01 3.97544831e-01\n",
      " 7.09915161e-01 9.99806345e-01 9.97151971e-01 9.90424573e-01\n",
      " 7.72156358e-01 9.98381853e-01 9.99499440e-01 9.98923242e-01\n",
      " 9.63034332e-01 1.00000000e+00 9.99940991e-01 9.98421073e-01\n",
      " 6.56566676e-03 1.65644661e-01 7.76476085e-01 9.99777973e-01\n",
      " 4.45638178e-03 9.99788702e-01 2.59391088e-02 9.95634019e-01\n",
      " 9.99059975e-01 9.32172477e-01 1.00000000e+00 3.74615490e-01\n",
      " 2.25142739e-03 9.99699473e-01 2.69158453e-01 1.58631280e-02\n",
      " 9.99101877e-01 9.99970913e-01 2.44383007e-01 1.96379684e-02\n",
      " 6.98311388e-01 1.37082979e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 199 [0/54 (0%)]\tTrain Loss: 0.002446\n",
      "Train Epoch: 199 [8/54 (15%)]\tTrain Loss: 0.023954\n",
      "Train Epoch: 199 [16/54 (30%)]\tTrain Loss: 0.007638\n",
      "Train Epoch: 199 [24/54 (44%)]\tTrain Loss: 0.012566\n",
      "Train Epoch: 199 [32/54 (59%)]\tTrain Loss: 0.035719\n",
      "Train Epoch: 199 [40/54 (74%)]\tTrain Loss: 0.002890\n",
      "Train Epoch: 199 [48/54 (89%)]\tTrain Loss: 0.009846\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.60077080e-03 4.97377455e-01 1.68668941e-01 9.94323015e-01\n",
      " 4.22314703e-01 2.73860060e-03 2.02367976e-01 9.54228878e-01\n",
      " 2.74491817e-01 4.68420804e-01 6.07225060e-01 1.77978724e-01\n",
      " 5.71593456e-02 2.47515412e-03 3.19157653e-02 6.37506172e-02\n",
      " 1.90165322e-02 1.28318399e-01 3.43260884e-01 1.84892058e-01\n",
      " 9.41622257e-02 9.88786459e-01 9.99312282e-01 9.99729812e-01\n",
      " 6.83345556e-01 9.99999166e-01 9.99998093e-01 9.98512685e-01\n",
      " 3.68377358e-01 2.84105808e-01 9.02197435e-02 9.91132557e-01\n",
      " 1.00958399e-01 1.79191411e-04 5.90457603e-05 1.18329469e-02\n",
      " 5.73373074e-03 9.99949932e-01 3.28169428e-02 2.69481570e-01\n",
      " 1.89536549e-02 4.06327434e-02 1.02739390e-02 1.07390970e-01\n",
      " 1.96760073e-01 5.06948046e-02 9.91363168e-01 9.43236411e-01\n",
      " 9.99958158e-01 9.98266816e-01 9.97896791e-01 3.17127779e-02\n",
      " 9.69155580e-02 1.34979159e-01 6.36392459e-02 9.62728709e-02\n",
      " 6.13130152e-01 1.31915450e-01 8.52357268e-01 1.92665875e-01\n",
      " 9.39657509e-01 9.25682783e-01 9.22937334e-01 9.73657131e-01\n",
      " 9.01145160e-01 9.64686275e-01 9.99949336e-01 9.99994636e-01\n",
      " 9.99980807e-01 8.03655863e-01 7.99931943e-01 9.02355909e-01\n",
      " 9.99843001e-01 9.98182416e-01 9.68868494e-01 8.38645160e-01\n",
      " 9.99868870e-01 9.99971509e-01 9.85093057e-01 9.99933720e-01\n",
      " 9.99729216e-01 9.94708538e-01 9.99569714e-01 4.56818998e-01\n",
      " 7.98392117e-01 9.97170746e-01 9.73502874e-01 9.51236784e-01\n",
      " 8.84880126e-01 9.97716188e-01 9.99305606e-01 9.75032330e-01\n",
      " 7.93894112e-01 1.00000000e+00 9.99914289e-01 9.99524713e-01\n",
      " 1.71340778e-02 9.18828845e-01 8.61929655e-01 9.99732792e-01\n",
      " 4.29177135e-02 9.99008775e-01 1.27098456e-01 9.96489346e-01\n",
      " 9.98612881e-01 8.46924365e-01 9.99999762e-01 9.94303450e-03\n",
      " 1.38598063e-03 9.84184265e-01 3.92798558e-02 1.64210293e-02\n",
      " 9.89187062e-01 9.98682201e-01 1.49542287e-01 2.06927925e-01\n",
      " 9.51349497e-01 6.81713939e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 200 [0/54 (0%)]\tTrain Loss: 0.014293\n",
      "Train Epoch: 200 [8/54 (15%)]\tTrain Loss: 0.012217\n",
      "Train Epoch: 200 [16/54 (30%)]\tTrain Loss: 0.012706\n",
      "Train Epoch: 200 [24/54 (44%)]\tTrain Loss: 0.001301\n",
      "Train Epoch: 200 [32/54 (59%)]\tTrain Loss: 0.001734\n",
      "Train Epoch: 200 [40/54 (74%)]\tTrain Loss: 0.043137\n",
      "Train Epoch: 200 [48/54 (89%)]\tTrain Loss: 0.006986\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.21084340e-03 1.77866537e-02 8.30457197e-04 8.29956830e-01\n",
      " 1.17201261e-01 7.95203086e-04 1.86210021e-03 5.41470706e-01\n",
      " 2.22148318e-02 7.62410998e-01 8.00812840e-01 3.01672518e-01\n",
      " 5.10884030e-03 3.56323881e-06 9.89384280e-05 2.86322087e-04\n",
      " 5.29913697e-04 5.90845160e-02 7.62297690e-01 7.60385692e-02\n",
      " 7.42426701e-03 8.59462380e-01 9.83043730e-01 9.99737918e-01\n",
      " 7.95707777e-02 9.99968767e-01 9.99962807e-01 9.65665877e-01\n",
      " 4.72334236e-01 8.40660743e-03 2.02906467e-02 9.96862054e-01\n",
      " 8.57577845e-03 3.12226875e-05 8.31099624e-06 6.56882825e-04\n",
      " 9.18014732e-04 9.99116838e-01 5.37987100e-03 1.99287850e-02\n",
      " 5.64178033e-03 1.74170895e-03 5.00843581e-03 9.29333619e-04\n",
      " 7.25924671e-02 5.92484698e-02 9.97515678e-01 8.61947358e-01\n",
      " 9.99987125e-01 9.92105484e-01 9.99558270e-01 1.98371266e-03\n",
      " 3.93320061e-03 2.42091082e-02 1.02394447e-02 3.86256725e-03\n",
      " 2.65666693e-01 2.85146739e-02 5.86454511e-01 1.05252583e-03\n",
      " 9.56497371e-01 6.47944450e-01 8.62385094e-01 9.77748275e-01\n",
      " 4.55228567e-01 1.72655836e-01 9.94193137e-01 9.99027729e-01\n",
      " 9.98429596e-01 7.03956842e-01 9.78433788e-01 9.82911050e-01\n",
      " 9.98579383e-01 9.93469715e-01 3.83640975e-01 5.78491151e-01\n",
      " 9.99999762e-01 1.00000000e+00 9.04371381e-01 9.99905586e-01\n",
      " 9.97607470e-01 9.29357469e-01 9.97619092e-01 8.13231766e-02\n",
      " 2.63861209e-01 9.98539209e-01 9.32528019e-01 8.22507560e-01\n",
      " 3.17354828e-01 9.75021362e-01 9.99459565e-01 8.27922463e-01\n",
      " 3.82198006e-01 1.00000000e+00 9.96633708e-01 9.98962522e-01\n",
      " 5.52265942e-02 1.03033237e-01 6.59225881e-01 9.80910897e-01\n",
      " 9.20820422e-03 9.98539209e-01 6.48613870e-02 9.89202321e-01\n",
      " 9.93743122e-01 7.45413661e-01 9.99998808e-01 2.18245899e-03\n",
      " 3.35178738e-05 9.69013453e-01 1.07074389e-03 1.26207515e-03\n",
      " 2.97303349e-01 9.99677181e-01 2.23108171e-03 2.02448033e-02\n",
      " 3.72440785e-01 4.01282832e-02]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "vote_pred [0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 42 FN= 13 FP= 18\n",
      "TP+FP 63\n",
      "precision 0.7142857142857143\n",
      "recall 0.7758620689655172\n",
      "F1 0.7438016528925621\n",
      "acc 0.7372881355932204\n",
      "AUCp 0.7379310344827587\n",
      "AUC 0.7543103448275863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 200, average recall: 0.7759, average precision: 0.7143,average F1: 0.7438, average accuracy: 0.7373, average AUC: 0.7543\n",
      "Train Epoch: 201 [0/54 (0%)]\tTrain Loss: 0.018506\n",
      "Train Epoch: 201 [8/54 (15%)]\tTrain Loss: 0.001124\n",
      "Train Epoch: 201 [16/54 (30%)]\tTrain Loss: 0.003000\n",
      "Train Epoch: 201 [24/54 (44%)]\tTrain Loss: 0.024094\n",
      "Train Epoch: 201 [32/54 (59%)]\tTrain Loss: 0.021760\n",
      "Train Epoch: 201 [40/54 (74%)]\tTrain Loss: 0.068489\n",
      "Train Epoch: 201 [48/54 (89%)]\tTrain Loss: 0.003175\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.03724051 0.79129601 0.84165847 0.98084569 0.88423568 0.04247833\n",
      " 0.68037909 0.92228395 0.51955312 0.83398217 0.21927759 0.58691329\n",
      " 0.05698834 0.59542483 0.48563591 0.26646379 0.7946012  0.10526127\n",
      " 0.88582623 0.01498702 0.12855767 0.99135828 0.99998724 0.99999845\n",
      " 0.70384806 1.         1.         0.98135513 0.82243353 0.56722969\n",
      " 0.54291874 0.99676442 0.54864091 0.00435454 0.00146352 0.28535935\n",
      " 0.01805853 0.99146527 0.3611773  0.79877925 0.28839067 0.11315836\n",
      " 0.00442247 0.48853964 0.44877368 0.6186614  0.99575031 0.9018355\n",
      " 0.99999893 0.99867117 0.99930775 0.02364747 0.06639214 0.83146805\n",
      " 0.08842361 0.32242858 0.73103923 0.32297087 0.73844004 0.77322227\n",
      " 0.99841571 0.98371857 0.98723233 0.99782819 0.99678469 0.99984431\n",
      " 0.99999869 0.99999928 0.99999988 0.97351813 0.99653971 0.99899513\n",
      " 0.99997985 0.99992192 0.98440534 0.94470668 0.99999857 0.99999988\n",
      " 0.99877447 0.99999833 0.99994791 0.99866378 0.9999274  0.28910986\n",
      " 0.90357864 0.99040997 0.98970211 0.95937192 0.97149175 0.99994147\n",
      " 0.99999714 0.99583948 0.97602624 0.99999988 0.98767161 0.98974341\n",
      " 0.18784885 0.96500599 0.74213004 0.97808313 0.08435837 0.99953043\n",
      " 0.36099371 0.9718883  0.97851413 0.95319176 0.99999988 0.32808581\n",
      " 0.49895296 0.99773443 0.13448057 0.99613476 0.99993265 0.99146563\n",
      " 0.05805679 0.21618652 0.49047092 0.45569736]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 202 [0/54 (0%)]\tTrain Loss: 0.003466\n",
      "Train Epoch: 202 [8/54 (15%)]\tTrain Loss: 0.016256\n",
      "Train Epoch: 202 [16/54 (30%)]\tTrain Loss: 0.001672\n",
      "Train Epoch: 202 [24/54 (44%)]\tTrain Loss: 0.008909\n",
      "Train Epoch: 202 [32/54 (59%)]\tTrain Loss: 0.009706\n",
      "Train Epoch: 202 [40/54 (74%)]\tTrain Loss: 0.008402\n",
      "Train Epoch: 202 [48/54 (89%)]\tTrain Loss: 0.015307\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.01169171e-02 9.01301354e-02 5.41278301e-03 5.04873574e-01\n",
      " 6.92616180e-02 2.51589203e-03 1.93568412e-02 1.35266736e-01\n",
      " 4.92134281e-02 5.17988145e-01 1.60173729e-01 8.79147798e-02\n",
      " 1.67475045e-02 8.70501681e-05 7.32894405e-04 2.45890371e-03\n",
      " 1.46703736e-03 4.80443686e-02 4.37945306e-01 7.26295589e-03\n",
      " 1.05626196e-01 9.67719555e-01 9.99703228e-01 9.99765813e-01\n",
      " 1.43633902e-01 9.99984741e-01 9.99949574e-01 8.89661610e-01\n",
      " 1.43526912e-01 2.83419073e-01 4.18771654e-02 9.57066357e-01\n",
      " 3.94411385e-01 9.33753472e-06 2.67195483e-05 1.01976562e-03\n",
      " 2.22010165e-03 7.92388737e-01 1.10542309e-02 7.96271414e-02\n",
      " 1.33554107e-02 5.37726097e-03 3.92446714e-03 2.16750503e-02\n",
      " 2.25889400e-01 7.93674663e-02 9.20730174e-01 2.53282458e-01\n",
      " 9.99994993e-01 9.68427718e-01 9.92566109e-01 5.83229004e-04\n",
      " 2.03698743e-02 1.26969432e-02 4.07394208e-02 1.09420065e-02\n",
      " 5.23803413e-01 3.40082645e-02 2.07349554e-01 1.97120868e-02\n",
      " 7.42674887e-01 6.60002470e-01 9.36969578e-01 9.96327698e-01\n",
      " 8.84586751e-01 9.49876606e-01 9.68633473e-01 9.99569595e-01\n",
      " 9.99919176e-01 5.40320456e-01 9.25279081e-01 9.69659984e-01\n",
      " 9.99698758e-01 9.95626569e-01 9.94692743e-01 8.95312130e-01\n",
      " 9.99977231e-01 9.99993205e-01 8.89381111e-01 9.99721706e-01\n",
      " 9.97099161e-01 9.93049979e-01 9.99231696e-01 1.56513318e-01\n",
      " 9.30650592e-01 9.11595941e-01 9.74307239e-01 8.75929058e-01\n",
      " 5.32004476e-01 9.28352475e-01 9.99826610e-01 6.43020332e-01\n",
      " 5.23730338e-01 9.99999762e-01 9.97604728e-01 9.98703837e-01\n",
      " 4.81218062e-02 8.28336030e-02 1.24033928e-01 9.81901467e-01\n",
      " 2.88119670e-02 9.98221457e-01 4.34687063e-02 7.63321698e-01\n",
      " 9.07643199e-01 8.04029226e-01 9.99956250e-01 5.68488948e-02\n",
      " 9.83564183e-04 9.46418941e-01 7.01495027e-03 1.35559635e-02\n",
      " 9.01620448e-01 4.90756869e-01 1.12205911e-02 1.80880930e-02\n",
      " 9.26920652e-01 9.23762247e-02]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 203 [0/54 (0%)]\tTrain Loss: 0.038170\n",
      "Train Epoch: 203 [8/54 (15%)]\tTrain Loss: 0.011844\n",
      "Train Epoch: 203 [16/54 (30%)]\tTrain Loss: 0.013545\n",
      "Train Epoch: 203 [24/54 (44%)]\tTrain Loss: 0.011918\n",
      "Train Epoch: 203 [32/54 (59%)]\tTrain Loss: 0.001412\n",
      "Train Epoch: 203 [40/54 (74%)]\tTrain Loss: 0.001745\n",
      "Train Epoch: 203 [48/54 (89%)]\tTrain Loss: 0.005062\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.26259255e-03 6.26421943e-02 9.44862701e-03 5.54891169e-01\n",
      " 6.76921979e-02 2.09649629e-03 2.04533115e-02 1.17011238e-02\n",
      " 2.25026533e-01 7.45378077e-01 8.98460858e-03 7.24348892e-03\n",
      " 3.23293475e-03 5.66997041e-04 1.44038303e-03 1.58679055e-03\n",
      " 9.78672528e-04 4.43123020e-02 3.30133021e-01 3.74680907e-02\n",
      " 1.90192666e-02 9.75419521e-01 9.96389151e-01 9.91545379e-01\n",
      " 6.04174398e-02 9.99952555e-01 9.99952078e-01 7.69900084e-01\n",
      " 1.26517281e-01 2.53750980e-01 3.97916362e-02 9.07972693e-01\n",
      " 2.94483379e-02 2.01863058e-05 7.07464496e-05 5.59976383e-04\n",
      " 6.82843442e-04 8.97973001e-01 5.80231240e-03 2.53046341e-02\n",
      " 2.92823906e-03 1.50457968e-03 8.58135638e-04 1.58247836e-02\n",
      " 3.64375897e-02 3.60969789e-02 9.06566262e-01 1.84729233e-01\n",
      " 9.99908924e-01 9.61324513e-01 9.92042720e-01 3.61136335e-04\n",
      " 8.40253104e-03 3.25097851e-02 3.54398713e-02 6.66951528e-03\n",
      " 2.76889235e-01 8.49475488e-02 9.87670273e-02 1.23410802e-02\n",
      " 6.89243674e-01 4.16005492e-01 8.52630079e-01 9.77395356e-01\n",
      " 8.28718781e-01 9.60962534e-01 9.55328882e-01 9.99993682e-01\n",
      " 9.99981046e-01 7.72821903e-01 9.39452410e-01 9.68598783e-01\n",
      " 9.98815417e-01 9.94959712e-01 9.83746827e-01 8.42391670e-01\n",
      " 9.98812318e-01 9.98852849e-01 7.05328882e-01 9.99105275e-01\n",
      " 9.99302864e-01 9.95111644e-01 9.98801708e-01 4.90804203e-02\n",
      " 5.11039913e-01 7.97245741e-01 9.66870606e-01 8.54514897e-01\n",
      " 2.48671636e-01 9.98716474e-01 9.99927402e-01 6.88310862e-01\n",
      " 5.92701375e-01 1.00000000e+00 9.98830497e-01 9.94450331e-01\n",
      " 6.02636905e-03 3.28880586e-02 5.64830244e-01 9.84519601e-01\n",
      " 1.58955269e-02 9.85654891e-01 6.84996741e-03 8.56511533e-01\n",
      " 9.39981759e-01 6.20359600e-01 9.99987245e-01 1.04504518e-01\n",
      " 1.30048553e-02 9.82882679e-01 5.22481129e-02 1.54624760e-01\n",
      " 9.99021053e-01 9.83387828e-01 3.10099106e-02 1.26027182e-01\n",
      " 7.54340827e-01 2.19035685e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 204 [0/54 (0%)]\tTrain Loss: 0.034482\n",
      "Train Epoch: 204 [8/54 (15%)]\tTrain Loss: 0.122753\n",
      "Train Epoch: 204 [16/54 (30%)]\tTrain Loss: 0.029924\n",
      "Train Epoch: 204 [24/54 (44%)]\tTrain Loss: 0.022128\n",
      "Train Epoch: 204 [32/54 (59%)]\tTrain Loss: 0.006748\n",
      "Train Epoch: 204 [40/54 (74%)]\tTrain Loss: 0.012243\n",
      "Train Epoch: 204 [48/54 (89%)]\tTrain Loss: 0.033555\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.10476536e-02 9.92136955e-01 8.99389923e-01 9.81853187e-01\n",
      " 6.05085731e-01 6.07582517e-02 9.42421854e-01 8.56263041e-01\n",
      " 6.41470373e-01 9.90437806e-01 9.68674719e-01 7.97127128e-01\n",
      " 1.70298815e-01 1.26500368e-01 5.22863150e-01 5.17875776e-02\n",
      " 4.89759207e-01 2.39706814e-01 7.72046268e-01 7.93697536e-01\n",
      " 3.09458882e-01 9.99873996e-01 9.99968171e-01 9.95767713e-01\n",
      " 9.48634624e-01 9.99998093e-01 9.99980569e-01 9.96640921e-01\n",
      " 9.97505367e-01 9.97353196e-01 7.12801397e-01 9.99770224e-01\n",
      " 9.91063952e-01 1.28177853e-04 1.97965559e-03 4.60623384e-01\n",
      " 5.42297214e-02 9.89237428e-01 2.79284298e-01 1.92611635e-01\n",
      " 6.20044656e-02 3.15308906e-02 4.03183652e-03 8.23638976e-01\n",
      " 6.95074260e-01 8.47159922e-01 9.98948038e-01 9.93778884e-01\n",
      " 1.00000000e+00 9.97626603e-01 9.99968171e-01 9.89472866e-03\n",
      " 2.15033635e-01 5.64527392e-01 5.60163975e-01 1.19999968e-01\n",
      " 9.86996531e-01 9.14975405e-01 9.34350669e-01 8.41007471e-01\n",
      " 9.99924541e-01 9.99748766e-01 9.99921679e-01 9.99996543e-01\n",
      " 9.98035967e-01 9.99069154e-01 9.98910546e-01 9.99999404e-01\n",
      " 9.99999166e-01 9.74323094e-01 9.98534441e-01 9.99463141e-01\n",
      " 9.99968648e-01 9.99979496e-01 9.99523163e-01 9.99933839e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99960899e-01 9.99996781e-01\n",
      " 9.99999881e-01 9.99979734e-01 9.99985695e-01 9.23551679e-01\n",
      " 9.99505520e-01 9.99032974e-01 9.99888778e-01 9.99746501e-01\n",
      " 6.77589357e-01 9.97988343e-01 9.66638863e-01 9.50936437e-01\n",
      " 9.88437712e-01 1.00000000e+00 9.99773681e-01 9.88999188e-01\n",
      " 4.86962378e-01 8.42612863e-01 9.89388645e-01 9.99586046e-01\n",
      " 2.04278067e-01 9.99761283e-01 2.48181224e-01 9.98687685e-01\n",
      " 9.99703705e-01 9.98717189e-01 1.00000000e+00 2.45537817e-01\n",
      " 5.05670309e-01 9.99453604e-01 8.32381129e-01 4.45343107e-01\n",
      " 9.98951674e-01 9.99905229e-01 9.49839354e-01 8.51630807e-01\n",
      " 9.89183903e-01 9.64230299e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 205 [0/54 (0%)]\tTrain Loss: 0.010903\n",
      "Train Epoch: 205 [8/54 (15%)]\tTrain Loss: 0.002210\n",
      "Train Epoch: 205 [16/54 (30%)]\tTrain Loss: 0.007732\n",
      "Train Epoch: 205 [24/54 (44%)]\tTrain Loss: 0.013687\n",
      "Train Epoch: 205 [32/54 (59%)]\tTrain Loss: 0.007998\n",
      "Train Epoch: 205 [40/54 (74%)]\tTrain Loss: 0.031820\n",
      "Train Epoch: 205 [48/54 (89%)]\tTrain Loss: 0.051716\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.12243006e-03 1.80794582e-01 1.92364864e-02 3.52769285e-01\n",
      " 1.71241716e-01 3.01713008e-03 2.84732599e-02 7.62866884e-02\n",
      " 4.39113751e-03 4.82351892e-03 5.24925515e-02 3.52825262e-02\n",
      " 1.23150973e-02 9.68785549e-04 1.01394914e-02 9.51867958e-04\n",
      " 1.29739798e-04 1.54442620e-02 2.75623858e-01 4.20866907e-02\n",
      " 1.68284159e-02 3.28257620e-01 9.96734560e-01 9.97666836e-01\n",
      " 3.24402601e-02 9.99492526e-01 9.98842418e-01 3.38450342e-01\n",
      " 3.08474936e-02 1.87614001e-02 5.82053177e-02 5.80843329e-01\n",
      " 2.65067995e-01 8.14671239e-06 5.61335510e-05 5.28743374e-04\n",
      " 6.17514830e-03 7.13387966e-01 1.91262853e-03 2.52052527e-02\n",
      " 9.13414359e-03 6.36063796e-03 1.14597927e-03 2.69769020e-02\n",
      " 7.16966530e-03 2.44696606e-02 4.75638270e-01 2.94380218e-01\n",
      " 9.81000960e-01 8.56207311e-01 8.74136508e-01 4.23743113e-05\n",
      " 3.09007522e-03 4.19661083e-04 2.11850405e-02 1.71187439e-03\n",
      " 7.89463460e-01 2.34823077e-04 2.51682606e-02 2.39982479e-03\n",
      " 9.57811415e-01 6.49403572e-01 6.11854732e-01 9.52044308e-01\n",
      " 8.87646019e-01 3.44071150e-01 4.07797433e-02 9.91501808e-01\n",
      " 9.97285008e-01 1.23639800e-01 8.82384598e-01 9.50258374e-01\n",
      " 9.14319396e-01 8.08230460e-01 5.90359032e-01 7.84425139e-01\n",
      " 9.67127681e-01 9.70300853e-01 3.83607239e-01 9.89372313e-01\n",
      " 9.28124189e-01 6.86970830e-01 9.56835330e-01 4.32516694e-01\n",
      " 7.99255073e-01 7.53786385e-01 4.78383482e-01 8.44970167e-01\n",
      " 1.22785620e-01 1.16509967e-01 9.83142376e-01 8.81284103e-02\n",
      " 1.62250921e-01 9.99995112e-01 9.94276941e-01 9.75613058e-01\n",
      " 4.57254387e-02 5.99799752e-01 5.48274480e-02 4.94263560e-01\n",
      " 6.03744723e-02 9.96740639e-01 2.95554638e-01 5.52598238e-01\n",
      " 8.92254591e-01 2.42141485e-01 9.99965906e-01 2.09800415e-02\n",
      " 6.01717737e-04 8.99806201e-01 5.00799231e-02 1.40854379e-03\n",
      " 3.51801217e-01 2.81472951e-01 2.04818845e-02 5.26349060e-02\n",
      " 6.82467639e-01 3.72519195e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 206 [0/54 (0%)]\tTrain Loss: 0.017403\n",
      "Train Epoch: 206 [8/54 (15%)]\tTrain Loss: 0.050585\n",
      "Train Epoch: 206 [16/54 (30%)]\tTrain Loss: 0.028861\n",
      "Train Epoch: 206 [24/54 (44%)]\tTrain Loss: 0.003781\n",
      "Train Epoch: 206 [32/54 (59%)]\tTrain Loss: 0.008201\n",
      "Train Epoch: 206 [40/54 (74%)]\tTrain Loss: 0.072877\n",
      "Train Epoch: 206 [48/54 (89%)]\tTrain Loss: 0.010606\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.01024395 0.77594101 0.4923943  0.99758315 0.89684594 0.00586754\n",
      " 0.48463619 0.98148537 0.30758452 0.30245921 0.99708802 0.24223967\n",
      " 0.8665365  0.52591234 0.53111613 0.19582283 0.2283783  0.1374068\n",
      " 0.91666204 0.85984427 0.80106205 0.99545896 0.99774468 0.9996165\n",
      " 0.90880281 0.99997067 0.99997663 0.98906797 0.96907783 0.82119894\n",
      " 0.93971223 0.97802562 0.85379565 0.03795334 0.04598803 0.29764861\n",
      " 0.77029467 0.99356925 0.06147921 0.34103644 0.32405785 0.28943485\n",
      " 0.01310603 0.96962637 0.44794631 0.9894098  0.99417794 0.94873333\n",
      " 0.99992621 0.9961254  0.99864584 0.12927659 0.21313946 0.68588102\n",
      " 0.41235617 0.70788771 0.95867682 0.45761573 0.36350623 0.42736503\n",
      " 0.99148601 0.98601568 0.91350132 0.99423909 0.9987244  0.99969542\n",
      " 0.98320872 0.99961048 0.99989426 0.93820477 0.98592401 0.99535698\n",
      " 0.99402517 0.99889344 0.99565035 0.98023856 0.99969602 0.99976367\n",
      " 0.99750012 0.9998129  0.99949718 0.99676323 0.9975962  0.96524829\n",
      " 0.87362653 0.92705888 0.94895089 0.94083381 0.9003244  0.99663794\n",
      " 0.99976188 0.99639469 0.98409283 1.         0.99986923 0.99990892\n",
      " 0.86447054 0.86584103 0.97086012 0.99993503 0.22999877 0.99766588\n",
      " 0.71855968 0.99778193 0.99901974 0.98406976 0.99999976 0.95724458\n",
      " 0.90493637 0.99676907 0.98941761 0.15718728 0.99062681 0.98728824\n",
      " 0.86857438 0.94259912 0.95093304 0.16409585]\n",
      "predict [0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 207 [0/54 (0%)]\tTrain Loss: 0.037327\n",
      "Train Epoch: 207 [8/54 (15%)]\tTrain Loss: 0.002932\n",
      "Train Epoch: 207 [16/54 (30%)]\tTrain Loss: 0.021849\n",
      "Train Epoch: 207 [24/54 (44%)]\tTrain Loss: 0.001898\n",
      "Train Epoch: 207 [32/54 (59%)]\tTrain Loss: 0.006896\n",
      "Train Epoch: 207 [40/54 (74%)]\tTrain Loss: 0.006634\n",
      "Train Epoch: 207 [48/54 (89%)]\tTrain Loss: 0.006249\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.58627627e-03 9.91813540e-01 8.83640885e-01 9.26226556e-01\n",
      " 3.25174004e-01 6.42948551e-03 8.93988490e-01 7.44782805e-01\n",
      " 1.21865541e-01 5.59019923e-01 7.37714589e-01 2.00833082e-01\n",
      " 5.63195646e-02 3.46503295e-02 1.87895641e-01 3.70644219e-02\n",
      " 7.42188841e-02 4.38972086e-01 9.84275162e-01 6.18834019e-01\n",
      " 6.28789812e-02 9.98380423e-01 9.99875069e-01 9.96242166e-01\n",
      " 6.95145190e-01 9.99984860e-01 9.99934673e-01 9.70642626e-01\n",
      " 9.61935222e-01 1.91646546e-01 3.33994389e-01 9.79060590e-01\n",
      " 4.55890745e-01 1.87844882e-04 1.22337241e-03 2.21634768e-02\n",
      " 5.62676452e-02 9.87092495e-01 4.12291400e-02 6.74693435e-02\n",
      " 2.56827213e-02 1.49857346e-02 1.90661917e-03 5.19676208e-01\n",
      " 5.83483279e-01 8.77954513e-02 9.94586825e-01 9.76881683e-01\n",
      " 9.99950767e-01 9.89847958e-01 9.97855365e-01 2.12022639e-03\n",
      " 1.44376652e-02 1.99925020e-01 1.32709190e-01 1.59727648e-01\n",
      " 9.91119564e-01 7.50337020e-02 5.40396795e-02 1.13754021e-02\n",
      " 9.98945653e-01 9.95124042e-01 9.91102457e-01 9.97992396e-01\n",
      " 9.94462311e-01 9.99615669e-01 9.99199569e-01 9.99629140e-01\n",
      " 9.99999762e-01 9.65228319e-01 9.77913082e-01 9.90994513e-01\n",
      " 9.99944091e-01 9.99875665e-01 9.96886909e-01 9.82439518e-01\n",
      " 9.99998927e-01 9.99995232e-01 9.95721042e-01 9.99836206e-01\n",
      " 9.99948263e-01 9.99166369e-01 9.99815524e-01 8.18539083e-01\n",
      " 9.85129595e-01 9.70508218e-01 9.39227283e-01 9.80644763e-01\n",
      " 3.26727599e-01 9.97717977e-01 9.94341731e-01 9.76677775e-01\n",
      " 9.15730238e-01 9.99976516e-01 9.99449432e-01 9.97384369e-01\n",
      " 7.79293701e-02 4.71322745e-01 7.68104196e-01 9.95569408e-01\n",
      " 3.83978114e-02 9.99134600e-01 2.74533361e-01 9.92421925e-01\n",
      " 9.98581648e-01 9.95254993e-01 1.00000000e+00 4.83072460e-01\n",
      " 2.70684864e-02 9.97638702e-01 2.48529166e-01 2.61173546e-01\n",
      " 9.83997464e-01 9.95155096e-01 4.76673096e-01 6.50773287e-01\n",
      " 8.68477881e-01 5.92813849e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 208 [0/54 (0%)]\tTrain Loss: 0.062640\n",
      "Train Epoch: 208 [8/54 (15%)]\tTrain Loss: 0.003175\n",
      "Train Epoch: 208 [16/54 (30%)]\tTrain Loss: 0.006076\n",
      "Train Epoch: 208 [24/54 (44%)]\tTrain Loss: 0.010533\n",
      "Train Epoch: 208 [32/54 (59%)]\tTrain Loss: 0.051332\n",
      "Train Epoch: 208 [40/54 (74%)]\tTrain Loss: 0.011958\n",
      "Train Epoch: 208 [48/54 (89%)]\tTrain Loss: 0.008978\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.36468967e-03 4.17750597e-01 2.57402826e-02 3.40745300e-01\n",
      " 7.57227605e-03 1.26670254e-03 5.07705426e-03 3.21236521e-01\n",
      " 2.51216609e-02 3.71334583e-01 6.35829642e-02 1.80167574e-02\n",
      " 9.76452255e-04 4.42241871e-04 1.06739011e-02 1.10009895e-03\n",
      " 2.39520770e-04 1.04081370e-01 7.16487989e-02 2.43120074e-01\n",
      " 9.52252094e-03 9.73460138e-01 9.94563043e-01 9.90159810e-01\n",
      " 1.49135202e-01 9.99936223e-01 9.93718147e-01 3.96914989e-01\n",
      " 4.27352078e-02 1.97898112e-02 4.40588981e-01 9.46537077e-01\n",
      " 8.69580388e-01 3.99077771e-06 6.66910410e-06 5.30341989e-04\n",
      " 1.22724706e-03 8.87115657e-01 4.11791774e-03 1.09938579e-02\n",
      " 3.86050553e-03 4.99099074e-03 2.71191937e-03 8.99239071e-03\n",
      " 4.56019305e-02 6.86524212e-02 9.99508023e-01 9.94453251e-01\n",
      " 9.99999285e-01 9.80977356e-01 9.99744117e-01 7.04613994e-05\n",
      " 3.62300518e-04 6.22948492e-03 1.11654932e-02 1.41755107e-03\n",
      " 9.80890393e-01 5.13227750e-03 5.11792256e-03 4.65014629e-04\n",
      " 9.80129182e-01 5.75157225e-01 9.66541052e-01 9.96967852e-01\n",
      " 9.48485076e-01 8.79254520e-01 9.75289822e-01 9.99956131e-01\n",
      " 9.99965072e-01 4.80982691e-01 9.48957860e-01 9.42355692e-01\n",
      " 9.99884129e-01 9.45213914e-01 9.66181517e-01 9.96626019e-01\n",
      " 9.99845505e-01 9.99822557e-01 9.75946903e-01 9.99775589e-01\n",
      " 9.99971867e-01 9.88127530e-01 9.99353707e-01 8.71980011e-01\n",
      " 9.77695048e-01 9.97037649e-01 9.95996833e-01 9.95810270e-01\n",
      " 6.02023071e-03 8.28958988e-01 9.32211220e-01 6.64831579e-01\n",
      " 5.17397821e-01 9.99951363e-01 9.97758269e-01 9.80335891e-01\n",
      " 1.21127989e-03 1.67308331e-01 6.12105250e-01 9.35479224e-01\n",
      " 5.06954268e-02 9.99589264e-01 1.01028970e-02 9.13422167e-01\n",
      " 9.99209881e-01 8.79267097e-01 9.99999881e-01 1.45760570e-02\n",
      " 6.15953642e-04 9.63602841e-01 2.49408334e-02 5.16580709e-04\n",
      " 8.33294094e-02 8.06509852e-01 7.91754015e-03 4.97924000e-01\n",
      " 5.31001329e-01 5.93806468e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 209 [0/54 (0%)]\tTrain Loss: 0.065353\n",
      "Train Epoch: 209 [8/54 (15%)]\tTrain Loss: 0.003841\n",
      "Train Epoch: 209 [16/54 (30%)]\tTrain Loss: 0.007232\n",
      "Train Epoch: 209 [24/54 (44%)]\tTrain Loss: 0.006443\n",
      "Train Epoch: 209 [32/54 (59%)]\tTrain Loss: 0.048458\n",
      "Train Epoch: 209 [40/54 (74%)]\tTrain Loss: 0.058612\n",
      "Train Epoch: 209 [48/54 (89%)]\tTrain Loss: 0.007459\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.27059740e-01 9.26046073e-01 5.69680214e-01 7.37996161e-01\n",
      " 9.59587470e-02 3.84948961e-02 6.39724076e-01 4.48910832e-01\n",
      " 4.27805334e-02 1.81831628e-01 4.22485061e-02 1.18200384e-01\n",
      " 1.29155284e-02 7.22065270e-02 2.38973543e-01 1.47637445e-02\n",
      " 6.06151670e-03 1.06725328e-01 3.89233083e-01 5.63215651e-02\n",
      " 7.31080398e-02 9.70776379e-01 9.97937560e-01 9.78463948e-01\n",
      " 6.65273070e-01 9.99584854e-01 9.96954203e-01 5.63131213e-01\n",
      " 5.81951082e-01 8.07902664e-02 7.79721856e-01 9.88836110e-01\n",
      " 9.42616582e-01 8.57340929e-04 4.90050472e-04 8.41187965e-03\n",
      " 5.20130573e-03 7.47785628e-01 2.02545859e-02 4.84169349e-02\n",
      " 3.90551277e-02 2.43016127e-02 1.70879532e-03 3.32084179e-01\n",
      " 1.28568083e-01 2.52465904e-01 9.91338849e-01 9.61524367e-01\n",
      " 9.99997139e-01 9.33013737e-01 9.99943376e-01 2.70478893e-04\n",
      " 2.32898723e-03 6.19911253e-02 7.79826269e-02 5.97395888e-03\n",
      " 9.76369441e-01 1.10578053e-02 5.20260893e-02 2.52087135e-02\n",
      " 9.99262750e-01 9.03107584e-01 9.80809510e-01 9.98673201e-01\n",
      " 9.94822741e-01 9.82206345e-01 9.53672826e-01 9.99538541e-01\n",
      " 9.99867558e-01 9.39880252e-01 9.73376215e-01 9.86578166e-01\n",
      " 9.99163866e-01 9.93610442e-01 9.50335085e-01 9.95694280e-01\n",
      " 9.99981642e-01 9.99944210e-01 9.99396086e-01 9.99976516e-01\n",
      " 9.99993920e-01 9.98285711e-01 9.99229550e-01 5.84788322e-01\n",
      " 9.18111026e-01 9.96492922e-01 9.87805247e-01 9.97738838e-01\n",
      " 3.08983177e-02 5.07700801e-01 9.61244106e-01 8.88119459e-01\n",
      " 7.18907416e-01 9.99816716e-01 9.91183400e-01 7.96988785e-01\n",
      " 2.41337232e-02 2.59823918e-01 2.76513398e-01 9.12244856e-01\n",
      " 4.63698544e-02 9.98049498e-01 6.28218278e-02 9.19783950e-01\n",
      " 9.74160016e-01 9.91968572e-01 9.99999881e-01 6.60155788e-02\n",
      " 2.08264031e-02 9.89840925e-01 1.30321130e-01 8.44397768e-03\n",
      " 6.34365141e-01 7.07997322e-01 7.07043707e-02 6.26259029e-01\n",
      " 3.68222535e-01 3.02917119e-02]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 210 [0/54 (0%)]\tTrain Loss: 0.001605\n",
      "Train Epoch: 210 [8/54 (15%)]\tTrain Loss: 0.002200\n",
      "Train Epoch: 210 [16/54 (30%)]\tTrain Loss: 0.013124\n",
      "Train Epoch: 210 [24/54 (44%)]\tTrain Loss: 0.006852\n",
      "Train Epoch: 210 [32/54 (59%)]\tTrain Loss: 0.021601\n",
      "Train Epoch: 210 [40/54 (74%)]\tTrain Loss: 0.005225\n",
      "Train Epoch: 210 [48/54 (89%)]\tTrain Loss: 0.064872\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.02882116e-02 4.89971071e-01 2.74460435e-01 7.39821792e-01\n",
      " 3.75001580e-01 8.48710164e-02 8.58656585e-01 9.58702326e-01\n",
      " 1.49922073e-01 3.03389400e-01 3.82188469e-01 4.80345726e-01\n",
      " 1.03586297e-02 6.02872558e-02 2.93527931e-01 5.87681197e-02\n",
      " 1.02210209e-01 3.74933958e-01 8.80336344e-01 3.84411901e-01\n",
      " 6.48055598e-02 9.92414653e-01 9.98793125e-01 9.99525547e-01\n",
      " 6.37535512e-01 9.99959111e-01 9.97566938e-01 8.93367469e-01\n",
      " 9.53289032e-01 1.51383936e-01 7.75600895e-02 9.03612018e-01\n",
      " 1.44450933e-01 2.10387792e-04 5.96259430e-04 5.77688217e-02\n",
      " 4.02479433e-02 6.66429222e-01 8.57402757e-03 1.60172865e-01\n",
      " 4.25875448e-02 1.54844830e-02 2.76246894e-04 3.13526802e-02\n",
      " 4.60665226e-01 5.41501865e-03 6.50308728e-02 4.12089705e-01\n",
      " 9.98607576e-01 9.77195501e-01 8.86186540e-01 5.40308282e-03\n",
      " 2.11173054e-02 9.61047946e-04 1.94729737e-03 1.20195657e-01\n",
      " 5.85296392e-01 2.44743839e-01 3.24497759e-01 1.41011074e-01\n",
      " 6.62444532e-01 5.03141761e-01 1.51629642e-01 9.77261007e-01\n",
      " 9.52555895e-01 9.90215659e-01 9.11140203e-01 9.99402761e-01\n",
      " 9.99920011e-01 9.42502320e-02 5.45373261e-01 7.44830012e-01\n",
      " 9.99772966e-01 9.98868763e-01 9.29712296e-01 1.32698938e-01\n",
      " 9.99172211e-01 9.99262989e-01 9.29865241e-01 9.87315297e-01\n",
      " 8.58203351e-01 9.68228504e-02 9.93440330e-01 8.96202549e-02\n",
      " 5.98239005e-01 6.25595152e-01 9.59530056e-01 9.86623824e-01\n",
      " 4.35893685e-01 7.32837260e-01 9.96913075e-01 9.72705126e-01\n",
      " 9.23277140e-01 9.99947906e-01 9.84914243e-01 9.97675240e-01\n",
      " 1.77914515e-01 5.33394933e-01 2.37282827e-01 9.44116771e-01\n",
      " 2.56524002e-03 8.03719580e-01 3.04822832e-01 3.89366567e-01\n",
      " 7.50040531e-01 8.31957161e-01 9.99946117e-01 1.01260897e-02\n",
      " 6.81237206e-02 9.95086730e-01 2.28171330e-02 2.58941855e-02\n",
      " 9.10542250e-01 8.68356705e-01 9.46950447e-03 3.68640595e-03\n",
      " 3.29250157e-01 5.53038955e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "vote_pred [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 43 FN= 13 FP= 17\n",
      "TP+FP 62\n",
      "precision 0.7258064516129032\n",
      "recall 0.7758620689655172\n",
      "F1 0.7500000000000001\n",
      "acc 0.7457627118644068\n",
      "AUCp 0.746264367816092\n",
      "AUC 0.7790229885057471\n",
      "\n",
      " The epoch is 210, average recall: 0.7759, average precision: 0.7258,average F1: 0.7500, average accuracy: 0.7458, average AUC: 0.7790\n",
      "Train Epoch: 211 [0/54 (0%)]\tTrain Loss: 0.017732\n",
      "Train Epoch: 211 [8/54 (15%)]\tTrain Loss: 0.013119\n",
      "Train Epoch: 211 [16/54 (30%)]\tTrain Loss: 0.015922\n",
      "Train Epoch: 211 [24/54 (44%)]\tTrain Loss: 0.009763\n",
      "Train Epoch: 211 [32/54 (59%)]\tTrain Loss: 0.061926\n",
      "Train Epoch: 211 [40/54 (74%)]\tTrain Loss: 0.020591\n",
      "Train Epoch: 211 [48/54 (89%)]\tTrain Loss: 0.046038\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.96823697e-02 6.64900780e-01 9.39361111e-04 5.34300745e-01\n",
      " 1.08875493e-02 1.38349356e-02 1.57191493e-02 9.91626084e-02\n",
      " 5.00272326e-02 3.28848734e-02 2.97897756e-02 1.77092627e-02\n",
      " 7.23005913e-04 2.22468720e-04 7.83893373e-03 7.40460306e-02\n",
      " 5.81713878e-02 1.23826124e-01 6.41767740e-01 1.77126788e-02\n",
      " 1.92508861e-01 8.92568231e-01 9.95000243e-01 9.57022309e-01\n",
      " 3.08823176e-02 9.99778092e-01 9.99851346e-01 8.00271928e-01\n",
      " 8.37798297e-01 5.09333551e-01 2.35804021e-01 6.70905232e-01\n",
      " 2.90109694e-01 2.52363202e-03 3.40713450e-05 8.07070523e-04\n",
      " 3.97831528e-03 6.68088496e-01 2.12280691e-04 2.62822560e-03\n",
      " 1.75690468e-04 3.60700389e-04 4.83295571e-06 6.03846833e-03\n",
      " 5.58886051e-01 1.35986810e-03 5.88757843e-02 7.65548646e-02\n",
      " 6.70766354e-01 9.11835253e-01 8.11903402e-02 4.44927309e-06\n",
      " 3.47195419e-05 2.50867824e-03 8.54975265e-03 4.07350510e-02\n",
      " 7.61680245e-01 2.01843023e-01 1.90212631e-05 1.13561063e-03\n",
      " 9.82293189e-01 4.84329790e-01 9.13832545e-01 9.86686707e-01\n",
      " 9.95973766e-01 9.94512677e-01 9.95659113e-01 9.99876857e-01\n",
      " 9.99988198e-01 3.68634224e-01 7.51545429e-01 8.84326398e-01\n",
      " 9.99980092e-01 9.99700785e-01 9.99014854e-01 9.84772444e-01\n",
      " 9.99225736e-01 9.97762918e-01 9.63418722e-01 9.91542101e-01\n",
      " 9.90232825e-01 8.83270383e-01 9.90708113e-01 7.19693005e-02\n",
      " 3.26382190e-01 5.73783398e-01 7.93591022e-01 8.45238984e-01\n",
      " 9.06085670e-02 9.85769451e-01 9.95613933e-01 7.90203273e-01\n",
      " 9.60917056e-01 9.99933958e-01 9.98682559e-01 9.97041643e-01\n",
      " 5.47994822e-02 3.19893956e-02 6.36057794e-01 9.99525189e-01\n",
      " 9.19974875e-04 9.87462223e-01 9.79143158e-02 7.63206005e-01\n",
      " 7.85580456e-01 9.30071235e-01 9.99606669e-01 3.80179845e-03\n",
      " 1.55937225e-02 9.06828880e-01 8.06596652e-02 1.12565339e-01\n",
      " 9.62661803e-01 8.49809289e-01 2.92652339e-01 4.34366725e-02\n",
      " 8.47633958e-01 9.87614870e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 212 [0/54 (0%)]\tTrain Loss: 0.059982\n",
      "Train Epoch: 212 [8/54 (15%)]\tTrain Loss: 0.034014\n",
      "Train Epoch: 212 [16/54 (30%)]\tTrain Loss: 0.033623\n",
      "Train Epoch: 212 [24/54 (44%)]\tTrain Loss: 0.004211\n",
      "Train Epoch: 212 [32/54 (59%)]\tTrain Loss: 0.012173\n",
      "Train Epoch: 212 [40/54 (74%)]\tTrain Loss: 0.007339\n",
      "Train Epoch: 212 [48/54 (89%)]\tTrain Loss: 0.068904\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.08822896 0.96572435 0.59021461 0.99895966 0.99840492 0.49735862\n",
      " 0.96324205 0.99762768 0.4335911  0.6884023  0.99760818 0.3686704\n",
      " 0.84859383 0.14013238 0.37198564 0.7288205  0.81758851 0.5120644\n",
      " 0.95685762 0.28410423 0.08190433 0.99599022 0.99999797 0.99991918\n",
      " 0.55475742 1.         1.         0.9939056  0.99905163 0.82045168\n",
      " 0.97488856 0.99912471 0.99499798 0.47721529 0.00213211 0.72778124\n",
      " 0.54246449 0.99991822 0.07716294 0.5002051  0.64305705 0.46996513\n",
      " 0.02102264 0.53653324 0.97263891 0.54300159 0.98619461 0.94183874\n",
      " 0.99602401 0.99024546 0.93826616 0.12025832 0.31447056 0.2765851\n",
      " 0.03085506 0.60937965 0.91192794 0.92539048 0.39569834 0.45197165\n",
      " 0.99906403 0.95325774 0.80311871 0.97751689 0.99524188 0.9997471\n",
      " 0.99999833 0.99999952 1.         0.90692693 0.99543864 0.99808806\n",
      " 0.99999988 0.99999952 0.99341065 0.97720063 0.99995804 0.99994743\n",
      " 0.9974969  0.99999797 0.99999666 0.99918908 0.99985659 0.86083961\n",
      " 0.98151338 0.9899593  0.99087101 0.99798453 0.84877706 0.99999952\n",
      " 0.99995565 0.9993068  0.99997616 1.         0.99999976 0.99999988\n",
      " 0.86094898 0.97645205 0.9524194  1.         0.48055393 0.99998844\n",
      " 0.98114431 0.99889839 0.99855334 0.9994573  1.         0.55803204\n",
      " 0.28971639 0.97627288 0.99128866 0.42684078 0.99998975 0.99993336\n",
      " 0.94321501 0.80327863 0.99994946 0.99961555]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 213 [0/54 (0%)]\tTrain Loss: 0.045438\n",
      "Train Epoch: 213 [8/54 (15%)]\tTrain Loss: 0.008299\n",
      "Train Epoch: 213 [16/54 (30%)]\tTrain Loss: 0.027066\n",
      "Train Epoch: 213 [24/54 (44%)]\tTrain Loss: 0.001482\n",
      "Train Epoch: 213 [32/54 (59%)]\tTrain Loss: 0.008587\n",
      "Train Epoch: 213 [40/54 (74%)]\tTrain Loss: 0.005595\n",
      "Train Epoch: 213 [48/54 (89%)]\tTrain Loss: 0.016133\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.42158741e-01 9.38497424e-01 3.51616800e-01 9.56102788e-01\n",
      " 7.41245568e-01 5.25440216e-01 5.30977726e-01 9.71948445e-01\n",
      " 3.49485606e-01 3.89699042e-01 2.87291914e-01 1.15071781e-01\n",
      " 6.08101394e-03 6.79916292e-02 3.77270728e-01 9.80565026e-02\n",
      " 4.66285087e-02 1.13076657e-01 6.16527557e-01 5.43534197e-02\n",
      " 3.91175561e-02 9.92618024e-01 9.99415636e-01 9.56812620e-01\n",
      " 6.56069458e-01 9.99879122e-01 9.98671055e-01 6.34088874e-01\n",
      " 9.20519054e-01 8.92678440e-01 6.47870839e-01 9.13175583e-01\n",
      " 9.97281194e-01 1.34925556e-03 4.86068660e-04 2.24263500e-02\n",
      " 9.85182598e-02 7.35148013e-01 1.66875869e-01 2.09085748e-01\n",
      " 5.12617230e-01 1.52517810e-01 1.23285623e-02 1.36594906e-01\n",
      " 2.54047513e-01 1.80292696e-01 9.41926479e-01 6.17466390e-01\n",
      " 9.99904752e-01 9.32833314e-01 9.99004424e-01 2.08540563e-03\n",
      " 2.09955439e-01 1.60296604e-01 1.65031124e-02 7.16050267e-02\n",
      " 9.00288582e-01 2.05685869e-01 1.48067266e-01 2.87908822e-01\n",
      " 9.71121728e-01 7.89481401e-01 9.31425095e-01 9.80976760e-01\n",
      " 9.98225868e-01 9.92121816e-01 9.99200165e-01 9.99926686e-01\n",
      " 9.99998808e-01 9.18418646e-01 8.34234953e-01 9.24123168e-01\n",
      " 9.99897242e-01 9.99798834e-01 9.98799682e-01 9.98755097e-01\n",
      " 9.99910235e-01 9.99686122e-01 9.97118473e-01 9.99586880e-01\n",
      " 9.99791801e-01 9.92872834e-01 9.98667479e-01 8.57794046e-01\n",
      " 9.85917509e-01 9.01966512e-01 9.91864979e-01 9.96044815e-01\n",
      " 3.17802578e-01 9.84725654e-01 9.96939540e-01 6.74553335e-01\n",
      " 9.13635194e-01 9.99994159e-01 9.98945892e-01 9.99465883e-01\n",
      " 1.42706916e-01 8.09756160e-01 3.62804383e-01 9.98965144e-01\n",
      " 1.20839871e-01 9.95563388e-01 3.64767015e-01 3.17688823e-01\n",
      " 8.02077770e-01 9.11779523e-01 9.99970198e-01 9.77038592e-02\n",
      " 1.48347884e-01 6.52673960e-01 3.78605545e-01 1.04231663e-01\n",
      " 9.72507894e-01 8.95452857e-01 5.02376974e-01 4.20915931e-01\n",
      " 9.61562276e-01 9.80092883e-01]\n",
      "predict [0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 214 [0/54 (0%)]\tTrain Loss: 0.009986\n",
      "Train Epoch: 214 [8/54 (15%)]\tTrain Loss: 0.028240\n",
      "Train Epoch: 214 [16/54 (30%)]\tTrain Loss: 0.017209\n",
      "Train Epoch: 214 [24/54 (44%)]\tTrain Loss: 0.002144\n",
      "Train Epoch: 214 [32/54 (59%)]\tTrain Loss: 0.012908\n",
      "Train Epoch: 214 [40/54 (74%)]\tTrain Loss: 0.041396\n",
      "Train Epoch: 214 [48/54 (89%)]\tTrain Loss: 0.004828\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.12648748e-01 9.98906851e-01 9.29615140e-01 9.97599185e-01\n",
      " 9.40079868e-01 6.10437989e-01 9.54824626e-01 9.98086572e-01\n",
      " 7.70972490e-01 2.03388095e-01 2.65557975e-01 8.24923441e-03\n",
      " 3.59414006e-03 1.46420956e-01 8.63424957e-01 9.36621130e-02\n",
      " 7.56176412e-02 4.29400325e-01 8.68965745e-01 6.01458788e-01\n",
      " 4.10082284e-03 9.88431871e-01 9.99677896e-01 9.98443425e-01\n",
      " 7.65014827e-01 9.99969125e-01 9.99744475e-01 9.35948849e-01\n",
      " 9.59604561e-01 7.22257793e-01 9.98343349e-01 9.92233634e-01\n",
      " 7.69829512e-01 4.13286500e-03 2.51724297e-04 2.62672268e-02\n",
      " 4.36051236e-03 9.92213786e-01 1.42211765e-01 1.81595176e-01\n",
      " 1.97353557e-01 5.47397658e-02 6.15000017e-02 7.02753663e-02\n",
      " 6.22028947e-01 8.50023806e-01 9.97067273e-01 9.57265437e-01\n",
      " 9.99992132e-01 9.83092666e-01 9.99976754e-01 6.31399127e-03\n",
      " 1.16385303e-01 8.20392430e-01 5.38267158e-02 1.18540861e-01\n",
      " 9.99845266e-01 6.18229993e-02 1.89975072e-02 7.14783907e-01\n",
      " 9.99680638e-01 9.94894922e-01 9.97843742e-01 9.99716222e-01\n",
      " 9.99546468e-01 9.98216331e-01 9.99970078e-01 9.99981642e-01\n",
      " 9.99990106e-01 9.99871969e-01 9.97597039e-01 9.99465644e-01\n",
      " 9.99986053e-01 9.99896526e-01 9.94968474e-01 9.99990225e-01\n",
      " 1.00000000e+00 9.99999881e-01 9.99981642e-01 9.99972582e-01\n",
      " 9.99999166e-01 9.99988556e-01 9.99984145e-01 7.59437740e-01\n",
      " 9.61891115e-01 9.97295678e-01 9.98419285e-01 9.98859763e-01\n",
      " 4.17946398e-01 9.95494843e-01 9.97017384e-01 9.90222454e-01\n",
      " 9.96222258e-01 9.99989629e-01 9.99045908e-01 9.53187525e-01\n",
      " 1.65424757e-02 8.31738114e-01 6.24976397e-01 9.99443591e-01\n",
      " 3.05962831e-01 9.99788582e-01 3.05882841e-01 9.98866439e-01\n",
      " 9.98157322e-01 9.99789059e-01 1.00000000e+00 6.30578622e-02\n",
      " 1.85565770e-01 9.05439317e-01 6.84885502e-01 6.37297094e-01\n",
      " 9.90196347e-01 9.94546771e-01 6.41927540e-01 8.11158538e-01\n",
      " 8.45186591e-01 9.29501116e-01]\n",
      "predict [0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 215 [0/54 (0%)]\tTrain Loss: 0.000877\n",
      "Train Epoch: 215 [8/54 (15%)]\tTrain Loss: 0.003716\n",
      "Train Epoch: 215 [16/54 (30%)]\tTrain Loss: 0.054948\n",
      "Train Epoch: 215 [24/54 (44%)]\tTrain Loss: 0.011957\n",
      "Train Epoch: 215 [32/54 (59%)]\tTrain Loss: 0.049121\n",
      "Train Epoch: 215 [40/54 (74%)]\tTrain Loss: 0.025108\n",
      "Train Epoch: 215 [48/54 (89%)]\tTrain Loss: 0.003380\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.36410990e-05 6.67837739e-01 7.56210804e-01 9.61133957e-01\n",
      " 5.43705225e-01 1.38638203e-03 5.19915521e-01 8.76329064e-01\n",
      " 4.60112542e-01 2.42642567e-01 4.23882939e-02 8.59263167e-03\n",
      " 6.62217848e-04 8.58418737e-03 1.45292178e-01 3.66330473e-03\n",
      " 3.23230005e-03 2.87692338e-01 9.11828041e-01 9.77402478e-02\n",
      " 1.79542918e-02 9.93864834e-01 9.99766171e-01 9.95788872e-01\n",
      " 7.07418442e-01 9.99980569e-01 9.99822557e-01 5.00855029e-01\n",
      " 8.02332819e-01 8.41489211e-02 3.42450708e-01 9.82710242e-01\n",
      " 8.30012932e-02 4.92048624e-04 7.67340651e-04 1.39870904e-02\n",
      " 2.34755836e-02 9.10691023e-01 1.07461900e-01 1.70741826e-01\n",
      " 9.16780680e-02 6.81657642e-02 4.22770046e-02 4.91129793e-02\n",
      " 1.28915384e-01 5.52534759e-01 8.02632391e-01 7.29304910e-01\n",
      " 9.99900818e-01 9.66053188e-01 9.98969793e-01 4.98649257e-04\n",
      " 2.14084168e-03 1.00918114e-01 2.85089370e-02 5.98170795e-03\n",
      " 9.93701816e-01 1.40447170e-02 1.36259217e-02 1.63183939e-02\n",
      " 9.95418668e-01 9.56274271e-01 7.57918417e-01 9.74631786e-01\n",
      " 9.76662159e-01 9.43869293e-01 9.91780698e-01 9.99579012e-01\n",
      " 9.99956727e-01 6.61231816e-01 9.89445150e-01 9.96715665e-01\n",
      " 9.99697685e-01 9.90202427e-01 8.00578177e-01 9.50076222e-01\n",
      " 9.99502659e-01 9.99478996e-01 9.19644713e-01 9.99325514e-01\n",
      " 9.99983788e-01 9.98265803e-01 9.99508142e-01 8.08642268e-01\n",
      " 8.80519390e-01 8.76126468e-01 9.62819934e-01 9.78178680e-01\n",
      " 5.55727124e-01 9.89412367e-01 9.99527335e-01 9.56160247e-01\n",
      " 8.33237171e-01 9.99998689e-01 9.99706924e-01 9.98168349e-01\n",
      " 2.53564399e-03 9.37853038e-01 3.65759730e-01 9.69545782e-01\n",
      " 2.95706511e-01 9.90816832e-01 4.56064761e-01 7.35909164e-01\n",
      " 8.91035736e-01 9.87975001e-01 1.00000000e+00 2.40565628e-01\n",
      " 1.78739130e-01 9.83378470e-01 8.74615788e-01 9.79417384e-01\n",
      " 9.84876752e-01 9.75250125e-01 6.03946671e-02 6.81743205e-01\n",
      " 9.99343812e-01 9.92845237e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 216 [0/54 (0%)]\tTrain Loss: 0.003995\n",
      "Train Epoch: 216 [8/54 (15%)]\tTrain Loss: 0.004042\n",
      "Train Epoch: 216 [16/54 (30%)]\tTrain Loss: 0.023471\n",
      "Train Epoch: 216 [24/54 (44%)]\tTrain Loss: 0.002237\n",
      "Train Epoch: 216 [32/54 (59%)]\tTrain Loss: 0.038134\n",
      "Train Epoch: 216 [40/54 (74%)]\tTrain Loss: 0.006612\n",
      "Train Epoch: 216 [48/54 (89%)]\tTrain Loss: 0.147694\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.03621860e-03 4.87419367e-02 3.74763608e-02 2.78944731e-01\n",
      " 1.28989751e-02 7.15633039e-04 1.43822224e-03 1.14503339e-01\n",
      " 1.17476262e-01 7.95217231e-02 4.81882039e-03 3.74017246e-02\n",
      " 1.88087899e-04 1.50075328e-04 3.42976674e-03 7.69399503e-06\n",
      " 2.19774574e-06 8.43458027e-02 4.06271487e-01 1.91898702e-03\n",
      " 3.76688084e-03 7.05554485e-01 9.99185860e-01 9.87118244e-01\n",
      " 5.76032214e-02 9.99978542e-01 9.96122777e-01 3.10016900e-01\n",
      " 5.73188327e-02 1.99538153e-02 3.01676076e-02 8.89145374e-01\n",
      " 4.09332663e-01 2.80907983e-07 1.34676327e-06 1.04035986e-04\n",
      " 1.01543637e-03 2.38701135e-01 1.02603843e-03 1.56090939e-02\n",
      " 1.56421661e-02 6.06529275e-03 7.84676615e-03 7.98638968e-04\n",
      " 2.52155960e-02 3.29156704e-02 8.08993042e-01 3.79182965e-01\n",
      " 9.92501378e-01 9.28384960e-01 9.64389265e-01 9.89418095e-06\n",
      " 1.64369514e-04 6.12032600e-04 3.28402221e-03 8.02120718e-04\n",
      " 8.80023718e-01 2.37388202e-04 3.03987507e-03 4.35921800e-04\n",
      " 4.23377097e-01 2.69626141e-01 2.41025358e-01 7.17862487e-01\n",
      " 6.85198188e-01 2.74555564e-01 6.61500335e-01 9.97662783e-01\n",
      " 9.98679101e-01 1.68869108e-01 7.86389112e-01 7.95721114e-01\n",
      " 9.76389110e-01 8.79131556e-01 9.82748210e-01 8.71792793e-01\n",
      " 9.96960580e-01 9.97525394e-01 2.76384592e-01 9.98515666e-01\n",
      " 9.97784555e-01 9.88580644e-01 9.99013543e-01 3.76230478e-01\n",
      " 5.98917902e-01 7.99349368e-01 4.27991360e-01 6.93277717e-01\n",
      " 7.05540702e-02 5.16646206e-02 9.94011223e-01 2.70888079e-02\n",
      " 1.80704564e-01 9.99995708e-01 9.98360097e-01 9.98999178e-01\n",
      " 2.78415205e-03 1.11263365e-01 3.07587571e-02 6.55690491e-01\n",
      " 1.34756267e-02 9.12187219e-01 3.12036322e-03 1.13901952e-02\n",
      " 3.45428377e-01 2.03055605e-01 9.99789894e-01 2.48687412e-03\n",
      " 5.71758021e-04 6.87694073e-01 1.08364159e-02 1.03617879e-02\n",
      " 1.88736051e-01 7.94792950e-01 6.19949680e-03 1.61101725e-02\n",
      " 5.92181802e-01 5.18803904e-03]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 217 [0/54 (0%)]\tTrain Loss: 0.003703\n",
      "Train Epoch: 217 [8/54 (15%)]\tTrain Loss: 0.017265\n",
      "Train Epoch: 217 [16/54 (30%)]\tTrain Loss: 0.013109\n",
      "Train Epoch: 217 [24/54 (44%)]\tTrain Loss: 0.017059\n",
      "Train Epoch: 217 [32/54 (59%)]\tTrain Loss: 0.001142\n",
      "Train Epoch: 217 [40/54 (74%)]\tTrain Loss: 0.076269\n",
      "Train Epoch: 217 [48/54 (89%)]\tTrain Loss: 0.002853\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.43504860e-03 8.60526979e-01 9.06555653e-01 8.66158843e-01\n",
      " 9.20618176e-02 3.03746993e-03 7.42110431e-01 6.22321188e-01\n",
      " 7.01697320e-02 3.95413637e-01 2.10893273e-01 3.67406309e-02\n",
      " 3.43018118e-03 5.24107600e-05 2.05351994e-03 4.00864577e-04\n",
      " 4.31598775e-04 4.38283756e-02 8.16969454e-01 8.37897882e-03\n",
      " 2.33623479e-03 8.78500581e-01 9.99977827e-01 8.78660977e-01\n",
      " 4.42310899e-01 9.99992967e-01 9.97179031e-01 4.85463977e-01\n",
      " 9.57681596e-01 5.42607866e-02 1.78143620e-01 9.95220959e-01\n",
      " 9.75888550e-01 2.50622020e-06 5.43224405e-06 2.64121760e-02\n",
      " 1.58669092e-02 2.20750421e-01 7.80458190e-03 5.83771653e-02\n",
      " 1.86546966e-01 1.36856418e-02 5.17782336e-03 3.27211269e-03\n",
      " 3.35439056e-01 1.96258590e-01 9.99793470e-01 9.98517215e-01\n",
      " 9.99999404e-01 9.43781018e-01 9.99916196e-01 1.09962610e-04\n",
      " 3.04903864e-04 1.13720186e-02 7.38377124e-03 1.16385482e-02\n",
      " 8.07784081e-01 2.36097574e-02 2.01867800e-02 1.79728642e-02\n",
      " 9.98360455e-01 9.89400804e-01 9.94387925e-01 9.99799907e-01\n",
      " 9.80424821e-01 9.56840277e-01 9.89110529e-01 9.99266565e-01\n",
      " 9.99999642e-01 3.04088622e-01 9.82135952e-01 9.80273008e-01\n",
      " 9.98255670e-01 9.99777019e-01 9.98867035e-01 9.95131016e-01\n",
      " 9.99966383e-01 9.99948978e-01 9.99948263e-01 9.99997735e-01\n",
      " 9.99993324e-01 9.99780476e-01 9.99111235e-01 2.13478506e-01\n",
      " 9.38881874e-01 9.91907001e-01 9.99036074e-01 9.98446405e-01\n",
      " 8.57838094e-02 1.36382729e-01 3.79923820e-01 4.11906540e-01\n",
      " 7.65716314e-01 9.99960423e-01 9.93638694e-01 9.81383383e-01\n",
      " 3.05416957e-02 7.21139908e-01 4.08572316e-01 9.86782908e-01\n",
      " 1.96206212e-01 9.91246879e-01 8.27573910e-02 2.31604993e-01\n",
      " 5.58710515e-01 6.34132326e-01 9.99934912e-01 3.23778242e-02\n",
      " 3.93548375e-03 9.60706294e-01 3.98482801e-03 7.68839940e-02\n",
      " 9.53345597e-01 2.10584179e-01 1.98945198e-02 1.85529873e-01\n",
      " 8.59066725e-01 1.42002434e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 218 [0/54 (0%)]\tTrain Loss: 0.006959\n",
      "Train Epoch: 218 [8/54 (15%)]\tTrain Loss: 0.002317\n",
      "Train Epoch: 218 [16/54 (30%)]\tTrain Loss: 0.022456\n",
      "Train Epoch: 218 [24/54 (44%)]\tTrain Loss: 0.014110\n",
      "Train Epoch: 218 [32/54 (59%)]\tTrain Loss: 0.019464\n",
      "Train Epoch: 218 [40/54 (74%)]\tTrain Loss: 0.006389\n",
      "Train Epoch: 218 [48/54 (89%)]\tTrain Loss: 0.001876\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.0258676  0.33960214 0.14262882 0.99972743 0.99748492 0.00772742\n",
      " 0.35348177 0.99998248 0.32875985 0.78003001 0.99668711 0.21473978\n",
      " 0.95286912 0.20651332 0.83364731 0.19483162 0.73928756 0.14903064\n",
      " 0.9829008  0.74762088 0.16978167 0.99879104 0.99999976 0.99998808\n",
      " 0.88329476 1.         0.99999988 0.99829382 0.98350304 0.92017299\n",
      " 0.92735481 0.99897987 0.99716431 0.00997144 0.07244909 0.87535834\n",
      " 0.99208802 0.99616712 0.21074489 0.90013862 0.83196342 0.94125259\n",
      " 0.02871549 0.97389913 0.93815386 0.91658741 0.99909019 0.95104694\n",
      " 0.99999797 0.99765414 0.99978834 0.76734668 0.41575566 0.83050323\n",
      " 0.00730805 0.95758289 0.95780212 0.85368019 0.64838952 0.41365677\n",
      " 0.99741936 0.94093609 0.94488704 0.99797422 0.99931049 0.99999607\n",
      " 0.9999938  0.99998355 0.99999642 0.78713727 0.87704486 0.98159009\n",
      " 0.99995601 0.99999094 0.99978071 0.98163199 0.99961108 0.99972826\n",
      " 0.99932134 0.99999845 0.99999821 0.99947852 0.99997914 0.93433261\n",
      " 0.99752301 0.99486464 0.99045229 0.99266839 0.94479358 0.99984038\n",
      " 0.99553382 0.99880075 0.99948812 1.         0.9999851  0.99999821\n",
      " 0.97419226 0.9639163  0.76958692 0.99999797 0.55087149 0.999403\n",
      " 0.98398131 0.97181702 0.99750632 0.94854945 1.         0.93128443\n",
      " 0.79815865 0.99997449 0.99483168 0.73200738 0.99999952 0.99361306\n",
      " 0.895064   0.86412489 0.99629211 0.98051971]\n",
      "predict [0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 219 [0/54 (0%)]\tTrain Loss: 0.005630\n",
      "Train Epoch: 219 [8/54 (15%)]\tTrain Loss: 0.016991\n",
      "Train Epoch: 219 [16/54 (30%)]\tTrain Loss: 0.005425\n",
      "Train Epoch: 219 [24/54 (44%)]\tTrain Loss: 0.005670\n",
      "Train Epoch: 219 [32/54 (59%)]\tTrain Loss: 0.033824\n",
      "Train Epoch: 219 [40/54 (74%)]\tTrain Loss: 0.002595\n",
      "Train Epoch: 219 [48/54 (89%)]\tTrain Loss: 0.000453\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.85415524e-03 8.98813426e-01 4.56204593e-01 9.96723473e-01\n",
      " 9.48205352e-01 7.78792950e-04 7.51656532e-01 9.98493075e-01\n",
      " 1.51584387e-01 2.67993007e-02 7.22653747e-01 1.16165949e-03\n",
      " 1.64327919e-02 1.90807246e-02 3.46835971e-01 8.55144521e-04\n",
      " 7.33129084e-02 2.62015909e-01 6.42216921e-01 3.21040392e-01\n",
      " 1.47386445e-02 9.97757852e-01 9.99856710e-01 9.91030216e-01\n",
      " 8.48491788e-01 9.99997258e-01 9.99695659e-01 9.90678728e-01\n",
      " 9.68910694e-01 5.36475956e-01 1.63123626e-02 9.98075962e-01\n",
      " 9.87550318e-01 1.57526101e-05 1.13322993e-03 5.72360694e-01\n",
      " 6.14693165e-01 9.96058702e-01 1.71600625e-01 4.01984423e-01\n",
      " 2.75331140e-01 3.79914671e-01 7.49101536e-03 8.97636056e-01\n",
      " 9.38320756e-01 8.01257074e-01 9.99658585e-01 9.97815728e-01\n",
      " 9.99996901e-01 9.85192060e-01 9.99925613e-01 4.96103941e-03\n",
      " 5.12110488e-03 3.08688618e-02 4.20537777e-03 2.43498459e-01\n",
      " 9.90895152e-01 1.15270808e-01 2.10833639e-01 6.67822408e-03\n",
      " 9.95266438e-01 9.16982770e-01 8.21433365e-01 9.95157301e-01\n",
      " 9.71819043e-01 9.99983311e-01 9.99701202e-01 9.99948382e-01\n",
      " 9.99999404e-01 9.13634479e-01 9.50526237e-01 9.90050972e-01\n",
      " 9.99739945e-01 9.99923468e-01 9.98855472e-01 9.41571355e-01\n",
      " 9.99939084e-01 9.99749959e-01 9.99979258e-01 9.99990821e-01\n",
      " 9.99999762e-01 9.99623179e-01 9.99964356e-01 5.16623259e-01\n",
      " 9.65113699e-01 9.60048378e-01 9.96908605e-01 9.93707895e-01\n",
      " 6.28790855e-01 9.89217162e-01 9.53548551e-01 9.95759904e-01\n",
      " 9.94948268e-01 9.99999046e-01 9.99741971e-01 9.96860027e-01\n",
      " 5.22360280e-02 8.08498502e-01 9.14565444e-01 9.98242736e-01\n",
      " 3.56180221e-01 9.99468744e-01 6.40925765e-01 6.32595003e-01\n",
      " 9.30496156e-01 9.56343472e-01 9.99997020e-01 8.18044841e-01\n",
      " 5.25831759e-01 9.99584496e-01 9.30615485e-01 1.67691886e-01\n",
      " 9.99911666e-01 8.95878375e-01 2.07324941e-02 9.25586522e-01\n",
      " 6.91320598e-01 5.09777009e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 220 [0/54 (0%)]\tTrain Loss: 0.001827\n",
      "Train Epoch: 220 [8/54 (15%)]\tTrain Loss: 0.004905\n",
      "Train Epoch: 220 [16/54 (30%)]\tTrain Loss: 0.005971\n",
      "Train Epoch: 220 [24/54 (44%)]\tTrain Loss: 0.068285\n",
      "Train Epoch: 220 [32/54 (59%)]\tTrain Loss: 0.031686\n",
      "Train Epoch: 220 [40/54 (74%)]\tTrain Loss: 0.012222\n",
      "Train Epoch: 220 [48/54 (89%)]\tTrain Loss: 0.009883\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.74166013e-02 9.84497547e-01 9.39218223e-01 7.33173728e-01\n",
      " 1.77076817e-01 6.00670290e-04 6.37120724e-01 1.71180934e-01\n",
      " 3.15437317e-01 5.71781993e-01 5.37017845e-02 6.23403192e-02\n",
      " 1.88282738e-03 1.04647996e-02 2.05043688e-01 5.13345469e-04\n",
      " 2.14501820e-03 2.11672768e-01 7.01173961e-01 3.27209234e-01\n",
      " 1.67885739e-02 9.55877841e-01 9.99748647e-01 9.62215364e-01\n",
      " 1.04182743e-01 9.99509573e-01 9.93380070e-01 9.88447487e-01\n",
      " 8.39556813e-01 6.74396694e-01 9.98422265e-01 9.99908924e-01\n",
      " 9.59565938e-01 6.47912035e-04 3.08473333e-04 2.20298380e-01\n",
      " 3.83902937e-01 9.59015489e-01 1.76858276e-01 1.05493322e-01\n",
      " 1.26719505e-01 1.86261237e-02 2.01661680e-02 6.57104433e-01\n",
      " 1.21242099e-01 9.91206467e-01 9.99868393e-01 9.99027729e-01\n",
      " 9.99996543e-01 9.39500868e-01 9.99982595e-01 4.31575696e-04\n",
      " 5.63318580e-02 2.96537369e-01 4.62943166e-01 5.51420636e-03\n",
      " 9.95971739e-01 6.68428019e-02 2.08965063e-01 4.31932360e-02\n",
      " 9.99540448e-01 9.93941784e-01 9.81477439e-01 9.99722302e-01\n",
      " 9.97092724e-01 8.73918951e-01 9.99022007e-01 9.99938250e-01\n",
      " 9.99945045e-01 7.53572941e-01 9.98484433e-01 9.96613324e-01\n",
      " 9.96588945e-01 9.97867823e-01 9.96013999e-01 9.98835146e-01\n",
      " 9.99948978e-01 2.43179202e-01 9.99987245e-01 9.99975085e-01\n",
      " 9.99996305e-01 9.99884248e-01 9.99253333e-01 1.36637077e-01\n",
      " 5.90788960e-01 9.99125540e-01 9.99379516e-01 9.99716699e-01\n",
      " 3.20307881e-01 6.70165345e-02 6.89449131e-01 8.36031258e-01\n",
      " 9.71408606e-01 9.99853134e-01 9.92810428e-01 7.19350636e-01\n",
      " 7.36461952e-03 3.32744300e-01 2.21072480e-01 9.19821739e-01\n",
      " 1.59173131e-01 9.84723091e-01 3.65251824e-02 7.50378549e-01\n",
      " 9.73113120e-01 9.94944751e-01 9.99950171e-01 1.70778651e-02\n",
      " 4.57121044e-01 9.85409439e-01 1.20854758e-01 5.72954237e-01\n",
      " 8.58883500e-01 5.03102541e-01 1.29967809e-01 9.44190204e-01\n",
      " 1.89762458e-01 2.68990546e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
      "vote_pred [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 48 TN= 35 FN= 10 FP= 25\n",
      "TP+FP 73\n",
      "precision 0.6575342465753424\n",
      "recall 0.8275862068965517\n",
      "F1 0.732824427480916\n",
      "acc 0.7033898305084746\n",
      "AUCp 0.7054597701149424\n",
      "AUC 0.7939655172413793\n",
      "\n",
      " The epoch is 220, average recall: 0.8276, average precision: 0.6575,average F1: 0.7328, average accuracy: 0.7034, average AUC: 0.7940\n",
      "Train Epoch: 221 [0/54 (0%)]\tTrain Loss: 0.035822\n",
      "Train Epoch: 221 [8/54 (15%)]\tTrain Loss: 0.003506\n",
      "Train Epoch: 221 [16/54 (30%)]\tTrain Loss: 0.018956\n",
      "Train Epoch: 221 [24/54 (44%)]\tTrain Loss: 0.007631\n",
      "Train Epoch: 221 [32/54 (59%)]\tTrain Loss: 0.009777\n",
      "Train Epoch: 221 [40/54 (74%)]\tTrain Loss: 0.003656\n",
      "Train Epoch: 221 [48/54 (89%)]\tTrain Loss: 0.014784\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.02946701 0.93188077 0.29493111 0.98224628 0.84499443 0.00640611\n",
      " 0.6867637  0.99728465 0.24162926 0.29710138 0.99542516 0.15131241\n",
      " 0.16846873 0.0106339  0.11433609 0.00325107 0.00919635 0.04153778\n",
      " 0.89189303 0.57547081 0.39241129 0.99944419 0.99999237 0.99973255\n",
      " 0.4009645  0.99999917 0.99998939 0.99646461 0.96968484 0.61288822\n",
      " 0.98541796 0.99831653 0.98584032 0.00330871 0.00824204 0.23448305\n",
      " 0.88838702 0.99366051 0.18160774 0.59042656 0.51317537 0.81584698\n",
      " 0.01834342 0.66146111 0.96817625 0.79977363 0.99172908 0.39631814\n",
      " 0.99998903 0.99726176 0.99950171 0.08147689 0.19202352 0.27075413\n",
      " 0.23714836 0.43625546 0.99911577 0.68498021 0.2360024  0.15656203\n",
      " 0.99894005 0.83305162 0.9025107  0.99017465 0.99889404 0.99749196\n",
      " 0.99997032 0.99995434 0.99999785 0.57271594 0.95984691 0.97921431\n",
      " 0.99993467 0.99908864 0.99632013 0.99756563 0.9999578  0.99994516\n",
      " 0.99878949 0.99996591 0.99999821 0.99961406 0.99998069 0.07184742\n",
      " 0.91546887 0.97721374 0.99403918 0.99461269 0.91052061 0.88899648\n",
      " 0.99950588 0.9916923  0.99722552 1.         0.99999332 0.99997544\n",
      " 0.74643832 0.39414328 0.92836511 0.99999404 0.0441197  0.99782974\n",
      " 0.38076407 0.99424052 0.99696499 0.99534386 0.99999988 0.29564598\n",
      " 0.04648966 0.9990682  0.870722   0.4533006  0.99789679 0.81235403\n",
      " 0.70187235 0.57955956 0.02282305 0.96671402]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 222 [0/54 (0%)]\tTrain Loss: 0.023229\n",
      "Train Epoch: 222 [8/54 (15%)]\tTrain Loss: 0.014088\n",
      "Train Epoch: 222 [16/54 (30%)]\tTrain Loss: 0.005102\n",
      "Train Epoch: 222 [24/54 (44%)]\tTrain Loss: 0.003527\n",
      "Train Epoch: 222 [32/54 (59%)]\tTrain Loss: 0.005349\n",
      "Train Epoch: 222 [40/54 (74%)]\tTrain Loss: 0.019726\n",
      "Train Epoch: 222 [48/54 (89%)]\tTrain Loss: 0.022078\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.58600565e-03 9.77536440e-02 2.29274249e-03 1.49011128e-02\n",
      " 5.97801693e-02 2.05039367e-04 3.63011321e-04 2.90775746e-02\n",
      " 4.88155484e-02 7.19983801e-02 1.47066042e-01 4.76663150e-02\n",
      " 1.76697667e-03 2.03553864e-04 1.47711148e-03 5.70412412e-05\n",
      " 1.90056744e-03 3.76171642e-03 3.17363709e-01 5.36665972e-03\n",
      " 8.01972859e-03 8.99277568e-01 9.88419533e-01 9.63410497e-01\n",
      " 8.01598933e-03 9.93946731e-01 9.99595106e-01 6.71627596e-02\n",
      " 4.09316808e-01 8.46737623e-02 6.63909269e-03 1.84356317e-01\n",
      " 3.97740491e-03 1.32875168e-03 5.79165295e-04 4.78043733e-03\n",
      " 3.57541442e-02 2.03650191e-01 1.76238979e-03 1.00996029e-02\n",
      " 1.01241062e-03 5.48255444e-03 1.63858567e-04 1.30402483e-02\n",
      " 5.04178368e-03 2.07562046e-03 2.59692669e-02 1.01277046e-02\n",
      " 9.88038957e-01 9.37088132e-01 9.68860328e-01 3.66848253e-04\n",
      " 8.80450389e-05 8.71748477e-03 1.25878993e-02 2.50356185e-04\n",
      " 9.66521680e-01 3.95982228e-02 2.08902595e-04 7.40891983e-06\n",
      " 8.53232741e-01 2.32106745e-01 6.83421254e-01 9.73738253e-01\n",
      " 3.87830138e-02 3.17948051e-02 4.00586516e-01 9.88012314e-01\n",
      " 9.96380389e-01 2.46319830e-01 6.59870207e-01 8.53469908e-01\n",
      " 9.20017779e-01 4.36013341e-01 4.62073050e-02 8.97293150e-01\n",
      " 9.92644012e-01 9.87225235e-01 8.00804555e-01 8.36548090e-01\n",
      " 9.95907903e-01 9.86073732e-01 9.60282385e-01 4.70449850e-02\n",
      " 4.40828353e-01 8.00982833e-01 8.79584849e-01 8.06204438e-01\n",
      " 8.16455409e-02 6.43167317e-01 9.98056829e-01 7.68381059e-02\n",
      " 4.26304728e-01 9.99981046e-01 9.99258935e-01 9.84594226e-01\n",
      " 9.66444612e-03 1.00362245e-02 2.34308317e-01 9.99028921e-01\n",
      " 2.27165613e-02 7.33355820e-01 3.50326262e-02 7.20324457e-01\n",
      " 7.49581516e-01 9.30891931e-01 9.99945879e-01 1.38897542e-03\n",
      " 2.58772192e-03 8.09099674e-01 2.68597603e-01 9.25126970e-02\n",
      " 7.16849267e-01 8.56188059e-01 9.32260230e-02 3.25964764e-02\n",
      " 9.14746821e-01 6.39776826e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 223 [0/54 (0%)]\tTrain Loss: 0.040617\n",
      "Train Epoch: 223 [8/54 (15%)]\tTrain Loss: 0.009169\n",
      "Train Epoch: 223 [16/54 (30%)]\tTrain Loss: 0.000812\n",
      "Train Epoch: 223 [24/54 (44%)]\tTrain Loss: 0.029550\n",
      "Train Epoch: 223 [32/54 (59%)]\tTrain Loss: 0.017801\n",
      "Train Epoch: 223 [40/54 (74%)]\tTrain Loss: 0.004662\n",
      "Train Epoch: 223 [48/54 (89%)]\tTrain Loss: 0.019974\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.39330705e-03 8.50633562e-01 3.57503444e-01 9.04381931e-01\n",
      " 5.75050533e-01 4.09830362e-03 7.62214959e-01 8.38047564e-01\n",
      " 1.31667703e-01 3.63367759e-02 1.42105641e-02 1.49759557e-03\n",
      " 1.66480914e-02 9.12026316e-03 4.40952219e-02 1.45326555e-02\n",
      " 4.17130394e-03 2.11650617e-02 9.41570520e-01 5.11370115e-02\n",
      " 1.06753800e-02 9.94411170e-01 9.99880910e-01 9.99102473e-01\n",
      " 3.13764542e-01 1.00000000e+00 9.99948025e-01 9.38730896e-01\n",
      " 6.85404658e-01 4.47602600e-01 2.62817554e-02 9.34816241e-01\n",
      " 5.61147779e-02 9.30911410e-05 8.13472434e-05 1.40374824e-02\n",
      " 3.62805314e-02 7.58528590e-01 1.85610831e-03 2.49936506e-02\n",
      " 5.95590053e-03 2.65974272e-02 2.81306496e-03 2.14591920e-01\n",
      " 4.31674480e-01 2.50524748e-03 1.93530634e-01 2.01611176e-01\n",
      " 9.99602616e-01 9.19760525e-01 9.86296535e-01 2.93718395e-03\n",
      " 1.25012011e-03 8.69738311e-03 3.95080680e-03 4.39594164e-02\n",
      " 9.41043437e-01 5.72086275e-02 3.72854853e-03 1.88455579e-03\n",
      " 6.49058282e-01 5.95751643e-01 3.96549702e-01 8.27368259e-01\n",
      " 4.52050894e-01 9.60067809e-01 9.95032907e-01 9.99049962e-01\n",
      " 9.99998093e-01 7.76152790e-01 5.27147233e-01 6.31899655e-01\n",
      " 9.99460280e-01 9.22200203e-01 2.00911149e-01 9.68384981e-01\n",
      " 9.99839306e-01 9.99626040e-01 9.95479822e-01 9.96846974e-01\n",
      " 9.99873638e-01 9.77596164e-01 9.98900533e-01 1.09245777e-01\n",
      " 8.68663430e-01 7.80183554e-01 9.56181407e-01 9.16777134e-01\n",
      " 6.36496663e-01 9.99892473e-01 9.99970675e-01 8.36746156e-01\n",
      " 5.66444516e-01 9.99998808e-01 9.94218230e-01 9.98809457e-01\n",
      " 1.16546536e-02 2.10607037e-01 2.55935222e-01 9.99993443e-01\n",
      " 2.29655616e-02 9.44014072e-01 1.00396715e-01 7.52684474e-01\n",
      " 6.89469516e-01 8.64092767e-01 9.99712527e-01 5.06268442e-02\n",
      " 3.11315246e-02 9.90597904e-01 9.92115319e-01 5.64588197e-02\n",
      " 9.99347031e-01 9.99943495e-01 8.84727061e-01 2.01670140e-01\n",
      " 9.33445930e-01 9.42814469e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 224 [0/54 (0%)]\tTrain Loss: 0.011546\n",
      "Train Epoch: 224 [8/54 (15%)]\tTrain Loss: 0.046378\n",
      "Train Epoch: 224 [16/54 (30%)]\tTrain Loss: 0.020477\n",
      "Train Epoch: 224 [24/54 (44%)]\tTrain Loss: 0.053261\n",
      "Train Epoch: 224 [32/54 (59%)]\tTrain Loss: 0.002985\n",
      "Train Epoch: 224 [40/54 (74%)]\tTrain Loss: 0.001457\n",
      "Train Epoch: 224 [48/54 (89%)]\tTrain Loss: 0.019854\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.37190416e-01 9.91772830e-01 7.23372817e-01 9.99512553e-01\n",
      " 9.26275134e-01 2.10157800e-02 9.97688293e-01 9.93285418e-01\n",
      " 1.08320788e-01 7.37012029e-01 7.49303997e-01 1.23605400e-01\n",
      " 6.92203224e-01 5.11979870e-02 2.74735957e-01 4.70394306e-02\n",
      " 1.09701790e-02 8.78273770e-02 9.60702002e-01 3.92953724e-01\n",
      " 3.11262727e-01 9.99945283e-01 9.99993205e-01 9.99840975e-01\n",
      " 5.77444732e-01 1.00000000e+00 9.99989867e-01 9.98924315e-01\n",
      " 9.54575360e-01 8.76566768e-01 2.08819732e-01 9.99282777e-01\n",
      " 6.50038302e-01 3.84321582e-04 2.03579734e-03 7.92369545e-02\n",
      " 5.85768580e-01 9.90151584e-01 4.10624072e-02 4.35367107e-01\n",
      " 3.71389538e-01 2.54445434e-01 1.21600619e-02 2.26064444e-01\n",
      " 6.93359256e-01 4.32498865e-02 9.95841086e-01 7.83526719e-01\n",
      " 1.00000000e+00 9.78435636e-01 9.99950528e-01 1.72643334e-01\n",
      " 1.29496843e-01 6.44149482e-02 6.00776821e-02 4.87539113e-01\n",
      " 9.85548556e-01 7.39542127e-01 7.05294907e-02 1.62526578e-01\n",
      " 9.76863027e-01 5.58506548e-01 9.57681835e-01 9.98855233e-01\n",
      " 9.87813234e-01 9.99575317e-01 9.99977708e-01 9.99987006e-01\n",
      " 1.00000000e+00 6.73097372e-01 9.40971792e-01 9.87073421e-01\n",
      " 9.99999881e-01 9.99815643e-01 9.92782474e-01 9.98254716e-01\n",
      " 1.00000000e+00 9.99999762e-01 9.99948025e-01 9.99999523e-01\n",
      " 9.99999762e-01 9.99847770e-01 9.99997377e-01 1.23471200e-01\n",
      " 9.30273354e-01 9.87675309e-01 9.99802291e-01 9.99715626e-01\n",
      " 9.65833545e-01 9.98561800e-01 9.99951482e-01 9.87354577e-01\n",
      " 9.91170049e-01 1.00000000e+00 9.99924898e-01 9.99996662e-01\n",
      " 3.86736959e-01 8.15787554e-01 6.50895000e-01 9.99990463e-01\n",
      " 1.24538742e-01 9.99865651e-01 1.64203897e-01 9.93877590e-01\n",
      " 9.97770667e-01 9.92951691e-01 1.00000000e+00 2.90934145e-01\n",
      " 2.20486876e-02 9.99839067e-01 7.89113700e-01 1.61544457e-01\n",
      " 9.99948025e-01 9.99984026e-01 8.30000222e-01 7.14944527e-02\n",
      " 9.96986806e-01 6.38880014e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 225 [0/54 (0%)]\tTrain Loss: 0.005818\n",
      "Train Epoch: 225 [8/54 (15%)]\tTrain Loss: 0.013626\n",
      "Train Epoch: 225 [16/54 (30%)]\tTrain Loss: 0.007089\n",
      "Train Epoch: 225 [24/54 (44%)]\tTrain Loss: 0.005483\n",
      "Train Epoch: 225 [32/54 (59%)]\tTrain Loss: 0.007041\n",
      "Train Epoch: 225 [40/54 (74%)]\tTrain Loss: 0.014315\n",
      "Train Epoch: 225 [48/54 (89%)]\tTrain Loss: 0.053911\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.82946371e-03 6.32766485e-01 9.32588577e-02 9.87992883e-01\n",
      " 8.77893865e-01 1.48864603e-03 1.71007082e-01 9.79421258e-01\n",
      " 7.12215230e-02 2.46574134e-01 6.88505098e-02 1.95371429e-03\n",
      " 1.69077460e-02 1.42286485e-03 1.11711718e-01 1.10052591e-02\n",
      " 1.24077694e-02 8.37347060e-02 7.61690319e-01 2.96350140e-02\n",
      " 7.75622344e-03 9.94805396e-01 9.97731626e-01 9.96650159e-01\n",
      " 1.06435880e-01 9.99776065e-01 9.99716103e-01 8.98660362e-01\n",
      " 6.37040615e-01 1.37776509e-01 6.89313173e-01 9.97003853e-01\n",
      " 4.27532464e-01 5.68397343e-04 4.54447145e-04 9.74163786e-02\n",
      " 3.30576420e-01 9.49353933e-01 4.45658304e-02 3.28318626e-01\n",
      " 1.42483130e-01 3.38078976e-01 2.31258497e-02 2.93596648e-03\n",
      " 1.08370185e-01 5.17328270e-02 9.80894387e-01 7.18895555e-01\n",
      " 9.99999762e-01 9.65205312e-01 9.99791682e-01 1.49793522e-02\n",
      " 5.54532511e-04 1.96551927e-03 2.67975009e-03 3.62785757e-02\n",
      " 9.61468399e-01 7.93004632e-02 3.65846536e-05 7.54138280e-04\n",
      " 7.19858229e-01 1.54091939e-01 9.25608456e-01 9.97050047e-01\n",
      " 2.32144207e-01 9.44224000e-01 9.99840140e-01 9.98574734e-01\n",
      " 9.99993443e-01 8.79728436e-01 7.84017086e-01 9.52287674e-01\n",
      " 9.99981403e-01 9.85689282e-01 8.06198835e-01 9.77253258e-01\n",
      " 9.99590099e-01 9.99105275e-01 9.65588629e-01 9.96615350e-01\n",
      " 9.99954343e-01 9.62270319e-01 9.96812761e-01 1.25912845e-01\n",
      " 4.47377086e-01 9.86536205e-01 9.97568667e-01 9.92536962e-01\n",
      " 2.48185664e-01 9.26024854e-01 9.99817431e-01 9.72995281e-01\n",
      " 9.72176433e-01 9.99999762e-01 9.59376097e-01 9.95022535e-01\n",
      " 1.38231530e-03 3.98435593e-01 8.04386735e-01 9.99944329e-01\n",
      " 2.73263574e-01 9.99333680e-01 1.29453957e-01 9.33622479e-01\n",
      " 9.95489180e-01 9.84268665e-01 1.00000000e+00 1.09547712e-02\n",
      " 1.41709130e-02 9.88555610e-01 9.85536397e-01 6.86999679e-01\n",
      " 9.88689363e-01 9.45549965e-01 8.37363362e-01 1.58965915e-01\n",
      " 9.86867428e-01 7.60636210e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 226 [0/54 (0%)]\tTrain Loss: 0.031766\n",
      "Train Epoch: 226 [8/54 (15%)]\tTrain Loss: 0.002835\n",
      "Train Epoch: 226 [16/54 (30%)]\tTrain Loss: 0.006222\n",
      "Train Epoch: 226 [24/54 (44%)]\tTrain Loss: 0.002545\n",
      "Train Epoch: 226 [32/54 (59%)]\tTrain Loss: 0.030040\n",
      "Train Epoch: 226 [40/54 (74%)]\tTrain Loss: 0.011961\n",
      "Train Epoch: 226 [48/54 (89%)]\tTrain Loss: 0.026084\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.67775918e-02 2.88956732e-01 4.14776266e-01 8.75880063e-01\n",
      " 5.82311332e-01 1.02497695e-03 1.15918227e-01 9.15866673e-01\n",
      " 1.35192603e-01 9.09526050e-02 1.10990806e-02 2.63450760e-02\n",
      " 6.29138900e-04 3.06665548e-04 8.49305540e-02 4.94101085e-03\n",
      " 2.95793230e-04 2.24259533e-02 9.13550496e-01 2.42694113e-02\n",
      " 3.14763963e-01 9.96117711e-01 9.99865651e-01 9.97809827e-01\n",
      " 1.20778970e-01 9.99947667e-01 9.99884129e-01 9.40277457e-01\n",
      " 8.53548169e-01 6.14128470e-01 1.83463484e-01 9.97524202e-01\n",
      " 2.65146419e-02 4.28763597e-05 1.12901058e-03 4.16871756e-02\n",
      " 3.56514275e-01 9.32139099e-01 7.71674588e-02 4.52383831e-02\n",
      " 5.40206432e-02 4.28878516e-02 1.56161366e-02 1.53775528e-01\n",
      " 1.50011718e-01 7.94835761e-03 9.67877507e-01 5.31250834e-01\n",
      " 9.99997377e-01 9.90379930e-01 9.99840856e-01 2.59716026e-02\n",
      " 3.82900645e-04 5.05423080e-03 2.35294104e-02 2.18347739e-02\n",
      " 9.36575294e-01 9.41099077e-02 8.54247541e-04 6.94610237e-04\n",
      " 9.52678978e-01 9.10873473e-01 9.93101120e-01 9.99639034e-01\n",
      " 9.20863092e-01 9.56529737e-01 9.99615550e-01 9.98158872e-01\n",
      " 9.99991655e-01 9.25964117e-01 7.18343675e-01 8.55778515e-01\n",
      " 9.99965549e-01 9.95128751e-01 9.40286934e-01 9.89163280e-01\n",
      " 9.99896407e-01 9.99623060e-01 9.98683631e-01 9.99880791e-01\n",
      " 9.99966741e-01 9.99738157e-01 9.99680281e-01 1.32043704e-01\n",
      " 3.87756258e-01 9.81323898e-01 9.99538541e-01 9.98413205e-01\n",
      " 7.29209661e-01 5.39173484e-01 9.99931216e-01 9.68581915e-01\n",
      " 9.32347178e-01 9.99999642e-01 9.96338844e-01 9.99171495e-01\n",
      " 1.00599416e-01 2.74853289e-01 6.19717598e-01 9.99049604e-01\n",
      " 2.24995777e-01 9.94263232e-01 8.90336037e-02 8.67861092e-01\n",
      " 9.43834424e-01 9.60396707e-01 9.99998689e-01 6.67484626e-02\n",
      " 7.59379491e-02 9.91335094e-01 7.91641176e-01 3.63548517e-01\n",
      " 9.75853920e-01 9.87673461e-01 5.62328994e-01 1.91227034e-01\n",
      " 9.60294247e-01 3.64421636e-01]\n",
      "predict [0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "Train Epoch: 227 [0/54 (0%)]\tTrain Loss: 0.003899\n",
      "Train Epoch: 227 [8/54 (15%)]\tTrain Loss: 0.003574\n",
      "Train Epoch: 227 [16/54 (30%)]\tTrain Loss: 0.001713\n",
      "Train Epoch: 227 [24/54 (44%)]\tTrain Loss: 0.000712\n",
      "Train Epoch: 227 [32/54 (59%)]\tTrain Loss: 0.025260\n",
      "Train Epoch: 227 [40/54 (74%)]\tTrain Loss: 0.000858\n",
      "Train Epoch: 227 [48/54 (89%)]\tTrain Loss: 0.005534\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.08066122e-02 8.02066684e-01 2.32619137e-01 9.14920211e-01\n",
      " 6.02017641e-01 1.61795691e-02 8.09219420e-01 8.88049066e-01\n",
      " 1.47237420e-01 5.73574044e-02 7.49903405e-03 3.06316949e-02\n",
      " 2.90646480e-04 9.63275693e-03 6.04074001e-01 9.54746082e-03\n",
      " 4.65147896e-03 1.21182352e-01 9.11591113e-01 9.09811556e-01\n",
      " 4.02951419e-01 9.99723852e-01 9.99970913e-01 9.99201238e-01\n",
      " 8.65293145e-01 9.99999881e-01 9.99969602e-01 9.94639933e-01\n",
      " 9.79310036e-01 8.60336721e-01 9.62053359e-01 9.98909831e-01\n",
      " 3.89215187e-04 1.44128890e-05 1.94390814e-04 4.70563434e-02\n",
      " 1.52414933e-01 8.77137482e-01 2.20340133e-01 6.11901045e-01\n",
      " 3.83375883e-01 2.49195367e-01 2.21449155e-02 5.81948936e-01\n",
      " 6.90912127e-01 4.40258235e-02 7.56256044e-01 1.04493916e-01\n",
      " 9.99977589e-01 8.72983456e-01 9.94196892e-01 3.68440337e-03\n",
      " 3.12907659e-02 1.03795920e-02 2.74010561e-02 6.16053283e-01\n",
      " 9.87278819e-01 1.67410851e-01 3.57708097e-01 5.69885112e-02\n",
      " 9.56985235e-01 9.19810772e-01 9.92503166e-01 9.99658108e-01\n",
      " 9.96123493e-01 9.99933481e-01 9.99935031e-01 9.99898791e-01\n",
      " 9.99966979e-01 8.31432700e-01 5.92209280e-01 5.62725842e-01\n",
      " 9.99987841e-01 9.97633576e-01 9.85375702e-01 9.98053312e-01\n",
      " 9.99380469e-01 9.99768794e-01 9.96075690e-01 9.99955058e-01\n",
      " 9.99994516e-01 9.99657631e-01 9.99977827e-01 2.06434235e-01\n",
      " 5.65012574e-01 9.61580157e-01 9.99408960e-01 9.97634649e-01\n",
      " 8.91903460e-01 9.95496750e-01 9.99188244e-01 9.56588984e-01\n",
      " 9.56138909e-01 9.99999285e-01 9.97975528e-01 9.92392004e-01\n",
      " 1.19820252e-01 4.13860321e-01 7.09755540e-01 9.98972535e-01\n",
      " 1.63701966e-01 9.94891405e-01 1.13506176e-01 4.90092486e-01\n",
      " 8.19014132e-01 9.77653682e-01 9.99994636e-01 3.61701578e-01\n",
      " 8.56641054e-01 9.98196423e-01 7.59542346e-01 8.51593912e-01\n",
      " 9.89589632e-01 8.82496357e-01 7.82517314e-01 2.83547848e-01\n",
      " 9.89481688e-01 8.48238051e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 228 [0/54 (0%)]\tTrain Loss: 0.005574\n",
      "Train Epoch: 228 [8/54 (15%)]\tTrain Loss: 0.103100\n",
      "Train Epoch: 228 [16/54 (30%)]\tTrain Loss: 0.004226\n",
      "Train Epoch: 228 [24/54 (44%)]\tTrain Loss: 0.014604\n",
      "Train Epoch: 228 [32/54 (59%)]\tTrain Loss: 0.000905\n",
      "Train Epoch: 228 [40/54 (74%)]\tTrain Loss: 0.062848\n",
      "Train Epoch: 228 [48/54 (89%)]\tTrain Loss: 0.003274\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.01256405 0.99991512 0.9999938  1.         0.99895298 0.00207069\n",
      " 0.99998641 1.         0.10833713 0.88177764 0.94620275 0.06539652\n",
      " 0.48244318 0.99247909 0.91622388 0.48143223 0.99992156 0.4743306\n",
      " 0.99994659 0.95270669 0.36826637 1.         0.99999976 0.99984789\n",
      " 0.99778843 1.         0.99999416 0.99999964 0.99998057 0.98713487\n",
      " 0.99636531 0.99999988 0.78861171 0.77280027 0.07945949 0.99999952\n",
      " 1.         1.         0.95293176 0.99006313 0.97936499 0.95195246\n",
      " 0.4547258  0.99553335 0.99835253 0.90081316 0.99814904 0.99015266\n",
      " 1.         0.9082374  0.99999547 0.9989869  0.94521624 0.99439335\n",
      " 0.00400323 0.97469485 0.99990892 0.99732107 0.98557878 0.98561698\n",
      " 0.99969637 0.99671543 0.999511   0.99998772 0.99995434 1.\n",
      " 1.         1.         1.         0.95935875 0.92747551 0.9236415\n",
      " 1.         0.9991014  0.99997342 0.99951673 1.         1.\n",
      " 1.         1.         1.         1.         0.99999952 0.09672549\n",
      " 0.99836558 0.99650252 0.999964   0.999946   0.99004155 0.99999869\n",
      " 0.9999882  0.99999917 0.99998808 1.         1.         1.\n",
      " 0.62358844 0.99924052 0.99999905 1.         0.94266677 0.99999213\n",
      " 0.99493045 0.99998391 0.99999475 0.99997735 1.         0.77752566\n",
      " 0.95179367 0.9999963  0.99999714 0.90581036 0.99999988 0.99964941\n",
      " 0.99258536 0.99870586 0.99999988 0.99999738]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 229 [0/54 (0%)]\tTrain Loss: 0.001393\n",
      "Train Epoch: 229 [8/54 (15%)]\tTrain Loss: 0.006313\n",
      "Train Epoch: 229 [16/54 (30%)]\tTrain Loss: 0.000911\n",
      "Train Epoch: 229 [24/54 (44%)]\tTrain Loss: 0.003402\n",
      "Train Epoch: 229 [32/54 (59%)]\tTrain Loss: 0.067101\n",
      "Train Epoch: 229 [40/54 (74%)]\tTrain Loss: 0.006709\n",
      "Train Epoch: 229 [48/54 (89%)]\tTrain Loss: 0.029076\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.28827256e-03 1.75381884e-01 8.55504870e-02 9.96768236e-01\n",
      " 8.42257738e-01 2.42264681e-02 6.29148424e-01 9.99819934e-01\n",
      " 7.71081680e-03 2.08804056e-01 3.86959970e-01 6.09408307e-04\n",
      " 1.13332714e-03 2.36445926e-02 8.45633745e-02 3.00969686e-02\n",
      " 1.20978551e-02 1.13776382e-02 5.54617226e-01 2.58431844e-02\n",
      " 6.50113123e-03 9.84754443e-01 9.99848247e-01 9.95178699e-01\n",
      " 9.13403183e-03 9.99998927e-01 9.99266922e-01 7.48422980e-01\n",
      " 7.38465130e-01 1.56882405e-01 4.34595793e-02 9.30208087e-01\n",
      " 2.47243866e-02 5.65331175e-06 8.79666914e-06 9.82332713e-05\n",
      " 6.94311457e-04 9.93112504e-01 8.36654846e-03 3.32317978e-01\n",
      " 3.00605774e-01 9.88182425e-03 1.43790636e-02 1.26945287e-01\n",
      " 4.75593805e-01 6.55872235e-03 5.43365441e-02 4.00531217e-02\n",
      " 9.99221563e-01 4.95156609e-02 8.08174551e-01 8.97681806e-03\n",
      " 7.16306642e-02 2.56252097e-04 5.05461649e-04 1.05852127e-01\n",
      " 8.56291473e-01 1.43979117e-02 1.32982414e-02 8.84269830e-03\n",
      " 3.63433957e-01 8.44633579e-02 4.13695693e-01 7.60829389e-01\n",
      " 9.95399535e-01 9.99986053e-01 9.99816000e-01 9.99795973e-01\n",
      " 9.99999404e-01 2.16613367e-01 7.15867355e-02 2.93811202e-01\n",
      " 9.99833703e-01 9.97759342e-01 9.89896178e-01 9.36430991e-01\n",
      " 9.99930978e-01 9.99234200e-01 9.96656299e-01 9.97994184e-01\n",
      " 9.99479711e-01 9.34547007e-01 9.99344766e-01 6.68653965e-01\n",
      " 9.37012255e-01 1.10725611e-01 9.20146167e-01 9.93755579e-01\n",
      " 4.70466942e-01 9.91481066e-01 9.72220123e-01 9.24311042e-01\n",
      " 6.56972170e-01 9.99999881e-01 9.66536283e-01 9.95481610e-01\n",
      " 7.08306162e-03 3.94615997e-03 4.05657776e-02 9.99590695e-01\n",
      " 1.42095815e-02 9.53884900e-01 6.54777046e-03 9.59565520e-01\n",
      " 5.96876025e-01 6.61288679e-01 9.93256807e-01 5.12395799e-03\n",
      " 9.62444581e-04 4.43936378e-01 3.64128351e-02 2.19222298e-03\n",
      " 1.97582513e-01 5.68098485e-01 4.66416925e-01 2.55138800e-03\n",
      " 8.70530367e-01 8.45040917e-01]\n",
      "predict [0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 230 [0/54 (0%)]\tTrain Loss: 0.024262\n",
      "Train Epoch: 230 [8/54 (15%)]\tTrain Loss: 0.010380\n",
      "Train Epoch: 230 [16/54 (30%)]\tTrain Loss: 0.042219\n",
      "Train Epoch: 230 [24/54 (44%)]\tTrain Loss: 0.003202\n",
      "Train Epoch: 230 [32/54 (59%)]\tTrain Loss: 0.004730\n",
      "Train Epoch: 230 [40/54 (74%)]\tTrain Loss: 0.037947\n",
      "Train Epoch: 230 [48/54 (89%)]\tTrain Loss: 0.017870\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.48700947e-05 8.46272767e-01 5.13913989e-01 9.79544997e-01\n",
      " 3.89891505e-01 7.11841218e-04 1.94651708e-01 8.54429126e-01\n",
      " 6.85698092e-02 2.82374829e-01 4.21719290e-02 2.21178550e-02\n",
      " 1.67972269e-03 7.77593302e-03 1.02997795e-01 6.49032649e-03\n",
      " 4.00266331e-03 2.46795155e-02 5.59906781e-01 7.23073125e-01\n",
      " 2.88675968e-02 9.88324881e-01 9.99574244e-01 9.97666717e-01\n",
      " 1.07797801e-01 9.99997258e-01 9.99992490e-01 9.15368497e-01\n",
      " 4.45680827e-01 5.38597524e-01 7.87265480e-01 9.86854553e-01\n",
      " 2.15179920e-02 1.66888384e-03 5.31400001e-05 2.43605655e-02\n",
      " 3.96040857e-01 9.53833282e-01 3.72957177e-02 1.58364102e-01\n",
      " 4.89545278e-02 6.44924492e-02 8.45922995e-03 1.38120905e-01\n",
      " 1.81212798e-01 7.17979521e-02 9.12570179e-01 4.70066220e-01\n",
      " 9.99997735e-01 9.82118487e-01 9.99345481e-01 7.66445417e-04\n",
      " 8.37097876e-04 5.58073260e-03 8.22227076e-03 1.18859718e-02\n",
      " 9.89928782e-01 1.10515535e-01 1.26652757e-03 1.26138225e-03\n",
      " 9.90907788e-01 9.92008209e-01 9.76123691e-01 9.97603714e-01\n",
      " 9.47912455e-01 9.89224255e-01 9.90815997e-01 9.99940634e-01\n",
      " 9.99952078e-01 7.36958146e-01 7.05628157e-01 7.06319273e-01\n",
      " 9.99529719e-01 9.92355704e-01 9.92361546e-01 9.88638997e-01\n",
      " 9.99993086e-01 9.99985933e-01 9.87753451e-01 9.99656677e-01\n",
      " 9.99978662e-01 9.97136235e-01 9.99885678e-01 1.57782853e-01\n",
      " 9.46515262e-01 8.97444367e-01 9.88229632e-01 9.65850413e-01\n",
      " 7.56862760e-02 9.79405820e-01 9.99800026e-01 8.56586576e-01\n",
      " 5.59116244e-01 9.99992847e-01 9.98797059e-01 9.96932864e-01\n",
      " 4.03172220e-04 7.94116080e-01 9.34526503e-01 9.99950647e-01\n",
      " 1.99314192e-01 9.97243404e-01 1.85564548e-01 3.77700478e-01\n",
      " 9.62162197e-01 8.57760370e-01 9.99997854e-01 1.78234372e-02\n",
      " 2.21203104e-01 9.95753884e-01 9.82500970e-01 1.46776527e-01\n",
      " 9.45606232e-01 8.72220814e-01 5.14216542e-01 2.13160560e-01\n",
      " 9.46649432e-01 8.34885001e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 49 TN= 39 FN= 9 FP= 21\n",
      "TP+FP 70\n",
      "precision 0.7\n",
      "recall 0.8448275862068966\n",
      "F1 0.765625\n",
      "acc 0.7457627118644068\n",
      "AUCp 0.7474137931034482\n",
      "AUC 0.7764367816091955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 230, average recall: 0.8448, average precision: 0.7000,average F1: 0.7656, average accuracy: 0.7458, average AUC: 0.7764\n",
      "Train Epoch: 231 [0/54 (0%)]\tTrain Loss: 0.004258\n",
      "Train Epoch: 231 [8/54 (15%)]\tTrain Loss: 0.002308\n",
      "Train Epoch: 231 [16/54 (30%)]\tTrain Loss: 0.003588\n",
      "Train Epoch: 231 [24/54 (44%)]\tTrain Loss: 0.004134\n",
      "Train Epoch: 231 [32/54 (59%)]\tTrain Loss: 0.024606\n",
      "Train Epoch: 231 [40/54 (74%)]\tTrain Loss: 0.001699\n",
      "Train Epoch: 231 [48/54 (89%)]\tTrain Loss: 0.000627\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.14661871e-05 8.28152061e-01 3.55607033e-01 6.77237570e-01\n",
      " 9.78866369e-02 2.57749460e-04 2.73645729e-01 6.34626746e-01\n",
      " 2.73906030e-02 5.54660819e-02 6.10459922e-03 4.10832465e-04\n",
      " 7.82545307e-04 6.22634171e-03 4.17686589e-02 1.50810974e-03\n",
      " 3.16193560e-04 1.06435083e-02 3.18153650e-02 1.47992792e-02\n",
      " 4.28401137e-04 8.52454960e-01 9.78526115e-01 9.92516577e-01\n",
      " 1.76508296e-02 9.99868989e-01 9.99821365e-01 1.86656713e-01\n",
      " 1.35059562e-02 6.37882203e-02 8.26581568e-02 7.54430652e-01\n",
      " 2.13311557e-02 2.33686546e-06 1.54395070e-06 1.40486786e-03\n",
      " 9.13719181e-03 6.41191006e-01 1.19193913e-02 1.30925134e-01\n",
      " 8.21414590e-02 6.75216466e-02 5.28571755e-03 2.43951399e-02\n",
      " 6.04910403e-02 1.88302808e-02 8.65269184e-01 2.77358383e-01\n",
      " 9.99988437e-01 7.51495183e-01 9.97388899e-01 2.00332579e-04\n",
      " 1.76464746e-04 3.03343497e-03 4.75715533e-05 8.69225041e-05\n",
      " 4.76511657e-01 2.37607723e-03 9.04898392e-04 2.42913724e-03\n",
      " 6.96901560e-01 4.84313935e-01 5.31073034e-01 9.32945430e-01\n",
      " 6.37839139e-01 9.40203667e-01 8.81594896e-01 9.99856830e-01\n",
      " 9.99960661e-01 4.98359710e-01 4.48001802e-01 3.85754555e-01\n",
      " 9.86973524e-01 8.95988882e-01 9.37803864e-01 8.75880420e-01\n",
      " 9.99973297e-01 9.99914169e-01 9.96543586e-01 9.99671936e-01\n",
      " 9.99833226e-01 9.90329385e-01 9.99337256e-01 5.94486929e-02\n",
      " 7.10136890e-01 7.66772568e-01 9.81156468e-01 9.08208013e-01\n",
      " 9.25096218e-03 3.79986078e-01 9.99252975e-01 5.58987260e-01\n",
      " 2.11797670e-01 9.99961019e-01 9.63406742e-01 9.78093266e-01\n",
      " 9.95474038e-05 7.44111091e-02 2.29752019e-01 9.96567845e-01\n",
      " 3.63841690e-02 9.84806240e-01 2.01197602e-02 4.33069468e-02\n",
      " 3.37313533e-01 2.97848761e-01 9.99900103e-01 1.09532522e-03\n",
      " 8.64541251e-03 8.11995387e-01 1.67494982e-01 9.25790425e-03\n",
      " 5.45869291e-01 1.08786978e-01 2.61304621e-02 1.52007649e-02\n",
      " 7.46800184e-01 2.09558427e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 232 [0/54 (0%)]\tTrain Loss: 0.001449\n",
      "Train Epoch: 232 [8/54 (15%)]\tTrain Loss: 0.000982\n",
      "Train Epoch: 232 [16/54 (30%)]\tTrain Loss: 0.017589\n",
      "Train Epoch: 232 [24/54 (44%)]\tTrain Loss: 0.009271\n",
      "Train Epoch: 232 [32/54 (59%)]\tTrain Loss: 0.007692\n",
      "Train Epoch: 232 [40/54 (74%)]\tTrain Loss: 0.000870\n",
      "Train Epoch: 232 [48/54 (89%)]\tTrain Loss: 0.001729\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.16666717e-06 9.45291042e-01 5.23326337e-01 9.82982457e-01\n",
      " 5.84189415e-01 1.56172711e-04 6.15802407e-01 9.82990146e-01\n",
      " 3.61005552e-02 7.73475587e-01 8.33367169e-01 4.47410971e-01\n",
      " 4.69550341e-01 2.42735841e-03 2.37232354e-02 1.58800511e-03\n",
      " 1.90676568e-04 7.83111900e-02 9.91875529e-01 1.05594762e-01\n",
      " 5.36913909e-02 9.98990715e-01 9.99976635e-01 9.99281347e-01\n",
      " 2.45718554e-01 1.00000000e+00 9.99988079e-01 9.98529196e-01\n",
      " 9.64670837e-01 2.16954857e-01 2.24959835e-01 9.93092299e-01\n",
      " 6.18223101e-02 3.14396966e-05 4.82619907e-05 5.08525148e-02\n",
      " 5.92640877e-01 9.98960972e-01 3.43366042e-02 1.55715391e-01\n",
      " 1.31995246e-01 1.00985669e-01 4.94488282e-03 9.16199163e-02\n",
      " 9.63448226e-01 9.00927745e-03 8.48032296e-01 1.85295314e-01\n",
      " 9.99904275e-01 9.06025946e-01 9.94621158e-01 2.60584895e-02\n",
      " 1.85354576e-02 3.46070575e-03 1.60556883e-02 4.18958254e-02\n",
      " 9.43448186e-01 1.83101743e-01 1.08590968e-01 5.40253194e-03\n",
      " 9.95079637e-01 9.71673727e-01 9.82271552e-01 9.99402642e-01\n",
      " 9.90985394e-01 9.40969646e-01 9.99679923e-01 9.99993563e-01\n",
      " 1.00000000e+00 6.51089907e-01 7.25917757e-01 7.82446802e-01\n",
      " 9.99987125e-01 9.99475896e-01 9.98813748e-01 9.93375480e-01\n",
      " 9.99999404e-01 9.99999762e-01 9.96695280e-01 9.99995232e-01\n",
      " 9.99999523e-01 9.99934554e-01 9.99992847e-01 5.98769903e-01\n",
      " 9.90284622e-01 8.82633507e-01 9.95643258e-01 9.95001376e-01\n",
      " 5.48163414e-01 9.39354241e-01 9.99422669e-01 8.83944631e-01\n",
      " 8.14802468e-01 1.00000000e+00 9.99941826e-01 9.99983311e-01\n",
      " 2.86501013e-02 6.87868476e-01 9.93785858e-01 9.99992847e-01\n",
      " 1.71445459e-01 9.95990336e-01 1.97904721e-01 9.94939089e-01\n",
      " 9.96396601e-01 9.49365735e-01 9.99999881e-01 2.25188793e-03\n",
      " 1.24309007e-02 9.92201209e-01 6.03437237e-02 1.53651331e-02\n",
      " 9.93255973e-01 9.94230628e-01 2.89295703e-01 1.90631807e-01\n",
      " 9.93998289e-01 9.69150245e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 233 [0/54 (0%)]\tTrain Loss: 0.002136\n",
      "Train Epoch: 233 [8/54 (15%)]\tTrain Loss: 0.077705\n",
      "Train Epoch: 233 [16/54 (30%)]\tTrain Loss: 0.012542\n",
      "Train Epoch: 233 [24/54 (44%)]\tTrain Loss: 0.004852\n",
      "Train Epoch: 233 [32/54 (59%)]\tTrain Loss: 0.009608\n",
      "Train Epoch: 233 [40/54 (74%)]\tTrain Loss: 0.048302\n",
      "Train Epoch: 233 [48/54 (89%)]\tTrain Loss: 0.004226\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.27725689e-05 4.58657771e-01 1.94454581e-01 7.07178295e-01\n",
      " 1.15159795e-01 2.40735812e-04 7.30368868e-02 4.54184860e-01\n",
      " 1.08505106e-02 5.71110368e-01 1.66840001e-03 9.36032161e-02\n",
      " 9.50296700e-04 1.78197154e-03 4.03632130e-03 1.20817218e-03\n",
      " 5.00739494e-04 1.29703861e-02 1.03847012e-01 2.52375292e-04\n",
      " 2.84049602e-04 9.26190794e-01 9.98195350e-01 9.89090741e-01\n",
      " 1.45863630e-02 9.99985933e-01 9.99899983e-01 2.87016124e-01\n",
      " 6.27416894e-02 8.93915538e-03 4.82641757e-02 4.78217214e-01\n",
      " 7.88623001e-03 5.85039961e-05 8.78235278e-06 3.18204961e-03\n",
      " 2.75856275e-02 3.90826583e-01 4.53457283e-03 1.81087311e-02\n",
      " 8.24859459e-03 9.46700852e-03 2.66848831e-04 1.95349799e-03\n",
      " 5.72408736e-02 1.82320387e-03 1.91635638e-01 3.75889614e-02\n",
      " 9.99780595e-01 7.67067909e-01 9.96749997e-01 4.18286363e-04\n",
      " 1.51504821e-04 4.13836708e-04 1.70333034e-04 2.29176527e-04\n",
      " 5.22684097e-01 1.03720080e-03 1.02317724e-02 1.96375957e-04\n",
      " 6.30371749e-01 8.61620128e-01 9.51227188e-01 9.83044863e-01\n",
      " 8.46781731e-02 5.80006599e-01 9.96636152e-01 9.94439125e-01\n",
      " 9.99999404e-01 4.15785551e-01 5.83913624e-01 2.81428754e-01\n",
      " 9.93669808e-01 9.81514037e-01 8.23753953e-01 3.32331359e-01\n",
      " 9.99905229e-01 9.99946475e-01 9.21322465e-01 9.98373151e-01\n",
      " 9.99996781e-01 9.97272670e-01 9.99938369e-01 8.72136578e-02\n",
      " 7.03259528e-01 4.80760336e-01 9.14877892e-01 9.32591379e-01\n",
      " 1.02350242e-01 2.09195271e-01 9.97565627e-01 9.72373784e-02\n",
      " 1.90129474e-01 9.99988437e-01 9.92582321e-01 9.99667883e-01\n",
      " 2.72891979e-04 1.22747749e-01 3.90035242e-01 9.99731243e-01\n",
      " 6.70710504e-02 8.91801715e-01 2.43353441e-01 2.11770982e-01\n",
      " 3.70306075e-01 3.01474005e-01 9.99999762e-01 7.92606384e-04\n",
      " 1.91079406e-03 4.84577239e-01 1.29341617e-01 7.36747533e-02\n",
      " 8.91737342e-01 3.30530137e-01 8.49353895e-02 5.92501312e-02\n",
      " 9.54774618e-01 4.86963123e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 234 [0/54 (0%)]\tTrain Loss: 0.005051\n",
      "Train Epoch: 234 [8/54 (15%)]\tTrain Loss: 0.003032\n",
      "Train Epoch: 234 [16/54 (30%)]\tTrain Loss: 0.022389\n",
      "Train Epoch: 234 [24/54 (44%)]\tTrain Loss: 0.002487\n",
      "Train Epoch: 234 [32/54 (59%)]\tTrain Loss: 0.008768\n",
      "Train Epoch: 234 [40/54 (74%)]\tTrain Loss: 0.020129\n",
      "Train Epoch: 234 [48/54 (89%)]\tTrain Loss: 0.001307\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.88812520e-06 9.98955727e-01 9.99619961e-01 9.99996066e-01\n",
      " 9.32998598e-01 1.93613032e-05 9.96676683e-01 9.99005854e-01\n",
      " 2.99927413e-01 9.65160549e-01 3.83756846e-01 5.18138647e-01\n",
      " 2.64473017e-02 4.51107137e-02 1.94321930e-01 2.54611461e-03\n",
      " 6.12616492e-03 2.61783838e-01 9.99287188e-01 6.29896402e-01\n",
      " 1.74863756e-01 9.99967217e-01 9.99998331e-01 9.99737799e-01\n",
      " 8.41755092e-01 1.00000000e+00 9.99999881e-01 9.98792648e-01\n",
      " 9.58399832e-01 4.16816592e-01 9.40984547e-01 9.99555051e-01\n",
      " 8.30623090e-01 3.14227911e-03 9.22577397e-04 9.22797561e-01\n",
      " 9.95721102e-01 9.99999285e-01 3.34779114e-01 5.57774544e-01\n",
      " 5.32714844e-01 5.47827244e-01 2.91473009e-02 2.13021174e-01\n",
      " 9.92061257e-01 1.16353467e-01 9.90301788e-01 9.70634639e-01\n",
      " 9.99999642e-01 9.99974847e-01 9.99998093e-01 2.56818011e-02\n",
      " 2.30364371e-02 2.60577425e-02 3.74048531e-01 2.68681459e-02\n",
      " 9.96603847e-01 4.60128844e-01 5.20840213e-02 1.23916984e-01\n",
      " 9.84839976e-01 9.91606355e-01 9.42408383e-01 9.98974562e-01\n",
      " 8.80647182e-01 9.96278703e-01 9.99999404e-01 9.99994516e-01\n",
      " 1.00000000e+00 5.02170384e-01 9.92106318e-01 9.92798924e-01\n",
      " 9.99994159e-01 9.98645008e-01 9.99463499e-01 9.94673669e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.98123467e-01 9.99892712e-01\n",
      " 1.00000000e+00 9.99999762e-01 9.99994516e-01 6.48173690e-01\n",
      " 9.99614239e-01 9.45448995e-01 9.99757111e-01 9.99851584e-01\n",
      " 9.02696311e-01 9.66053069e-01 9.99999166e-01 9.93226469e-01\n",
      " 9.86123681e-01 1.00000000e+00 9.99996305e-01 9.99997616e-01\n",
      " 2.39466596e-02 9.96390402e-01 9.92537320e-01 9.99914646e-01\n",
      " 7.04076767e-01 9.89982903e-01 9.96332228e-01 9.61504579e-01\n",
      " 9.99609292e-01 9.94207144e-01 1.00000000e+00 5.17470911e-02\n",
      " 8.67127329e-02 9.98845696e-01 6.44107521e-01 9.13115442e-01\n",
      " 9.97737765e-01 9.94906604e-01 9.25098062e-02 8.48124325e-01\n",
      " 9.99999642e-01 9.98206258e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 235 [0/54 (0%)]\tTrain Loss: 0.006501\n",
      "Train Epoch: 235 [8/54 (15%)]\tTrain Loss: 0.006617\n",
      "Train Epoch: 235 [16/54 (30%)]\tTrain Loss: 0.001845\n",
      "Train Epoch: 235 [24/54 (44%)]\tTrain Loss: 0.006936\n",
      "Train Epoch: 235 [32/54 (59%)]\tTrain Loss: 0.007738\n",
      "Train Epoch: 235 [40/54 (74%)]\tTrain Loss: 0.010120\n",
      "Train Epoch: 235 [48/54 (89%)]\tTrain Loss: 0.005803\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.07765581e-04 9.71436620e-01 6.92319214e-01 9.97974932e-01\n",
      " 3.07504982e-01 2.30238307e-04 1.79224804e-01 9.97097731e-01\n",
      " 1.34200707e-01 5.16128421e-01 9.67191517e-01 2.66908053e-02\n",
      " 6.34492263e-02 3.00061004e-03 8.75871405e-02 2.13976838e-02\n",
      " 1.38795497e-02 6.53007030e-02 2.94087648e-01 2.70425044e-02\n",
      " 2.14535301e-03 9.81424689e-01 9.99437988e-01 9.99801815e-01\n",
      " 9.14931148e-02 1.00000000e+00 1.00000000e+00 4.88599151e-01\n",
      " 1.51684478e-01 2.93597996e-01 1.80908233e-01 9.86711621e-01\n",
      " 7.36811459e-01 1.77637022e-02 1.02256739e-03 8.25925730e-03\n",
      " 1.14217950e-02 9.98956323e-01 2.45645046e-02 5.53220883e-02\n",
      " 2.89332699e-02 8.34846403e-03 6.37110975e-03 4.51456606e-01\n",
      " 7.39499450e-01 2.43642256e-02 9.89588976e-01 9.42132235e-01\n",
      " 9.99999046e-01 9.97658610e-01 9.99981642e-01 1.04141451e-01\n",
      " 4.23075538e-03 4.74386029e-02 1.88882972e-04 1.37669984e-02\n",
      " 9.98365343e-01 7.00880121e-03 2.07186164e-03 5.83904684e-02\n",
      " 8.39553773e-01 9.61696565e-01 9.42795753e-01 9.84770179e-01\n",
      " 9.34919357e-01 9.98643816e-01 9.99449551e-01 9.99993205e-01\n",
      " 1.00000000e+00 7.74391890e-01 9.21525598e-01 9.49751079e-01\n",
      " 9.99994040e-01 9.99953747e-01 9.99876380e-01 9.23774719e-01\n",
      " 9.99998093e-01 9.99995708e-01 9.98923719e-01 9.99999166e-01\n",
      " 1.00000000e+00 9.99957919e-01 9.99999881e-01 2.07149759e-01\n",
      " 8.83450508e-01 8.46634030e-01 9.88427699e-01 9.92620170e-01\n",
      " 2.91049242e-01 9.99950290e-01 9.99954462e-01 9.50242639e-01\n",
      " 9.77506995e-01 9.99999523e-01 9.99978900e-01 9.99961734e-01\n",
      " 4.48610546e-04 1.24586016e-01 8.92516077e-01 9.99999881e-01\n",
      " 1.59912378e-01 9.99999046e-01 5.30228555e-01 9.95448291e-01\n",
      " 9.70053315e-01 7.98173606e-01 1.00000000e+00 5.57271205e-03\n",
      " 9.90380812e-03 9.81759310e-01 9.74260271e-01 2.38016024e-02\n",
      " 9.84006345e-01 8.39080453e-01 3.32007676e-01 3.63745131e-02\n",
      " 9.99675632e-01 7.21623302e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 236 [0/54 (0%)]\tTrain Loss: 0.000813\n",
      "Train Epoch: 236 [8/54 (15%)]\tTrain Loss: 0.000765\n",
      "Train Epoch: 236 [16/54 (30%)]\tTrain Loss: 0.008041\n",
      "Train Epoch: 236 [24/54 (44%)]\tTrain Loss: 0.000830\n",
      "Train Epoch: 236 [32/54 (59%)]\tTrain Loss: 0.012997\n",
      "Train Epoch: 236 [40/54 (74%)]\tTrain Loss: 0.003705\n",
      "Train Epoch: 236 [48/54 (89%)]\tTrain Loss: 0.045568\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.54427066e-05 9.98253167e-01 9.75446105e-01 9.99863625e-01\n",
      " 9.86710608e-01 2.83587165e-03 9.93863344e-01 9.99788463e-01\n",
      " 4.13245372e-02 2.41734162e-01 9.86802995e-01 7.25694140e-03\n",
      " 9.74567473e-01 1.72000751e-03 8.67107630e-01 9.44800954e-03\n",
      " 8.36259201e-02 3.46070617e-01 9.77807641e-01 5.99397719e-01\n",
      " 7.00514913e-02 9.95934010e-01 9.99987602e-01 9.99983191e-01\n",
      " 4.31612730e-01 1.00000000e+00 9.99999642e-01 9.99944448e-01\n",
      " 9.95510340e-01 6.31579757e-01 9.99994397e-01 9.99961138e-01\n",
      " 9.68330145e-01 9.85791485e-05 4.46254329e-04 7.56793082e-01\n",
      " 5.05985200e-01 9.99993443e-01 5.12943463e-03 5.14683604e-01\n",
      " 7.04840600e-01 8.91957879e-01 2.27256976e-02 9.91595685e-01\n",
      " 9.99861598e-01 8.12162578e-01 9.99724925e-01 9.87485468e-01\n",
      " 9.99996662e-01 9.98402894e-01 9.99368846e-01 2.09238287e-02\n",
      " 7.23652959e-01 5.97991608e-03 7.26624206e-02 9.85294580e-01\n",
      " 9.99760926e-01 4.03636634e-01 2.40752295e-01 6.53167009e-01\n",
      " 9.99168754e-01 9.93360460e-01 8.93063307e-01 9.90548432e-01\n",
      " 9.99740660e-01 9.99998808e-01 9.99824703e-01 9.99999881e-01\n",
      " 1.00000000e+00 8.13931048e-01 9.12442446e-01 8.06238770e-01\n",
      " 9.99999642e-01 9.99999166e-01 9.99690652e-01 9.98440087e-01\n",
      " 9.99995232e-01 9.99993801e-01 9.99676943e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999166e-01 1.00000000e+00 1.44327849e-01\n",
      " 5.52724659e-01 9.54064012e-01 9.92320597e-01 9.93310928e-01\n",
      " 7.17549264e-01 9.99949694e-01 9.99985814e-01 9.99945521e-01\n",
      " 9.99289513e-01 1.00000000e+00 9.99999642e-01 9.99992013e-01\n",
      " 7.37920046e-01 5.08397996e-01 9.94931281e-01 9.99999642e-01\n",
      " 2.34440267e-01 9.99991179e-01 9.92139876e-01 9.99994993e-01\n",
      " 9.98011708e-01 9.99537230e-01 1.00000000e+00 3.10638845e-01\n",
      " 8.55060369e-02 9.99843717e-01 4.32104170e-01 5.83806694e-01\n",
      " 9.99985218e-01 9.77572560e-01 3.31891865e-01 1.26418948e-01\n",
      " 9.99479830e-01 8.12936485e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 237 [0/54 (0%)]\tTrain Loss: 0.000755\n",
      "Train Epoch: 237 [8/54 (15%)]\tTrain Loss: 0.051376\n",
      "Train Epoch: 237 [16/54 (30%)]\tTrain Loss: 0.000842\n",
      "Train Epoch: 237 [24/54 (44%)]\tTrain Loss: 0.009969\n",
      "Train Epoch: 237 [32/54 (59%)]\tTrain Loss: 0.000436\n",
      "Train Epoch: 237 [40/54 (74%)]\tTrain Loss: 0.001777\n",
      "Train Epoch: 237 [48/54 (89%)]\tTrain Loss: 0.002636\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.05788242e-04 8.36517394e-01 7.39846587e-01 9.99955297e-01\n",
      " 5.56729361e-02 4.87767793e-05 1.08531579e-01 9.97881353e-01\n",
      " 1.91620976e-01 3.95581214e-04 1.12088379e-02 1.19646713e-04\n",
      " 2.36446201e-03 8.96272759e-05 6.46896601e-01 1.92675972e-04\n",
      " 3.95647628e-04 1.25900107e-02 6.01618111e-01 4.44431216e-01\n",
      " 4.08064649e-02 9.94999766e-01 9.98881161e-01 9.99931931e-01\n",
      " 1.07956499e-01 1.00000000e+00 9.99996305e-01 9.96100783e-01\n",
      " 1.81437790e-01 3.59834284e-01 9.74050999e-01 9.97890294e-01\n",
      " 9.31811929e-01 6.65859043e-05 6.40074722e-06 7.21200695e-03\n",
      " 3.08779508e-01 9.99945760e-01 3.91129084e-04 8.07654765e-03\n",
      " 5.75159024e-03 1.66475043e-01 3.08550452e-03 4.33397859e-01\n",
      " 8.78479898e-01 2.74649113e-01 9.99710619e-01 9.63547289e-01\n",
      " 9.99999642e-01 9.99465764e-01 9.99869227e-01 2.42004753e-04\n",
      " 3.10003711e-03 6.10953197e-03 7.34223146e-03 5.85173583e-03\n",
      " 9.97730196e-01 2.75623836e-02 1.04323299e-04 4.73015979e-02\n",
      " 9.39684749e-01 9.49028492e-01 4.42035228e-01 9.02866840e-01\n",
      " 9.99793470e-01 9.99978304e-01 9.99607742e-01 1.00000000e+00\n",
      " 1.00000000e+00 6.27567530e-01 7.38359988e-01 5.18569946e-01\n",
      " 9.99996185e-01 9.97681856e-01 9.94239807e-01 9.98585463e-01\n",
      " 9.99934077e-01 9.99754965e-01 9.99959469e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 1.00000000e+00 1.93933062e-02\n",
      " 1.87508941e-01 9.61238027e-01 9.85483527e-01 9.35093939e-01\n",
      " 4.48824227e-01 9.99395847e-01 9.99999642e-01 9.02387142e-01\n",
      " 9.47414398e-01 1.00000000e+00 9.99993920e-01 9.99933362e-01\n",
      " 1.18329331e-01 3.77733223e-02 9.77020621e-01 9.99976039e-01\n",
      " 1.11561054e-02 9.99620080e-01 2.07876246e-02 8.54548872e-01\n",
      " 9.99773324e-01 9.90887403e-01 9.99998808e-01 1.60400625e-02\n",
      " 6.25438010e-03 9.94518697e-01 5.81327021e-01 3.71937011e-03\n",
      " 9.76557314e-01 9.65725660e-01 1.14580609e-01 1.10973127e-01\n",
      " 9.99112427e-01 6.12819910e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 238 [0/54 (0%)]\tTrain Loss: 0.000372\n",
      "Train Epoch: 238 [8/54 (15%)]\tTrain Loss: 0.023872\n",
      "Train Epoch: 238 [16/54 (30%)]\tTrain Loss: 0.006294\n",
      "Train Epoch: 238 [24/54 (44%)]\tTrain Loss: 0.011517\n",
      "Train Epoch: 238 [32/54 (59%)]\tTrain Loss: 0.001816\n",
      "Train Epoch: 238 [40/54 (74%)]\tTrain Loss: 0.061845\n",
      "Train Epoch: 238 [48/54 (89%)]\tTrain Loss: 0.001202\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.89330482e-05 8.07742000e-01 3.21562253e-02 5.42339921e-01\n",
      " 3.76798306e-03 6.40577946e-06 2.32960001e-01 2.82934666e-01\n",
      " 1.13429374e-03 1.90238267e-01 7.59897709e-01 1.31883547e-02\n",
      " 7.78931426e-03 1.57470106e-06 5.27003023e-04 4.23879465e-06\n",
      " 5.62039122e-06 6.24526031e-02 7.43582785e-01 7.81888366e-01\n",
      " 4.67836624e-03 9.67435837e-01 9.87028122e-01 9.66601074e-01\n",
      " 9.09010842e-02 9.99991775e-01 9.97707844e-01 8.99109185e-01\n",
      " 1.54333577e-01 3.55484569e-03 1.54734952e-02 9.54920948e-01\n",
      " 4.69416939e-02 1.73368971e-06 2.06386903e-06 2.37503601e-03\n",
      " 1.99355915e-01 8.20702195e-01 3.30090802e-03 3.34216328e-03\n",
      " 3.64058279e-03 2.73829582e-03 1.03724585e-03 1.69940328e-03\n",
      " 2.10036933e-01 1.42179328e-04 7.11549342e-01 5.25572039e-02\n",
      " 9.99825060e-01 8.23079467e-01 9.60676372e-01 3.96107025e-05\n",
      " 3.39455117e-04 6.69164074e-05 8.83334130e-03 4.83770185e-04\n",
      " 9.47722137e-01 7.61690899e-04 4.86221500e-02 6.43086896e-05\n",
      " 9.30501521e-01 3.33879292e-01 6.59086943e-01 9.50036883e-01\n",
      " 2.37310618e-01 2.19215035e-01 5.41758716e-01 9.97968495e-01\n",
      " 1.00000000e+00 3.76608968e-01 3.50731492e-01 2.35740229e-01\n",
      " 9.88532305e-01 9.59278882e-01 9.38372791e-01 9.68778133e-01\n",
      " 9.99957442e-01 9.99929905e-01 4.43188399e-01 9.97956395e-01\n",
      " 9.99959469e-01 9.30471063e-01 9.99518871e-01 2.24324875e-02\n",
      " 9.61073488e-02 7.65832067e-01 9.66611147e-01 9.17508602e-01\n",
      " 2.10162513e-02 2.84173071e-01 9.82944191e-01 1.57541960e-01\n",
      " 1.69727981e-01 9.99999762e-01 9.99994278e-01 9.98317719e-01\n",
      " 1.84755703e-03 1.91353019e-02 9.72004950e-01 9.94189262e-01\n",
      " 2.37040892e-02 8.85661483e-01 2.60346923e-02 8.57485712e-01\n",
      " 8.82037044e-01 7.09270418e-01 9.99998689e-01 1.18103216e-03\n",
      " 5.35423169e-04 7.92941630e-01 2.72667920e-03 5.74690312e-05\n",
      " 4.93274689e-01 3.36517543e-01 7.20256474e-04 2.38022972e-02\n",
      " 9.00125325e-01 2.32870178e-03]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 239 [0/54 (0%)]\tTrain Loss: 0.006875\n",
      "Train Epoch: 239 [8/54 (15%)]\tTrain Loss: 0.004663\n",
      "Train Epoch: 239 [16/54 (30%)]\tTrain Loss: 0.000898\n",
      "Train Epoch: 239 [24/54 (44%)]\tTrain Loss: 0.011479\n",
      "Train Epoch: 239 [32/54 (59%)]\tTrain Loss: 0.048732\n",
      "Train Epoch: 239 [40/54 (74%)]\tTrain Loss: 0.001127\n",
      "Train Epoch: 239 [48/54 (89%)]\tTrain Loss: 0.010303\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.48035251e-04 8.44390631e-01 4.37423736e-01 6.17819965e-01\n",
      " 1.13268401e-02 1.08461441e-04 9.47963297e-02 2.70515829e-01\n",
      " 9.34234187e-02 6.07434332e-01 6.49605036e-01 7.82802049e-03\n",
      " 4.32956178e-04 1.18410010e-02 9.84017625e-02 2.10770313e-03\n",
      " 2.99296342e-04 7.19733238e-02 7.06212699e-01 2.99250335e-01\n",
      " 5.85045957e-04 9.50713813e-01 9.99567211e-01 9.90489125e-01\n",
      " 2.64465678e-02 9.99999404e-01 9.99989033e-01 9.87241507e-01\n",
      " 6.08807802e-01 4.45012711e-02 6.52236819e-01 9.95611370e-01\n",
      " 3.74997519e-02 3.14054450e-05 1.60713262e-05 2.13495689e-03\n",
      " 2.36925576e-02 9.50735807e-01 6.28184201e-03 7.31044263e-02\n",
      " 7.30604157e-02 1.56999342e-02 2.51434883e-03 4.65692692e-02\n",
      " 1.80892721e-01 3.76639626e-04 9.65097010e-01 7.51145631e-02\n",
      " 9.99769032e-01 9.90989149e-01 9.93955076e-01 1.52590964e-03\n",
      " 1.47366012e-03 1.28050835e-03 7.84922019e-03 3.33688431e-03\n",
      " 9.87503588e-01 1.78858582e-02 2.74143498e-02 1.02608018e-02\n",
      " 5.54170251e-01 2.79018402e-01 3.95164311e-01 7.87277758e-01\n",
      " 2.95299321e-01 9.92085755e-01 9.99693155e-01 9.99993324e-01\n",
      " 9.99939322e-01 5.18382430e-01 3.46159160e-01 2.98696071e-01\n",
      " 9.99884844e-01 9.99320745e-01 9.61218894e-01 8.19141924e-01\n",
      " 9.99538660e-01 9.99824703e-01 9.06457245e-01 9.99798238e-01\n",
      " 1.00000000e+00 9.98216689e-01 9.99982357e-01 1.35081476e-02\n",
      " 3.70428562e-01 6.50084674e-01 9.94117975e-01 9.36406970e-01\n",
      " 4.91848364e-02 9.99790728e-01 9.99788105e-01 7.76030123e-01\n",
      " 5.05071640e-01 9.99999642e-01 9.99990106e-01 9.98273730e-01\n",
      " 7.75235385e-05 1.22067882e-02 9.55127060e-01 9.99987602e-01\n",
      " 8.86257179e-03 9.63848650e-01 1.78166609e-02 8.52689922e-01\n",
      " 9.82247889e-01 9.67921615e-01 1.00000000e+00 2.57461844e-03\n",
      " 1.73454527e-02 8.36894274e-01 1.26674786e-01 4.02285904e-02\n",
      " 9.94563639e-01 8.51297379e-01 1.15760863e-02 3.52602676e-02\n",
      " 9.98476923e-01 1.37301758e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 240 [0/54 (0%)]\tTrain Loss: 0.000154\n",
      "Train Epoch: 240 [8/54 (15%)]\tTrain Loss: 0.000484\n",
      "Train Epoch: 240 [16/54 (30%)]\tTrain Loss: 0.001919\n",
      "Train Epoch: 240 [24/54 (44%)]\tTrain Loss: 0.011994\n",
      "Train Epoch: 240 [32/54 (59%)]\tTrain Loss: 0.000801\n",
      "Train Epoch: 240 [40/54 (74%)]\tTrain Loss: 0.010002\n",
      "Train Epoch: 240 [48/54 (89%)]\tTrain Loss: 0.008227\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.88926557e-02 9.28101063e-01 5.18687189e-01 3.35047483e-01\n",
      " 5.23274206e-02 3.51128611e-03 1.99693248e-01 3.87692094e-01\n",
      " 4.62084375e-02 5.29766142e-01 9.76506770e-01 1.44605218e-02\n",
      " 6.85392413e-04 1.07079803e-03 7.17049912e-02 2.52720347e-04\n",
      " 3.46526329e-04 9.76330712e-02 8.21031213e-01 8.16374570e-02\n",
      " 3.17910500e-02 7.95341969e-01 9.99153733e-01 9.17400539e-01\n",
      " 3.41391489e-02 9.99761403e-01 9.99494910e-01 9.97254431e-01\n",
      " 7.04430819e-01 6.64685249e-01 9.29184079e-01 9.94676232e-01\n",
      " 9.55246508e-01 5.85611560e-05 3.43370593e-05 6.42106310e-02\n",
      " 2.88599908e-01 6.97672665e-01 5.69348736e-03 1.11864461e-02\n",
      " 8.59328546e-03 2.13920069e-03 2.68523465e-03 1.47532329e-01\n",
      " 9.53212976e-01 1.18018731e-01 9.99211073e-01 9.03824449e-01\n",
      " 1.00000000e+00 9.97806251e-01 9.99999881e-01 1.39020318e-02\n",
      " 1.62542202e-02 1.37764633e-01 5.64369746e-02 3.35622057e-02\n",
      " 9.99218583e-01 3.80053818e-01 4.71266136e-02 3.72139225e-03\n",
      " 9.80032980e-01 9.26899195e-01 9.96144891e-01 9.97929811e-01\n",
      " 9.78401721e-01 9.99970555e-01 9.99082565e-01 9.99886632e-01\n",
      " 9.99976397e-01 8.98342013e-01 8.54918718e-01 7.52851188e-01\n",
      " 9.99976397e-01 9.99447286e-01 9.99690056e-01 9.96760547e-01\n",
      " 9.99986768e-01 9.99993563e-01 9.99203622e-01 9.99705732e-01\n",
      " 9.99999881e-01 9.99716461e-01 9.99976158e-01 1.42069936e-01\n",
      " 4.23615366e-01 9.96263206e-01 9.97703731e-01 9.91576791e-01\n",
      " 3.42539512e-02 1.48234561e-01 9.95651066e-01 9.21381593e-01\n",
      " 8.77353251e-01 9.99993682e-01 9.96935487e-01 7.67371953e-01\n",
      " 1.13861365e-02 7.37994611e-02 9.98465657e-01 9.22205985e-01\n",
      " 2.62629576e-02 9.93290424e-01 1.56635605e-02 8.81216645e-01\n",
      " 9.17619824e-01 9.68054235e-01 1.00000000e+00 4.92847674e-02\n",
      " 1.77077402e-03 9.99837399e-01 9.46151465e-03 6.30288012e-03\n",
      " 9.53682244e-01 3.53733122e-01 7.41027435e-03 6.82591721e-02\n",
      " 9.39176083e-01 1.51051264e-02]\n",
      "predict [0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 39 FN= 13 FP= 21\n",
      "TP+FP 66\n",
      "precision 0.6818181818181818\n",
      "recall 0.7758620689655172\n",
      "F1 0.7258064516129032\n",
      "acc 0.711864406779661\n",
      "AUCp 0.7129310344827586\n",
      "AUC 0.757183908045977\n",
      "\n",
      " The epoch is 240, average recall: 0.7759, average precision: 0.6818,average F1: 0.7258, average accuracy: 0.7119, average AUC: 0.7572\n",
      "Train Epoch: 241 [0/54 (0%)]\tTrain Loss: 0.003052\n",
      "Train Epoch: 241 [8/54 (15%)]\tTrain Loss: 0.002973\n",
      "Train Epoch: 241 [16/54 (30%)]\tTrain Loss: 0.003520\n",
      "Train Epoch: 241 [24/54 (44%)]\tTrain Loss: 0.014920\n",
      "Train Epoch: 241 [32/54 (59%)]\tTrain Loss: 0.019595\n",
      "Train Epoch: 241 [40/54 (74%)]\tTrain Loss: 0.009935\n",
      "Train Epoch: 241 [48/54 (89%)]\tTrain Loss: 0.004844\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.57544792e-01 9.80093241e-01 5.35723984e-01 6.30846798e-01\n",
      " 2.16065496e-02 4.41559963e-03 7.65748680e-01 8.81325066e-01\n",
      " 1.01395160e-01 4.97947663e-01 1.95885584e-01 4.53330344e-03\n",
      " 4.25981842e-02 5.35205763e-04 2.13308096e-01 1.20722130e-02\n",
      " 2.81366426e-03 1.69130173e-02 9.43710562e-03 3.08604389e-02\n",
      " 1.68165867e-03 9.74178493e-01 9.96982038e-01 9.94631648e-01\n",
      " 6.59406558e-03 9.99754846e-01 9.99943137e-01 8.81434500e-01\n",
      " 2.39921957e-02 1.51185438e-01 8.62932205e-01 5.81232250e-01\n",
      " 9.99425650e-01 6.37352650e-06 3.71550159e-05 3.06874950e-04\n",
      " 2.68796110e-03 9.50038135e-01 5.66887576e-03 2.85587944e-02\n",
      " 8.33539292e-03 1.23262620e-02 1.19709531e-02 1.67301089e-01\n",
      " 3.87968123e-01 2.60970350e-02 9.86751914e-01 9.34308648e-01\n",
      " 9.99988675e-01 9.16830242e-01 9.99361455e-01 5.42684551e-03\n",
      " 5.34286583e-03 1.35667939e-02 2.56053056e-04 3.60198697e-04\n",
      " 9.86238480e-01 9.30902199e-04 4.97380048e-01 1.03738587e-02\n",
      " 9.82429862e-01 2.01115161e-01 9.80511785e-01 9.88596737e-01\n",
      " 9.96448278e-01 9.96022165e-01 9.87564623e-01 9.99982834e-01\n",
      " 9.99998093e-01 9.12418723e-01 7.40637064e-01 9.23433661e-01\n",
      " 9.99993205e-01 9.91489828e-01 9.78637993e-01 9.99932885e-01\n",
      " 9.99923587e-01 9.99926925e-01 9.97695267e-01 9.99900699e-01\n",
      " 9.99986649e-01 9.99776065e-01 9.99993086e-01 4.35656548e-01\n",
      " 8.23700607e-01 7.91672051e-01 9.88016725e-01 9.82728660e-01\n",
      " 2.23992735e-01 9.93724287e-01 9.99471366e-01 4.85288441e-01\n",
      " 7.96640396e-01 9.99998689e-01 9.86912608e-01 9.94305074e-01\n",
      " 1.98348402e-03 8.54098871e-02 2.92500645e-01 9.79466438e-01\n",
      " 4.96215709e-02 9.99982238e-01 2.62751570e-03 9.42586303e-01\n",
      " 8.56586635e-01 8.22567940e-01 9.99996662e-01 4.71913069e-03\n",
      " 1.60048745e-04 1.34847686e-01 3.06624323e-02 4.61127143e-04\n",
      " 9.32606384e-02 2.48749331e-01 6.95353895e-02 3.59570272e-02\n",
      " 7.41224825e-01 4.47554320e-01]\n",
      "predict [1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 242 [0/54 (0%)]\tTrain Loss: 0.014342\n",
      "Train Epoch: 242 [8/54 (15%)]\tTrain Loss: 0.000330\n",
      "Train Epoch: 242 [16/54 (30%)]\tTrain Loss: 0.006355\n",
      "Train Epoch: 242 [24/54 (44%)]\tTrain Loss: 0.010916\n",
      "Train Epoch: 242 [32/54 (59%)]\tTrain Loss: 0.009453\n",
      "Train Epoch: 242 [40/54 (74%)]\tTrain Loss: 0.007931\n",
      "Train Epoch: 242 [48/54 (89%)]\tTrain Loss: 0.005002\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.40240705e-03 9.58210945e-01 9.86058891e-01 9.95688140e-01\n",
      " 1.66492268e-01 2.83374713e-04 8.05457830e-01 9.99205649e-01\n",
      " 1.05438801e-02 2.36046016e-02 4.37558115e-01 4.87615645e-04\n",
      " 2.76348352e-01 3.04988772e-02 6.02916181e-01 9.62916389e-02\n",
      " 2.51648482e-02 2.73063760e-02 8.53725150e-02 2.74395347e-02\n",
      " 6.07342343e-04 7.23908842e-01 9.01722074e-01 9.94480133e-01\n",
      " 6.92867069e-03 9.99903321e-01 9.99414563e-01 6.94752216e-01\n",
      " 3.79775703e-01 3.78534719e-02 2.26032808e-01 4.60706085e-01\n",
      " 9.60965514e-01 3.49555077e-04 1.10535859e-03 7.03871995e-02\n",
      " 4.59667062e-03 9.90932107e-01 1.13978516e-03 1.38720861e-02\n",
      " 9.90780257e-03 4.61087126e-04 1.58293433e-02 7.86109120e-02\n",
      " 1.83826819e-01 2.13351414e-05 5.89961410e-01 2.41880968e-01\n",
      " 9.99046862e-01 5.50790787e-01 5.92184961e-01 2.75842496e-03\n",
      " 7.42952689e-04 2.00136229e-02 2.66440766e-05 1.47580251e-03\n",
      " 2.50947118e-01 7.25835375e-03 3.42900902e-02 2.74808845e-03\n",
      " 7.25766122e-01 1.21623367e-01 7.72148252e-01 7.90407300e-01\n",
      " 9.14435327e-01 9.62351680e-01 9.99873877e-01 9.97495294e-01\n",
      " 9.99994755e-01 6.84131384e-02 1.52083328e-02 3.01525705e-02\n",
      " 9.99961615e-01 9.59820569e-01 9.66551185e-01 4.52769011e-01\n",
      " 9.99568284e-01 9.99943852e-01 9.37887907e-01 9.20838237e-01\n",
      " 9.99372900e-01 9.84708428e-01 9.97658253e-01 1.07685952e-02\n",
      " 3.10555473e-02 8.96720365e-02 9.21383321e-01 8.13712597e-01\n",
      " 4.49004024e-01 8.38672459e-01 9.92800832e-01 7.40634084e-01\n",
      " 7.54932821e-01 9.99997497e-01 9.74083900e-01 9.54564631e-01\n",
      " 6.59025216e-04 7.96079412e-02 7.88204193e-01 9.95861709e-01\n",
      " 5.02152648e-03 9.77168918e-01 2.30839178e-02 9.66750026e-01\n",
      " 9.03733969e-01 6.14702217e-02 9.99945879e-01 5.93579486e-02\n",
      " 4.56645852e-03 8.81173611e-01 2.48884130e-02 8.85927211e-03\n",
      " 7.79212058e-01 9.02334511e-01 5.27622588e-02 2.35236567e-02\n",
      " 9.73534703e-01 9.67443526e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 243 [0/54 (0%)]\tTrain Loss: 0.045004\n",
      "Train Epoch: 243 [8/54 (15%)]\tTrain Loss: 0.017965\n",
      "Train Epoch: 243 [16/54 (30%)]\tTrain Loss: 0.006966\n",
      "Train Epoch: 243 [24/54 (44%)]\tTrain Loss: 0.011545\n",
      "Train Epoch: 243 [32/54 (59%)]\tTrain Loss: 0.020365\n",
      "Train Epoch: 243 [40/54 (74%)]\tTrain Loss: 0.019103\n",
      "Train Epoch: 243 [48/54 (89%)]\tTrain Loss: 0.004125\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.77070291e-02 9.83582139e-01 4.99614865e-01 9.71821427e-01\n",
      " 2.02008337e-02 1.37805352e-02 5.88363647e-01 2.05081969e-01\n",
      " 7.85427466e-02 5.94254196e-01 2.02935711e-01 8.29528458e-03\n",
      " 8.70581064e-03 2.26415141e-04 1.25143528e-01 3.90189956e-03\n",
      " 1.01037396e-04 3.19374442e-01 1.34681746e-01 1.91172119e-02\n",
      " 4.19918373e-02 9.38507497e-01 9.87772644e-01 9.80567515e-01\n",
      " 9.30253118e-02 9.99929905e-01 9.98369634e-01 9.78924870e-01\n",
      " 5.80522180e-01 6.31665349e-01 9.94995952e-01 9.97931838e-01\n",
      " 9.93402898e-01 1.06093168e-04 9.61921687e-05 1.55224674e-03\n",
      " 2.26460444e-03 8.64242017e-01 2.00146670e-03 5.04125329e-03\n",
      " 9.02169105e-03 6.01074751e-03 1.32030258e-02 1.48987547e-01\n",
      " 5.25989711e-01 2.79063219e-03 9.99923706e-01 9.88122523e-01\n",
      " 9.99997497e-01 9.82721746e-01 9.99732912e-01 5.87624345e-05\n",
      " 9.70442314e-04 8.57537910e-02 6.12338670e-02 4.91482206e-04\n",
      " 9.68110621e-01 8.85701098e-04 3.33316326e-02 1.00917974e-03\n",
      " 9.95696664e-01 8.92376065e-01 9.96387720e-01 9.99244452e-01\n",
      " 9.87616360e-01 8.30366731e-01 9.95372832e-01 9.99893427e-01\n",
      " 9.99992728e-01 9.72520649e-01 8.45287502e-01 9.44267571e-01\n",
      " 9.99997020e-01 9.99431312e-01 9.99664187e-01 9.90778685e-01\n",
      " 9.99971628e-01 9.99989629e-01 9.64992881e-01 9.99477327e-01\n",
      " 9.99985218e-01 9.94745016e-01 9.99897838e-01 7.08917454e-02\n",
      " 2.61880785e-01 8.51556838e-01 9.94585097e-01 9.69614387e-01\n",
      " 2.22500980e-01 9.83338356e-01 9.98692095e-01 3.67336094e-01\n",
      " 9.00738299e-01 9.99863863e-01 9.84859407e-01 9.76185381e-01\n",
      " 7.05248967e-04 7.68075228e-01 9.59895253e-01 9.98081803e-01\n",
      " 3.50530177e-01 9.99806464e-01 2.84413863e-02 9.78188515e-01\n",
      " 9.42702055e-01 9.20692980e-01 9.99997258e-01 3.37981954e-02\n",
      " 8.73488747e-03 9.34177637e-01 4.02059704e-02 1.58130884e-01\n",
      " 8.76949370e-01 6.95126712e-01 4.67002273e-01 7.65451252e-01\n",
      " 9.90898669e-01 9.96277034e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 244 [0/54 (0%)]\tTrain Loss: 0.013207\n",
      "Train Epoch: 244 [8/54 (15%)]\tTrain Loss: 0.003862\n",
      "Train Epoch: 244 [16/54 (30%)]\tTrain Loss: 0.009169\n",
      "Train Epoch: 244 [24/54 (44%)]\tTrain Loss: 0.007884\n",
      "Train Epoch: 244 [32/54 (59%)]\tTrain Loss: 0.033353\n",
      "Train Epoch: 244 [40/54 (74%)]\tTrain Loss: 0.007129\n",
      "Train Epoch: 244 [48/54 (89%)]\tTrain Loss: 0.026260\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.45895165e-01 9.87370968e-01 8.66377115e-01 9.90517199e-01\n",
      " 3.31573248e-01 6.95128217e-02 7.31441140e-01 6.97021723e-01\n",
      " 6.60804361e-02 7.43889332e-01 1.75012633e-01 5.10246586e-03\n",
      " 7.84721505e-03 1.39003331e-02 5.33750713e-01 2.33180914e-03\n",
      " 6.80331199e-04 6.66867733e-01 3.66320729e-01 4.81928652e-03\n",
      " 5.63276419e-03 9.64601517e-01 9.99291062e-01 9.91922498e-01\n",
      " 4.50765938e-01 9.99678493e-01 9.97715473e-01 9.25135612e-01\n",
      " 8.92592072e-01 9.45455849e-01 9.99318242e-01 9.99254882e-01\n",
      " 9.99981284e-01 1.96139740e-06 2.54403840e-05 8.61604419e-03\n",
      " 1.53499236e-02 9.43052530e-01 6.25214279e-02 8.47959444e-02\n",
      " 4.23374444e-01 1.53648317e-01 4.83781546e-02 5.16668797e-01\n",
      " 7.02287138e-01 4.35362488e-01 9.99984145e-01 9.96150494e-01\n",
      " 9.99999762e-01 9.82331514e-01 9.99928236e-01 4.56111477e-04\n",
      " 4.05746419e-03 1.76927984e-01 2.88859475e-03 2.45250179e-03\n",
      " 9.92702842e-01 2.51300121e-03 6.29100278e-02 2.54395641e-02\n",
      " 9.99691486e-01 9.75011289e-01 9.99881506e-01 9.99977827e-01\n",
      " 9.65419888e-01 9.94110167e-01 9.99858379e-01 9.99998093e-01\n",
      " 9.99996901e-01 9.86939192e-01 9.98698235e-01 9.99545157e-01\n",
      " 9.99999762e-01 9.99694109e-01 9.99940395e-01 9.99976516e-01\n",
      " 9.99997139e-01 9.99999166e-01 9.99939799e-01 9.99999881e-01\n",
      " 1.00000000e+00 9.99994874e-01 9.99998689e-01 5.08211434e-01\n",
      " 8.51159811e-01 9.97843862e-01 9.99208391e-01 9.94129658e-01\n",
      " 3.37446570e-01 9.74111140e-01 9.90473807e-01 9.57213342e-01\n",
      " 9.97741222e-01 9.99969959e-01 9.81235623e-01 9.39778149e-01\n",
      " 7.10908440e-04 5.64795315e-01 7.80692041e-01 9.98018861e-01\n",
      " 1.97608575e-01 9.99993443e-01 1.54837845e-02 9.96532321e-01\n",
      " 9.98704553e-01 9.98558939e-01 9.99999285e-01 2.03017704e-02\n",
      " 2.47263233e-03 9.15430844e-01 1.54351769e-02 4.98324744e-02\n",
      " 8.22934091e-01 7.94416308e-01 6.53514504e-01 9.15107787e-01\n",
      " 8.85956943e-01 7.16309667e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 245 [0/54 (0%)]\tTrain Loss: 0.000872\n",
      "Train Epoch: 245 [8/54 (15%)]\tTrain Loss: 0.000908\n",
      "Train Epoch: 245 [16/54 (30%)]\tTrain Loss: 0.002571\n",
      "Train Epoch: 245 [24/54 (44%)]\tTrain Loss: 0.000755\n",
      "Train Epoch: 245 [32/54 (59%)]\tTrain Loss: 0.010737\n",
      "Train Epoch: 245 [40/54 (74%)]\tTrain Loss: 0.010413\n",
      "Train Epoch: 245 [48/54 (89%)]\tTrain Loss: 0.002549\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.83481839e-04 9.07842696e-01 4.69287455e-01 6.78115427e-01\n",
      " 1.51801351e-02 8.47746327e-04 6.69347048e-01 8.31958592e-01\n",
      " 1.00932317e-02 2.53665727e-02 2.96737105e-01 1.08355063e-03\n",
      " 4.94480766e-02 6.37647754e-05 3.83114554e-02 5.15031221e-04\n",
      " 2.32691073e-05 4.53097373e-02 2.07810163e-01 2.02944696e-01\n",
      " 2.40105577e-03 9.96229231e-01 9.96586800e-01 9.99947667e-01\n",
      " 2.19975322e-01 9.99990225e-01 9.99994516e-01 8.22745264e-01\n",
      " 1.43519208e-01 3.41009274e-02 5.49880341e-02 8.08688939e-01\n",
      " 1.51456716e-02 1.14998493e-05 1.54722857e-05 1.59352086e-04\n",
      " 4.90137842e-03 9.95651543e-01 3.44460510e-04 1.11817522e-02\n",
      " 7.01906718e-03 3.86625752e-02 3.48323549e-04 1.18135743e-01\n",
      " 2.70413280e-01 2.21017544e-04 9.36475217e-01 9.11220163e-02\n",
      " 9.99396801e-01 9.91210699e-01 9.44480658e-01 9.53926283e-05\n",
      " 2.66647694e-05 8.92669545e-04 7.65786608e-05 1.63634075e-04\n",
      " 9.70318139e-01 2.91753584e-03 4.79322625e-03 1.19028091e-05\n",
      " 9.17633474e-01 2.50959992e-01 9.45985734e-01 9.66442525e-01\n",
      " 9.86810446e-01 9.85795975e-01 9.96946514e-01 9.99895930e-01\n",
      " 1.00000000e+00 6.49849057e-01 8.22347701e-01 9.46075261e-01\n",
      " 9.99824822e-01 8.79564285e-01 7.82089710e-01 9.98420238e-01\n",
      " 9.99725997e-01 9.99994755e-01 9.98137474e-01 9.99790251e-01\n",
      " 9.99999762e-01 9.99884963e-01 9.99992609e-01 3.67527157e-02\n",
      " 1.81145087e-01 6.81038201e-01 9.98190820e-01 9.74575758e-01\n",
      " 7.82670856e-01 9.99349773e-01 9.99980569e-01 9.63661492e-01\n",
      " 9.00232136e-01 1.00000000e+00 9.99516964e-01 9.99729693e-01\n",
      " 7.81211653e-04 1.48409173e-01 6.96295559e-01 9.99948382e-01\n",
      " 2.75447637e-01 9.99618769e-01 3.76156084e-02 9.92929399e-01\n",
      " 9.91492808e-01 5.15600920e-01 9.99997973e-01 1.29133724e-02\n",
      " 1.58829629e-04 9.93857682e-01 1.15887254e-01 3.48648392e-02\n",
      " 8.22988331e-01 8.12594354e-01 6.57973468e-01 6.17712550e-02\n",
      " 9.84327912e-01 6.05712235e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 246 [0/54 (0%)]\tTrain Loss: 0.000708\n",
      "Train Epoch: 246 [8/54 (15%)]\tTrain Loss: 0.002012\n",
      "Train Epoch: 246 [16/54 (30%)]\tTrain Loss: 0.000817\n",
      "Train Epoch: 246 [24/54 (44%)]\tTrain Loss: 0.000707\n",
      "Train Epoch: 246 [32/54 (59%)]\tTrain Loss: 0.001158\n",
      "Train Epoch: 246 [40/54 (74%)]\tTrain Loss: 0.011176\n",
      "Train Epoch: 246 [48/54 (89%)]\tTrain Loss: 0.016795\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.36319362e-02 9.46148872e-01 9.88863945e-01 9.80844080e-01\n",
      " 2.64654219e-01 1.30537823e-02 9.56445098e-01 9.25574243e-01\n",
      " 2.98018027e-02 8.29905391e-01 7.68616617e-01 3.57667077e-03\n",
      " 3.02951541e-02 1.29229175e-02 5.62668443e-01 3.61018062e-01\n",
      " 1.09781034e-03 3.60238314e-01 4.24458176e-01 9.84963328e-02\n",
      " 6.09482266e-03 9.99418378e-01 9.99707878e-01 9.98954654e-01\n",
      " 9.18351591e-01 9.99997497e-01 9.99985933e-01 3.85266721e-01\n",
      " 8.47502589e-01 9.75081444e-01 9.73198354e-01 9.92830575e-01\n",
      " 8.17121863e-01 1.89990402e-04 1.61353208e-04 5.76349683e-02\n",
      " 8.82973000e-02 9.99718010e-01 2.91644096e-01 5.34027755e-01\n",
      " 3.89848292e-01 4.42682616e-02 4.44087014e-02 3.92756343e-01\n",
      " 5.90539336e-01 6.76545873e-02 9.95653510e-01 9.15352523e-01\n",
      " 9.99998689e-01 9.26168561e-01 9.99504805e-01 1.65819544e-02\n",
      " 3.15802201e-04 3.58642340e-02 4.46660270e-04 2.81316647e-03\n",
      " 9.84895051e-01 5.66135272e-02 3.60032395e-02 1.21255650e-03\n",
      " 9.71865892e-01 7.76245475e-01 9.87671256e-01 9.99453008e-01\n",
      " 9.58826244e-01 9.99688268e-01 9.99998569e-01 9.99948859e-01\n",
      " 9.99999404e-01 9.23981488e-01 9.34617817e-01 9.51329112e-01\n",
      " 9.99994993e-01 9.96776998e-01 6.54176056e-01 9.85082865e-01\n",
      " 9.99999523e-01 9.99999881e-01 9.99599636e-01 9.99953389e-01\n",
      " 1.00000000e+00 9.99988198e-01 9.99989629e-01 6.39023602e-01\n",
      " 6.87895238e-01 9.98436511e-01 9.99434173e-01 9.87583101e-01\n",
      " 1.50685310e-01 9.99982238e-01 9.99994636e-01 9.96843815e-01\n",
      " 9.92437184e-01 9.99983072e-01 9.96934652e-01 9.90894914e-01\n",
      " 3.33085656e-04 9.57400560e-01 9.68534827e-01 9.99996781e-01\n",
      " 2.92422533e-01 9.99984145e-01 1.66780323e-01 9.93782938e-01\n",
      " 9.97992039e-01 5.36822081e-01 9.99999881e-01 3.44155282e-02\n",
      " 1.66426916e-02 9.99090791e-01 3.95490438e-01 8.47632706e-01\n",
      " 9.96300697e-01 9.99899507e-01 9.93124664e-01 8.41486514e-01\n",
      " 9.98505116e-01 9.82778013e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 247 [0/54 (0%)]\tTrain Loss: 0.000784\n",
      "Train Epoch: 247 [8/54 (15%)]\tTrain Loss: 0.010543\n",
      "Train Epoch: 247 [16/54 (30%)]\tTrain Loss: 0.021123\n",
      "Train Epoch: 247 [24/54 (44%)]\tTrain Loss: 0.001720\n",
      "Train Epoch: 247 [32/54 (59%)]\tTrain Loss: 0.004315\n",
      "Train Epoch: 247 [40/54 (74%)]\tTrain Loss: 0.030140\n",
      "Train Epoch: 247 [48/54 (89%)]\tTrain Loss: 0.000553\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.23662378e-03 1.80020958e-01 4.69734035e-02 5.81124723e-01\n",
      " 1.75854921e-01 1.52138388e-03 4.22462970e-01 7.25256085e-01\n",
      " 2.54968461e-02 5.15807331e-01 7.09537983e-01 2.01867651e-02\n",
      " 4.62977961e-02 7.47032510e-03 5.21524027e-02 2.84450263e-01\n",
      " 2.66871396e-02 5.29282503e-02 6.85771286e-01 8.85925710e-01\n",
      " 1.31066442e-01 9.80527997e-01 9.98768866e-01 9.98125970e-01\n",
      " 9.35875535e-01 9.99982715e-01 9.99973536e-01 9.89428461e-01\n",
      " 6.02207720e-01 8.19522142e-01 9.90987480e-01 8.93251240e-01\n",
      " 9.12938952e-01 8.15508701e-03 5.70105063e-03 1.03565164e-01\n",
      " 5.64677358e-01 9.21556294e-01 1.14425406e-01 1.48141161e-01\n",
      " 9.78320185e-03 7.54575208e-02 4.17496369e-04 6.17257178e-01\n",
      " 1.80331782e-01 9.96182263e-02 9.54403698e-01 2.59950072e-01\n",
      " 1.00000000e+00 9.93149817e-01 9.99992967e-01 9.42766434e-04\n",
      " 3.33156288e-02 6.79123728e-03 2.83217162e-01 7.95793384e-02\n",
      " 9.95408475e-01 1.44139096e-01 3.61400051e-03 1.33707181e-01\n",
      " 6.67763293e-01 3.47759604e-01 7.28253245e-01 5.90517640e-01\n",
      " 9.93453979e-01 9.99749839e-01 9.96119022e-01 9.99629498e-01\n",
      " 9.99999642e-01 9.49525535e-01 7.64089465e-01 7.84947932e-01\n",
      " 9.99977350e-01 9.99954224e-01 9.99976754e-01 8.69858265e-01\n",
      " 8.60915720e-01 9.80436504e-01 9.52172160e-01 9.98440444e-01\n",
      " 1.00000000e+00 9.99986887e-01 9.99996901e-01 8.05191472e-02\n",
      " 3.56863402e-02 8.17233622e-01 9.87824917e-01 8.24785233e-01\n",
      " 8.80511343e-01 9.98426795e-01 9.99871612e-01 9.90693033e-01\n",
      " 8.50972116e-01 9.99999762e-01 9.98920918e-01 9.99184787e-01\n",
      " 5.78104937e-03 9.13061976e-01 9.99652743e-01 9.99962449e-01\n",
      " 2.23263323e-01 9.86600697e-01 4.44703072e-01 9.95571852e-01\n",
      " 9.90809560e-01 9.52732742e-01 9.99999762e-01 8.14444482e-01\n",
      " 5.43892622e-01 9.99988317e-01 9.98405993e-01 9.91320789e-01\n",
      " 9.99857426e-01 9.97224331e-01 7.95073688e-01 4.08090562e-01\n",
      " 4.96148348e-01 7.21466422e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "Train Epoch: 248 [0/54 (0%)]\tTrain Loss: 0.000816\n",
      "Train Epoch: 248 [8/54 (15%)]\tTrain Loss: 0.048340\n",
      "Train Epoch: 248 [16/54 (30%)]\tTrain Loss: 0.004505\n",
      "Train Epoch: 248 [24/54 (44%)]\tTrain Loss: 0.013540\n",
      "Train Epoch: 248 [32/54 (59%)]\tTrain Loss: 0.007459\n",
      "Train Epoch: 248 [40/54 (74%)]\tTrain Loss: 0.031802\n",
      "Train Epoch: 248 [48/54 (89%)]\tTrain Loss: 0.002384\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.28318757e-01 9.36326563e-01 8.48916650e-01 9.98060286e-01\n",
      " 9.97545540e-01 1.28096670e-01 9.19742703e-01 9.99891520e-01\n",
      " 6.66157678e-02 4.82320786e-01 9.91037250e-01 7.70185068e-02\n",
      " 9.89453435e-01 3.98499280e-01 9.97880220e-01 1.72611326e-01\n",
      " 5.86995631e-02 7.45276690e-01 9.87499535e-01 9.82677519e-01\n",
      " 8.71551991e-01 7.18473136e-01 9.99954700e-01 9.99972820e-01\n",
      " 9.70953703e-01 9.99953985e-01 9.99579847e-01 9.99806106e-01\n",
      " 9.95233119e-01 9.60641503e-01 9.96172369e-01 9.99991536e-01\n",
      " 9.95582163e-01 4.12730545e-01 5.92860691e-02 7.85909593e-01\n",
      " 9.70352352e-01 9.98205423e-01 8.59048963e-01 8.83743644e-01\n",
      " 7.70133734e-01 6.48824990e-01 7.16369927e-01 9.98807907e-01\n",
      " 9.97167289e-01 9.87074733e-01 9.99909163e-01 9.98516858e-01\n",
      " 9.99999523e-01 9.99099731e-01 9.99995828e-01 1.20726481e-01\n",
      " 9.95274901e-01 8.69393826e-01 1.28599405e-01 6.08260930e-01\n",
      " 9.99980092e-01 2.61894375e-01 6.77220047e-01 9.97222781e-01\n",
      " 9.98039782e-01 9.97394800e-01 9.97037768e-01 9.97661114e-01\n",
      " 9.99999762e-01 9.99980450e-01 9.99922037e-01 9.99992251e-01\n",
      " 9.99999762e-01 9.75692511e-01 8.58257651e-01 8.91685426e-01\n",
      " 9.99677658e-01 9.99973536e-01 9.99996185e-01 9.96127188e-01\n",
      " 9.99890924e-01 9.99947906e-01 9.99998808e-01 9.99999881e-01\n",
      " 9.99959588e-01 9.99906898e-01 9.99994278e-01 7.89275050e-01\n",
      " 9.88941491e-01 9.96892273e-01 9.99856234e-01 9.99055684e-01\n",
      " 9.91514206e-01 4.76981113e-05 8.92693222e-01 9.99436200e-01\n",
      " 9.98747468e-01 9.99999762e-01 9.99843717e-01 9.99565899e-01\n",
      " 2.31051981e-01 5.77491522e-02 9.72274661e-01 9.95733202e-01\n",
      " 7.50784934e-01 9.99820054e-01 9.39908683e-01 9.98350739e-01\n",
      " 9.99418020e-01 9.97593582e-01 9.99999881e-01 3.62623721e-01\n",
      " 1.72491252e-01 9.99657989e-01 6.64098382e-01 3.50988358e-01\n",
      " 5.85460067e-01 9.01874185e-01 5.67089260e-01 9.47494686e-01\n",
      " 1.05681354e-02 4.78234410e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 249 [0/54 (0%)]\tTrain Loss: 0.098294\n",
      "Train Epoch: 249 [8/54 (15%)]\tTrain Loss: 0.014777\n",
      "Train Epoch: 249 [16/54 (30%)]\tTrain Loss: 0.004630\n",
      "Train Epoch: 249 [24/54 (44%)]\tTrain Loss: 0.005464\n",
      "Train Epoch: 249 [32/54 (59%)]\tTrain Loss: 0.015081\n",
      "Train Epoch: 249 [40/54 (74%)]\tTrain Loss: 0.009870\n",
      "Train Epoch: 249 [48/54 (89%)]\tTrain Loss: 0.006719\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.11470393e-03 8.28832328e-01 8.64086509e-01 9.16165650e-01\n",
      " 5.70097752e-02 1.60423433e-03 7.99445271e-01 4.16558057e-01\n",
      " 1.13634123e-02 6.81654513e-02 1.90755457e-01 1.37211836e-03\n",
      " 2.22555874e-03 2.49254554e-05 2.84776658e-01 7.82950010e-05\n",
      " 4.98288045e-06 2.23016560e-01 9.03656483e-01 2.07932577e-01\n",
      " 2.95283161e-02 9.87814188e-01 9.98312950e-01 9.97857034e-01\n",
      " 3.52353573e-01 9.99664903e-01 9.99441922e-01 9.76977706e-01\n",
      " 7.77196109e-01 3.28281701e-01 9.98940289e-01 9.99090433e-01\n",
      " 3.19758385e-01 3.52710072e-06 1.12734451e-05 2.57003267e-04\n",
      " 2.13616025e-02 9.97721136e-01 3.87921231e-03 1.34784773e-01\n",
      " 2.22784877e-02 5.04818000e-03 2.68585887e-02 2.01887563e-02\n",
      " 9.73567888e-02 1.65099278e-02 9.99631166e-01 9.49147880e-01\n",
      " 9.99916911e-01 9.83154655e-01 9.99217987e-01 5.76909088e-07\n",
      " 2.50841677e-02 2.21356843e-03 3.95680917e-03 3.24246637e-03\n",
      " 9.92061853e-01 2.46214420e-02 3.38138314e-03 4.11053926e-01\n",
      " 7.84819901e-01 2.90222436e-01 6.38778210e-01 9.13127482e-01\n",
      " 9.97448862e-01 9.92343485e-01 9.99708474e-01 9.99991179e-01\n",
      " 9.99887109e-01 4.57402736e-01 8.71102452e-01 9.33299124e-01\n",
      " 9.98497963e-01 9.84455705e-01 9.96893644e-01 9.97937977e-01\n",
      " 9.99935389e-01 9.99968886e-01 9.99961615e-01 9.99983311e-01\n",
      " 9.99999762e-01 9.99823034e-01 9.99983191e-01 2.88828462e-01\n",
      " 4.44468230e-01 9.29318607e-01 9.99515772e-01 9.91346776e-01\n",
      " 3.17660272e-02 9.74513829e-01 9.99340355e-01 5.53974986e-01\n",
      " 7.66305447e-01 9.99985456e-01 9.98973012e-01 9.80092525e-01\n",
      " 3.93507333e-04 3.66205513e-01 9.10071254e-01 9.97652233e-01\n",
      " 2.43440658e-01 9.92299020e-01 4.55534365e-03 9.60798323e-01\n",
      " 9.98687088e-01 9.89176095e-01 9.99999404e-01 2.36297096e-03\n",
      " 2.14219000e-02 9.75921690e-01 5.61478063e-02 7.81638399e-02\n",
      " 8.71636808e-01 9.99442875e-01 3.32904577e-01 6.92089140e-01\n",
      " 7.21562028e-01 6.04151964e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 250 [0/54 (0%)]\tTrain Loss: 0.001652\n",
      "Train Epoch: 250 [8/54 (15%)]\tTrain Loss: 0.021145\n",
      "Train Epoch: 250 [16/54 (30%)]\tTrain Loss: 0.017305\n",
      "Train Epoch: 250 [24/54 (44%)]\tTrain Loss: 0.000713\n",
      "Train Epoch: 250 [32/54 (59%)]\tTrain Loss: 0.000305\n",
      "Train Epoch: 250 [40/54 (74%)]\tTrain Loss: 0.005339\n",
      "Train Epoch: 250 [48/54 (89%)]\tTrain Loss: 0.000267\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.33325747e-02 3.38328242e-01 5.75536899e-02 9.28908467e-01\n",
      " 3.20948899e-01 1.72248576e-02 1.40711144e-01 9.72504735e-01\n",
      " 4.71125953e-02 1.66478027e-02 7.72376716e-01 1.81965705e-04\n",
      " 4.86503989e-01 5.50226017e-04 9.10409689e-02 8.92971270e-03\n",
      " 6.18931372e-04 1.97560683e-01 8.36272180e-01 4.23007756e-01\n",
      " 3.54393244e-01 9.90197420e-01 9.99857068e-01 9.99989748e-01\n",
      " 1.12313636e-01 1.00000000e+00 1.00000000e+00 9.76325333e-01\n",
      " 7.40711331e-01 1.47355217e-02 9.11357760e-01 9.98888195e-01\n",
      " 9.66018736e-01 1.38516307e-05 7.40499217e-06 4.03598044e-03\n",
      " 3.17716482e-03 9.98926103e-01 1.42863335e-03 8.55132937e-01\n",
      " 3.88934553e-01 5.30284010e-02 3.79756242e-02 2.07553104e-01\n",
      " 8.15721154e-01 9.11059141e-01 9.99806106e-01 9.70653534e-01\n",
      " 9.99999404e-01 9.98077273e-01 9.99743402e-01 1.94371082e-02\n",
      " 3.25150281e-01 6.66419566e-02 8.88304412e-03 4.41812649e-02\n",
      " 9.99830365e-01 2.84895692e-02 4.55092452e-03 7.28073061e-01\n",
      " 9.95940447e-01 7.93126643e-01 9.88414049e-01 9.89558339e-01\n",
      " 9.99994636e-01 9.99938250e-01 9.99947667e-01 1.00000000e+00\n",
      " 9.99991059e-01 9.20328379e-01 7.31052339e-01 9.55890357e-01\n",
      " 9.99996066e-01 9.89976704e-01 9.99954820e-01 9.99380589e-01\n",
      " 9.99939203e-01 9.99878049e-01 9.99971628e-01 9.99999881e-01\n",
      " 1.00000000e+00 9.99359071e-01 9.99999762e-01 2.30013937e-01\n",
      " 9.31191325e-01 9.87752438e-01 9.99900699e-01 9.99223590e-01\n",
      " 5.44056833e-01 9.99997616e-01 9.99951482e-01 7.77663648e-01\n",
      " 7.31325448e-01 1.00000000e+00 9.99976039e-01 9.90793407e-01\n",
      " 5.07823937e-03 3.62423986e-01 9.37045455e-01 9.79136169e-01\n",
      " 5.91320246e-02 9.99382019e-01 3.43865529e-02 9.99882340e-01\n",
      " 9.99157548e-01 9.99190390e-01 1.00000000e+00 1.05206491e-02\n",
      " 1.91334577e-03 9.41330373e-01 9.10832081e-03 3.52175120e-04\n",
      " 8.93684685e-01 4.16222572e-01 6.83076084e-02 1.77911878e-01\n",
      " 4.52758878e-01 1.84864953e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 44 TN= 38 FN= 14 FP= 22\n",
      "TP+FP 66\n",
      "precision 0.6666666666666666\n",
      "recall 0.7586206896551724\n",
      "F1 0.7096774193548386\n",
      "acc 0.6949152542372882\n",
      "AUCp 0.6959770114942528\n",
      "AUC 0.7658045977011494\n",
      "\n",
      " The epoch is 250, average recall: 0.7586, average precision: 0.6667,average F1: 0.7097, average accuracy: 0.6949, average AUC: 0.7658\n",
      "Train Epoch: 251 [0/54 (0%)]\tTrain Loss: 0.048603\n",
      "Train Epoch: 251 [8/54 (15%)]\tTrain Loss: 0.011645\n",
      "Train Epoch: 251 [16/54 (30%)]\tTrain Loss: 0.012170\n",
      "Train Epoch: 251 [24/54 (44%)]\tTrain Loss: 0.005354\n",
      "Train Epoch: 251 [32/54 (59%)]\tTrain Loss: 0.001496\n",
      "Train Epoch: 251 [40/54 (74%)]\tTrain Loss: 0.001744\n",
      "Train Epoch: 251 [48/54 (89%)]\tTrain Loss: 0.001415\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.46787964e-07 4.86830115e-01 1.57343090e-01 3.85702774e-02\n",
      " 4.83837863e-03 1.23846147e-03 2.05491021e-01 2.03460623e-02\n",
      " 1.49744307e-03 8.88862833e-03 7.74816573e-02 2.60516565e-04\n",
      " 7.88579986e-04 8.20238274e-05 3.19472700e-02 9.10010713e-05\n",
      " 2.20557122e-04 6.47182669e-03 7.04674199e-02 3.90779674e-02\n",
      " 6.45037915e-04 3.12167138e-01 9.71996963e-01 9.22019184e-01\n",
      " 3.05667147e-03 9.87359345e-01 9.99809206e-01 3.03386211e-01\n",
      " 7.21913695e-01 9.45146475e-03 9.92139637e-01 8.32213581e-01\n",
      " 1.49249638e-04 2.47118987e-05 7.16135173e-06 1.70780311e-03\n",
      " 2.06717988e-03 9.20967221e-01 1.35658134e-03 1.02262490e-03\n",
      " 6.99241878e-04 4.14538590e-05 5.29326906e-04 8.21538153e-04\n",
      " 9.22339875e-03 2.66649784e-03 7.23399282e-01 4.12068376e-03\n",
      " 8.26594114e-01 8.61856520e-01 8.88163269e-01 8.24382994e-07\n",
      " 1.26473342e-05 3.89391626e-03 1.82856359e-02 1.53960893e-04\n",
      " 3.57799530e-01 8.53648968e-03 1.22407230e-03 3.45763401e-04\n",
      " 3.79551053e-01 2.12605253e-01 1.57892674e-01 7.79051721e-01\n",
      " 3.12073052e-01 7.63454884e-02 8.87569368e-01 9.98908281e-01\n",
      " 9.99681830e-01 2.90832549e-01 3.11009884e-02 9.97795835e-02\n",
      " 9.50665414e-01 7.64598429e-01 3.93554688e-01 3.40052396e-01\n",
      " 9.98304009e-01 9.99698400e-01 9.51189876e-01 9.99308944e-01\n",
      " 9.99978185e-01 9.98333037e-01 9.96410310e-01 2.34293845e-03\n",
      " 6.71901368e-03 6.31180882e-01 2.11561963e-01 1.30525544e-01\n",
      " 1.67631712e-02 7.92771578e-01 9.99129593e-01 2.12334488e-02\n",
      " 3.84074375e-02 9.95653152e-01 9.82817054e-01 8.97387683e-01\n",
      " 1.46668841e-04 3.61727215e-02 6.98007822e-01 9.90140498e-01\n",
      " 1.20771164e-02 5.99951327e-01 1.03352796e-02 1.18242074e-02\n",
      " 3.23354781e-01 3.71668965e-01 9.99657154e-01 1.10745415e-04\n",
      " 1.38607912e-03 7.19552115e-02 6.80778474e-02 9.38964859e-02\n",
      " 9.56520557e-01 3.78624618e-01 1.07430909e-02 2.25811321e-02\n",
      " 9.51504230e-01 2.70384401e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 252 [0/54 (0%)]\tTrain Loss: 0.019315\n",
      "Train Epoch: 252 [8/54 (15%)]\tTrain Loss: 0.000564\n",
      "Train Epoch: 252 [16/54 (30%)]\tTrain Loss: 0.002464\n",
      "Train Epoch: 252 [24/54 (44%)]\tTrain Loss: 0.000937\n",
      "Train Epoch: 252 [32/54 (59%)]\tTrain Loss: 0.018847\n",
      "Train Epoch: 252 [40/54 (74%)]\tTrain Loss: 0.022435\n",
      "Train Epoch: 252 [48/54 (89%)]\tTrain Loss: 0.011785\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.97984991e-04 8.51997495e-01 9.71740007e-01 9.73283052e-01\n",
      " 7.47939348e-01 4.95450608e-02 9.90751266e-01 9.55555081e-01\n",
      " 3.35851192e-01 9.52182114e-01 9.82230484e-01 5.39651588e-02\n",
      " 7.34647453e-01 1.94063306e-01 8.08022916e-01 2.64948577e-01\n",
      " 2.25346059e-01 5.85122347e-01 9.97218728e-01 7.37149894e-01\n",
      " 9.80422124e-02 9.98811483e-01 9.99994516e-01 9.99715388e-01\n",
      " 9.02702451e-01 1.00000000e+00 9.99998212e-01 9.99304175e-01\n",
      " 9.98826325e-01 2.74712503e-01 9.99960303e-01 9.99941826e-01\n",
      " 4.06319588e-01 4.59531806e-02 4.11795266e-03 9.04951513e-01\n",
      " 6.61679983e-01 9.99962449e-01 2.38137379e-01 5.51307380e-01\n",
      " 3.24673831e-01 1.73568770e-01 1.46024451e-01 9.27506924e-01\n",
      " 9.53783274e-01 3.99672717e-01 9.99526143e-01 8.18291426e-01\n",
      " 9.99961615e-01 9.92398441e-01 9.99970675e-01 1.57627389e-02\n",
      " 7.74213195e-01 9.46785092e-01 1.13519922e-01 6.71279132e-01\n",
      " 9.96592581e-01 3.90175998e-01 9.46549654e-01 9.29747760e-01\n",
      " 9.99977827e-01 9.93430197e-01 9.98545289e-01 9.99892950e-01\n",
      " 9.99819815e-01 9.94704187e-01 9.99940991e-01 9.99999404e-01\n",
      " 9.99999046e-01 9.78538096e-01 9.45943952e-01 9.32519436e-01\n",
      " 9.99987245e-01 9.99810755e-01 9.98440802e-01 9.99878287e-01\n",
      " 9.99995232e-01 9.99999881e-01 9.99998927e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999523e-01 9.99999762e-01 7.33804226e-01\n",
      " 9.64485884e-01 9.98397648e-01 9.99565423e-01 9.99737322e-01\n",
      " 8.38833511e-01 9.98790562e-01 9.99971747e-01 9.95371521e-01\n",
      " 9.54612076e-01 9.99999881e-01 9.99406695e-01 9.99838114e-01\n",
      " 3.55655141e-02 8.56281698e-01 9.96047795e-01 9.99816239e-01\n",
      " 7.58642256e-01 9.99524117e-01 9.08520997e-01 9.99492764e-01\n",
      " 9.98583674e-01 9.99211073e-01 1.00000000e+00 5.97371124e-02\n",
      " 2.37164527e-01 9.79137957e-01 8.85900497e-01 8.21555793e-01\n",
      " 9.99587715e-01 9.91852343e-01 1.76137567e-01 4.71970290e-01\n",
      " 9.98800874e-01 9.99899268e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 253 [0/54 (0%)]\tTrain Loss: 0.033793\n",
      "Train Epoch: 253 [8/54 (15%)]\tTrain Loss: 0.000565\n",
      "Train Epoch: 253 [16/54 (30%)]\tTrain Loss: 0.001796\n",
      "Train Epoch: 253 [24/54 (44%)]\tTrain Loss: 0.002506\n",
      "Train Epoch: 253 [32/54 (59%)]\tTrain Loss: 0.000785\n",
      "Train Epoch: 253 [40/54 (74%)]\tTrain Loss: 0.003926\n",
      "Train Epoch: 253 [48/54 (89%)]\tTrain Loss: 0.011180\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.06751642e-04 3.76992710e-02 1.17159292e-01 7.14214504e-01\n",
      " 3.24456632e-01 1.18813533e-02 8.29127505e-02 9.70520198e-01\n",
      " 9.34020206e-02 9.16294754e-01 9.92170930e-01 5.20930588e-02\n",
      " 7.67539501e-01 1.18834596e-05 7.04298588e-03 1.86143145e-02\n",
      " 1.36823663e-02 1.46073297e-01 8.41215968e-01 6.01306297e-02\n",
      " 8.84767342e-03 6.48376763e-01 9.99894023e-01 9.99974728e-01\n",
      " 1.65742457e-01 9.99990463e-01 9.99999642e-01 8.35407734e-01\n",
      " 7.34316230e-01 8.43075290e-03 5.45904398e-01 9.62413728e-01\n",
      " 9.10332724e-02 3.27992579e-03 3.52531904e-03 3.84146750e-01\n",
      " 1.02333963e-01 9.98410344e-01 8.47632997e-03 2.40790084e-01\n",
      " 9.55684483e-03 5.00777923e-03 9.70489252e-03 3.17821000e-03\n",
      " 1.73684627e-01 5.07174805e-03 9.90685165e-01 2.13685259e-01\n",
      " 9.58077669e-01 9.97731626e-01 9.94482040e-01 7.55950855e-03\n",
      " 2.48286454e-03 3.19075018e-01 1.94562611e-03 9.80357155e-02\n",
      " 9.59365785e-01 8.15410540e-02 2.88677603e-01 1.01095217e-03\n",
      " 9.97835815e-01 9.40428197e-01 9.80507553e-01 9.88550484e-01\n",
      " 9.70646799e-01 4.15337265e-01 9.96395051e-01 9.99812901e-01\n",
      " 9.99995947e-01 9.67466950e-01 7.55256176e-01 8.79386902e-01\n",
      " 9.95021343e-01 9.99219656e-01 8.69656265e-01 8.72853935e-01\n",
      " 9.97931838e-01 9.98923123e-01 9.67969894e-01 9.99934435e-01\n",
      " 9.99891281e-01 9.98092473e-01 9.99919415e-01 2.38801911e-01\n",
      " 4.00363326e-01 9.70436990e-01 8.76515090e-01 8.30336571e-01\n",
      " 3.24525267e-01 9.86857533e-01 9.99898672e-01 9.87830818e-01\n",
      " 9.15589809e-01 1.00000000e+00 9.99433339e-01 9.99045193e-01\n",
      " 9.34461430e-02 2.55477101e-01 9.78888452e-01 9.99022245e-01\n",
      " 3.66548538e-01 9.94487584e-01 3.28674555e-01 9.99941826e-01\n",
      " 9.98767376e-01 9.85503197e-01 1.00000000e+00 1.24625504e-01\n",
      " 4.99234833e-02 9.13147926e-01 2.65671760e-01 8.30354512e-01\n",
      " 9.93817151e-01 9.66272295e-01 3.02402452e-02 3.60918790e-02\n",
      " 5.98496079e-01 7.61866331e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 254 [0/54 (0%)]\tTrain Loss: 0.008828\n",
      "Train Epoch: 254 [8/54 (15%)]\tTrain Loss: 0.006575\n",
      "Train Epoch: 254 [16/54 (30%)]\tTrain Loss: 0.022062\n",
      "Train Epoch: 254 [24/54 (44%)]\tTrain Loss: 0.001933\n",
      "Train Epoch: 254 [32/54 (59%)]\tTrain Loss: 0.003674\n",
      "Train Epoch: 254 [40/54 (74%)]\tTrain Loss: 0.001001\n",
      "Train Epoch: 254 [48/54 (89%)]\tTrain Loss: 0.005951\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.84074296e-04 6.24904692e-01 9.95900691e-01 9.69720483e-01\n",
      " 8.42692196e-01 8.97889733e-02 9.07078147e-01 9.57242072e-01\n",
      " 2.16753438e-01 8.70873511e-01 8.86958420e-01 1.09147830e-02\n",
      " 2.34681234e-01 1.39664095e-02 9.40835774e-02 1.12095356e-01\n",
      " 1.00831665e-01 1.34219557e-01 8.88020754e-01 1.78101808e-01\n",
      " 1.41721927e-02 9.64644551e-01 9.99435484e-01 9.99307036e-01\n",
      " 3.52298707e-01 9.99981284e-01 9.99998808e-01 9.68247533e-01\n",
      " 7.60411859e-01 1.63041130e-01 8.40438962e-01 9.88249302e-01\n",
      " 2.45508887e-02 8.14579718e-04 7.78669375e-04 1.23647436e-01\n",
      " 7.51812430e-03 9.56225216e-01 2.61724018e-03 3.34633812e-02\n",
      " 2.81734322e-03 6.16185716e-05 1.40062869e-02 6.07147478e-02\n",
      " 6.32681847e-01 9.68875643e-03 8.59114945e-01 7.06143230e-02\n",
      " 8.58566463e-01 9.87415254e-01 9.97246385e-01 7.80646049e-04\n",
      " 3.44937714e-03 5.56165218e-01 2.14468837e-02 1.33777276e-01\n",
      " 9.76497412e-01 1.10642493e-01 6.52391315e-01 2.97087312e-01\n",
      " 9.98954654e-01 9.26690996e-01 8.31334710e-01 9.51650739e-01\n",
      " 9.97144163e-01 9.95602608e-01 9.99968648e-01 9.99974966e-01\n",
      " 9.99998569e-01 5.75714171e-01 7.68314421e-01 8.50003481e-01\n",
      " 9.99571741e-01 9.99908328e-01 9.39034700e-01 7.81030059e-01\n",
      " 9.99996305e-01 9.99986291e-01 9.97724593e-01 9.99965668e-01\n",
      " 1.00000000e+00 9.99903440e-01 9.99993801e-01 1.79789335e-01\n",
      " 2.48964623e-01 8.22050035e-01 9.70284820e-01 8.41912925e-01\n",
      " 6.12857699e-01 9.73940730e-01 9.99638319e-01 9.54621851e-01\n",
      " 8.03113818e-01 9.99998093e-01 9.99471009e-01 9.96081173e-01\n",
      " 4.20330325e-03 2.43043855e-01 9.87646580e-01 9.96998072e-01\n",
      " 6.03810176e-02 9.27390099e-01 1.41079471e-01 9.50281084e-01\n",
      " 9.60151911e-01 9.20231342e-01 9.99998093e-01 8.03518295e-03\n",
      " 1.09178036e-01 9.38009441e-01 6.94275051e-02 7.93053091e-01\n",
      " 9.98708487e-01 9.90534961e-01 1.26907472e-02 9.41142589e-02\n",
      " 5.01630425e-01 7.55810201e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 255 [0/54 (0%)]\tTrain Loss: 0.003192\n",
      "Train Epoch: 255 [8/54 (15%)]\tTrain Loss: 0.004965\n",
      "Train Epoch: 255 [16/54 (30%)]\tTrain Loss: 0.000398\n",
      "Train Epoch: 255 [24/54 (44%)]\tTrain Loss: 0.001781\n",
      "Train Epoch: 255 [32/54 (59%)]\tTrain Loss: 0.016064\n",
      "Train Epoch: 255 [40/54 (74%)]\tTrain Loss: 0.017236\n",
      "Train Epoch: 255 [48/54 (89%)]\tTrain Loss: 0.004828\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.09024831e-04 4.88579065e-01 9.75987196e-01 7.85896897e-01\n",
      " 6.20388806e-01 2.09914763e-02 9.00596917e-01 8.82378280e-01\n",
      " 9.61443409e-02 1.81454405e-01 9.44394618e-02 2.48639844e-03\n",
      " 3.06567103e-01 3.44888754e-02 3.38897437e-01 7.42117176e-03\n",
      " 6.91570248e-03 5.76030135e-01 1.97351322e-01 3.89533751e-02\n",
      " 3.18513322e-03 9.98100817e-01 9.95697379e-01 9.92261112e-01\n",
      " 3.05262327e-01 9.99976158e-01 9.99334157e-01 8.95635009e-01\n",
      " 1.08556978e-01 1.17238434e-02 8.72276306e-01 7.08464861e-01\n",
      " 1.01069383e-01 3.49910370e-05 6.15340177e-05 7.28407595e-03\n",
      " 3.36674824e-02 9.99456584e-01 3.37826237e-02 2.04205334e-01\n",
      " 7.07603665e-03 8.79873335e-03 3.30989175e-02 3.24124008e-01\n",
      " 1.02213830e-01 2.19603643e-01 8.99802029e-01 3.11669260e-01\n",
      " 9.95914042e-01 9.77994025e-01 9.99071956e-01 7.48488645e-04\n",
      " 5.72401360e-02 5.64513981e-01 1.27934758e-02 1.88627727e-02\n",
      " 9.97665882e-01 1.36567587e-02 1.57229558e-01 1.26425028e-01\n",
      " 9.93199646e-01 8.12045276e-01 8.81619871e-01 9.60467398e-01\n",
      " 9.99650717e-01 9.98733580e-01 9.99668241e-01 9.99999523e-01\n",
      " 9.99999881e-01 2.30341882e-01 8.30359757e-01 8.50332379e-01\n",
      " 8.61146510e-01 9.96263564e-01 9.63030934e-01 9.64478731e-01\n",
      " 9.99946475e-01 9.99981165e-01 9.98717785e-01 9.99999404e-01\n",
      " 1.00000000e+00 9.99737799e-01 9.99971032e-01 7.75779486e-01\n",
      " 8.10982168e-01 8.42826128e-01 9.84215915e-01 8.52128208e-01\n",
      " 1.27565935e-01 4.50574905e-01 9.98441994e-01 7.66387105e-01\n",
      " 8.17276597e-01 9.99980092e-01 9.60116506e-01 9.93051767e-01\n",
      " 5.45186980e-04 8.03177834e-01 7.74333417e-01 8.93394411e-01\n",
      " 2.36556679e-01 9.89787459e-01 2.03775913e-01 7.09128439e-01\n",
      " 6.37845159e-01 7.86130309e-01 9.99963403e-01 7.73590803e-03\n",
      " 4.09098156e-02 9.07619596e-01 3.07170182e-01 2.51997635e-02\n",
      " 9.52561617e-01 5.78665793e-01 5.38671529e-03 2.24238455e-01\n",
      " 7.95278966e-01 1.70034319e-01]\n",
      "predict [0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 256 [0/54 (0%)]\tTrain Loss: 0.003841\n",
      "Train Epoch: 256 [8/54 (15%)]\tTrain Loss: 0.010288\n",
      "Train Epoch: 256 [16/54 (30%)]\tTrain Loss: 0.004828\n",
      "Train Epoch: 256 [24/54 (44%)]\tTrain Loss: 0.006227\n",
      "Train Epoch: 256 [32/54 (59%)]\tTrain Loss: 0.004968\n",
      "Train Epoch: 256 [40/54 (74%)]\tTrain Loss: 0.027254\n",
      "Train Epoch: 256 [48/54 (89%)]\tTrain Loss: 0.015547\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.96528654e-02 9.99566019e-01 9.99479592e-01 9.10444915e-01\n",
      " 8.04265738e-01 6.24091038e-03 9.90715742e-01 9.93525743e-01\n",
      " 2.38033179e-02 2.38505006e-01 5.77919364e-01 2.65029003e-03\n",
      " 5.83929539e-01 4.01623838e-04 4.44275528e-01 1.16524461e-03\n",
      " 4.72326006e-04 3.21743369e-01 1.56956181e-01 3.57700765e-01\n",
      " 1.06903380e-02 9.72383976e-01 9.99640346e-01 9.13650393e-01\n",
      " 4.27530348e-01 9.99801338e-01 9.91746426e-01 6.54327452e-01\n",
      " 3.49129476e-02 4.03759331e-02 9.12097871e-01 8.74394834e-01\n",
      " 9.80405211e-01 1.44002042e-04 2.95341510e-04 4.08782996e-02\n",
      " 7.76955068e-01 9.95532990e-01 1.85223240e-02 3.42939189e-03\n",
      " 1.03368354e-03 1.73570449e-03 4.24808264e-03 3.53451699e-01\n",
      " 1.10821128e-01 2.79841065e-01 9.99929667e-01 9.97883856e-01\n",
      " 1.00000000e+00 7.34461308e-01 1.00000000e+00 1.61277503e-02\n",
      " 2.46938970e-03 5.73594987e-01 1.46503467e-03 2.63340480e-04\n",
      " 9.96977091e-01 2.23394558e-02 2.29223445e-02 2.98433900e-01\n",
      " 9.99768436e-01 9.51050401e-01 9.99449193e-01 9.99946594e-01\n",
      " 9.99952912e-01 9.99872446e-01 9.99921083e-01 9.99998689e-01\n",
      " 1.00000000e+00 9.27207530e-01 9.89064038e-01 9.87629294e-01\n",
      " 9.99983907e-01 9.99943852e-01 9.99676704e-01 9.99997139e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999523e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999523e-01 9.99999881e-01 7.79693797e-02\n",
      " 6.38045371e-01 9.89571452e-01 9.97170150e-01 9.94839013e-01\n",
      " 2.17371479e-01 8.25305820e-01 9.97203827e-01 9.80038464e-01\n",
      " 8.40086162e-01 9.99338210e-01 9.98930991e-01 9.98418450e-01\n",
      " 6.64631254e-04 8.63580287e-01 8.48415315e-01 8.74573588e-01\n",
      " 1.24888562e-01 9.99964476e-01 6.95989877e-02 9.88712907e-01\n",
      " 9.98360336e-01 6.88694477e-01 9.99999285e-01 2.43767630e-02\n",
      " 1.36839086e-02 9.36401963e-01 1.46489218e-01 1.13377020e-01\n",
      " 9.84299660e-01 8.79185915e-01 1.20579591e-02 1.49685428e-01\n",
      " 9.80148494e-01 9.80786502e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 257 [0/54 (0%)]\tTrain Loss: 0.010187\n",
      "Train Epoch: 257 [8/54 (15%)]\tTrain Loss: 0.004346\n",
      "Train Epoch: 257 [16/54 (30%)]\tTrain Loss: 0.000837\n",
      "Train Epoch: 257 [24/54 (44%)]\tTrain Loss: 0.011440\n",
      "Train Epoch: 257 [32/54 (59%)]\tTrain Loss: 0.015984\n",
      "Train Epoch: 257 [40/54 (74%)]\tTrain Loss: 0.079998\n",
      "Train Epoch: 257 [48/54 (89%)]\tTrain Loss: 0.011512\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.55761183e-04 2.72080600e-02 1.80350225e-02 2.64292598e-01\n",
      " 8.05081800e-02 1.07541168e-03 1.06963264e-02 9.07375634e-01\n",
      " 2.03298852e-02 5.17024584e-02 7.79990613e-01 2.63505033e-03\n",
      " 4.63187397e-01 1.78597048e-07 7.56784400e-04 4.36492264e-04\n",
      " 1.25789805e-03 2.03682240e-02 8.64393532e-01 1.28389642e-01\n",
      " 3.86089832e-02 8.96232486e-01 9.96585608e-01 9.99806821e-01\n",
      " 8.67590755e-02 9.99995947e-01 9.99971747e-01 4.08667743e-01\n",
      " 8.02590977e-03 2.71703000e-04 5.26985884e-01 5.66846192e-01\n",
      " 1.03082202e-01 1.71071180e-04 3.50260925e-05 1.64025376e-04\n",
      " 3.53547260e-02 9.78182197e-01 2.31138343e-04 2.69223121e-04\n",
      " 7.16722716e-05 5.22315422e-05 9.27049841e-05 1.10345753e-03\n",
      " 3.18305306e-02 2.08818470e-03 9.84729230e-01 3.06876987e-01\n",
      " 9.97175336e-01 9.76314545e-01 9.97932673e-01 1.65252073e-04\n",
      " 2.12046434e-03 5.40993235e-04 2.15584156e-03 5.03485498e-04\n",
      " 8.36599648e-01 4.69088601e-03 1.39603233e-02 5.63377514e-04\n",
      " 9.72642183e-01 3.51972342e-01 8.60497236e-01 9.56721008e-01\n",
      " 8.79505038e-01 5.61376035e-01 9.95462358e-01 9.99713600e-01\n",
      " 9.99977946e-01 1.54855937e-01 6.81411684e-01 7.69703686e-01\n",
      " 9.99830484e-01 9.99511480e-01 9.99125540e-01 9.70151603e-01\n",
      " 9.98011589e-01 9.99216676e-01 9.25755978e-01 9.99989271e-01\n",
      " 9.99999881e-01 9.99992609e-01 9.99986172e-01 7.55431177e-03\n",
      " 4.22456302e-02 5.59587061e-01 7.76333272e-01 7.06464767e-01\n",
      " 1.75557062e-01 8.01362634e-01 9.99116600e-01 2.62129068e-01\n",
      " 1.08501367e-01 9.99998093e-01 9.99620318e-01 9.99792516e-01\n",
      " 1.52594259e-03 2.92157177e-02 4.00941670e-01 9.93052661e-01\n",
      " 1.64606012e-02 9.73864734e-01 1.39453962e-01 9.89675224e-01\n",
      " 9.98089969e-01 9.35238659e-01 9.99998093e-01 5.57262730e-03\n",
      " 1.10223722e-02 8.57624710e-01 1.17729589e-01 1.04085985e-03\n",
      " 9.85910058e-01 9.26065803e-01 3.52754109e-02 4.28486150e-03\n",
      " 3.05405378e-01 3.02814171e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 258 [0/54 (0%)]\tTrain Loss: 0.060966\n",
      "Train Epoch: 258 [8/54 (15%)]\tTrain Loss: 0.000935\n",
      "Train Epoch: 258 [16/54 (30%)]\tTrain Loss: 0.005476\n",
      "Train Epoch: 258 [24/54 (44%)]\tTrain Loss: 0.000547\n",
      "Train Epoch: 258 [32/54 (59%)]\tTrain Loss: 0.022270\n",
      "Train Epoch: 258 [40/54 (74%)]\tTrain Loss: 0.000545\n",
      "Train Epoch: 258 [48/54 (89%)]\tTrain Loss: 0.059781\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.90837717e-03 9.97810900e-01 9.95282948e-01 9.85520899e-01\n",
      " 9.47951138e-01 5.74997291e-02 9.96844172e-01 9.81259048e-01\n",
      " 4.61194694e-01 5.76341629e-01 4.36171383e-01 3.18495035e-02\n",
      " 4.36516881e-01 5.08950278e-03 1.70345619e-01 1.57989096e-02\n",
      " 2.07199026e-02 3.95692259e-01 9.91499126e-01 2.70005375e-01\n",
      " 1.34940565e-01 9.85650480e-01 9.99976397e-01 9.99816239e-01\n",
      " 5.22233427e-01 1.00000000e+00 9.99957800e-01 9.76765871e-01\n",
      " 9.16120231e-01 3.33342314e-01 7.31992573e-02 9.61915910e-01\n",
      " 5.70547879e-01 7.80292103e-05 6.61162994e-05 3.89809310e-02\n",
      " 4.35911834e-01 9.97233808e-01 4.30873083e-03 6.21993914e-02\n",
      " 2.75371457e-03 3.15909437e-03 2.01817229e-03 6.34720385e-01\n",
      " 3.76304209e-01 2.25794651e-02 7.27475822e-01 8.80426228e-01\n",
      " 9.99991655e-01 9.41399097e-01 9.99759495e-01 2.01715366e-03\n",
      " 1.97249711e-01 4.94097918e-02 2.19790023e-02 3.64161022e-02\n",
      " 6.47740543e-01 1.38922513e-01 8.15608576e-02 2.93198735e-01\n",
      " 9.74976242e-01 5.03731668e-01 9.74890471e-01 9.96683300e-01\n",
      " 9.94185150e-01 9.99825060e-01 9.99725401e-01 9.99997377e-01\n",
      " 9.99999046e-01 4.97444987e-01 8.98862600e-01 9.26507175e-01\n",
      " 9.98418093e-01 9.98505950e-01 9.96674895e-01 9.92517829e-01\n",
      " 9.99999404e-01 9.99999881e-01 9.99966383e-01 9.99994516e-01\n",
      " 9.99999404e-01 9.97578084e-01 9.99977589e-01 2.98682779e-01\n",
      " 7.21415818e-01 9.28149939e-01 9.76869941e-01 9.73415911e-01\n",
      " 7.01766133e-01 9.90367174e-01 9.95936036e-01 4.98330563e-01\n",
      " 5.34823060e-01 9.99990940e-01 9.96823430e-01 9.97238636e-01\n",
      " 9.72581655e-03 4.84206706e-01 9.21089172e-01 9.41539466e-01\n",
      " 3.09367955e-01 9.94949818e-01 1.59407184e-01 9.89576221e-01\n",
      " 9.60029781e-01 9.92015243e-01 9.99831080e-01 2.73437165e-02\n",
      " 1.10593013e-01 9.96514916e-01 9.06045586e-02 3.81953120e-02\n",
      " 9.64059412e-01 9.38250721e-01 1.21364281e-01 1.71874315e-01\n",
      " 9.29539025e-01 9.77045178e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 259 [0/54 (0%)]\tTrain Loss: 0.000367\n",
      "Train Epoch: 259 [8/54 (15%)]\tTrain Loss: 0.071798\n",
      "Train Epoch: 259 [16/54 (30%)]\tTrain Loss: 0.002301\n",
      "Train Epoch: 259 [24/54 (44%)]\tTrain Loss: 0.063859\n",
      "Train Epoch: 259 [32/54 (59%)]\tTrain Loss: 0.040044\n",
      "Train Epoch: 259 [40/54 (74%)]\tTrain Loss: 0.034870\n",
      "Train Epoch: 259 [48/54 (89%)]\tTrain Loss: 0.058029\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.00194155 0.99081832 0.99929225 0.95085829 0.48321626 0.00372282\n",
      " 0.94236499 0.76072752 0.04951993 0.72846854 0.8109743  0.10311826\n",
      " 0.00456676 0.00107909 0.01417298 0.00196917 0.00224299 0.47580937\n",
      " 0.32736468 0.06522824 0.00524085 0.95967758 0.99808073 0.91452235\n",
      " 0.44203386 0.99972802 0.99836498 0.84504563 0.96538568 0.76569873\n",
      " 0.6535458  0.99522239 0.871948   0.00173779 0.00114374 0.4186109\n",
      " 0.54055911 0.9800204  0.05248433 0.11724784 0.00564305 0.00266766\n",
      " 0.03086297 0.57360834 0.7470178  0.25377452 0.73958665 0.66865474\n",
      " 0.99999702 0.95245105 0.99997914 0.15846543 0.00143313 0.09571051\n",
      " 0.00274806 0.001075   0.5687927  0.68810779 0.03556499 0.03229427\n",
      " 0.99946481 0.85276139 0.98675901 0.99787152 0.95756274 0.99525815\n",
      " 0.99601364 0.9993524  0.99996257 0.66350734 0.96924555 0.87960869\n",
      " 0.99954945 0.99854493 0.98935449 0.99303597 0.99999785 0.99806076\n",
      " 0.99982589 0.99998307 0.9999994  0.99979287 0.99966288 0.04208321\n",
      " 0.74165583 0.99165994 0.98585814 0.99196666 0.03006746 0.43886578\n",
      " 0.96742398 0.95897186 0.87785906 0.99725866 0.9895215  0.99649042\n",
      " 0.02324861 0.94442964 0.99358118 0.81064534 0.20338154 0.9961527\n",
      " 0.03345383 0.85232651 0.92823672 0.93913621 0.99960047 0.02546857\n",
      " 0.02913416 0.9830572  0.02554794 0.69452357 0.86603814 0.98229951\n",
      " 0.12940043 0.32178521 0.92849308 0.8477906 ]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 260 [0/54 (0%)]\tTrain Loss: 0.003400\n",
      "Train Epoch: 260 [8/54 (15%)]\tTrain Loss: 0.008474\n",
      "Train Epoch: 260 [16/54 (30%)]\tTrain Loss: 0.002935\n",
      "Train Epoch: 260 [24/54 (44%)]\tTrain Loss: 0.044157\n",
      "Train Epoch: 260 [32/54 (59%)]\tTrain Loss: 0.001527\n",
      "Train Epoch: 260 [40/54 (74%)]\tTrain Loss: 0.010572\n",
      "Train Epoch: 260 [48/54 (89%)]\tTrain Loss: 0.048435\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.77494847e-04 9.28284287e-01 8.83287609e-01 6.59669280e-01\n",
      " 3.11656445e-01 3.92297312e-04 9.23322976e-01 6.12049460e-01\n",
      " 1.04744919e-02 5.37042439e-01 5.49498558e-01 4.92480677e-03\n",
      " 1.72156423e-01 5.55366976e-04 1.14991972e-02 2.06975499e-03\n",
      " 2.15187762e-03 2.17259191e-02 9.85799432e-02 1.03134485e-02\n",
      " 1.25716934e-02 8.78548145e-01 9.95864511e-01 9.86836910e-01\n",
      " 1.23376764e-01 9.99943733e-01 9.99947429e-01 9.29138422e-01\n",
      " 2.51260877e-01 4.00647730e-01 3.92896205e-01 9.11321998e-01\n",
      " 8.56750429e-01 4.19085799e-03 9.72304679e-03 4.74499196e-01\n",
      " 1.54868513e-01 3.80915582e-01 4.18943167e-03 1.30494144e-02\n",
      " 1.24149106e-03 3.50404195e-02 3.82021675e-03 6.80755258e-01\n",
      " 1.36639699e-01 8.92684516e-03 4.12285447e-01 6.40779972e-01\n",
      " 9.99996901e-01 9.47771907e-01 9.99967337e-01 1.33489547e-02\n",
      " 3.01858224e-03 3.92837226e-02 1.60198752e-03 2.02175174e-02\n",
      " 4.60841358e-01 3.93880725e-01 1.40678473e-02 6.36088848e-02\n",
      " 9.97582197e-01 6.94062531e-01 9.81020689e-01 9.98575211e-01\n",
      " 9.88677919e-01 9.98001039e-01 9.85169828e-01 9.99556124e-01\n",
      " 9.99951720e-01 6.86720490e-01 8.90369833e-01 6.30115330e-01\n",
      " 9.99711215e-01 9.99471962e-01 9.94996548e-01 9.04249728e-01\n",
      " 9.99933720e-01 9.99946952e-01 9.98665094e-01 9.99925017e-01\n",
      " 9.99997735e-01 9.99649763e-01 9.99556363e-01 3.27084120e-03\n",
      " 1.36362895e-01 7.07269013e-01 7.00719774e-01 8.31570327e-01\n",
      " 3.85442376e-02 9.60517645e-01 9.83350694e-01 9.65562046e-01\n",
      " 7.34214544e-01 9.99970436e-01 9.94163215e-01 9.99513268e-01\n",
      " 3.88222411e-02 1.78991616e-01 8.71547878e-01 9.71379042e-01\n",
      " 4.35199216e-02 9.86819029e-01 1.09752379e-02 9.70729887e-01\n",
      " 9.13744032e-01 7.05334485e-01 9.99940515e-01 3.06888483e-02\n",
      " 6.15410320e-02 9.27129745e-01 1.64598048e-01 6.27668798e-01\n",
      " 9.92309809e-01 9.23708797e-01 4.62223403e-02 9.43969190e-03\n",
      " 4.02611673e-01 3.65740478e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 38 FN= 13 FP= 22\n",
      "TP+FP 67\n",
      "precision 0.6716417910447762\n",
      "recall 0.7758620689655172\n",
      "F1 0.7200000000000001\n",
      "acc 0.7033898305084746\n",
      "AUCp 0.7045977011494253\n",
      "AUC 0.7663793103448275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 260, average recall: 0.7759, average precision: 0.6716,average F1: 0.7200, average accuracy: 0.7034, average AUC: 0.7664\n",
      "Train Epoch: 261 [0/54 (0%)]\tTrain Loss: 0.006267\n",
      "Train Epoch: 261 [8/54 (15%)]\tTrain Loss: 0.039933\n",
      "Train Epoch: 261 [16/54 (30%)]\tTrain Loss: 0.002723\n",
      "Train Epoch: 261 [24/54 (44%)]\tTrain Loss: 0.000814\n",
      "Train Epoch: 261 [32/54 (59%)]\tTrain Loss: 0.003073\n",
      "Train Epoch: 261 [40/54 (74%)]\tTrain Loss: 0.013788\n",
      "Train Epoch: 261 [48/54 (89%)]\tTrain Loss: 0.009360\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.00748206 0.99751174 0.97626013 0.99006885 0.9749459  0.00493593\n",
      " 0.9983058  0.99939656 0.00910705 0.57821637 0.92437106 0.13799866\n",
      " 0.99446702 0.01503881 0.81578273 0.17652366 0.90256995 0.98762637\n",
      " 0.98958218 0.88938397 0.67625093 0.94782138 0.99996734 0.99999702\n",
      " 0.83907056 1.         1.         0.99997449 0.12806812 0.08928211\n",
      " 0.99221206 0.99778807 0.99934155 0.9407869  0.16310373 0.71578747\n",
      " 0.61215407 0.99836785 0.21754171 0.3269738  0.24107563 0.60671973\n",
      " 0.21950924 0.95618379 0.76353961 0.04224681 0.99927586 0.99440926\n",
      " 1.         0.99996305 0.99997878 0.61022472 0.98672456 0.85081017\n",
      " 0.03806916 0.89145952 0.99922299 0.57639122 0.07049868 0.96369195\n",
      " 0.99961472 0.91383255 0.99798632 0.99986637 0.99990559 0.99999952\n",
      " 1.         0.99999976 0.99999237 0.6735158  0.77424443 0.94607633\n",
      " 0.99999845 0.99999917 0.99999595 0.99334151 0.99999249 0.99999952\n",
      " 0.99993646 1.         1.         0.99999976 0.99999976 0.05555268\n",
      " 0.76105207 0.99344468 0.99824983 0.99907517 0.9378925  0.99998069\n",
      " 0.9999994  0.99949384 0.99745971 1.         0.99999344 0.99999905\n",
      " 0.2412682  0.92828017 0.92127442 0.99993694 0.2954303  0.99998188\n",
      " 0.77029753 0.99999952 0.99993074 0.9880482  1.         0.84226888\n",
      " 0.31236625 0.99983406 0.99892408 0.83135319 0.9999963  0.99982506\n",
      " 0.77718133 0.02942617 0.86724323 0.99993968]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 262 [0/54 (0%)]\tTrain Loss: 0.002720\n",
      "Train Epoch: 262 [8/54 (15%)]\tTrain Loss: 0.009755\n",
      "Train Epoch: 262 [16/54 (30%)]\tTrain Loss: 0.026879\n",
      "Train Epoch: 262 [24/54 (44%)]\tTrain Loss: 0.020946\n",
      "Train Epoch: 262 [32/54 (59%)]\tTrain Loss: 0.000429\n",
      "Train Epoch: 262 [40/54 (74%)]\tTrain Loss: 0.006008\n",
      "Train Epoch: 262 [48/54 (89%)]\tTrain Loss: 0.006805\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.13658583e-01 9.97124851e-01 9.97328401e-01 9.93502438e-01\n",
      " 9.44101691e-01 8.67152810e-02 9.95996952e-01 9.95080709e-01\n",
      " 2.52531022e-01 9.26781416e-01 7.18131006e-01 8.92562978e-03\n",
      " 7.50099361e-01 2.67936429e-03 9.12064433e-01 1.89436466e-01\n",
      " 1.22352637e-01 6.43419683e-01 9.92731750e-01 4.84647721e-01\n",
      " 2.05047987e-02 9.94885147e-01 9.99967098e-01 9.99972224e-01\n",
      " 4.33393478e-01 1.00000000e+00 9.99999046e-01 9.78721797e-01\n",
      " 3.90643865e-01 2.68351287e-01 9.98469889e-01 9.99841094e-01\n",
      " 9.77702022e-01 8.81054846e-04 1.78826519e-03 5.43226838e-01\n",
      " 7.01894522e-01 9.99950290e-01 4.12875377e-02 3.36459190e-01\n",
      " 2.02586874e-01 4.99925345e-01 3.28527302e-01 9.42826867e-01\n",
      " 9.86766636e-01 5.16273677e-01 9.99856830e-01 9.98773992e-01\n",
      " 1.00000000e+00 9.99616623e-01 1.00000000e+00 4.22722995e-01\n",
      " 4.85710829e-01 3.80798787e-01 3.31923477e-02 7.10963756e-02\n",
      " 9.88365054e-01 5.20154476e-01 9.60720181e-01 9.20866728e-01\n",
      " 9.96906221e-01 8.35384429e-01 9.85874295e-01 9.99691129e-01\n",
      " 9.99167085e-01 9.99997377e-01 9.99998808e-01 9.99999762e-01\n",
      " 9.99997735e-01 8.17888975e-01 9.95592654e-01 9.72226441e-01\n",
      " 9.99996424e-01 9.98600304e-01 9.99602377e-01 9.98555601e-01\n",
      " 9.99999881e-01 1.00000000e+00 9.99982476e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999046e-01 9.99998331e-01 3.68155479e-01\n",
      " 8.90175104e-01 9.97750103e-01 9.99622464e-01 9.98801589e-01\n",
      " 6.85681462e-01 9.99601185e-01 1.00000000e+00 9.88487363e-01\n",
      " 8.22348833e-01 1.00000000e+00 9.95310128e-01 9.99987960e-01\n",
      " 1.28144249e-01 7.70135939e-01 9.63844895e-01 9.99988794e-01\n",
      " 6.19936526e-01 9.99761045e-01 2.94696689e-01 9.91290212e-01\n",
      " 9.47440505e-01 9.59211409e-01 1.00000000e+00 1.91372216e-01\n",
      " 9.42235887e-02 9.99892950e-01 8.56809735e-01 8.80933642e-01\n",
      " 9.87409770e-01 9.77908969e-01 4.26244706e-01 1.87107831e-01\n",
      " 6.13541424e-01 9.66109157e-01]\n",
      "predict [1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 263 [0/54 (0%)]\tTrain Loss: 0.001070\n",
      "Train Epoch: 263 [8/54 (15%)]\tTrain Loss: 0.007557\n",
      "Train Epoch: 263 [16/54 (30%)]\tTrain Loss: 0.000781\n",
      "Train Epoch: 263 [24/54 (44%)]\tTrain Loss: 0.006189\n",
      "Train Epoch: 263 [32/54 (59%)]\tTrain Loss: 0.001511\n",
      "Train Epoch: 263 [40/54 (74%)]\tTrain Loss: 0.001924\n",
      "Train Epoch: 263 [48/54 (89%)]\tTrain Loss: 0.013809\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.63578894e-03 3.74404266e-02 3.40469182e-02 5.52728891e-01\n",
      " 2.86292702e-01 3.94399249e-04 9.15123448e-02 4.78200436e-01\n",
      " 1.87825672e-02 1.67719230e-01 1.70566648e-01 3.54409777e-03\n",
      " 2.50009745e-01 5.77420496e-06 1.97216286e-03 3.69430031e-03\n",
      " 9.48040467e-03 2.57803295e-02 1.91211894e-01 6.78230822e-03\n",
      " 6.73127652e-04 7.04388738e-01 9.96524394e-01 9.89286125e-01\n",
      " 1.21806143e-02 9.99982119e-01 9.99992490e-01 3.04188460e-01\n",
      " 7.74146570e-03 6.66547194e-02 7.97259152e-01 4.18201923e-01\n",
      " 6.79211378e-01 1.56891216e-02 6.69475761e-04 6.65895417e-02\n",
      " 3.04072909e-02 9.75962579e-01 2.95725698e-03 9.52639896e-03\n",
      " 2.95046833e-03 2.39764936e-02 2.54265824e-03 1.35113880e-01\n",
      " 7.29935050e-01 1.72765914e-03 9.54964399e-01 7.31347024e-01\n",
      " 1.00000000e+00 9.97778594e-01 9.99998569e-01 1.92341227e-02\n",
      " 2.52578495e-04 1.10455742e-02 1.26451505e-02 2.30984343e-03\n",
      " 9.21900809e-01 2.48886466e-01 5.78268319e-02 3.10884527e-04\n",
      " 6.49606586e-01 5.02553105e-01 5.90349138e-01 8.11227024e-01\n",
      " 9.40812826e-01 9.91041362e-01 9.99839187e-01 9.99100327e-01\n",
      " 9.99977231e-01 6.83732986e-01 5.68583965e-01 2.67833591e-01\n",
      " 9.99888659e-01 9.99231815e-01 9.65098262e-01 6.75650895e-01\n",
      " 9.90197301e-01 9.98895764e-01 9.29539442e-01 9.99717891e-01\n",
      " 9.99999762e-01 9.99653697e-01 9.99840856e-01 6.00160426e-03\n",
      " 2.46028319e-01 6.84447527e-01 8.35501850e-01 6.53983057e-01\n",
      " 2.97386553e-02 2.77873248e-01 9.99991894e-01 6.00788593e-01\n",
      " 1.92222267e-01 9.99999523e-01 9.99624610e-01 9.99951243e-01\n",
      " 2.66174972e-02 7.83298258e-03 8.54297459e-01 9.99990702e-01\n",
      " 7.36505464e-02 8.92730474e-01 4.63229883e-03 6.58146560e-01\n",
      " 9.83401120e-01 5.01836181e-01 9.99999762e-01 6.84910733e-03\n",
      " 3.49289477e-02 9.99664426e-01 9.89614427e-01 9.36148107e-01\n",
      " 9.99590814e-01 7.38601685e-01 3.00596148e-01 1.63583048e-02\n",
      " 5.12903452e-01 7.13073492e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 264 [0/54 (0%)]\tTrain Loss: 0.001043\n",
      "Train Epoch: 264 [8/54 (15%)]\tTrain Loss: 0.009597\n",
      "Train Epoch: 264 [16/54 (30%)]\tTrain Loss: 0.033101\n",
      "Train Epoch: 264 [24/54 (44%)]\tTrain Loss: 0.003673\n",
      "Train Epoch: 264 [32/54 (59%)]\tTrain Loss: 0.004944\n",
      "Train Epoch: 264 [40/54 (74%)]\tTrain Loss: 0.148850\n",
      "Train Epoch: 264 [48/54 (89%)]\tTrain Loss: 0.006508\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.00205385 0.97507066 0.83455533 0.98669004 0.73429668 0.04368548\n",
      " 0.92094147 0.85850477 0.1293823  0.77855176 0.77089858 0.16540021\n",
      " 0.71736091 0.00898374 0.38200843 0.05261104 0.00915906 0.20472121\n",
      " 0.12506223 0.14137121 0.01102849 0.90007955 0.99434859 0.99891889\n",
      " 0.08296065 0.99975401 0.99997854 0.77046847 0.11046532 0.08278881\n",
      " 0.1993601  0.81095529 0.06080359 0.00244454 0.00769899 0.13434796\n",
      " 0.08907505 0.57083166 0.05847468 0.12871699 0.05554225 0.12936129\n",
      " 0.0129251  0.3402012  0.62726331 0.00190981 0.99736565 0.9924137\n",
      " 0.99999976 0.99737835 0.99993122 0.04960058 0.09682565 0.08449291\n",
      " 0.02780202 0.02223071 0.94446206 0.03584649 0.39207441 0.76306552\n",
      " 0.99882227 0.95507061 0.98200536 0.99912971 0.9873957  0.86816251\n",
      " 0.9811368  0.99801183 0.99989235 0.92864221 0.97668636 0.97883713\n",
      " 0.99764556 0.99885654 0.92053884 0.99469322 0.99999869 0.99998271\n",
      " 0.99987411 0.99992895 0.99995255 0.99763167 0.99989629 0.64498603\n",
      " 0.91670662 0.96783376 0.99912363 0.99836701 0.07128716 0.77609289\n",
      " 0.99873811 0.61300552 0.64081687 0.99986172 0.87893337 0.98741478\n",
      " 0.05749247 0.93529159 0.75961739 0.99876261 0.62126756 0.9996444\n",
      " 0.2861006  0.79022002 0.81008452 0.68933928 0.99993718 0.01752198\n",
      " 0.03970907 0.89956111 0.550955   0.65381539 0.88394415 0.84959\n",
      " 0.32505476 0.09933174 0.05423968 0.61842626]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "Train Epoch: 265 [0/54 (0%)]\tTrain Loss: 0.035115\n",
      "Train Epoch: 265 [8/54 (15%)]\tTrain Loss: 0.016570\n",
      "Train Epoch: 265 [16/54 (30%)]\tTrain Loss: 0.018454\n",
      "Train Epoch: 265 [24/54 (44%)]\tTrain Loss: 0.020231\n",
      "Train Epoch: 265 [32/54 (59%)]\tTrain Loss: 0.003146\n",
      "Train Epoch: 265 [40/54 (74%)]\tTrain Loss: 0.070273\n",
      "Train Epoch: 265 [48/54 (89%)]\tTrain Loss: 0.010995\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.04029672e-02 2.77777493e-01 2.47187972e-01 3.94943684e-01\n",
      " 3.23736854e-02 3.51626333e-03 8.88544600e-03 2.62377530e-01\n",
      " 1.72051489e-02 5.02512567e-02 2.36065865e-01 9.81986872e-04\n",
      " 4.33151722e-01 5.13651539e-05 1.12047635e-01 4.90623899e-03\n",
      " 2.77369842e-03 1.63983315e-01 2.19970390e-01 5.30399978e-01\n",
      " 6.32138476e-02 9.48008299e-01 9.99287903e-01 9.99997854e-01\n",
      " 4.04814184e-01 9.99985218e-01 1.00000000e+00 8.54500353e-01\n",
      " 9.39960927e-02 3.28570992e-01 9.90266860e-01 9.47696090e-01\n",
      " 9.96132731e-01 1.28595252e-03 1.15795723e-04 4.60268930e-03\n",
      " 1.13198366e-02 4.57403719e-01 2.60626501e-03 3.00080944e-02\n",
      " 6.26781676e-03 5.98741183e-03 1.05890771e-02 1.97936535e-01\n",
      " 8.11137259e-01 3.95112813e-01 9.99926209e-01 9.56176579e-01\n",
      " 1.00000000e+00 9.99829531e-01 9.99998331e-01 4.12191497e-03\n",
      " 2.58303247e-02 1.93170924e-02 8.55620354e-02 3.88796703e-04\n",
      " 9.97671306e-01 2.62788590e-02 7.00033363e-03 4.03795391e-01\n",
      " 9.99946594e-01 9.27784979e-01 9.99489188e-01 9.99960780e-01\n",
      " 9.99989748e-01 9.93817031e-01 9.94765639e-01 9.99855280e-01\n",
      " 9.99739826e-01 5.83934665e-01 6.12554967e-01 7.54320920e-01\n",
      " 1.00000000e+00 9.99548852e-01 9.99611676e-01 9.99871373e-01\n",
      " 9.99165297e-01 9.93956685e-01 9.99779284e-01 9.99998927e-01\n",
      " 9.99995232e-01 9.99980211e-01 9.99969244e-01 3.99216823e-02\n",
      " 1.37747750e-01 9.98676836e-01 9.99587834e-01 9.89609599e-01\n",
      " 2.80194938e-01 8.50683093e-01 9.99999285e-01 6.53300643e-01\n",
      " 8.02701592e-01 9.99994993e-01 9.99279320e-01 9.99519110e-01\n",
      " 2.72440255e-01 4.63666439e-01 9.01433945e-01 9.99414444e-01\n",
      " 5.33716194e-03 9.99961853e-01 2.35365611e-02 8.41299534e-01\n",
      " 9.61579144e-01 9.42173004e-01 9.99998808e-01 4.59669530e-02\n",
      " 1.17255999e-02 9.08192396e-01 6.85582578e-01 8.07637931e-04\n",
      " 6.29865825e-01 8.07422519e-01 5.32584727e-01 2.59938896e-01\n",
      " 1.26014906e-03 1.15951039e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "Train Epoch: 266 [0/54 (0%)]\tTrain Loss: 0.042180\n",
      "Train Epoch: 266 [8/54 (15%)]\tTrain Loss: 0.006664\n",
      "Train Epoch: 266 [16/54 (30%)]\tTrain Loss: 0.013279\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.14701968e-02 4.84529555e-01 3.51842195e-01 2.98658490e-01\n",
      " 4.53198422e-03 1.84755865e-03 8.63985531e-03 3.02315261e-02\n",
      " 8.73268172e-02 7.98670411e-01 3.71208936e-01 2.06051953e-02\n",
      " 2.05036044e-01 1.78025930e-05 3.12019815e-03 5.45262126e-04\n",
      " 1.06251966e-02 6.15256190e-01 3.61452311e-01 4.28990275e-01\n",
      " 2.51395460e-02 9.96772349e-01 9.86320317e-01 9.85533774e-01\n",
      " 7.06074834e-01 9.98036921e-01 9.97473896e-01 8.42487276e-01\n",
      " 1.84194833e-01 1.88391864e-01 6.75840735e-01 9.33826685e-01\n",
      " 6.94475770e-01 1.86867881e-04 1.10746664e-03 1.59158558e-01\n",
      " 1.87959015e-01 6.81943119e-01 3.42999697e-02 4.16123085e-02\n",
      " 9.51706804e-03 1.66377693e-03 3.89365554e-02 3.67419362e-01\n",
      " 6.19259775e-01 8.83819982e-02 9.98153150e-01 9.68762755e-01\n",
      " 9.99996424e-01 9.72390294e-01 9.99691248e-01 4.41624857e-02\n",
      " 4.45349328e-03 7.33330175e-02 4.90752049e-02 4.40613396e-04\n",
      " 9.92733598e-01 4.53663245e-02 2.50064760e-01 1.70051923e-03\n",
      " 9.97143924e-01 5.83334744e-01 6.12916827e-01 9.88373756e-01\n",
      " 8.13838661e-01 8.84824038e-01 9.96953368e-01 9.99386430e-01\n",
      " 9.99933124e-01 2.37521827e-01 6.06278419e-01 7.69152105e-01\n",
      " 9.99986649e-01 9.84720230e-01 9.99268472e-01 9.99413133e-01\n",
      " 9.99946713e-01 9.99959826e-01 9.99839783e-01 9.99671221e-01\n",
      " 9.99971986e-01 9.99848962e-01 9.98319328e-01 1.59899667e-01\n",
      " 6.99899077e-01 9.90737021e-01 9.99729812e-01 9.98504400e-01\n",
      " 2.44110361e-01 7.76463091e-01 9.99640346e-01 9.08755958e-01\n",
      " 8.47657800e-01 9.99852180e-01 9.97497499e-01 9.95592535e-01\n",
      " 5.77529669e-02 8.19613755e-01 9.95596945e-01 9.50182259e-01\n",
      " 8.03732350e-02 9.97703969e-01 5.12827188e-02 8.78352702e-01\n",
      " 9.23028529e-01 6.95573866e-01 9.99825656e-01 4.91201431e-02\n",
      " 5.34304082e-02 9.24598753e-01 4.23030853e-02 4.66932088e-01\n",
      " 6.98176444e-01 7.13235557e-01 7.10216314e-02 7.41038263e-01\n",
      " 1.34820774e-01 1.14334486e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0.]\n",
      "Train Epoch: 267 [0/54 (0%)]\tTrain Loss: 0.006736\n",
      "Train Epoch: 267 [8/54 (15%)]\tTrain Loss: 0.003150\n",
      "Train Epoch: 267 [16/54 (30%)]\tTrain Loss: 0.003294\n",
      "Train Epoch: 267 [24/54 (44%)]\tTrain Loss: 0.059800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 267 [32/54 (59%)]\tTrain Loss: 0.005764\n",
      "Train Epoch: 267 [40/54 (74%)]\tTrain Loss: 0.003741\n",
      "Train Epoch: 267 [48/54 (89%)]\tTrain Loss: 0.005156\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.07712372 0.65730596 0.25672558 0.82724822 0.3769573  0.01931152\n",
      " 0.10766757 0.28721586 0.09880446 0.93257868 0.66323519 0.04002069\n",
      " 0.73947048 0.0121593  0.62160683 0.05530472 0.83589935 0.39616323\n",
      " 0.32451883 0.71838391 0.06375726 0.99640876 0.9990558  0.99897242\n",
      " 0.7764523  0.99997151 0.99989927 0.96639878 0.28339982 0.54858863\n",
      " 0.45025796 0.88332063 0.85560787 0.00356798 0.00624379 0.49600688\n",
      " 0.60702646 0.96010089 0.00209035 0.45354167 0.03011935 0.11569166\n",
      " 0.02801948 0.81775224 0.78151119 0.24193309 0.93941611 0.80559057\n",
      " 0.99999857 0.99109882 0.99914348 0.58219898 0.14441708 0.42615032\n",
      " 0.00883681 0.02624467 0.95353597 0.31613642 0.66738832 0.02706437\n",
      " 0.99354529 0.53100777 0.84066343 0.96617985 0.99877948 0.99946231\n",
      " 0.99903405 0.99998868 0.99999774 0.85773069 0.51073778 0.37045994\n",
      " 0.99998999 0.9959771  0.98542547 0.99481046 0.99989378 0.99998772\n",
      " 0.99995923 0.99926573 0.99999368 0.999569   0.99968553 0.05381884\n",
      " 0.53414834 0.94746685 0.99921608 0.99843484 0.75955194 0.99995935\n",
      " 0.99998689 0.97964925 0.94827044 0.99999583 0.99700242 0.99801278\n",
      " 0.15408868 0.35393035 0.99657577 0.99269861 0.03615624 0.98902953\n",
      " 0.1944292  0.96167582 0.96859187 0.89215362 0.99998271 0.54045498\n",
      " 0.43034554 0.99806207 0.96684098 0.73111463 0.9946031  0.84536034\n",
      " 0.30587    0.84247881 0.16447417 0.77355927]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "Train Epoch: 268 [0/54 (0%)]\tTrain Loss: 0.016429\n",
      "Train Epoch: 268 [8/54 (15%)]\tTrain Loss: 0.008610\n",
      "Train Epoch: 268 [16/54 (30%)]\tTrain Loss: 0.004067\n",
      "Train Epoch: 268 [24/54 (44%)]\tTrain Loss: 0.018066\n",
      "Train Epoch: 268 [32/54 (59%)]\tTrain Loss: 0.005077\n",
      "Train Epoch: 268 [40/54 (74%)]\tTrain Loss: 0.008190\n",
      "Train Epoch: 268 [48/54 (89%)]\tTrain Loss: 0.003214\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.80227941e-02 9.82144475e-01 9.58780348e-01 8.76897156e-01\n",
      " 4.50945139e-01 7.13642081e-03 5.89762449e-01 7.02928066e-01\n",
      " 3.75907272e-02 2.24907562e-01 1.06910259e-01 6.66392641e-03\n",
      " 4.09744948e-01 2.03767084e-02 5.64798295e-01 5.10510756e-03\n",
      " 2.09858879e-01 1.94696665e-01 3.72987092e-02 1.39671594e-01\n",
      " 2.92508467e-03 9.99851942e-01 9.99503255e-01 9.96610582e-01\n",
      " 5.58677137e-01 9.99969125e-01 9.99839664e-01 7.76463568e-01\n",
      " 1.42967463e-01 2.10368216e-01 6.77007616e-01 8.28754067e-01\n",
      " 9.68107164e-01 6.73683127e-04 3.39889247e-03 5.96644342e-01\n",
      " 1.51278675e-01 8.47286880e-01 3.45167555e-02 1.64360046e-01\n",
      " 3.09885275e-02 2.68449262e-02 2.87176892e-02 4.38582718e-01\n",
      " 4.13914740e-01 1.22587435e-01 9.95917261e-01 9.79564250e-01\n",
      " 1.00000000e+00 9.71821547e-01 9.99593079e-01 7.72459581e-02\n",
      " 9.11387578e-02 2.97047138e-01 3.45106423e-03 1.33366389e-02\n",
      " 9.20454562e-01 3.85605805e-02 2.79353887e-01 1.49684384e-01\n",
      " 9.75338101e-01 4.55916226e-01 6.46207154e-01 9.00747836e-01\n",
      " 9.98654723e-01 9.99697685e-01 9.98970747e-01 9.99935985e-01\n",
      " 9.99995232e-01 5.47129333e-01 3.87980819e-01 2.60107875e-01\n",
      " 9.99953032e-01 9.99486208e-01 9.90486443e-01 9.85016108e-01\n",
      " 9.99992132e-01 9.99997616e-01 9.99995708e-01 9.99985456e-01\n",
      " 9.99999285e-01 9.99736488e-01 9.99738991e-01 1.91455111e-01\n",
      " 6.84226334e-01 7.20137715e-01 9.95549321e-01 9.97502863e-01\n",
      " 7.03179389e-02 9.67419982e-01 9.93724167e-01 6.93031728e-01\n",
      " 7.49777555e-01 9.99986053e-01 9.81354773e-01 9.87714529e-01\n",
      " 3.10690720e-02 4.32128340e-01 7.34481633e-01 9.55983281e-01\n",
      " 2.37351730e-02 9.97689962e-01 5.02185412e-02 2.46307865e-01\n",
      " 7.98424304e-01 2.62492806e-01 9.99267399e-01 7.23199025e-02\n",
      " 8.30993615e-03 9.83125627e-01 1.64397225e-01 4.43400592e-02\n",
      " 9.89701271e-01 2.84702569e-01 5.43130469e-03 2.02873141e-01\n",
      " 3.91297698e-01 3.55308533e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 269 [0/54 (0%)]\tTrain Loss: 0.008595\n",
      "Train Epoch: 269 [8/54 (15%)]\tTrain Loss: 0.031624\n",
      "Train Epoch: 269 [16/54 (30%)]\tTrain Loss: 0.094933\n",
      "Train Epoch: 269 [24/54 (44%)]\tTrain Loss: 0.036681\n",
      "Train Epoch: 269 [32/54 (59%)]\tTrain Loss: 0.006083\n",
      "Train Epoch: 269 [40/54 (74%)]\tTrain Loss: 0.061382\n",
      "Train Epoch: 269 [48/54 (89%)]\tTrain Loss: 0.003969\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.13274472e-03 7.42011249e-01 5.52352369e-01 6.69988036e-01\n",
      " 7.77672082e-02 3.22621129e-03 8.76749277e-01 4.18133795e-01\n",
      " 2.77299285e-01 5.29077888e-01 1.50751784e-01 2.54995450e-02\n",
      " 9.57455486e-02 2.62589343e-02 1.82870373e-01 1.71942972e-02\n",
      " 1.18713900e-01 1.01138346e-01 2.69811422e-01 2.39916414e-01\n",
      " 8.32377991e-04 9.34875429e-01 9.96313870e-01 9.99381423e-01\n",
      " 5.53298630e-02 9.99832273e-01 9.99941111e-01 7.47952938e-01\n",
      " 2.27707878e-01 1.60057351e-01 4.83453274e-02 6.82685077e-01\n",
      " 1.12946212e-01 5.38549793e-04 1.10395448e-02 1.62341639e-01\n",
      " 4.34726551e-02 7.63706982e-01 1.76747739e-02 3.75311017e-01\n",
      " 7.18598366e-02 1.27543524e-01 2.75239274e-02 5.94994836e-02\n",
      " 1.20775245e-01 4.15877737e-02 6.70699120e-01 2.52326876e-01\n",
      " 9.99987364e-01 9.86831546e-01 9.76456046e-01 1.33824572e-01\n",
      " 2.34897174e-02 3.54421623e-02 1.46279810e-02 4.02464829e-02\n",
      " 7.65339255e-01 1.49597242e-01 4.28451091e-01 8.27124119e-02\n",
      " 8.88741910e-01 2.77821362e-01 6.35131180e-01 7.79488027e-01\n",
      " 8.00037742e-01 9.75275993e-01 9.79472935e-01 9.97714639e-01\n",
      " 9.99885559e-01 3.70702207e-01 2.81793684e-01 1.75546795e-01\n",
      " 9.99701321e-01 9.85334277e-01 5.42735577e-01 5.35059214e-01\n",
      " 9.99639392e-01 9.99848604e-01 9.98425603e-01 9.98339772e-01\n",
      " 9.99960661e-01 9.95678127e-01 9.97720182e-01 3.09885114e-01\n",
      " 3.94972384e-01 7.82755017e-01 9.54828322e-01 9.73111928e-01\n",
      " 2.63120145e-01 9.97820497e-01 9.99869347e-01 6.20170116e-01\n",
      " 3.28218341e-01 9.99976635e-01 7.37652004e-01 9.48532403e-01\n",
      " 3.19099650e-02 1.41710669e-01 6.70360923e-01 9.85739529e-01\n",
      " 2.10261140e-02 9.79171813e-01 7.31669813e-02 1.71651319e-01\n",
      " 2.38075867e-01 2.23002136e-01 9.99909282e-01 5.26274502e-01\n",
      " 3.57407480e-02 9.59169626e-01 4.83450949e-01 2.55977660e-01\n",
      " 9.94719744e-01 7.87808597e-01 3.81591558e-01 7.49775171e-02\n",
      " 3.55837584e-01 2.11521357e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 270 [0/54 (0%)]\tTrain Loss: 0.004147\n",
      "Train Epoch: 270 [8/54 (15%)]\tTrain Loss: 0.005097\n",
      "Train Epoch: 270 [16/54 (30%)]\tTrain Loss: 0.003592\n",
      "Train Epoch: 270 [24/54 (44%)]\tTrain Loss: 0.011895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 270 [32/54 (59%)]\tTrain Loss: 0.014999\n",
      "Train Epoch: 270 [40/54 (74%)]\tTrain Loss: 0.010636\n",
      "Train Epoch: 270 [48/54 (89%)]\tTrain Loss: 0.005598\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.32963900e-02 9.64367986e-01 9.21131372e-01 9.58432198e-01\n",
      " 1.24591745e-01 4.45285905e-03 7.28795648e-01 8.21590424e-01\n",
      " 3.32373857e-01 5.90354621e-01 3.14732969e-01 1.27365086e-02\n",
      " 1.79945871e-01 3.79729387e-03 8.31638351e-02 4.68953047e-03\n",
      " 1.78476438e-01 9.45387781e-02 8.62197101e-01 5.23843706e-01\n",
      " 2.73152278e-03 9.82603192e-01 9.99750793e-01 9.99731243e-01\n",
      " 5.86514547e-02 9.99990106e-01 9.99993443e-01 8.56881440e-01\n",
      " 5.16468108e-01 2.28305429e-01 5.35606980e-01 9.69919324e-01\n",
      " 7.04192698e-01 7.22923840e-04 3.08092707e-03 5.26874304e-01\n",
      " 1.59297764e-01 8.50392222e-01 1.62912104e-02 9.24428105e-02\n",
      " 2.58514192e-02 3.08128372e-02 2.02685855e-02 2.05408596e-02\n",
      " 3.79392952e-01 1.60786942e-01 9.96785045e-01 9.69783723e-01\n",
      " 9.99999881e-01 9.96385336e-01 9.99904513e-01 1.42234311e-01\n",
      " 8.51406809e-03 1.24479346e-01 3.85245197e-02 1.58447884e-02\n",
      " 9.57215309e-01 1.75654873e-01 2.58264720e-01 2.29062475e-02\n",
      " 9.97292697e-01 8.57435226e-01 9.57434356e-01 9.94186521e-01\n",
      " 9.04504299e-01 9.83517289e-01 9.99856234e-01 9.99852896e-01\n",
      " 9.99999762e-01 7.08059311e-01 9.35068786e-01 9.18949246e-01\n",
      " 9.99999762e-01 9.99950171e-01 9.84061182e-01 9.76175606e-01\n",
      " 9.99998808e-01 1.00000000e+00 9.99973059e-01 9.99999642e-01\n",
      " 1.00000000e+00 9.99999523e-01 9.99987125e-01 4.47539806e-01\n",
      " 8.36492717e-01 9.94786620e-01 9.97336328e-01 9.96084213e-01\n",
      " 7.06636906e-01 9.70590711e-01 9.99998450e-01 5.58899462e-01\n",
      " 4.53770965e-01 9.99998689e-01 9.98935282e-01 9.99864340e-01\n",
      " 7.92796835e-02 6.77490652e-01 9.98028815e-01 9.97451127e-01\n",
      " 7.66086280e-02 9.99940634e-01 2.60647178e-01 6.95180953e-01\n",
      " 9.77815986e-01 7.05462754e-01 9.99986768e-01 1.75500542e-01\n",
      " 1.94941144e-02 9.97682571e-01 7.59010077e-01 3.41932625e-01\n",
      " 9.99986291e-01 7.82889843e-01 2.92869389e-01 2.54145414e-01\n",
      " 9.78944182e-01 2.41138488e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 38 FN= 13 FP= 22\n",
      "TP+FP 67\n",
      "precision 0.6716417910447762\n",
      "recall 0.7758620689655172\n",
      "F1 0.7200000000000001\n",
      "acc 0.7033898305084746\n",
      "AUCp 0.7045977011494253\n",
      "AUC 0.7591954022988505\n",
      "\n",
      " The epoch is 270, average recall: 0.7759, average precision: 0.6716,average F1: 0.7200, average accuracy: 0.7034, average AUC: 0.7592\n",
      "Train Epoch: 271 [0/54 (0%)]\tTrain Loss: 0.004101\n",
      "Train Epoch: 271 [8/54 (15%)]\tTrain Loss: 0.008398\n",
      "Train Epoch: 271 [16/54 (30%)]\tTrain Loss: 0.001301\n",
      "Train Epoch: 271 [24/54 (44%)]\tTrain Loss: 0.000685\n",
      "Train Epoch: 271 [32/54 (59%)]\tTrain Loss: 0.001821\n",
      "Train Epoch: 271 [40/54 (74%)]\tTrain Loss: 0.014287\n",
      "Train Epoch: 271 [48/54 (89%)]\tTrain Loss: 0.014431\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.56223488e-02 9.83903766e-01 9.91506994e-01 9.94980752e-01\n",
      " 7.53136218e-01 3.92922051e-02 9.19842541e-01 9.61524308e-01\n",
      " 5.92625737e-01 8.85220230e-01 9.41044927e-01 9.99967828e-02\n",
      " 9.74606872e-01 2.13371981e-02 7.91164339e-01 6.76497594e-02\n",
      " 8.84704366e-02 7.10173011e-01 7.48531044e-01 6.48872495e-01\n",
      " 1.59665793e-02 9.99435127e-01 9.99862671e-01 9.99949932e-01\n",
      " 4.76350754e-01 9.99996662e-01 9.99986887e-01 9.92338181e-01\n",
      " 9.76235032e-01 9.86911178e-01 9.99972939e-01 9.99965906e-01\n",
      " 9.99994993e-01 2.84855603e-04 1.07822418e-02 6.94971502e-01\n",
      " 6.72131360e-01 9.71604049e-01 8.25285912e-01 8.03092420e-01\n",
      " 8.15511465e-01 7.52777934e-01 4.42074120e-01 8.61457944e-01\n",
      " 9.46119428e-01 9.98276353e-01 9.99999762e-01 9.99993205e-01\n",
      " 1.00000000e+00 9.99906421e-01 1.00000000e+00 1.67032287e-01\n",
      " 6.53558850e-01 9.24538553e-01 5.55317998e-01 1.28081203e-01\n",
      " 9.99908924e-01 4.33739692e-01 7.71336019e-01 9.47431505e-01\n",
      " 9.99995589e-01 9.99055684e-01 9.99946356e-01 9.99997854e-01\n",
      " 9.99981642e-01 9.99748886e-01 9.99831676e-01 9.99999762e-01\n",
      " 1.00000000e+00 9.88066554e-01 9.99431312e-01 9.99788821e-01\n",
      " 1.00000000e+00 9.99999404e-01 9.99998808e-01 9.99996305e-01\n",
      " 9.99999762e-01 9.99999642e-01 9.99999523e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 9.92617786e-01\n",
      " 9.94211972e-01 9.99998093e-01 9.99995589e-01 9.99988079e-01\n",
      " 4.93089110e-01 8.59854639e-01 9.99705851e-01 9.84175980e-01\n",
      " 9.92937386e-01 9.99995828e-01 9.99416232e-01 9.99323487e-01\n",
      " 3.34266096e-01 9.97917354e-01 9.97348666e-01 9.99554336e-01\n",
      " 7.73035705e-01 9.99999046e-01 4.72857326e-01 9.72334206e-01\n",
      " 9.96433854e-01 9.87597644e-01 9.99998808e-01 7.20951796e-01\n",
      " 2.81188607e-01 9.98304129e-01 6.89045250e-01 4.58072245e-01\n",
      " 9.99624610e-01 9.60153222e-01 3.15834761e-01 9.31069136e-01\n",
      " 9.08888578e-01 2.03964174e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0.]\n",
      "Train Epoch: 272 [0/54 (0%)]\tTrain Loss: 0.007671\n",
      "Train Epoch: 272 [8/54 (15%)]\tTrain Loss: 0.006679\n",
      "Train Epoch: 272 [16/54 (30%)]\tTrain Loss: 0.002741\n",
      "Train Epoch: 272 [24/54 (44%)]\tTrain Loss: 0.003089\n",
      "Train Epoch: 272 [32/54 (59%)]\tTrain Loss: 0.005933\n",
      "Train Epoch: 272 [40/54 (74%)]\tTrain Loss: 0.004576\n",
      "Train Epoch: 272 [48/54 (89%)]\tTrain Loss: 0.005259\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.98427916e-03 7.95633018e-01 8.53421032e-01 9.61898148e-01\n",
      " 3.21169376e-01 3.47403256e-04 8.93382668e-01 9.65360463e-01\n",
      " 1.10121056e-01 1.32727414e-01 5.97098291e-01 4.83113853e-03\n",
      " 6.75016046e-01 1.79522656e-04 2.48201475e-01 3.10794741e-04\n",
      " 5.02600987e-03 5.19698150e-02 7.12200522e-01 3.77490878e-01\n",
      " 2.09056612e-04 9.91563559e-01 9.97970760e-01 9.99771297e-01\n",
      " 1.83981210e-01 9.99982476e-01 9.99838948e-01 9.52535331e-01\n",
      " 4.59004372e-01 6.50034904e-01 5.60505211e-01 9.17888224e-01\n",
      " 8.59606564e-01 5.69947821e-04 2.51212204e-03 4.04234529e-01\n",
      " 4.99535382e-01 9.05965865e-01 7.74049258e-04 6.43800199e-02\n",
      " 3.20917666e-02 5.72496653e-02 1.75381526e-02 2.32215941e-01\n",
      " 3.70275050e-01 1.23508476e-01 9.79733229e-01 8.20354760e-01\n",
      " 9.99999642e-01 9.85895216e-01 9.99213457e-01 6.83098361e-02\n",
      " 9.02006589e-03 2.49076903e-01 1.20313810e-02 2.68226350e-03\n",
      " 9.08429623e-01 7.66846836e-02 2.76667804e-01 2.68931664e-03\n",
      " 8.81710172e-01 4.68782961e-01 7.34451532e-01 9.45914388e-01\n",
      " 7.82791853e-01 9.92922187e-01 9.95811701e-01 9.98811603e-01\n",
      " 9.99996066e-01 2.31286690e-01 5.10385752e-01 3.30882758e-01\n",
      " 9.99990463e-01 9.93020713e-01 9.70951915e-01 9.45268333e-01\n",
      " 9.99902844e-01 9.99940038e-01 9.96705830e-01 9.99987483e-01\n",
      " 9.99999046e-01 9.99943852e-01 9.99325514e-01 1.10996932e-01\n",
      " 4.50616747e-01 9.98113632e-01 9.85444009e-01 9.32217240e-01\n",
      " 5.36054671e-01 8.68523479e-01 9.99964118e-01 7.13508606e-01\n",
      " 4.89364624e-01 9.99995351e-01 9.98095334e-01 9.99745667e-01\n",
      " 5.60021475e-02 8.91365707e-01 9.88229156e-01 9.74068403e-01\n",
      " 5.16398139e-02 9.97132063e-01 3.13228756e-01 3.60914767e-01\n",
      " 8.16179335e-01 1.46080866e-01 9.99396205e-01 7.28868306e-01\n",
      " 1.61818899e-02 9.97573197e-01 7.85539925e-01 1.14575975e-01\n",
      " 9.98720586e-01 8.70919704e-01 1.21456143e-02 1.60375446e-01\n",
      " 8.59224617e-01 2.26032391e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 273 [0/54 (0%)]\tTrain Loss: 0.002020\n",
      "Train Epoch: 273 [8/54 (15%)]\tTrain Loss: 0.002222\n",
      "Train Epoch: 273 [16/54 (30%)]\tTrain Loss: 0.004244\n",
      "Train Epoch: 273 [24/54 (44%)]\tTrain Loss: 0.000684\n",
      "Train Epoch: 273 [32/54 (59%)]\tTrain Loss: 0.004733\n",
      "Train Epoch: 273 [40/54 (74%)]\tTrain Loss: 0.004305\n",
      "Train Epoch: 273 [48/54 (89%)]\tTrain Loss: 0.013737\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.46941927e-03 9.12712276e-01 8.45813155e-01 9.77623820e-01\n",
      " 6.24767959e-01 2.39063549e-04 8.25486124e-01 9.27180827e-01\n",
      " 2.91804105e-01 1.60329357e-01 1.71659254e-02 4.41721827e-03\n",
      " 4.08978127e-02 2.83277733e-03 5.99101007e-01 7.21441407e-04\n",
      " 1.21528935e-02 1.58961907e-01 9.30296659e-01 5.81921101e-01\n",
      " 1.33172015e-03 9.86663222e-01 9.99943972e-01 9.99996662e-01\n",
      " 2.00612754e-01 9.99999404e-01 9.99980569e-01 9.81217146e-01\n",
      " 8.44517708e-01 8.09323430e-01 9.83812273e-01 9.73221838e-01\n",
      " 8.69568646e-01 2.49601584e-02 5.19372709e-03 1.59138665e-01\n",
      " 3.28290075e-01 9.45463955e-01 3.08718602e-03 7.35474825e-02\n",
      " 5.65613136e-02 1.90623850e-01 1.29399160e-02 2.17710182e-01\n",
      " 4.56165612e-01 3.09793085e-01 9.99048173e-01 9.42816198e-01\n",
      " 9.99996901e-01 9.99400973e-01 9.99626994e-01 3.26564070e-03\n",
      " 2.83995904e-02 1.28447846e-01 2.23068923e-01 6.84321346e-03\n",
      " 9.94821668e-01 4.54627462e-02 5.62879816e-02 9.58024561e-02\n",
      " 9.99900937e-01 9.92593944e-01 9.98681128e-01 9.99285519e-01\n",
      " 9.86946821e-01 9.86933172e-01 9.99800861e-01 9.99977231e-01\n",
      " 9.99993205e-01 9.58702564e-01 9.85893965e-01 9.89852011e-01\n",
      " 9.99999762e-01 9.99878049e-01 9.94000971e-01 9.99613822e-01\n",
      " 9.99999642e-01 9.99999166e-01 9.98198926e-01 9.99999285e-01\n",
      " 9.99999881e-01 9.99998569e-01 9.99982476e-01 4.79818285e-02\n",
      " 3.76892835e-01 9.99191821e-01 9.97451365e-01 9.68452990e-01\n",
      " 7.09119916e-01 9.13416207e-01 9.99998093e-01 7.93961763e-01\n",
      " 8.92897427e-01 9.99998331e-01 9.99980330e-01 9.99671698e-01\n",
      " 1.28585473e-02 9.61102247e-01 9.84964192e-01 9.99551117e-01\n",
      " 2.24527389e-01 9.99915838e-01 4.52047467e-01 9.77258265e-01\n",
      " 9.93652821e-01 9.90405500e-01 9.99996662e-01 4.59854491e-02\n",
      " 5.90679646e-02 9.99526143e-01 8.93066287e-01 3.90652269e-01\n",
      " 9.99899030e-01 9.83646274e-01 1.20261736e-01 4.66142923e-01\n",
      " 8.28835130e-01 7.12672412e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 274 [0/54 (0%)]\tTrain Loss: 0.000637\n",
      "Train Epoch: 274 [8/54 (15%)]\tTrain Loss: 0.001570\n",
      "Train Epoch: 274 [16/54 (30%)]\tTrain Loss: 0.000506\n",
      "Train Epoch: 274 [24/54 (44%)]\tTrain Loss: 0.001060\n",
      "Train Epoch: 274 [32/54 (59%)]\tTrain Loss: 0.021850\n",
      "Train Epoch: 274 [40/54 (74%)]\tTrain Loss: 0.002961\n",
      "Train Epoch: 274 [48/54 (89%)]\tTrain Loss: 0.001306\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [9.07524303e-03 9.45312858e-01 8.92218471e-01 8.73222828e-01\n",
      " 2.19650194e-01 2.89896503e-04 9.62003052e-01 9.34438646e-01\n",
      " 3.20927620e-01 9.57603678e-02 1.60106190e-03 4.16728784e-04\n",
      " 2.14689523e-02 1.15726923e-03 6.18097782e-01 1.06347725e-03\n",
      " 1.35663419e-03 1.02238528e-01 2.80603200e-01 7.43426085e-02\n",
      " 3.24591747e-05 9.97519135e-01 9.99985814e-01 9.99914527e-01\n",
      " 2.19670430e-01 9.99999404e-01 9.99967456e-01 8.16176653e-01\n",
      " 6.38452113e-01 8.63170147e-01 9.14459944e-01 8.27933252e-01\n",
      " 6.96273446e-01 1.77730089e-05 1.13279128e-03 8.10790211e-02\n",
      " 1.33712187e-01 8.35264206e-01 4.72960819e-04 1.32324863e-02\n",
      " 4.55285329e-03 5.43952286e-02 7.63467001e-03 6.83043063e-01\n",
      " 4.18499336e-02 1.47537366e-01 9.85641897e-01 6.82232082e-01\n",
      " 9.99837995e-01 9.83673215e-01 9.93994176e-01 1.25788443e-03\n",
      " 4.56005422e-04 1.60894692e-01 9.78563167e-03 1.00340405e-02\n",
      " 9.89255428e-01 5.63039584e-03 2.06720475e-02 3.94850300e-04\n",
      " 9.99320745e-01 9.82664049e-01 9.79506135e-01 9.59538281e-01\n",
      " 9.74846959e-01 9.98148680e-01 9.99566615e-01 9.99931216e-01\n",
      " 9.99956369e-01 8.75779390e-01 9.78788376e-01 9.74787056e-01\n",
      " 9.99979734e-01 9.96355534e-01 9.87536490e-01 9.96444523e-01\n",
      " 9.99994278e-01 9.99999046e-01 9.97931719e-01 9.99990463e-01\n",
      " 9.99998450e-01 9.98540163e-01 9.99952674e-01 3.82393077e-02\n",
      " 7.89502978e-01 9.51471686e-01 9.86206114e-01 9.30830061e-01\n",
      " 1.32129952e-01 8.49403858e-01 9.98141289e-01 7.12183714e-01\n",
      " 8.79477262e-01 9.99949932e-01 9.99875784e-01 9.70877528e-01\n",
      " 6.68938318e-03 8.52103055e-01 8.31371725e-01 9.96749520e-01\n",
      " 1.02467731e-01 9.99701440e-01 3.21240127e-01 9.37042296e-01\n",
      " 9.78001237e-01 9.40245390e-01 9.99995351e-01 1.09929340e-02\n",
      " 3.13102221e-03 9.97539163e-01 3.08792412e-01 4.93614405e-01\n",
      " 9.77908671e-01 8.00109327e-01 5.74217029e-02 8.58283341e-01\n",
      " 5.31955421e-01 4.45604980e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.]\n",
      "Train Epoch: 275 [0/54 (0%)]\tTrain Loss: 0.000959\n",
      "Train Epoch: 275 [8/54 (15%)]\tTrain Loss: 0.037673\n",
      "Train Epoch: 275 [16/54 (30%)]\tTrain Loss: 0.003205\n",
      "Train Epoch: 275 [24/54 (44%)]\tTrain Loss: 0.001957\n",
      "Train Epoch: 275 [32/54 (59%)]\tTrain Loss: 0.001640\n",
      "Train Epoch: 275 [40/54 (74%)]\tTrain Loss: 0.001291\n",
      "Train Epoch: 275 [48/54 (89%)]\tTrain Loss: 0.003955\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.61626231e-04 7.79157877e-01 4.90387410e-01 1.57108292e-01\n",
      " 1.85294356e-02 4.82713331e-05 5.47465026e-01 1.68200433e-01\n",
      " 4.11712565e-02 3.97079438e-01 1.23615498e-02 6.85118372e-03\n",
      " 1.12225814e-02 2.83224726e-05 1.23446368e-01 6.41820588e-05\n",
      " 1.38658215e-04 1.14414066e-01 3.40405196e-01 5.14865756e-01\n",
      " 2.01540548e-04 8.74464691e-01 9.93229270e-01 9.98814106e-01\n",
      " 2.25916971e-02 9.99705851e-01 9.99811947e-01 7.72235930e-01\n",
      " 3.00045192e-01 3.45323056e-01 3.64851087e-01 8.29125881e-01\n",
      " 4.44590211e-01 1.22422284e-06 1.47254323e-04 4.82937545e-02\n",
      " 2.45229863e-02 4.08318281e-01 5.75781334e-04 6.25894591e-03\n",
      " 1.59341667e-03 1.43411709e-03 2.07803156e-02 2.36499041e-01\n",
      " 5.75103834e-02 2.73456890e-02 9.45153832e-01 5.37569523e-01\n",
      " 9.99965072e-01 9.68203247e-01 9.97712016e-01 5.22766868e-03\n",
      " 4.07817934e-05 9.10948366e-02 2.71615852e-02 7.36714515e-04\n",
      " 9.44781780e-01 2.44999193e-02 2.86580265e-01 5.30893249e-06\n",
      " 9.95881796e-01 6.44163072e-01 8.84419203e-01 9.39696968e-01\n",
      " 6.73659742e-01 9.78378654e-01 9.67937827e-01 9.96972203e-01\n",
      " 9.99570429e-01 2.77164936e-01 7.33756602e-01 6.35333657e-01\n",
      " 9.99868870e-01 9.26713288e-01 9.14543986e-01 9.60147500e-01\n",
      " 9.99904990e-01 9.99879479e-01 9.93134379e-01 9.99308467e-01\n",
      " 9.99916315e-01 9.93281960e-01 9.99813139e-01 1.27868369e-01\n",
      " 4.56482381e-01 9.05306697e-01 9.98645127e-01 9.63544965e-01\n",
      " 3.01846880e-02 8.17629814e-01 9.95661557e-01 5.49908459e-01\n",
      " 6.92158461e-01 9.99994278e-01 9.95491207e-01 9.82284784e-01\n",
      " 9.14030883e-04 3.71432155e-01 8.36209774e-01 8.01174760e-01\n",
      " 2.55292505e-02 9.96369362e-01 1.76259596e-02 7.70268798e-01\n",
      " 6.12938106e-01 2.56163180e-01 9.99989390e-01 3.00394883e-03\n",
      " 5.09927282e-04 8.99118185e-01 8.14242288e-02 7.01325536e-02\n",
      " 7.92511642e-01 2.32345358e-01 5.82545958e-02 5.82491517e-01\n",
      " 6.30210221e-01 2.98158497e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 276 [0/54 (0%)]\tTrain Loss: 0.002477\n",
      "Train Epoch: 276 [8/54 (15%)]\tTrain Loss: 0.002507\n",
      "Train Epoch: 276 [16/54 (30%)]\tTrain Loss: 0.004026\n",
      "Train Epoch: 276 [24/54 (44%)]\tTrain Loss: 0.003422\n",
      "Train Epoch: 276 [32/54 (59%)]\tTrain Loss: 0.005066\n",
      "Train Epoch: 276 [40/54 (74%)]\tTrain Loss: 0.024145\n",
      "Train Epoch: 276 [48/54 (89%)]\tTrain Loss: 0.007788\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.24519335e-03 9.97913182e-01 9.89300907e-01 9.19047713e-01\n",
      " 2.93569893e-01 2.89463042e-03 9.96472538e-01 7.88450181e-01\n",
      " 3.40314478e-01 8.50990713e-01 1.77104641e-02 3.71940136e-02\n",
      " 1.17843434e-01 6.19349144e-02 9.43338752e-01 4.36934223e-03\n",
      " 1.36626363e-02 9.06717181e-01 9.89059567e-01 8.75032663e-01\n",
      " 4.09596153e-02 9.99784052e-01 1.00000000e+00 9.99969363e-01\n",
      " 6.13503277e-01 1.00000000e+00 9.99999285e-01 9.95380998e-01\n",
      " 9.98027146e-01 4.93338972e-01 9.89838481e-01 9.96371031e-01\n",
      " 6.48735702e-01 2.66528696e-05 1.76435115e-03 6.16169393e-01\n",
      " 4.76040483e-01 9.98140574e-01 7.90383890e-02 3.66273105e-01\n",
      " 3.57466817e-01 7.15232611e-01 1.64541498e-01 2.13549867e-01\n",
      " 3.22540134e-01 7.83239976e-02 9.96787548e-01 9.79198873e-01\n",
      " 9.99999881e-01 9.97006118e-01 9.98846412e-01 4.51925173e-02\n",
      " 6.52483329e-02 4.64186013e-01 3.49507183e-01 8.23430866e-02\n",
      " 9.68106031e-01 5.38245402e-02 4.15161252e-01 3.25705141e-01\n",
      " 9.99937415e-01 9.96694803e-01 9.97799456e-01 9.99710381e-01\n",
      " 9.53362048e-01 9.99304652e-01 9.99890924e-01 9.99988079e-01\n",
      " 9.99999881e-01 8.81718934e-01 9.73512232e-01 9.37923193e-01\n",
      " 1.00000000e+00 9.97699201e-01 9.93981898e-01 9.99862075e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99365032e-01 9.99999762e-01\n",
      " 9.99999404e-01 9.99117315e-01 9.99984980e-01 6.52868271e-01\n",
      " 9.98894513e-01 9.65518355e-01 9.99847412e-01 9.95969176e-01\n",
      " 9.10474718e-01 9.99998212e-01 1.00000000e+00 8.79187524e-01\n",
      " 7.83332705e-01 9.99999404e-01 9.99963999e-01 9.99992967e-01\n",
      " 3.32794935e-02 9.98417616e-01 9.98697877e-01 9.99284208e-01\n",
      " 8.83610904e-01 9.99983788e-01 3.48914832e-01 9.75688279e-01\n",
      " 9.93031979e-01 9.92763817e-01 9.99999762e-01 5.21382511e-01\n",
      " 5.14722802e-02 9.96462047e-01 4.86641437e-01 9.40383971e-01\n",
      " 9.99886632e-01 2.72401810e-01 1.73323616e-01 9.85930264e-01\n",
      " 9.99995947e-01 7.44452715e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1.]\n",
      "Train Epoch: 277 [0/54 (0%)]\tTrain Loss: 0.011736\n",
      "Train Epoch: 277 [8/54 (15%)]\tTrain Loss: 0.002349\n",
      "Train Epoch: 277 [16/54 (30%)]\tTrain Loss: 0.008052\n",
      "Train Epoch: 277 [24/54 (44%)]\tTrain Loss: 0.011559\n",
      "Train Epoch: 277 [32/54 (59%)]\tTrain Loss: 0.007390\n",
      "Train Epoch: 277 [40/54 (74%)]\tTrain Loss: 0.014492\n",
      "Train Epoch: 277 [48/54 (89%)]\tTrain Loss: 0.006413\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.84205121e-03 9.97266769e-01 8.78373384e-01 9.35812473e-01\n",
      " 9.14983675e-02 9.62275267e-03 9.97556806e-01 7.83638895e-01\n",
      " 6.88756183e-02 3.30145419e-01 5.16953766e-01 7.76697183e-03\n",
      " 4.90517825e-01 2.03209855e-02 9.62712646e-01 9.85354767e-04\n",
      " 2.28160992e-03 3.29875559e-01 2.30675891e-01 6.69078410e-01\n",
      " 1.02321254e-02 9.99279678e-01 9.99909401e-01 9.99993682e-01\n",
      " 3.22371036e-01 9.99996781e-01 9.99999404e-01 9.26469803e-01\n",
      " 8.59551787e-01 8.62360477e-01 4.93523419e-01 4.54645455e-01\n",
      " 8.68894398e-01 1.69784201e-07 3.80015117e-04 6.14176750e-01\n",
      " 2.80878186e-01 8.44423294e-01 4.06608611e-01 7.03492463e-01\n",
      " 3.40672880e-01 9.02773380e-01 3.99532989e-02 6.35747075e-01\n",
      " 4.28788811e-01 4.92798313e-02 9.33903813e-01 9.64811444e-01\n",
      " 9.99999881e-01 9.95863795e-01 9.99588072e-01 6.65342668e-03\n",
      " 2.68230494e-02 2.43197829e-01 9.96263921e-02 3.28159839e-01\n",
      " 9.95410740e-01 9.66494158e-02 6.89417720e-01 4.47290689e-02\n",
      " 9.99588668e-01 8.51177573e-01 9.87405121e-01 9.98623490e-01\n",
      " 9.96788263e-01 9.99972224e-01 9.99711335e-01 9.99988914e-01\n",
      " 9.99999762e-01 8.38922560e-01 8.48707497e-01 9.27918434e-01\n",
      " 9.99998569e-01 9.99766409e-01 9.98415828e-01 9.90331769e-01\n",
      " 9.99979496e-01 9.99975681e-01 9.96818662e-01 9.99967694e-01\n",
      " 9.99932170e-01 9.98891056e-01 9.99990821e-01 9.13627386e-01\n",
      " 9.86617327e-01 9.67759728e-01 9.98831570e-01 9.96151865e-01\n",
      " 4.05727267e-01 9.26199555e-01 9.99988675e-01 9.71444547e-01\n",
      " 9.72174525e-01 1.00000000e+00 9.99811828e-01 9.99932408e-01\n",
      " 5.60445189e-02 9.76870954e-01 9.80510533e-01 9.73943651e-01\n",
      " 5.20709693e-01 9.99948740e-01 3.09398975e-02 8.67382050e-01\n",
      " 9.69490111e-01 9.28400397e-01 9.99998927e-01 5.51910400e-01\n",
      " 7.81950131e-02 9.97666717e-01 9.01236460e-02 9.46970463e-01\n",
      " 9.98899221e-01 7.18051195e-01 2.18831245e-02 5.83003223e-01\n",
      " 9.65193450e-01 5.57156466e-02]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0.]\n",
      "Train Epoch: 278 [0/54 (0%)]\tTrain Loss: 0.001681\n",
      "Train Epoch: 278 [8/54 (15%)]\tTrain Loss: 0.001477\n",
      "Train Epoch: 278 [16/54 (30%)]\tTrain Loss: 0.002866\n",
      "Train Epoch: 278 [24/54 (44%)]\tTrain Loss: 0.000587\n",
      "Train Epoch: 278 [32/54 (59%)]\tTrain Loss: 0.003146\n",
      "Train Epoch: 278 [40/54 (74%)]\tTrain Loss: 0.000688\n",
      "Train Epoch: 278 [48/54 (89%)]\tTrain Loss: 0.057265\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.78437810e-02 9.98487949e-01 9.71975565e-01 9.51002419e-01\n",
      " 2.52315700e-01 4.45467699e-03 9.99630094e-01 9.71777737e-01\n",
      " 4.24472466e-02 5.75693846e-01 3.08141947e-01 6.07636466e-04\n",
      " 5.13404787e-01 8.50879587e-03 9.56970572e-01 5.88632887e-03\n",
      " 5.06787539e-01 2.79862657e-02 4.53003757e-02 3.57807428e-01\n",
      " 9.12191637e-04 9.89164531e-01 9.99782860e-01 9.99973536e-01\n",
      " 9.47952718e-02 9.99952435e-01 9.99989867e-01 7.78617680e-01\n",
      " 1.83098271e-01 5.54629266e-01 4.32119817e-01 2.68889755e-01\n",
      " 3.41800332e-01 1.14478571e-04 7.62741489e-04 5.90465784e-01\n",
      " 5.79884164e-02 8.77344072e-01 4.15904745e-02 5.57470731e-02\n",
      " 4.71543148e-02 5.00720963e-02 1.88231319e-02 1.77750096e-01\n",
      " 2.72111923e-01 1.98313016e-02 9.95223343e-01 9.94475543e-01\n",
      " 1.00000000e+00 9.97456729e-01 9.99953628e-01 2.71698654e-01\n",
      " 3.06597818e-02 8.79560888e-01 6.91929832e-04 4.72890120e-03\n",
      " 9.88220990e-01 9.08410922e-03 2.74087209e-02 2.18738094e-02\n",
      " 9.99906421e-01 9.90595222e-01 9.99504209e-01 9.99148846e-01\n",
      " 9.97738242e-01 9.75504518e-01 9.99842525e-01 9.99735892e-01\n",
      " 1.00000000e+00 9.75223899e-01 9.57157314e-01 9.67200816e-01\n",
      " 9.99999642e-01 9.99778688e-01 9.50832129e-01 9.99854684e-01\n",
      " 9.99999881e-01 1.00000000e+00 9.99864221e-01 9.99992490e-01\n",
      " 9.99998569e-01 9.99986768e-01 9.99995112e-01 4.99419689e-01\n",
      " 9.77287650e-01 9.58926558e-01 9.99246597e-01 9.98363793e-01\n",
      " 1.81662709e-01 9.71277952e-01 9.99995828e-01 9.68709528e-01\n",
      " 9.14588153e-01 9.99989033e-01 9.96303558e-01 9.98615503e-01\n",
      " 4.41455282e-04 4.40827489e-01 9.44281816e-01 9.98815894e-01\n",
      " 2.14715764e-01 9.99993682e-01 1.45423293e-01 9.93345857e-01\n",
      " 9.95362461e-01 9.86985981e-01 9.99998808e-01 4.36486416e-02\n",
      " 9.76478308e-03 9.95904744e-01 2.19000638e-01 7.15160012e-01\n",
      " 9.95609820e-01 5.50029457e-01 8.01295400e-01 1.46740451e-01\n",
      " 8.68846536e-01 7.11421728e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 279 [0/54 (0%)]\tTrain Loss: 0.046304\n",
      "Train Epoch: 279 [8/54 (15%)]\tTrain Loss: 0.000817\n",
      "Train Epoch: 279 [16/54 (30%)]\tTrain Loss: 0.003220\n",
      "Train Epoch: 279 [24/54 (44%)]\tTrain Loss: 0.027621\n",
      "Train Epoch: 279 [32/54 (59%)]\tTrain Loss: 0.020898\n",
      "Train Epoch: 279 [40/54 (74%)]\tTrain Loss: 0.006832\n",
      "Train Epoch: 279 [48/54 (89%)]\tTrain Loss: 0.001213\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.40821515e-02 9.70700443e-01 8.48927319e-01 8.81137073e-01\n",
      " 2.24500597e-01 5.01324609e-02 9.94519770e-01 9.93596911e-01\n",
      " 2.38294322e-02 1.30710527e-01 8.59286487e-01 3.59205966e-04\n",
      " 9.65869904e-01 5.04370145e-02 9.37797904e-01 3.97141650e-02\n",
      " 8.89749467e-01 6.43436238e-02 4.90726799e-01 3.77424508e-01\n",
      " 2.68295836e-02 9.80593085e-01 9.99996543e-01 9.99989510e-01\n",
      " 2.99070895e-01 1.00000000e+00 9.99996305e-01 9.80509162e-01\n",
      " 4.32587475e-01 7.66771078e-01 7.53071249e-01 8.50299120e-01\n",
      " 8.12951684e-01 3.38798133e-03 1.16358129e-02 6.44102633e-01\n",
      " 4.46404696e-01 8.95897090e-01 9.52969771e-03 1.80116341e-01\n",
      " 9.50953141e-02 8.48855451e-02 3.39798108e-02 6.00727856e-01\n",
      " 2.99725920e-01 8.75634979e-03 7.80664086e-01 8.08337867e-01\n",
      " 9.99996662e-01 9.83801663e-01 9.98585701e-01 4.30614501e-01\n",
      " 2.17761040e-01 5.62938035e-01 1.93337630e-02 2.53970951e-01\n",
      " 6.94344223e-01 3.97616774e-01 6.85882568e-02 6.87539503e-02\n",
      " 9.94307697e-01 7.49245465e-01 9.06610250e-01 9.68723655e-01\n",
      " 9.94579196e-01 9.99932051e-01 9.99524713e-01 9.99974012e-01\n",
      " 1.00000000e+00 8.28049541e-01 4.53870118e-01 5.20329058e-01\n",
      " 1.00000000e+00 9.99958992e-01 9.99449193e-01 6.95720017e-01\n",
      " 9.99999285e-01 9.99999762e-01 9.89908338e-01 9.99987841e-01\n",
      " 9.99970436e-01 9.99389052e-01 9.99672174e-01 1.46578541e-02\n",
      " 7.74583817e-01 8.74016166e-01 9.67883646e-01 9.56045926e-01\n",
      " 8.28473568e-01 9.96713281e-01 9.99998927e-01 9.36451733e-01\n",
      " 9.04393911e-01 1.00000000e+00 9.99909520e-01 9.99995351e-01\n",
      " 4.27644551e-01 8.19656104e-02 8.52725506e-01 9.99223351e-01\n",
      " 1.81296598e-02 9.99026179e-01 4.35234047e-02 9.83349323e-01\n",
      " 9.31520522e-01 9.57425416e-01 9.99963403e-01 3.44346434e-01\n",
      " 4.71080691e-02 9.99744952e-01 4.64862645e-01 5.45373559e-02\n",
      " 9.99845982e-01 9.48664784e-01 8.58903751e-02 1.32420482e-02\n",
      " 6.49380624e-01 6.34466350e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 280 [0/54 (0%)]\tTrain Loss: 0.089516\n",
      "Train Epoch: 280 [8/54 (15%)]\tTrain Loss: 0.002188\n",
      "Train Epoch: 280 [16/54 (30%)]\tTrain Loss: 0.000527\n",
      "Train Epoch: 280 [24/54 (44%)]\tTrain Loss: 0.021043\n",
      "Train Epoch: 280 [32/54 (59%)]\tTrain Loss: 0.008472\n",
      "Train Epoch: 280 [40/54 (74%)]\tTrain Loss: 0.015427\n",
      "Train Epoch: 280 [48/54 (89%)]\tTrain Loss: 0.003392\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.05393508e-03 5.36306381e-01 9.60609540e-02 1.76104814e-01\n",
      " 4.31705685e-03 1.88837608e-03 1.63371041e-01 1.01577587e-01\n",
      " 8.99171550e-03 3.94559801e-02 1.23706236e-02 6.29796414e-05\n",
      " 5.86966909e-02 7.39002144e-06 1.94736775e-02 7.70457555e-05\n",
      " 2.89525767e-03 8.17219261e-04 1.47112003e-02 5.99392271e-03\n",
      " 4.31143344e-05 7.42222011e-01 9.99969840e-01 9.89350021e-01\n",
      " 1.03325490e-02 1.00000000e+00 9.99094129e-01 1.49765596e-01\n",
      " 3.31768300e-03 9.15322006e-02 7.43887961e-01 5.62046111e-01\n",
      " 4.19454835e-02 1.83061429e-03 2.02285621e-04 1.42176328e-02\n",
      " 1.32266269e-03 1.25014439e-01 1.54536712e-04 2.42331927e-03\n",
      " 1.98164815e-03 4.47773607e-04 7.32979912e-04 9.50146001e-03\n",
      " 1.88197079e-03 3.27929592e-04 1.78092763e-01 2.25337576e-02\n",
      " 9.98285592e-01 5.71080506e-01 9.79183376e-01 3.55562457e-04\n",
      " 1.59828141e-05 6.06069050e-04 3.04260151e-03 6.91877678e-04\n",
      " 1.87359244e-01 2.05306318e-02 6.84869941e-03 9.25812037e-06\n",
      " 9.89264846e-01 8.51377666e-01 8.23703170e-01 8.98681164e-01\n",
      " 2.48306796e-01 9.56532061e-01 9.83541310e-01 9.97901320e-01\n",
      " 9.99669790e-01 1.23258948e-01 2.34678298e-01 3.06178242e-01\n",
      " 9.99139309e-01 9.99501705e-01 4.51932997e-01 1.49681315e-01\n",
      " 9.99258220e-01 9.99916196e-01 7.38641262e-01 9.99926329e-01\n",
      " 9.99999642e-01 9.86569703e-01 9.95491803e-01 4.63502156e-03\n",
      " 3.30640942e-01 8.01360130e-01 5.41873753e-01 3.01390707e-01\n",
      " 3.51208113e-02 9.95632589e-01 4.88523811e-01 2.46625558e-01\n",
      " 2.13749871e-01 9.99893188e-01 9.92948532e-01 9.90845859e-01\n",
      " 6.94011687e-04 1.37490407e-03 1.06099866e-01 9.99923825e-01\n",
      " 2.27736402e-03 9.82692599e-01 5.69472974e-03 2.10872710e-01\n",
      " 8.58007222e-02 9.82285291e-02 9.99134600e-01 4.50275512e-03\n",
      " 4.16128343e-04 2.63497561e-01 2.04197485e-02 3.30209494e-01\n",
      " 8.99877131e-01 9.28430378e-01 2.58274451e-02 9.12987220e-04\n",
      " 4.35398489e-01 7.84344301e-02]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 46 TN= 37 FN= 12 FP= 23\n",
      "TP+FP 69\n",
      "precision 0.6666666666666666\n",
      "recall 0.7931034482758621\n",
      "F1 0.7244094488188977\n",
      "acc 0.7033898305084746\n",
      "AUCp 0.7048850574712644\n",
      "AUC 0.7672413793103449\n",
      "\n",
      " The epoch is 280, average recall: 0.7931, average precision: 0.6667,average F1: 0.7244, average accuracy: 0.7034, average AUC: 0.7672\n",
      "Train Epoch: 281 [0/54 (0%)]\tTrain Loss: 0.007223\n",
      "Train Epoch: 281 [8/54 (15%)]\tTrain Loss: 0.057709\n",
      "Train Epoch: 281 [16/54 (30%)]\tTrain Loss: 0.031222\n",
      "Train Epoch: 281 [24/54 (44%)]\tTrain Loss: 0.016269\n",
      "Train Epoch: 281 [32/54 (59%)]\tTrain Loss: 0.012153\n",
      "Train Epoch: 281 [40/54 (74%)]\tTrain Loss: 0.017256\n",
      "Train Epoch: 281 [48/54 (89%)]\tTrain Loss: 0.001649\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.06103286e-04 3.31402123e-01 3.33258044e-03 3.18005495e-02\n",
      " 7.68647762e-04 1.69582214e-04 2.81773554e-03 3.72629985e-02\n",
      " 1.66239229e-03 2.15192069e-03 5.01743983e-03 1.65373840e-05\n",
      " 2.76131183e-03 2.89516407e-07 1.16372446e-03 1.60060381e-07\n",
      " 9.11235475e-06 3.16665071e-04 7.53134629e-03 1.75745115e-02\n",
      " 6.72244278e-05 1.79715648e-01 9.99974966e-01 9.99672532e-01\n",
      " 2.71480036e-04 1.00000000e+00 9.99989986e-01 3.57959181e-01\n",
      " 2.47451989e-03 5.11434674e-02 1.81367490e-02 6.63344786e-02\n",
      " 3.03224544e-03 1.14387394e-05 2.50148496e-05 8.73434299e-04\n",
      " 1.01550584e-04 2.65977606e-02 1.09745679e-05 6.07904687e-04\n",
      " 2.68676667e-04 1.28771389e-05 3.34652723e-05 2.94002850e-04\n",
      " 1.24743208e-03 3.40346355e-06 1.43755181e-02 2.58105737e-03\n",
      " 9.16834354e-01 6.02831423e-01 3.18520069e-01 2.31463855e-05\n",
      " 6.23492670e-05 9.78467688e-06 7.73922366e-04 1.57532064e-04\n",
      " 1.35947093e-01 9.33694886e-04 1.43829687e-03 1.04229537e-06\n",
      " 9.98809576e-01 9.81259644e-01 9.03778017e-01 9.36809063e-01\n",
      " 2.88461268e-01 2.03475744e-01 5.96939147e-01 9.96232331e-01\n",
      " 9.99968529e-01 4.20488566e-02 2.02387065e-01 2.19166577e-01\n",
      " 9.98394787e-01 9.98072386e-01 5.63515484e-01 1.74468800e-01\n",
      " 9.99535799e-01 9.99956250e-01 7.92400539e-01 9.99562800e-01\n",
      " 9.99494195e-01 9.83694136e-01 9.87128019e-01 1.26480137e-03\n",
      " 1.28172696e-01 3.51283014e-01 7.84073651e-01 6.27439916e-01\n",
      " 2.29807254e-02 6.48448408e-01 9.98738825e-01 5.07540675e-03\n",
      " 2.87506506e-02 9.99999285e-01 9.96940374e-01 9.97662306e-01\n",
      " 1.34445762e-03 2.05548276e-04 6.18072413e-02 9.98464346e-01\n",
      " 1.05457089e-03 7.76391566e-01 4.59987903e-03 1.54279351e-01\n",
      " 1.69615932e-02 1.05691403e-01 9.90428805e-01 3.32857925e-03\n",
      " 3.48941830e-06 4.10214037e-01 2.61120638e-03 2.55464896e-04\n",
      " 3.44125390e-01 3.71419668e-01 2.75267812e-04 7.09965825e-05\n",
      " 1.29028678e-01 1.32908067e-03]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 282 [0/54 (0%)]\tTrain Loss: 0.002860\n",
      "Train Epoch: 282 [8/54 (15%)]\tTrain Loss: 0.006910\n",
      "Train Epoch: 282 [16/54 (30%)]\tTrain Loss: 0.009339\n",
      "Train Epoch: 282 [24/54 (44%)]\tTrain Loss: 0.003373\n",
      "Train Epoch: 282 [32/54 (59%)]\tTrain Loss: 0.018665\n",
      "Train Epoch: 282 [40/54 (74%)]\tTrain Loss: 0.003162\n",
      "Train Epoch: 282 [48/54 (89%)]\tTrain Loss: 0.009255\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.20159134e-02 9.97701585e-01 9.83604014e-01 9.03508484e-01\n",
      " 8.70665908e-02 1.33745391e-02 9.58577216e-01 9.87015367e-01\n",
      " 1.81858376e-01 1.20508358e-01 3.69948633e-02 1.79349480e-03\n",
      " 4.52829413e-02 8.21210444e-03 7.36640871e-01 5.46434545e-04\n",
      " 1.00584130e-03 1.88463658e-01 5.05841494e-01 1.51259258e-01\n",
      " 1.06610404e-03 9.96954322e-01 9.99988437e-01 9.99989867e-01\n",
      " 2.00959802e-01 1.00000000e+00 1.00000000e+00 9.72118974e-01\n",
      " 3.48967344e-01 5.51342249e-01 9.99248683e-01 9.96912599e-01\n",
      " 9.01845634e-01 2.00486043e-04 6.13140175e-04 1.01802692e-01\n",
      " 1.14772664e-02 9.39009845e-01 7.11337477e-03 1.21989578e-01\n",
      " 5.40865548e-02 4.46953811e-03 2.74445117e-02 3.12115937e-01\n",
      " 2.09042042e-01 2.22611457e-01 9.99327421e-01 9.94625628e-01\n",
      " 9.99995708e-01 9.77439761e-01 9.99941826e-01 2.71122297e-03\n",
      " 2.09720895e-01 2.69862860e-01 2.24150475e-02 3.58796231e-02\n",
      " 9.99811590e-01 1.20043866e-02 3.87499392e-01 2.95169596e-02\n",
      " 9.99987006e-01 9.98842537e-01 9.99596894e-01 9.99946952e-01\n",
      " 9.99449670e-01 9.96902764e-01 9.99857068e-01 9.99877214e-01\n",
      " 9.99999642e-01 8.84627163e-01 9.91039813e-01 9.97571051e-01\n",
      " 1.00000000e+00 9.99987602e-01 9.95272100e-01 9.99886155e-01\n",
      " 9.99999762e-01 9.99999642e-01 9.99980927e-01 9.99999881e-01\n",
      " 9.99999881e-01 9.99999523e-01 9.99998569e-01 2.56771296e-01\n",
      " 9.60059464e-01 9.99327779e-01 9.99937773e-01 9.99835610e-01\n",
      " 2.11499989e-01 9.83185470e-01 9.99848247e-01 8.33570123e-01\n",
      " 9.85056221e-01 1.00000000e+00 9.99576986e-01 9.99560177e-01\n",
      " 1.35433953e-02 5.22669137e-01 8.36475492e-01 9.98041630e-01\n",
      " 1.21646717e-01 9.99997377e-01 6.96632713e-02 9.98129547e-01\n",
      " 9.98507202e-01 9.88430023e-01 9.99999881e-01 4.50896323e-02\n",
      " 5.46095055e-03 9.14847076e-01 3.39968622e-01 1.56092361e-01\n",
      " 8.97003174e-01 9.56434429e-01 1.80826738e-01 1.64219365e-01\n",
      " 3.71862680e-01 3.79867069e-02]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "Train Epoch: 283 [0/54 (0%)]\tTrain Loss: 0.013071\n",
      "Train Epoch: 283 [8/54 (15%)]\tTrain Loss: 0.000363\n",
      "Train Epoch: 283 [16/54 (30%)]\tTrain Loss: 0.012713\n",
      "Train Epoch: 283 [24/54 (44%)]\tTrain Loss: 0.011126\n",
      "Train Epoch: 283 [32/54 (59%)]\tTrain Loss: 0.001534\n",
      "Train Epoch: 283 [40/54 (74%)]\tTrain Loss: 0.001028\n",
      "Train Epoch: 283 [48/54 (89%)]\tTrain Loss: 0.049622\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.81655828e-03 7.85355031e-01 5.22717476e-01 6.76525116e-01\n",
      " 8.30760077e-02 9.41107050e-04 4.56792533e-01 9.50482547e-01\n",
      " 4.41485867e-02 1.43534482e-01 1.20541342e-01 1.11772874e-02\n",
      " 2.65353881e-02 2.14675183e-05 1.45004457e-02 1.16268500e-04\n",
      " 8.88253795e-04 1.99271843e-01 2.85323858e-01 1.06574669e-01\n",
      " 1.03856495e-04 9.99506950e-01 9.99455988e-01 9.99922752e-01\n",
      " 3.08727115e-01 9.99999523e-01 9.99999404e-01 9.90047514e-01\n",
      " 4.49163169e-02 6.70174733e-02 9.82827663e-01 8.48377705e-01\n",
      " 2.79885363e-02 1.94432345e-04 3.42202518e-04 4.15301949e-01\n",
      " 6.43854290e-02 9.98972416e-01 3.24287917e-03 6.90726414e-02\n",
      " 2.35812031e-02 1.82939209e-02 1.86583683e-01 1.33384570e-01\n",
      " 6.46952773e-03 1.80261489e-02 7.95809805e-01 1.78892851e-01\n",
      " 9.99925256e-01 9.88784671e-01 9.99556243e-01 5.98657134e-05\n",
      " 1.25851547e-02 4.26658476e-03 5.91290854e-02 4.16434556e-03\n",
      " 9.93166387e-01 9.32748429e-03 5.88652253e-01 5.07542165e-04\n",
      " 9.90220428e-01 7.39154220e-01 3.24983656e-01 7.68719018e-01\n",
      " 3.24410230e-01 9.83284295e-01 9.66758192e-01 9.99964356e-01\n",
      " 1.00000000e+00 2.53391981e-01 6.42460346e-01 8.04354966e-01\n",
      " 9.97368693e-01 9.97523129e-01 9.26841617e-01 8.48838568e-01\n",
      " 9.99304175e-01 9.99860048e-01 9.42917407e-01 9.99989033e-01\n",
      " 1.00000000e+00 9.99366581e-01 9.99933958e-01 2.15102300e-01\n",
      " 7.32009172e-01 9.26226437e-01 9.93600488e-01 9.80879962e-01\n",
      " 7.16037154e-02 9.24457550e-01 9.99692082e-01 2.62301356e-01\n",
      " 7.84644067e-01 1.00000000e+00 9.99981642e-01 9.99751627e-01\n",
      " 1.26449182e-03 7.95174718e-01 8.88938129e-01 9.79554534e-01\n",
      " 7.00260699e-02 9.97862875e-01 3.44527923e-02 9.89843190e-01\n",
      " 9.52965140e-01 3.73730093e-01 9.99995828e-01 1.73153684e-01\n",
      " 2.10371111e-02 9.88736331e-01 9.95842516e-01 1.38560295e-01\n",
      " 9.63893414e-01 9.45691526e-01 1.31602762e-02 9.54754800e-02\n",
      " 9.57481146e-01 1.58558860e-02]\n",
      "predict [0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 284 [0/54 (0%)]\tTrain Loss: 0.004068\n",
      "Train Epoch: 284 [8/54 (15%)]\tTrain Loss: 0.000074\n",
      "Train Epoch: 284 [16/54 (30%)]\tTrain Loss: 0.018470\n",
      "Train Epoch: 284 [24/54 (44%)]\tTrain Loss: 0.000532\n",
      "Train Epoch: 284 [32/54 (59%)]\tTrain Loss: 0.000373\n",
      "Train Epoch: 284 [40/54 (74%)]\tTrain Loss: 0.001661\n",
      "Train Epoch: 284 [48/54 (89%)]\tTrain Loss: 0.005564\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.40227229e-05 9.72882211e-01 9.96740162e-01 8.93397629e-01\n",
      " 1.08737247e-02 2.81792163e-04 8.64652336e-01 4.75671291e-01\n",
      " 5.08922189e-02 2.78113961e-01 5.50336251e-03 8.54065933e-04\n",
      " 6.98875934e-02 1.99351879e-03 8.28063935e-02 2.64336908e-04\n",
      " 6.91263063e-04 7.13573694e-02 9.71531272e-01 4.44366485e-01\n",
      " 3.40583501e-03 9.98984873e-01 9.99998569e-01 9.99742687e-01\n",
      " 5.35752594e-01 1.00000000e+00 9.99961853e-01 9.68337297e-01\n",
      " 9.55912709e-01 8.79527330e-01 8.64413917e-01 9.92897630e-01\n",
      " 1.79382637e-02 3.47251247e-04 4.47445287e-04 3.89980078e-02\n",
      " 9.06729847e-02 9.85694945e-01 2.23883195e-03 2.29516327e-02\n",
      " 8.65288898e-02 2.33489349e-02 3.54670919e-02 7.58183360e-01\n",
      " 1.51958928e-01 1.92225333e-02 4.32997018e-01 3.06262165e-01\n",
      " 9.98362601e-01 9.54249382e-01 9.96322870e-01 2.19665840e-03\n",
      " 3.53809670e-02 6.10881448e-02 6.74600899e-02 3.69869202e-01\n",
      " 9.01855290e-01 9.41823572e-02 5.27062565e-02 8.26627314e-02\n",
      " 9.98681247e-01 9.61538911e-01 7.76177764e-01 9.84430373e-01\n",
      " 9.91131246e-01 9.97820377e-01 9.97631192e-01 9.99999523e-01\n",
      " 9.99999523e-01 4.32543397e-01 8.86669576e-01 9.19236660e-01\n",
      " 9.99959230e-01 9.96377289e-01 8.60036254e-01 9.32013094e-01\n",
      " 9.99986410e-01 9.99962449e-01 9.99687076e-01 9.99996305e-01\n",
      " 9.99999404e-01 9.99960542e-01 9.99911547e-01 5.93745708e-03\n",
      " 6.03762269e-01 8.94255579e-01 9.97693241e-01 9.94577289e-01\n",
      " 6.74791276e-01 9.85593259e-01 9.99974489e-01 2.47450799e-01\n",
      " 8.93471122e-01 1.00000000e+00 9.99990582e-01 9.99950051e-01\n",
      " 1.15735702e-01 1.57989725e-01 4.24244136e-01 9.94663000e-01\n",
      " 3.19130979e-02 9.87867594e-01 6.03111181e-03 9.83511567e-01\n",
      " 7.82453537e-01 9.48419809e-01 9.99998927e-01 1.29707813e-01\n",
      " 1.40203331e-02 8.39215398e-01 5.95773049e-02 3.33909899e-01\n",
      " 9.61863399e-01 9.95714486e-01 2.05238596e-01 1.16271831e-01\n",
      " 9.59191680e-01 4.43414897e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 285 [0/54 (0%)]\tTrain Loss: 0.005942\n",
      "Train Epoch: 285 [8/54 (15%)]\tTrain Loss: 0.000602\n",
      "Train Epoch: 285 [16/54 (30%)]\tTrain Loss: 0.014330\n",
      "Train Epoch: 285 [24/54 (44%)]\tTrain Loss: 0.008848\n",
      "Train Epoch: 285 [32/54 (59%)]\tTrain Loss: 0.002729\n",
      "Train Epoch: 285 [40/54 (74%)]\tTrain Loss: 0.047287\n",
      "Train Epoch: 285 [48/54 (89%)]\tTrain Loss: 0.006202\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.90185271e-02 9.88335907e-01 9.94542718e-01 9.62388456e-01\n",
      " 1.57174215e-01 2.52674520e-02 9.94774520e-01 9.87395287e-01\n",
      " 3.75306681e-02 1.60329994e-02 4.72175665e-02 8.24252376e-04\n",
      " 3.36605944e-02 1.50732584e-02 7.57101297e-01 1.38550391e-02\n",
      " 1.37497601e-03 4.47065430e-03 1.51040191e-02 2.32748702e-01\n",
      " 2.00098526e-04 8.98150682e-01 9.84574020e-01 9.96950984e-01\n",
      " 4.92511280e-02 9.97229278e-01 9.99900699e-01 9.03410077e-01\n",
      " 6.16843402e-02 5.89328595e-02 3.44085008e-01 7.95121014e-01\n",
      " 6.24790907e-01 5.26265785e-06 2.04487194e-04 3.18064578e-02\n",
      " 3.65980132e-03 9.19432998e-01 8.49777018e-04 2.67385133e-02\n",
      " 1.34272436e-02 4.39366745e-03 4.38971008e-04 5.74980140e-01\n",
      " 2.03664973e-01 3.54746953e-02 8.94986272e-01 8.71530652e-01\n",
      " 9.99982595e-01 3.30251157e-01 9.99635935e-01 1.16600454e-01\n",
      " 1.82246529e-02 4.54922952e-02 6.16639387e-03 7.15955123e-02\n",
      " 8.88491035e-01 3.18517862e-03 4.00718004e-02 6.33154213e-02\n",
      " 9.99804080e-01 9.44663405e-01 9.03490722e-01 9.31752801e-01\n",
      " 9.99412179e-01 9.99708831e-01 9.64311004e-01 9.99763310e-01\n",
      " 9.99990344e-01 7.32676744e-01 8.68934274e-01 6.57404006e-01\n",
      " 9.99237537e-01 9.98774469e-01 5.32963634e-01 9.38208342e-01\n",
      " 9.99990582e-01 9.99998331e-01 9.98420358e-01 9.99952674e-01\n",
      " 9.99955893e-01 9.72601473e-01 9.99873996e-01 1.44683449e-02\n",
      " 7.19443709e-02 5.83952487e-01 9.55731571e-01 9.72953439e-01\n",
      " 6.13836125e-02 8.73969555e-01 2.35706925e-01 6.53132319e-01\n",
      " 8.24838161e-01 9.99993563e-01 8.01351666e-01 5.74830294e-01\n",
      " 4.54382825e-04 1.35729332e-02 3.01203430e-01 2.17502862e-01\n",
      " 7.07707508e-03 9.98508990e-01 3.63422185e-01 9.64639485e-01\n",
      " 1.87469691e-01 1.51769102e-01 9.97220874e-01 1.03885092e-01\n",
      " 5.24579640e-03 5.97794592e-01 1.25385309e-02 7.33150169e-03\n",
      " 4.13354859e-02 2.72711098e-01 9.80498791e-02 9.48696339e-04\n",
      " 1.77095488e-01 6.33431137e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Train Epoch: 286 [0/54 (0%)]\tTrain Loss: 0.003754\n",
      "Train Epoch: 286 [8/54 (15%)]\tTrain Loss: 0.018777\n",
      "Train Epoch: 286 [16/54 (30%)]\tTrain Loss: 0.007372\n",
      "Train Epoch: 286 [24/54 (44%)]\tTrain Loss: 0.047240\n",
      "Train Epoch: 286 [32/54 (59%)]\tTrain Loss: 0.021406\n",
      "Train Epoch: 286 [40/54 (74%)]\tTrain Loss: 0.046534\n",
      "Train Epoch: 286 [48/54 (89%)]\tTrain Loss: 0.001253\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.47742790e-03 9.99810398e-01 9.99051392e-01 9.95829403e-01\n",
      " 4.76020612e-02 4.53758538e-02 9.98615384e-01 9.38035965e-01\n",
      " 2.38470346e-01 6.22944117e-01 1.20805092e-01 2.89969649e-02\n",
      " 2.20410198e-01 1.58557098e-03 4.54872012e-01 6.79198429e-02\n",
      " 1.50914937e-01 7.38674868e-03 6.61445260e-02 2.22203866e-01\n",
      " 1.65776303e-03 9.94844437e-01 9.99641657e-01 9.99593437e-01\n",
      " 3.83966118e-01 9.99995351e-01 9.99588192e-01 8.68547857e-01\n",
      " 1.34435996e-01 4.21036929e-01 9.20340478e-01 9.91427183e-01\n",
      " 5.26051521e-01 8.81194544e-04 7.50347564e-04 1.17413968e-01\n",
      " 6.76643699e-02 9.94970262e-01 3.17194080e-03 3.36662680e-01\n",
      " 7.05903396e-02 2.49623749e-02 1.61119923e-03 5.30223906e-01\n",
      " 1.65609911e-01 4.42063063e-01 9.89782095e-01 9.89731848e-01\n",
      " 9.99974966e-01 8.86475325e-01 9.99836087e-01 2.40208864e-01\n",
      " 6.60685301e-02 6.33956134e-01 4.34315670e-03 1.46329418e-01\n",
      " 8.85011852e-01 1.33992672e-01 3.70967895e-01 8.58719274e-02\n",
      " 9.99498725e-01 9.58618164e-01 9.49245095e-01 9.84563053e-01\n",
      " 9.98860121e-01 9.99542952e-01 9.99861121e-01 9.99985576e-01\n",
      " 1.00000000e+00 1.89382583e-01 9.80760932e-01 9.76000369e-01\n",
      " 9.99995589e-01 9.97580647e-01 9.66477811e-01 9.56821620e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99994874e-01 9.99998808e-01\n",
      " 9.99998331e-01 9.99922872e-01 9.99986887e-01 2.67145455e-01\n",
      " 8.36340725e-01 9.80223775e-01 9.97073889e-01 9.81418312e-01\n",
      " 9.35202062e-01 9.05456305e-01 9.99896169e-01 5.26394129e-01\n",
      " 7.26185203e-01 1.00000000e+00 9.99992847e-01 9.99975324e-01\n",
      " 1.25018852e-02 7.99796820e-01 9.98878300e-01 9.89121020e-01\n",
      " 9.72249061e-02 9.98992145e-01 5.65489531e-01 9.99041975e-01\n",
      " 9.72351670e-01 9.19641674e-01 9.99976516e-01 8.64790156e-02\n",
      " 1.04280762e-01 9.82688785e-01 5.24696469e-01 2.12236106e-01\n",
      " 9.81510937e-01 9.32523131e-01 7.80422211e-01 5.01749158e-01\n",
      " 9.95343626e-01 8.13848555e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 287 [0/54 (0%)]\tTrain Loss: 0.013110\n",
      "Train Epoch: 287 [8/54 (15%)]\tTrain Loss: 0.003179\n",
      "Train Epoch: 287 [16/54 (30%)]\tTrain Loss: 0.003424\n",
      "Train Epoch: 287 [24/54 (44%)]\tTrain Loss: 0.058198\n",
      "Train Epoch: 287 [32/54 (59%)]\tTrain Loss: 0.082597\n",
      "Train Epoch: 287 [40/54 (74%)]\tTrain Loss: 0.010019\n",
      "Train Epoch: 287 [48/54 (89%)]\tTrain Loss: 0.001274\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.08390954e-04 9.99902010e-01 9.94402945e-01 9.80658889e-01\n",
      " 7.90578276e-02 6.90038200e-04 9.98352528e-01 9.51591492e-01\n",
      " 5.66677935e-02 3.71489197e-01 2.01748282e-01 5.49679846e-02\n",
      " 7.98735209e-03 5.01941440e-06 6.25662282e-02 6.72730198e-03\n",
      " 2.21667974e-03 4.59213927e-02 4.87927973e-01 7.86004007e-01\n",
      " 4.33765538e-03 9.99980927e-01 9.99982953e-01 9.99912143e-01\n",
      " 9.48022902e-01 9.99998927e-01 9.99900103e-01 8.76211047e-01\n",
      " 8.41990888e-01 2.58891672e-01 9.89547610e-01 9.99068558e-01\n",
      " 5.88693976e-01 3.19439073e-06 1.54645550e-05 2.30115745e-02\n",
      " 1.26645975e-02 9.97143686e-01 4.62406315e-02 7.44862676e-01\n",
      " 4.99471962e-01 2.35949248e-01 1.20470580e-02 7.74975121e-01\n",
      " 5.32220066e-01 5.64428866e-01 9.96516943e-01 9.98071015e-01\n",
      " 9.99999404e-01 9.87169981e-01 9.99940872e-01 5.34712970e-02\n",
      " 2.93649472e-02 5.86147547e-01 3.22697423e-02 4.84075844e-02\n",
      " 9.99359190e-01 4.00333991e-03 3.91644448e-01 7.62007374e-04\n",
      " 9.99913931e-01 9.58944619e-01 9.88175511e-01 9.99254763e-01\n",
      " 9.94582832e-01 9.94732857e-01 9.98605430e-01 9.99996781e-01\n",
      " 9.99999762e-01 9.63890314e-01 9.96027112e-01 9.94784772e-01\n",
      " 9.99981642e-01 9.95220244e-01 9.93578553e-01 9.99758422e-01\n",
      " 1.00000000e+00 9.99999881e-01 9.99994278e-01 9.99999404e-01\n",
      " 9.99999762e-01 9.99884963e-01 9.99998331e-01 8.88806403e-01\n",
      " 9.85287786e-01 9.99916077e-01 9.99831080e-01 9.99173224e-01\n",
      " 1.39415056e-01 9.90709543e-01 9.99571025e-01 2.87211120e-01\n",
      " 9.55899060e-01 1.00000000e+00 9.99899983e-01 9.99595940e-01\n",
      " 2.36924011e-02 9.97961044e-01 9.97058272e-01 9.05462146e-01\n",
      " 7.35348821e-01 9.99968052e-01 1.97664529e-01 9.99803722e-01\n",
      " 9.90496516e-01 9.79323745e-01 1.00000000e+00 1.53805941e-01\n",
      " 2.54222620e-02 9.92359221e-01 4.51374024e-01 3.99221361e-01\n",
      " 8.79726589e-01 7.97652960e-01 4.78341281e-01 8.96927714e-01\n",
      " 9.93903577e-01 9.93021309e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 288 [0/54 (0%)]\tTrain Loss: 0.001305\n",
      "Train Epoch: 288 [8/54 (15%)]\tTrain Loss: 0.001873\n",
      "Train Epoch: 288 [16/54 (30%)]\tTrain Loss: 0.000808\n",
      "Train Epoch: 288 [24/54 (44%)]\tTrain Loss: 0.060778\n",
      "Train Epoch: 288 [32/54 (59%)]\tTrain Loss: 0.006052\n",
      "Train Epoch: 288 [40/54 (74%)]\tTrain Loss: 0.000640\n",
      "Train Epoch: 288 [48/54 (89%)]\tTrain Loss: 0.005957\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.79253523e-04 9.75204766e-01 9.40423429e-01 4.17462498e-01\n",
      " 1.17815994e-02 4.06500476e-05 3.27492267e-01 2.54406154e-01\n",
      " 3.79332267e-02 1.33300915e-01 2.59735379e-02 4.64171433e-04\n",
      " 1.25261943e-03 8.25475752e-07 1.80757110e-04 1.76106885e-04\n",
      " 3.14521603e-04 2.43961951e-03 4.03751165e-01 8.49610642e-02\n",
      " 6.49846450e-04 9.99971628e-01 9.99690056e-01 9.99999762e-01\n",
      " 1.23546220e-01 9.99999881e-01 1.00000000e+00 2.60338515e-01\n",
      " 1.03864051e-01 3.88148203e-02 5.48945606e-01 8.78184497e-01\n",
      " 4.95204004e-04 3.61001148e-05 2.76600713e-05 2.48698634e-03\n",
      " 5.16322954e-03 9.71870184e-01 4.56918590e-03 2.02650633e-02\n",
      " 8.27647652e-03 3.87973757e-03 1.12633435e-02 4.90947105e-02\n",
      " 2.34556980e-02 5.91989458e-02 5.39607227e-01 8.88231635e-01\n",
      " 9.81590211e-01 9.99890804e-01 9.95281279e-01 1.09982593e-02\n",
      " 6.21527070e-05 9.03174207e-02 5.47424778e-02 2.54952931e-03\n",
      " 9.99681592e-01 4.10895143e-03 1.34211807e-02 1.82304448e-05\n",
      " 9.99999881e-01 9.87901092e-01 9.91669536e-01 9.99376118e-01\n",
      " 7.21471667e-01 1.61149770e-01 7.35818148e-01 9.99928355e-01\n",
      " 9.99999404e-01 6.42646313e-01 9.94119406e-01 9.93367016e-01\n",
      " 9.99744356e-01 9.10123587e-01 6.37710929e-01 9.98438776e-01\n",
      " 9.99999881e-01 9.99999762e-01 9.99669194e-01 9.99998927e-01\n",
      " 9.99999881e-01 9.99991655e-01 9.99999046e-01 1.16034269e-01\n",
      " 8.52778852e-01 9.99907374e-01 9.93321717e-01 9.85037625e-01\n",
      " 1.35740712e-02 9.99848366e-01 9.99998331e-01 1.11695327e-01\n",
      " 5.97742081e-01 1.00000000e+00 9.99999166e-01 9.99859929e-01\n",
      " 9.48320783e-04 9.16975141e-01 9.99502540e-01 9.95621741e-01\n",
      " 4.89314139e-01 9.99999762e-01 1.73323397e-02 9.99805272e-01\n",
      " 9.87592161e-01 9.98349905e-01 1.00000000e+00 3.14924829e-02\n",
      " 9.83977504e-03 9.75169957e-01 2.94861525e-01 6.03529692e-01\n",
      " 9.33475435e-01 9.93731439e-01 1.07649788e-01 1.74949497e-01\n",
      " 9.53029871e-01 6.97728992e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 289 [0/54 (0%)]\tTrain Loss: 0.066688\n",
      "Train Epoch: 289 [8/54 (15%)]\tTrain Loss: 0.002305\n",
      "Train Epoch: 289 [16/54 (30%)]\tTrain Loss: 0.000814\n",
      "Train Epoch: 289 [24/54 (44%)]\tTrain Loss: 0.056533\n",
      "Train Epoch: 289 [32/54 (59%)]\tTrain Loss: 0.046983\n",
      "Train Epoch: 289 [40/54 (74%)]\tTrain Loss: 0.044531\n",
      "Train Epoch: 289 [48/54 (89%)]\tTrain Loss: 0.015762\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.13473642e-04 7.44996250e-01 4.65732187e-01 1.16569847e-01\n",
      " 1.83658185e-03 2.04762502e-04 2.15088814e-01 6.92763645e-03\n",
      " 1.33554107e-02 1.37678338e-02 2.14002779e-04 2.70594959e-04\n",
      " 7.86000222e-04 1.05436502e-05 8.66096874e-04 2.39026631e-04\n",
      " 2.60469187e-05 3.24194855e-03 2.36123018e-02 1.48426279e-01\n",
      " 4.25965962e-04 7.13328779e-01 9.68079805e-01 9.64151084e-01\n",
      " 6.32295106e-03 9.99304652e-01 9.90838826e-01 1.15350448e-01\n",
      " 1.13706626e-02 5.93963824e-02 3.98422241e-01 7.34195113e-01\n",
      " 2.55304277e-01 1.01880140e-08 1.17156662e-06 4.40722750e-03\n",
      " 8.18446628e-04 1.71862885e-01 3.45107721e-04 1.64616783e-03\n",
      " 1.58937051e-04 3.66734130e-05 8.95337900e-04 2.40040198e-02\n",
      " 1.91743695e-03 6.67071249e-03 7.10180342e-01 5.68773389e-01\n",
      " 9.83848035e-01 9.06854689e-01 9.73812640e-01 2.72383204e-05\n",
      " 9.72976486e-05 5.03500523e-05 2.58490425e-02 4.58802067e-04\n",
      " 9.92285609e-01 8.33862519e-04 9.59831057e-04 1.32136074e-06\n",
      " 9.98824894e-01 9.34148550e-01 9.12288129e-01 9.88215685e-01\n",
      " 9.04382840e-02 5.66631913e-01 2.19577879e-01 9.99581158e-01\n",
      " 9.99947548e-01 1.49891272e-01 7.08750308e-01 7.10250497e-01\n",
      " 9.96984541e-01 9.84599769e-01 9.87524390e-01 4.35697824e-01\n",
      " 9.99702156e-01 9.99898791e-01 9.90965605e-01 9.99906540e-01\n",
      " 9.99972939e-01 9.99683142e-01 9.99896526e-01 1.24604041e-02\n",
      " 1.76443860e-01 9.79698181e-01 9.87538934e-01 9.57967043e-01\n",
      " 2.21053250e-02 5.04436381e-02 8.69358301e-01 4.75781877e-03\n",
      " 8.45292211e-02 9.99964356e-01 8.93438816e-01 7.21793473e-01\n",
      " 1.24051585e-04 5.69975330e-03 2.86457092e-01 4.60065417e-02\n",
      " 2.94930395e-02 9.52283561e-01 2.86431215e-03 2.58412719e-01\n",
      " 1.40800066e-02 3.94583493e-01 9.96447682e-01 7.30195176e-03\n",
      " 1.57908872e-02 8.82762730e-01 3.02572511e-02 4.27038502e-03\n",
      " 7.09448382e-02 7.75174126e-02 9.66236554e-03 5.21861017e-03\n",
      " 8.12184885e-02 2.28557065e-02]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 290 [0/54 (0%)]\tTrain Loss: 0.020827\n",
      "Train Epoch: 290 [8/54 (15%)]\tTrain Loss: 0.001864\n",
      "Train Epoch: 290 [16/54 (30%)]\tTrain Loss: 0.003038\n",
      "Train Epoch: 290 [24/54 (44%)]\tTrain Loss: 0.000607\n",
      "Train Epoch: 290 [32/54 (59%)]\tTrain Loss: 0.001007\n",
      "Train Epoch: 290 [40/54 (74%)]\tTrain Loss: 0.000357\n",
      "Train Epoch: 290 [48/54 (89%)]\tTrain Loss: 0.008418\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.87522707e-04 8.99150550e-01 8.02781940e-01 7.15473950e-01\n",
      " 2.19575856e-02 9.36162833e-05 7.90913939e-01 2.28181556e-01\n",
      " 1.53222736e-02 1.10489801e-01 9.43387393e-03 2.85694667e-04\n",
      " 4.85514058e-03 2.46795153e-05 2.23893160e-03 2.22258409e-03\n",
      " 4.56572161e-04 2.43368130e-02 6.15870237e-01 6.08137131e-01\n",
      " 4.53061512e-04 9.94446397e-01 9.99699593e-01 9.99967575e-01\n",
      " 3.98647003e-02 9.99999762e-01 9.99992013e-01 5.41391730e-01\n",
      " 1.46414950e-01 1.50352538e-01 1.39114290e-01 9.15650427e-01\n",
      " 2.69174546e-01 2.05717583e-06 1.62379547e-05 6.52140304e-02\n",
      " 1.12011600e-02 8.45501542e-01 2.92395405e-03 2.06652418e-01\n",
      " 1.39357904e-02 3.73378606e-03 5.96183166e-03 4.38596606e-01\n",
      " 1.21234469e-02 3.25749908e-03 7.39932597e-01 6.54139042e-01\n",
      " 9.91526783e-01 9.36433315e-01 9.39266622e-01 1.25503261e-02\n",
      " 3.64005705e-03 1.82856084e-03 3.03587336e-02 8.88009276e-03\n",
      " 9.93696511e-01 1.07239010e-02 1.26780500e-03 1.04150931e-04\n",
      " 9.99866724e-01 9.14095044e-01 9.38515246e-01 9.92541313e-01\n",
      " 9.05530214e-01 9.70876038e-01 9.35058475e-01 9.99898434e-01\n",
      " 1.00000000e+00 1.81041151e-01 6.94517791e-01 5.79416215e-01\n",
      " 9.99864340e-01 9.72427189e-01 9.93027747e-01 6.92329228e-01\n",
      " 9.99921799e-01 9.99995232e-01 9.91760612e-01 9.99998808e-01\n",
      " 9.99999881e-01 9.99830842e-01 9.99984384e-01 2.72727609e-02\n",
      " 5.57177126e-01 9.83581066e-01 9.94669139e-01 9.84767258e-01\n",
      " 7.17595443e-02 9.90956366e-01 9.55360830e-01 2.27224067e-01\n",
      " 5.65073192e-01 1.00000000e+00 9.99875546e-01 9.97898221e-01\n",
      " 1.44170807e-03 1.76206343e-02 5.07072508e-01 7.23465979e-01\n",
      " 3.29697877e-02 9.99110520e-01 3.54343932e-03 9.93275046e-01\n",
      " 9.97950807e-02 4.80213076e-01 9.99993443e-01 3.06685716e-02\n",
      " 1.55119434e-01 7.84205735e-01 4.17718679e-01 9.81570706e-02\n",
      " 7.89934337e-01 9.80575860e-01 3.89055870e-02 1.81591162e-03\n",
      " 3.48801613e-01 5.54544091e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 41 TN= 41 FN= 17 FP= 19\n",
      "TP+FP 60\n",
      "precision 0.6833333333333333\n",
      "recall 0.7068965517241379\n",
      "F1 0.6949152542372882\n",
      "acc 0.6949152542372882\n",
      "AUCp 0.6951149425287356\n",
      "AUC 0.7764367816091954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 290, average recall: 0.7069, average precision: 0.6833,average F1: 0.6949, average accuracy: 0.6949, average AUC: 0.7764\n",
      "Train Epoch: 291 [0/54 (0%)]\tTrain Loss: 0.000640\n",
      "Train Epoch: 291 [8/54 (15%)]\tTrain Loss: 0.000587\n",
      "Train Epoch: 291 [16/54 (30%)]\tTrain Loss: 0.004638\n",
      "Train Epoch: 291 [24/54 (44%)]\tTrain Loss: 0.001342\n",
      "Train Epoch: 291 [32/54 (59%)]\tTrain Loss: 0.004942\n",
      "Train Epoch: 291 [40/54 (74%)]\tTrain Loss: 0.000336\n",
      "Train Epoch: 291 [48/54 (89%)]\tTrain Loss: 0.011911\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.75941704e-05 8.91639054e-01 8.68688822e-01 9.79363739e-01\n",
      " 1.84788004e-01 2.04693715e-05 9.31245089e-01 8.31948280e-01\n",
      " 4.74646203e-02 1.09766498e-01 1.36865685e-02 1.64624871e-04\n",
      " 2.33255792e-03 7.06195442e-06 3.05742561e-03 5.04169567e-03\n",
      " 1.13736233e-03 3.39634381e-02 7.10559130e-01 2.71111399e-01\n",
      " 9.42337283e-05 9.96437192e-01 9.98992383e-01 9.99991775e-01\n",
      " 4.88728695e-02 9.99993563e-01 9.99996305e-01 4.21385318e-01\n",
      " 4.32839058e-02 5.31064011e-02 1.89209402e-01 9.45922136e-01\n",
      " 5.53436764e-02 8.37393509e-06 8.41298315e-05 1.27496377e-01\n",
      " 1.77380107e-02 9.65791047e-01 3.36949830e-03 4.53853458e-02\n",
      " 8.18288513e-03 3.11253156e-04 3.79185751e-02 2.73748904e-01\n",
      " 3.58421542e-03 5.70877746e-04 7.91798830e-01 6.03530586e-01\n",
      " 9.93652821e-01 8.62103105e-01 9.27731752e-01 1.91860273e-02\n",
      " 4.47775284e-03 1.83028483e-03 9.23188310e-03 2.17736396e-03\n",
      " 9.91383314e-01 1.76558234e-02 4.90305275e-02 5.51298472e-05\n",
      " 9.99981642e-01 9.77097273e-01 9.87228632e-01 9.98292744e-01\n",
      " 8.12925398e-01 9.03457165e-01 9.67378795e-01 9.99030471e-01\n",
      " 9.99998689e-01 1.78821295e-01 8.17935228e-01 8.44663441e-01\n",
      " 9.98852849e-01 9.26833391e-01 8.02289426e-01 8.87739301e-01\n",
      " 9.99961853e-01 9.99984264e-01 9.98505473e-01 9.99985814e-01\n",
      " 9.99996781e-01 9.99317646e-01 9.99785006e-01 3.71598065e-01\n",
      " 6.05534732e-01 9.85480011e-01 9.95249271e-01 9.96906221e-01\n",
      " 3.81024443e-02 9.96210337e-01 9.69529390e-01 6.78299487e-01\n",
      " 6.86199605e-01 1.00000000e+00 9.99741137e-01 9.99349058e-01\n",
      " 3.32763162e-03 5.42179942e-02 5.89927435e-01 9.86402929e-01\n",
      " 6.30699545e-02 9.99676466e-01 5.96877933e-02 9.99295473e-01\n",
      " 4.59467351e-01 7.73034573e-01 9.99999046e-01 9.27509181e-03\n",
      " 7.60413408e-02 6.25699699e-01 5.81239462e-01 4.31960523e-02\n",
      " 9.15839970e-01 9.84293401e-01 2.04743758e-01 9.60545689e-02\n",
      " 6.76637530e-01 9.76475358e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 292 [0/54 (0%)]\tTrain Loss: 0.045318\n",
      "Train Epoch: 292 [8/54 (15%)]\tTrain Loss: 0.002911\n",
      "Train Epoch: 292 [16/54 (30%)]\tTrain Loss: 0.005414\n",
      "Train Epoch: 292 [24/54 (44%)]\tTrain Loss: 0.000732\n",
      "Train Epoch: 292 [32/54 (59%)]\tTrain Loss: 0.000799\n",
      "Train Epoch: 292 [40/54 (74%)]\tTrain Loss: 0.000882\n",
      "Train Epoch: 292 [48/54 (89%)]\tTrain Loss: 0.000729\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.88682386e-05 8.73409569e-01 5.38647354e-01 9.99076128e-01\n",
      " 8.20453763e-01 2.32746629e-06 9.19868290e-01 9.98711586e-01\n",
      " 1.10489875e-01 3.32613766e-01 4.69278060e-02 1.94809778e-04\n",
      " 1.79921910e-01 2.86344317e-07 1.99177172e-02 4.72079366e-02\n",
      " 1.05665354e-02 7.02166706e-02 7.83024013e-01 2.63617098e-01\n",
      " 2.25166627e-03 9.99770701e-01 9.99960542e-01 9.99962807e-01\n",
      " 2.23510444e-01 9.99999881e-01 9.99995947e-01 8.91870677e-01\n",
      " 3.43401641e-01 6.22165352e-02 8.74672353e-01 9.94862497e-01\n",
      " 5.90745499e-03 9.96177696e-05 1.85429433e-03 6.00311339e-01\n",
      " 6.09009452e-02 9.98271346e-01 2.89621623e-03 1.78080618e-01\n",
      " 1.62348803e-02 1.07633905e-03 6.24022782e-02 9.08799350e-01\n",
      " 6.06045388e-02 7.66782206e-04 9.48123276e-01 8.13686371e-01\n",
      " 9.99945879e-01 8.99876118e-01 9.97708321e-01 2.81323418e-02\n",
      " 2.39429995e-02 3.37696858e-02 7.78015377e-03 3.68320905e-02\n",
      " 9.92865562e-01 1.29649192e-01 2.46800527e-01 9.64699965e-03\n",
      " 9.99994516e-01 9.57420826e-01 9.54163790e-01 9.93584335e-01\n",
      " 9.97389257e-01 9.99631166e-01 9.98939574e-01 9.99710739e-01\n",
      " 1.00000000e+00 5.56025207e-01 9.65155423e-01 9.50146317e-01\n",
      " 9.99996901e-01 9.95839357e-01 8.32582235e-01 8.46959174e-01\n",
      " 9.99904990e-01 9.99983788e-01 9.99977231e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99979496e-01 9.99988914e-01 4.36997004e-02\n",
      " 5.72001636e-01 9.71830904e-01 9.98785555e-01 9.95325208e-01\n",
      " 2.32034385e-01 9.99971271e-01 9.35906529e-01 9.91574705e-01\n",
      " 9.63650644e-01 1.00000000e+00 9.99987960e-01 9.99882936e-01\n",
      " 3.68936211e-01 2.63776034e-01 6.44205689e-01 9.99299645e-01\n",
      " 1.71313491e-02 9.99969363e-01 6.26243185e-03 9.98657584e-01\n",
      " 8.09667408e-01 8.18382978e-01 9.99999762e-01 2.47374937e-01\n",
      " 3.16899359e-01 9.25573945e-01 5.87156713e-01 5.57926632e-02\n",
      " 9.96153295e-01 9.97115254e-01 1.21030159e-01 4.87782694e-02\n",
      " 2.26338923e-01 9.48088109e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1.]\n",
      "Train Epoch: 293 [0/54 (0%)]\tTrain Loss: 0.032129\n",
      "Train Epoch: 293 [8/54 (15%)]\tTrain Loss: 0.004001\n",
      "Train Epoch: 293 [16/54 (30%)]\tTrain Loss: 0.000656\n",
      "Train Epoch: 293 [24/54 (44%)]\tTrain Loss: 0.003870\n",
      "Train Epoch: 293 [32/54 (59%)]\tTrain Loss: 0.007824\n",
      "Train Epoch: 293 [40/54 (74%)]\tTrain Loss: 0.000122\n",
      "Train Epoch: 293 [48/54 (89%)]\tTrain Loss: 0.000540\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.88091333e-04 5.65821588e-01 1.27528340e-01 9.98323381e-01\n",
      " 4.35496598e-01 2.89151794e-04 2.57927895e-01 9.93558824e-01\n",
      " 2.45165914e-01 8.17879796e-01 5.92414081e-01 1.21197179e-02\n",
      " 3.62843394e-01 5.24653423e-08 3.21620889e-03 3.54969478e-03\n",
      " 8.97319615e-03 2.22826432e-02 9.90423501e-01 7.31883347e-01\n",
      " 9.96704549e-02 9.99978662e-01 9.99994397e-01 9.99999523e-01\n",
      " 2.48038262e-01 1.00000000e+00 1.00000000e+00 9.83696401e-01\n",
      " 1.35648027e-01 1.98439851e-01 6.16375864e-01 9.95974243e-01\n",
      " 4.22622040e-02 8.64772010e-04 3.22615891e-03 1.13767453e-01\n",
      " 5.80474967e-03 9.99564707e-01 5.36431558e-04 6.79081604e-02\n",
      " 1.26108341e-02 3.22503247e-03 1.50184017e-02 1.66195825e-01\n",
      " 4.74364311e-02 2.33831073e-04 1.53474584e-01 2.93334484e-01\n",
      " 9.99365032e-01 9.93431032e-01 9.02598500e-01 2.52770889e-03\n",
      " 6.60142154e-02 1.01748630e-02 8.17816705e-02 1.13035962e-02\n",
      " 9.94565964e-01 3.13279331e-01 7.98159003e-01 2.68458575e-03\n",
      " 9.99999046e-01 9.71984029e-01 9.74101126e-01 9.95759070e-01\n",
      " 9.74024415e-01 6.73061788e-01 9.73030508e-01 9.99958038e-01\n",
      " 1.00000000e+00 2.01494321e-01 9.66618836e-01 9.78145123e-01\n",
      " 9.99968290e-01 9.96593058e-01 7.29052663e-01 9.89450872e-01\n",
      " 9.94353533e-01 9.98531342e-01 9.99989510e-01 9.99998212e-01\n",
      " 9.99992728e-01 9.99907851e-01 9.99802172e-01 7.43979216e-01\n",
      " 9.23957050e-01 9.91075635e-01 9.99808848e-01 9.98751163e-01\n",
      " 7.58516669e-01 9.99994755e-01 9.99538064e-01 9.47868764e-01\n",
      " 9.26002741e-01 1.00000000e+00 9.99998689e-01 9.99999881e-01\n",
      " 9.20298696e-01 9.76986945e-01 9.99795020e-01 9.99994636e-01\n",
      " 3.78056824e-01 9.99916553e-01 2.70098895e-01 9.99906182e-01\n",
      " 9.93261278e-01 6.52101457e-01 9.99999762e-01 1.38048567e-02\n",
      " 4.21861336e-02 7.28235960e-01 2.44916379e-01 1.03782371e-01\n",
      " 9.99485731e-01 9.99198139e-01 8.69830608e-01 3.92403007e-01\n",
      " 9.95515049e-01 9.99364197e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 294 [0/54 (0%)]\tTrain Loss: 0.001209\n",
      "Train Epoch: 294 [8/54 (15%)]\tTrain Loss: 0.001167\n",
      "Train Epoch: 294 [16/54 (30%)]\tTrain Loss: 0.009883\n",
      "Train Epoch: 294 [24/54 (44%)]\tTrain Loss: 0.001715\n",
      "Train Epoch: 294 [32/54 (59%)]\tTrain Loss: 0.039678\n",
      "Train Epoch: 294 [40/54 (74%)]\tTrain Loss: 0.000693\n",
      "Train Epoch: 294 [48/54 (89%)]\tTrain Loss: 0.028498\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.88165213e-04 9.86322999e-01 9.25073385e-01 9.87747073e-01\n",
      " 9.45742801e-02 6.78765864e-05 6.55967414e-01 7.36146808e-01\n",
      " 9.77037922e-02 4.62819397e-01 5.40977344e-02 2.41534493e-04\n",
      " 1.88904107e-02 2.70311080e-04 1.60459578e-02 1.88509596e-03\n",
      " 1.20164861e-03 1.21030817e-02 5.03259242e-01 8.35489154e-01\n",
      " 1.88039834e-04 9.78696704e-01 9.99102712e-01 9.99925852e-01\n",
      " 8.37087631e-02 9.99996066e-01 9.97909606e-01 2.55025148e-01\n",
      " 1.10431619e-01 2.53673583e-01 7.44580805e-01 9.95593369e-01\n",
      " 1.08457208e-01 5.41993404e-06 8.50246306e-06 2.59958189e-02\n",
      " 7.28596561e-03 9.98834312e-01 4.52042441e-05 1.45923859e-02\n",
      " 3.19123128e-03 1.57729737e-04 3.30867544e-02 2.22628817e-01\n",
      " 3.32003017e-03 8.68477277e-04 7.30772674e-01 6.69745266e-01\n",
      " 9.97493267e-01 9.76831734e-01 9.73793328e-01 1.91145821e-03\n",
      " 1.05324760e-03 9.41231672e-04 3.73887015e-04 2.35124328e-03\n",
      " 9.52012956e-01 1.04354806e-02 3.01960409e-01 2.67737708e-03\n",
      " 9.98945534e-01 8.98518264e-01 9.14029360e-01 9.84356225e-01\n",
      " 9.51885164e-01 9.04390812e-01 9.96751070e-01 9.98196661e-01\n",
      " 9.99971747e-01 2.01191381e-02 6.72277987e-01 6.27677739e-01\n",
      " 9.91608679e-01 7.79251099e-01 8.75073254e-01 9.93557513e-01\n",
      " 9.99996066e-01 9.99997258e-01 9.99942064e-01 9.99938488e-01\n",
      " 9.99998450e-01 9.99771893e-01 9.95736957e-01 4.29508761e-02\n",
      " 4.34529305e-01 9.94847059e-01 9.97944415e-01 9.95657563e-01\n",
      " 1.18988715e-01 4.13758874e-01 8.43536675e-01 3.35108310e-01\n",
      " 4.10777837e-01 9.99983549e-01 8.85733366e-01 9.98778999e-01\n",
      " 6.76654221e-04 4.68270630e-02 6.11328959e-01 7.64349401e-01\n",
      " 1.05674220e-02 9.80984092e-01 1.57259610e-02 8.46290708e-01\n",
      " 3.44514370e-01 1.56050436e-02 9.99769509e-01 2.89448421e-03\n",
      " 5.83506636e-02 9.62850094e-01 1.97951809e-01 1.18843475e-02\n",
      " 5.18785179e-01 9.24757242e-01 7.05114380e-02 8.82435068e-02\n",
      " 7.16032684e-01 9.43979025e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 295 [0/54 (0%)]\tTrain Loss: 0.002459\n",
      "Train Epoch: 295 [8/54 (15%)]\tTrain Loss: 0.013554\n",
      "Train Epoch: 295 [16/54 (30%)]\tTrain Loss: 0.000214\n",
      "Train Epoch: 295 [24/54 (44%)]\tTrain Loss: 0.001304\n",
      "Train Epoch: 295 [32/54 (59%)]\tTrain Loss: 0.000617\n",
      "Train Epoch: 295 [40/54 (74%)]\tTrain Loss: 0.027747\n",
      "Train Epoch: 295 [48/54 (89%)]\tTrain Loss: 0.000778\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.85742903e-03 5.01395404e-01 4.62960064e-01 6.78728640e-01\n",
      " 8.46635029e-02 1.72028740e-05 2.02775717e-01 3.30343634e-01\n",
      " 1.36330454e-02 9.07862902e-01 9.75505784e-02 3.02675292e-02\n",
      " 1.05662227e-01 6.74375997e-06 1.21645618e-03 1.93224987e-03\n",
      " 8.03433417e-04 5.25683118e-03 7.98389733e-01 3.69809359e-01\n",
      " 1.61492068e-03 9.67603326e-01 9.99986529e-01 9.99998569e-01\n",
      " 4.61794287e-02 1.00000000e+00 1.00000000e+00 8.89811575e-01\n",
      " 1.63702250e-01 4.70999420e-01 9.55242157e-01 9.99903679e-01\n",
      " 5.12863159e-01 2.98242638e-04 9.42572020e-04 1.86228380e-02\n",
      " 8.98336153e-03 9.99758780e-01 2.47217156e-03 3.34482193e-01\n",
      " 2.14065649e-02 7.73356203e-03 3.52559052e-03 1.01997197e-01\n",
      " 1.98785048e-02 7.52188847e-04 9.64779019e-01 9.59917963e-01\n",
      " 9.99085069e-01 9.60661411e-01 9.84145701e-01 2.71235779e-03\n",
      " 4.32846742e-03 1.58187635e-02 5.05983224e-03 1.59997307e-02\n",
      " 9.53510106e-01 2.45684721e-02 2.97183059e-02 6.98894076e-03\n",
      " 9.97930050e-01 7.98946917e-01 8.26702416e-01 9.82616067e-01\n",
      " 9.99877810e-01 6.70388281e-01 9.99879718e-01 9.99326944e-01\n",
      " 1.00000000e+00 5.16194403e-01 5.73730052e-01 7.67603099e-01\n",
      " 9.99941111e-01 9.89296734e-01 9.99823630e-01 9.95269120e-01\n",
      " 9.99967337e-01 9.99987841e-01 9.99981165e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99979258e-01 9.99901175e-01 2.02055331e-02\n",
      " 9.35137212e-01 9.99935031e-01 9.99860883e-01 9.99404311e-01\n",
      " 4.01947983e-02 9.89090621e-01 9.98089135e-01 8.38208616e-01\n",
      " 2.54142761e-01 9.99999881e-01 9.89475846e-01 9.99915123e-01\n",
      " 8.17116871e-02 2.41146952e-01 8.28883469e-01 9.67917144e-01\n",
      " 3.18417996e-02 9.99998689e-01 1.12176884e-03 9.18217063e-01\n",
      " 8.74050617e-01 2.79776514e-01 1.00000000e+00 1.36900516e-02\n",
      " 3.27738300e-02 9.41321790e-01 2.29830872e-02 2.81480290e-02\n",
      " 9.42900300e-01 9.87956822e-01 6.86964765e-03 1.80505570e-02\n",
      " 9.96421576e-01 9.99485135e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 296 [0/54 (0%)]\tTrain Loss: 0.018612\n",
      "Train Epoch: 296 [8/54 (15%)]\tTrain Loss: 0.000809\n",
      "Train Epoch: 296 [16/54 (30%)]\tTrain Loss: 0.001955\n",
      "Train Epoch: 296 [24/54 (44%)]\tTrain Loss: 0.047357\n",
      "Train Epoch: 296 [32/54 (59%)]\tTrain Loss: 0.013582\n",
      "Train Epoch: 296 [40/54 (74%)]\tTrain Loss: 0.002327\n",
      "Train Epoch: 296 [48/54 (89%)]\tTrain Loss: 0.004751\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.67429069e-04 5.16505003e-01 8.23614970e-02 9.20185983e-01\n",
      " 3.07783503e-02 2.80808563e-05 9.23263282e-02 3.67480129e-01\n",
      " 7.29066208e-02 4.17466760e-01 5.18359896e-03 8.09667225e-04\n",
      " 3.04057375e-02 6.12248405e-05 3.03220539e-03 2.27023440e-04\n",
      " 5.44398681e-05 2.10651592e-03 8.51650357e-01 1.25814646e-01\n",
      " 2.65379879e-03 9.85666931e-01 9.99998927e-01 9.99999762e-01\n",
      " 3.44772860e-02 1.00000000e+00 9.99999881e-01 5.40661275e-01\n",
      " 9.43322927e-02 1.88589424e-01 7.63903782e-02 9.90463853e-01\n",
      " 2.72759353e-03 2.86505878e-04 9.14078730e-04 4.15096767e-02\n",
      " 1.46510592e-03 6.83070183e-01 3.15959100e-04 5.29395416e-03\n",
      " 7.95977539e-04 5.07308869e-04 3.26317531e-04 6.24793507e-02\n",
      " 6.16322132e-03 3.32526361e-05 7.82091081e-01 2.19853088e-01\n",
      " 9.88407433e-01 9.33548450e-01 9.88713503e-01 4.87559482e-05\n",
      " 1.86021614e-03 2.89925700e-03 2.07252633e-02 5.20579563e-03\n",
      " 6.53728247e-01 3.17225442e-03 1.37431666e-01 5.04968362e-03\n",
      " 9.98555601e-01 9.11784887e-01 7.23796368e-01 8.30812991e-01\n",
      " 9.99988079e-01 5.90690911e-01 9.96390045e-01 9.99697566e-01\n",
      " 9.99999881e-01 3.45118374e-01 8.80425513e-01 9.11389232e-01\n",
      " 9.99992013e-01 9.98236537e-01 9.90918875e-01 9.11266506e-01\n",
      " 9.99998689e-01 9.99999404e-01 9.99937296e-01 9.99993801e-01\n",
      " 1.00000000e+00 9.99660969e-01 9.99995828e-01 3.89989757e-04\n",
      " 1.65407985e-01 6.20277762e-01 9.99293208e-01 9.97766733e-01\n",
      " 1.28204927e-01 9.96008992e-01 9.58650589e-01 3.40910852e-01\n",
      " 8.65666792e-02 9.99999881e-01 9.42367017e-01 9.99461114e-01\n",
      " 5.89125836e-03 8.65344480e-02 3.81440312e-01 8.08433294e-01\n",
      " 3.21001150e-02 9.99791086e-01 8.18068627e-03 8.51759613e-02\n",
      " 5.97245507e-02 8.45420808e-02 9.99999404e-01 5.31290565e-03\n",
      " 4.36372310e-01 9.92505491e-01 7.77944699e-02 1.60820782e-01\n",
      " 9.32398438e-01 9.57741082e-01 4.63634916e-02 4.52227704e-03\n",
      " 9.22052741e-01 9.84240413e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 297 [0/54 (0%)]\tTrain Loss: 0.000794\n",
      "Train Epoch: 297 [8/54 (15%)]\tTrain Loss: 0.000944\n",
      "Train Epoch: 297 [16/54 (30%)]\tTrain Loss: 0.004987\n",
      "Train Epoch: 297 [24/54 (44%)]\tTrain Loss: 0.001080\n",
      "Train Epoch: 297 [32/54 (59%)]\tTrain Loss: 0.018543\n",
      "Train Epoch: 297 [40/54 (74%)]\tTrain Loss: 0.000106\n",
      "Train Epoch: 297 [48/54 (89%)]\tTrain Loss: 0.000596\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.26373207e-04 9.48734701e-01 6.77640259e-01 9.22001123e-01\n",
      " 7.13570341e-02 8.85336849e-05 6.19828820e-01 9.34547007e-01\n",
      " 3.93873341e-02 2.02326998e-01 2.71741394e-03 5.16156761e-05\n",
      " 9.22884326e-03 2.06797558e-04 4.06432971e-02 1.81792115e-04\n",
      " 2.69575758e-05 2.49313079e-02 5.90438843e-01 2.26985335e-01\n",
      " 6.46216577e-05 9.92947340e-01 9.99999285e-01 9.99999642e-01\n",
      " 6.83812425e-03 1.00000000e+00 1.00000000e+00 2.34806478e-01\n",
      " 2.63576061e-02 1.24837689e-01 1.76021338e-01 9.90973771e-01\n",
      " 6.07980378e-02 4.29621878e-06 1.08665474e-04 1.53322276e-02\n",
      " 4.00680961e-04 9.11157131e-01 3.32680135e-03 9.83517151e-03\n",
      " 1.40522898e-03 8.03044473e-04 5.36417635e-03 3.12441997e-02\n",
      " 2.49189250e-02 3.39126826e-04 9.61461663e-01 7.30242312e-01\n",
      " 9.99270260e-01 9.56376433e-01 9.97256339e-01 8.78044462e-04\n",
      " 5.84052061e-04 1.81324586e-01 2.19425699e-03 2.23102910e-03\n",
      " 9.99205530e-01 1.82384420e-02 5.76724969e-02 1.07923988e-02\n",
      " 9.99690771e-01 9.78917658e-01 9.94513988e-01 9.97905016e-01\n",
      " 9.99724090e-01 9.99068201e-01 9.99907374e-01 9.99952316e-01\n",
      " 1.00000000e+00 2.25979418e-01 9.73784924e-01 9.48239684e-01\n",
      " 9.99998569e-01 9.98777926e-01 9.94969666e-01 9.96283352e-01\n",
      " 9.99993205e-01 9.99999523e-01 9.99982357e-01 9.99989986e-01\n",
      " 1.00000000e+00 9.99973536e-01 9.99999046e-01 1.11148627e-02\n",
      " 9.12910521e-01 9.97621238e-01 9.99977946e-01 9.99916434e-01\n",
      " 2.85228435e-02 3.37105423e-01 9.76446509e-01 9.54229653e-01\n",
      " 6.55111849e-01 1.00000000e+00 9.43908572e-01 9.99850273e-01\n",
      " 9.38068726e-04 1.87452868e-01 3.29323918e-01 3.01394165e-01\n",
      " 3.45698223e-02 9.99897838e-01 8.03282578e-03 7.79902816e-01\n",
      " 5.60520291e-01 1.10954046e-01 1.00000000e+00 2.41629477e-03\n",
      " 8.87502916e-03 9.43562448e-01 6.54689595e-02 1.31015599e-01\n",
      " 8.52399707e-01 6.70460761e-01 9.81421769e-03 7.77247995e-02\n",
      " 6.49122953e-01 9.54313993e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 298 [0/54 (0%)]\tTrain Loss: 0.000817\n",
      "Train Epoch: 298 [8/54 (15%)]\tTrain Loss: 0.000380\n",
      "Train Epoch: 298 [16/54 (30%)]\tTrain Loss: 0.004908\n",
      "Train Epoch: 298 [24/54 (44%)]\tTrain Loss: 0.051451\n",
      "Train Epoch: 298 [32/54 (59%)]\tTrain Loss: 0.007284\n",
      "Train Epoch: 298 [40/54 (74%)]\tTrain Loss: 0.000564\n",
      "Train Epoch: 298 [48/54 (89%)]\tTrain Loss: 0.000752\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.91336007e-04 9.99611914e-01 9.75749016e-01 9.94248748e-01\n",
      " 9.35160637e-01 1.15570810e-03 9.98425245e-01 9.96039748e-01\n",
      " 1.53355628e-01 7.61813641e-01 1.08032882e-01 2.08144294e-04\n",
      " 5.99610806e-01 2.76652854e-02 6.64486229e-01 1.06098847e-02\n",
      " 3.01590979e-01 3.03554893e-01 9.05183792e-01 8.16757441e-01\n",
      " 2.69007846e-03 9.99813378e-01 1.00000000e+00 9.99719560e-01\n",
      " 6.78214312e-01 1.00000000e+00 9.99940038e-01 9.62340772e-01\n",
      " 9.88509953e-01 7.86885202e-01 8.77523780e-01 9.72123265e-01\n",
      " 2.84954906e-01 5.38099650e-03 1.55967828e-02 1.40066236e-01\n",
      " 6.47310093e-02 9.60387349e-01 4.04330045e-02 1.85821444e-01\n",
      " 1.21407118e-02 1.39694959e-02 1.70359798e-02 6.94113016e-01\n",
      " 3.18788469e-01 7.32382899e-03 9.87275243e-01 8.94855022e-01\n",
      " 9.99564230e-01 9.83786166e-01 9.99302506e-01 4.40873280e-02\n",
      " 1.74930934e-02 6.58569992e-01 1.33848578e-01 7.61758238e-02\n",
      " 9.98944581e-01 1.73805803e-01 7.31667995e-01 4.47674692e-01\n",
      " 9.95086133e-01 9.62090790e-01 9.85600352e-01 9.96197879e-01\n",
      " 9.95017231e-01 9.99553144e-01 9.99980569e-01 9.99998212e-01\n",
      " 1.00000000e+00 5.12660623e-01 9.80230391e-01 9.81432498e-01\n",
      " 9.99990702e-01 9.99729931e-01 9.96357143e-01 9.85655010e-01\n",
      " 9.99998689e-01 9.99999762e-01 9.99987721e-01 9.99988317e-01\n",
      " 1.00000000e+00 9.99973655e-01 9.99999166e-01 3.56091075e-02\n",
      " 7.94322431e-01 9.60943341e-01 9.99845624e-01 9.99560654e-01\n",
      " 2.47392893e-01 9.90801513e-01 9.15940762e-01 9.94360626e-01\n",
      " 9.29393709e-01 1.00000000e+00 9.96833146e-01 9.99968886e-01\n",
      " 5.62486500e-02 9.93713558e-01 9.60236192e-01 9.97562289e-01\n",
      " 2.12326795e-01 9.91476953e-01 1.96437091e-01 9.88600016e-01\n",
      " 5.40231049e-01 8.30721080e-01 9.99999046e-01 2.26010606e-01\n",
      " 7.72169590e-01 9.96890843e-01 8.98548186e-01 7.70852327e-01\n",
      " 9.99938011e-01 9.99911070e-01 3.51057082e-01 5.97359717e-01\n",
      " 9.15009558e-01 9.90576029e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "Train Epoch: 299 [0/54 (0%)]\tTrain Loss: 0.002737\n",
      "Train Epoch: 299 [8/54 (15%)]\tTrain Loss: 0.009308\n",
      "Train Epoch: 299 [16/54 (30%)]\tTrain Loss: 0.005443\n",
      "Train Epoch: 299 [24/54 (44%)]\tTrain Loss: 0.000428\n",
      "Train Epoch: 299 [32/54 (59%)]\tTrain Loss: 0.000477\n",
      "Train Epoch: 299 [40/54 (74%)]\tTrain Loss: 0.000339\n",
      "Train Epoch: 299 [48/54 (89%)]\tTrain Loss: 0.004060\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.61973779e-03 9.86028075e-01 7.85524428e-01 8.59375894e-01\n",
      " 9.61696655e-02 1.19009370e-03 9.69041228e-01 7.95529425e-01\n",
      " 2.15280857e-02 9.33111191e-01 3.78620952e-01 3.02733714e-03\n",
      " 3.63607891e-02 3.77422271e-06 1.03984913e-02 1.12115076e-05\n",
      " 5.43704140e-04 5.23951054e-02 8.39805841e-01 6.05512619e-01\n",
      " 1.62295857e-03 9.95682955e-01 9.99999642e-01 9.99982238e-01\n",
      " 2.52469659e-01 1.00000000e+00 9.99993801e-01 4.11309510e-01\n",
      " 6.94034457e-01 8.81830379e-02 3.24429907e-02 9.57089186e-01\n",
      " 1.92653462e-01 4.71829162e-06 3.08423332e-04 2.08836999e-02\n",
      " 3.97233351e-04 9.10827041e-01 1.11659220e-03 9.76689905e-03\n",
      " 3.39841412e-04 2.63394730e-04 3.05897836e-03 1.26023525e-02\n",
      " 7.03596622e-02 1.20372903e-02 9.35689211e-01 8.72217178e-01\n",
      " 9.99403954e-01 9.08137441e-01 9.99671817e-01 5.01483819e-03\n",
      " 5.72425127e-03 1.15663454e-01 5.98740880e-04 2.95465160e-03\n",
      " 9.82765853e-01 4.14183848e-02 7.17134893e-01 3.39027904e-02\n",
      " 9.99819696e-01 9.15703654e-01 9.55326021e-01 9.98907804e-01\n",
      " 9.78581727e-01 8.04380476e-01 9.99817073e-01 9.99973655e-01\n",
      " 9.99999881e-01 5.36717176e-02 9.85339701e-01 9.67400372e-01\n",
      " 9.99996543e-01 9.95591581e-01 9.60013986e-01 9.85228837e-01\n",
      " 9.99999642e-01 1.00000000e+00 9.99996662e-01 9.99999523e-01\n",
      " 1.00000000e+00 9.99962211e-01 9.99997973e-01 7.86277577e-02\n",
      " 9.77902293e-01 9.94698882e-01 9.99982715e-01 9.99813139e-01\n",
      " 2.13698789e-01 2.20103100e-01 9.99780118e-01 9.64545071e-01\n",
      " 5.70504427e-01 1.00000000e+00 9.99940157e-01 9.99999523e-01\n",
      " 1.50227966e-02 9.53774393e-01 9.96689141e-01 9.20061469e-01\n",
      " 2.98366603e-02 9.97311950e-01 3.50278206e-02 9.99388456e-01\n",
      " 8.23993146e-01 6.20461464e-01 1.00000000e+00 1.46615244e-02\n",
      " 4.30871826e-03 9.90648568e-01 5.11789368e-03 1.62799601e-02\n",
      " 9.93778646e-01 9.79166985e-01 1.12392241e-02 3.59704137e-01\n",
      " 9.65216994e-01 5.00007093e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 300 [0/54 (0%)]\tTrain Loss: 0.000670\n",
      "Train Epoch: 300 [8/54 (15%)]\tTrain Loss: 0.001492\n",
      "Train Epoch: 300 [16/54 (30%)]\tTrain Loss: 0.009541\n",
      "Train Epoch: 300 [24/54 (44%)]\tTrain Loss: 0.000168\n",
      "Train Epoch: 300 [32/54 (59%)]\tTrain Loss: 0.001961\n",
      "Train Epoch: 300 [40/54 (74%)]\tTrain Loss: 0.000195\n",
      "Train Epoch: 300 [48/54 (89%)]\tTrain Loss: 0.000084\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.93664324e-04 5.97434580e-01 4.46933419e-01 8.98874521e-01\n",
      " 1.58751272e-02 4.98114860e-05 4.87360060e-01 3.85377824e-01\n",
      " 1.98785424e-01 9.72212613e-01 1.88296229e-01 2.08490458e-03\n",
      " 9.13327560e-03 4.54014298e-06 4.35056165e-03 3.03679626e-05\n",
      " 3.21679072e-05 5.54598719e-02 9.60340619e-01 1.03066713e-01\n",
      " 2.94445752e-04 9.97446775e-01 9.99999881e-01 9.99999762e-01\n",
      " 1.28698692e-01 1.00000000e+00 9.99999762e-01 1.29837766e-01\n",
      " 3.85025799e-01 1.50950268e-01 2.46741362e-02 9.86752868e-01\n",
      " 1.57727730e-02 7.99433963e-07 3.26159279e-05 5.22329612e-03\n",
      " 2.22497154e-04 9.25110400e-01 3.18110513e-04 8.01372994e-03\n",
      " 9.65701533e-04 9.78451688e-04 1.22077600e-03 2.98231724e-03\n",
      " 5.28692938e-02 6.55348040e-03 9.41751480e-01 9.59258676e-01\n",
      " 9.99947071e-01 9.85876620e-01 9.99994397e-01 5.13852392e-05\n",
      " 1.83977769e-04 9.77335405e-03 2.36835820e-03 2.90082977e-03\n",
      " 9.69668925e-01 1.90354194e-02 8.04297805e-01 5.46222441e-02\n",
      " 9.86225605e-01 8.39417279e-01 8.90672922e-01 9.89605904e-01\n",
      " 9.89949465e-01 5.76763391e-01 9.96387720e-01 9.99919534e-01\n",
      " 9.99999642e-01 1.77773312e-01 9.81994212e-01 9.58729386e-01\n",
      " 9.99952793e-01 9.39698100e-01 9.03702557e-01 9.70612526e-01\n",
      " 9.99949217e-01 9.99994397e-01 9.99997258e-01 9.99998808e-01\n",
      " 1.00000000e+00 9.99957919e-01 9.99999881e-01 6.10329490e-03\n",
      " 8.18354130e-01 9.88379836e-01 9.99967217e-01 9.99876618e-01\n",
      " 7.50114024e-02 7.19715953e-01 9.99980450e-01 7.84285784e-01\n",
      " 3.62363517e-01 1.00000000e+00 9.99988437e-01 9.99999523e-01\n",
      " 5.03538065e-02 8.26045036e-01 8.84196103e-01 9.89844084e-01\n",
      " 4.67531532e-02 9.58232105e-01 1.01245372e-02 9.98187840e-01\n",
      " 9.90080893e-01 8.53449523e-01 1.00000000e+00 3.67414579e-03\n",
      " 6.70251343e-03 9.92036283e-01 1.27668902e-02 3.09216119e-02\n",
      " 9.96144176e-01 9.81981456e-01 3.09171900e-02 4.16157395e-01\n",
      " 7.96329618e-01 1.87588125e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 41 FN= 13 FP= 19\n",
      "TP+FP 64\n",
      "precision 0.703125\n",
      "recall 0.7758620689655172\n",
      "F1 0.7377049180327868\n",
      "acc 0.7288135593220338\n",
      "AUCp 0.7295977011494252\n",
      "AUC 0.7767241379310345\n",
      "\n",
      " The epoch is 300, average recall: 0.7759, average precision: 0.7031,average F1: 0.7377, average accuracy: 0.7288, average AUC: 0.7767\n",
      "Train Epoch: 301 [0/54 (0%)]\tTrain Loss: 0.003584\n",
      "Train Epoch: 301 [8/54 (15%)]\tTrain Loss: 0.002142\n",
      "Train Epoch: 301 [16/54 (30%)]\tTrain Loss: 0.005619\n",
      "Train Epoch: 301 [24/54 (44%)]\tTrain Loss: 0.002766\n",
      "Train Epoch: 301 [32/54 (59%)]\tTrain Loss: 0.002960\n",
      "Train Epoch: 301 [40/54 (74%)]\tTrain Loss: 0.014023\n",
      "Train Epoch: 301 [48/54 (89%)]\tTrain Loss: 0.005929\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.27069277e-01 9.98578668e-01 6.84530437e-01 9.94059801e-01\n",
      " 9.92172956e-02 2.99596344e-03 9.83504057e-01 9.97943580e-01\n",
      " 8.13258365e-02 2.06624627e-01 2.01497152e-02 2.80648645e-04\n",
      " 3.98258381e-02 2.01065708e-02 4.60495859e-01 1.78048573e-02\n",
      " 1.41592734e-02 1.70508012e-01 4.43051577e-01 1.26270309e-01\n",
      " 7.05296581e-04 9.97866094e-01 9.99941468e-01 9.99901414e-01\n",
      " 2.06422761e-01 1.00000000e+00 9.99667287e-01 1.50083467e-01\n",
      " 9.31691378e-02 4.00188416e-01 9.73018229e-01 9.72579062e-01\n",
      " 9.73362803e-01 6.50093611e-03 4.77828691e-03 8.60929396e-03\n",
      " 5.61244180e-03 9.99824703e-01 1.19450819e-02 2.33937919e-01\n",
      " 6.37733340e-02 1.03982456e-01 2.68358015e-03 2.62627602e-01\n",
      " 2.35359326e-01 1.19654546e-02 9.99907374e-01 9.90003347e-01\n",
      " 9.99999166e-01 9.94721293e-01 9.99999285e-01 4.60867397e-02\n",
      " 8.97283317e-04 4.39461678e-01 2.22057500e-03 1.16911912e-02\n",
      " 9.99975801e-01 2.03625076e-02 5.87233715e-02 9.66229513e-02\n",
      " 9.99840498e-01 9.65019524e-01 9.99581277e-01 9.99529719e-01\n",
      " 9.99994040e-01 9.99850988e-01 9.99694824e-01 9.99999285e-01\n",
      " 1.00000000e+00 9.70192909e-01 9.98193562e-01 9.95697379e-01\n",
      " 1.00000000e+00 9.99887824e-01 9.96719897e-01 9.99841213e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999285e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999285e-01 9.99999881e-01 2.73247454e-02\n",
      " 8.08694005e-01 9.88679707e-01 9.99737442e-01 9.99301314e-01\n",
      " 3.48738134e-02 9.96078074e-01 9.98035848e-01 9.92554128e-01\n",
      " 9.08725739e-01 1.00000000e+00 9.86979842e-01 9.99826610e-01\n",
      " 9.70123394e-04 4.99040812e-01 5.57392955e-01 9.75983441e-01\n",
      " 1.41394719e-01 9.99996424e-01 1.71003714e-02 9.99955416e-01\n",
      " 9.97108161e-01 9.59380388e-01 9.99999523e-01 6.83206394e-02\n",
      " 6.87794313e-02 9.46828067e-01 4.12287533e-01 7.38421738e-01\n",
      " 9.15913761e-01 9.54366028e-01 7.42266536e-01 2.04410121e-01\n",
      " 9.95617151e-01 9.99936342e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 302 [0/54 (0%)]\tTrain Loss: 0.005885\n",
      "Train Epoch: 302 [8/54 (15%)]\tTrain Loss: 0.001557\n",
      "Train Epoch: 302 [16/54 (30%)]\tTrain Loss: 0.000508\n",
      "Train Epoch: 302 [24/54 (44%)]\tTrain Loss: 0.001647\n",
      "Train Epoch: 302 [32/54 (59%)]\tTrain Loss: 0.010065\n",
      "Train Epoch: 302 [40/54 (74%)]\tTrain Loss: 0.000838\n",
      "Train Epoch: 302 [48/54 (89%)]\tTrain Loss: 0.000515\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.91105670e-04 9.51350808e-01 5.75164616e-01 9.96856689e-01\n",
      " 1.10176012e-01 1.82072213e-03 9.35241580e-01 9.96985734e-01\n",
      " 2.76355684e-01 1.60991073e-01 5.17441854e-02 2.94976548e-04\n",
      " 1.77426696e-01 7.73545238e-04 5.18972158e-01 9.51767527e-03\n",
      " 3.74327344e-03 7.31903434e-01 7.68489301e-01 4.60724503e-01\n",
      " 1.96713139e-03 9.99993205e-01 9.99985456e-01 9.99995589e-01\n",
      " 8.70276272e-01 1.00000000e+00 9.99999046e-01 9.95766521e-01\n",
      " 7.30573893e-01 9.38738346e-01 9.99772608e-01 9.99623656e-01\n",
      " 9.90106761e-01 1.34212669e-05 6.64164618e-05 2.01562382e-02\n",
      " 7.05261290e-01 9.99999404e-01 8.56990516e-01 9.82930720e-01\n",
      " 9.14502800e-01 9.51741755e-01 5.46529114e-01 9.40727353e-01\n",
      " 5.99894047e-01 9.60198604e-03 9.98213649e-01 9.89488661e-01\n",
      " 9.99987602e-01 9.99391913e-01 9.99988198e-01 3.52432095e-02\n",
      " 1.38625000e-02 8.32679629e-01 8.62418488e-02 7.57538453e-02\n",
      " 9.99987602e-01 5.01254201e-02 9.87084568e-01 3.63489807e-01\n",
      " 9.99048293e-01 9.66302693e-01 9.74540532e-01 9.94669616e-01\n",
      " 9.99989033e-01 9.99989390e-01 9.99595582e-01 1.00000000e+00\n",
      " 1.00000000e+00 8.95376801e-01 9.23646450e-01 8.93368244e-01\n",
      " 9.99983430e-01 9.95541275e-01 9.99966025e-01 9.94824648e-01\n",
      " 1.00000000e+00 9.99999404e-01 9.99969244e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99881387e-01 1.00000000e+00 3.17044258e-01\n",
      " 9.88965750e-01 9.94807780e-01 9.99990821e-01 9.99839067e-01\n",
      " 4.50289808e-02 9.99750316e-01 9.99990344e-01 9.90340769e-01\n",
      " 9.88031387e-01 1.00000000e+00 9.99191344e-01 9.99990940e-01\n",
      " 2.80243512e-02 9.95600820e-01 5.67919493e-01 9.94673431e-01\n",
      " 9.33314264e-01 9.99999166e-01 2.82105003e-02 9.97600019e-01\n",
      " 9.55618978e-01 8.79492640e-01 9.99997139e-01 6.00027442e-01\n",
      " 2.28377417e-01 9.90444839e-01 9.96042848e-01 8.38234365e-01\n",
      " 9.97527063e-01 9.94613588e-01 4.42459524e-01 1.56880200e-01\n",
      " 9.99989152e-01 9.99991059e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 303 [0/54 (0%)]\tTrain Loss: 0.018247\n",
      "Train Epoch: 303 [8/54 (15%)]\tTrain Loss: 0.002242\n",
      "Train Epoch: 303 [16/54 (30%)]\tTrain Loss: 0.004084\n",
      "Train Epoch: 303 [24/54 (44%)]\tTrain Loss: 0.002640\n",
      "Train Epoch: 303 [32/54 (59%)]\tTrain Loss: 0.001628\n",
      "Train Epoch: 303 [40/54 (74%)]\tTrain Loss: 0.000422\n",
      "Train Epoch: 303 [48/54 (89%)]\tTrain Loss: 0.028135\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.07050409e-05 5.85162759e-01 2.41458029e-01 2.00989455e-01\n",
      " 5.65819070e-03 5.64947550e-05 5.31138420e-01 2.34885082e-01\n",
      " 9.20104310e-02 9.44060802e-01 4.95874742e-03 3.58670987e-02\n",
      " 1.54606067e-02 2.46165419e-05 1.64679214e-02 3.85911204e-03\n",
      " 2.72474746e-04 4.16302711e-01 2.05372781e-01 2.37823844e-01\n",
      " 2.19498877e-03 9.08673048e-01 9.96704638e-01 9.87949133e-01\n",
      " 1.02555156e-01 9.98003900e-01 9.96038198e-01 5.07132232e-01\n",
      " 2.08066583e-01 5.39585292e-01 1.00592285e-01 5.99074066e-01\n",
      " 4.89243248e-04 9.18248334e-05 5.18415880e-04 2.01930571e-02\n",
      " 3.18485312e-02 6.07546866e-01 3.13216031e-01 9.99723598e-02\n",
      " 5.41347675e-02 3.04473013e-01 6.05969876e-02 4.91183996e-02\n",
      " 3.63379046e-02 6.45546184e-04 9.68929827e-01 9.60228801e-01\n",
      " 9.95985925e-01 9.74283338e-01 9.97911274e-01 1.49281591e-03\n",
      " 3.50677365e-05 6.12980761e-02 1.05989613e-01 1.79557479e-03\n",
      " 9.16936874e-01 1.41982110e-02 6.44441724e-01 3.67464521e-03\n",
      " 9.82520044e-01 9.86950338e-01 9.65271950e-01 9.88571882e-01\n",
      " 8.10032845e-01 9.46551502e-01 9.89040017e-01 9.99786556e-01\n",
      " 9.99581277e-01 4.22904313e-01 4.89955157e-01 7.00825632e-01\n",
      " 9.73993540e-01 9.20874417e-01 8.52595270e-01 8.63842189e-01\n",
      " 9.99999762e-01 9.99995947e-01 9.99373019e-01 9.99248564e-01\n",
      " 9.99856234e-01 9.83334899e-01 9.99950767e-01 2.02822238e-01\n",
      " 9.42714691e-01 7.32144475e-01 9.99544799e-01 9.98852015e-01\n",
      " 3.92585211e-02 5.74059129e-01 9.60256517e-01 6.91369772e-01\n",
      " 3.50986183e-01 9.99746025e-01 9.64138687e-01 9.98770654e-01\n",
      " 6.28070091e-04 4.98905987e-01 4.43024755e-01 4.20267344e-01\n",
      " 5.46392500e-01 9.90140975e-01 4.09582717e-04 1.50139436e-01\n",
      " 3.54974061e-01 6.68260753e-01 9.99579489e-01 1.92082711e-02\n",
      " 4.42996651e-01 9.45030749e-01 2.15791747e-01 9.45570946e-01\n",
      " 9.34320509e-01 9.34077084e-01 1.61191560e-02 5.00118956e-02\n",
      " 9.30656135e-01 9.29633379e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 304 [0/54 (0%)]\tTrain Loss: 0.002844\n",
      "Train Epoch: 304 [8/54 (15%)]\tTrain Loss: 0.004263\n",
      "Train Epoch: 304 [16/54 (30%)]\tTrain Loss: 0.032668\n",
      "Train Epoch: 304 [24/54 (44%)]\tTrain Loss: 0.022660\n",
      "Train Epoch: 304 [32/54 (59%)]\tTrain Loss: 0.009574\n",
      "Train Epoch: 304 [40/54 (74%)]\tTrain Loss: 0.003989\n",
      "Train Epoch: 304 [48/54 (89%)]\tTrain Loss: 0.004914\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.86615163e-04 6.94245458e-01 8.08108505e-03 4.00048167e-01\n",
      " 3.26095195e-03 3.23843764e-04 1.01722427e-01 4.14526224e-01\n",
      " 5.71596138e-02 8.41974020e-01 1.64159596e-01 7.22604841e-02\n",
      " 3.98096368e-02 6.28655607e-06 2.53934693e-03 2.01674365e-03\n",
      " 5.59799781e-04 1.73818156e-01 1.36700183e-01 3.29235792e-01\n",
      " 3.03255278e-03 9.10666466e-01 9.97836292e-01 9.99730170e-01\n",
      " 1.32346958e-01 9.99971867e-01 9.99980092e-01 7.48221159e-01\n",
      " 4.31298018e-02 2.94606745e-01 8.58591557e-01 9.97295201e-01\n",
      " 9.62852299e-01 3.13509263e-05 5.43556991e-04 1.94387272e-01\n",
      " 2.63311677e-02 9.11749423e-01 3.55826914e-01 1.35568038e-01\n",
      " 1.53382169e-02 1.21376283e-01 6.02152161e-02 1.99994650e-02\n",
      " 1.87215999e-01 2.22082287e-02 9.97848034e-01 8.74119341e-01\n",
      " 9.99984741e-01 9.87095058e-01 9.99925613e-01 1.52385440e-02\n",
      " 5.39402768e-04 1.74940422e-01 1.01467229e-01 5.68210706e-03\n",
      " 9.99836564e-01 3.04569434e-02 2.66231149e-01 9.26741771e-03\n",
      " 9.99848247e-01 9.97714162e-01 9.99355376e-01 9.99851108e-01\n",
      " 9.92814243e-01 9.82307434e-01 9.95830715e-01 9.99979019e-01\n",
      " 9.99789417e-01 9.32894289e-01 8.88523221e-01 8.93975914e-01\n",
      " 9.99743044e-01 9.98367012e-01 9.99454200e-01 9.99546587e-01\n",
      " 9.99994874e-01 9.99967337e-01 9.98868227e-01 9.99976754e-01\n",
      " 9.99999166e-01 9.98780429e-01 9.99996424e-01 9.65414822e-01\n",
      " 9.88206327e-01 9.98840272e-01 9.99680042e-01 9.99059379e-01\n",
      " 2.32737511e-02 7.01235473e-01 9.98961806e-01 9.32070434e-01\n",
      " 8.14219713e-01 9.99994516e-01 9.99118745e-01 9.99480665e-01\n",
      " 3.87491398e-02 8.49199951e-01 9.67933834e-01 6.44493222e-01\n",
      " 6.28655493e-01 9.99995112e-01 2.93555390e-02 9.87450242e-01\n",
      " 9.90388930e-01 8.97259116e-01 9.99994755e-01 3.06237377e-02\n",
      " 3.95732000e-02 9.66433525e-01 3.71871293e-01 3.06914628e-01\n",
      " 9.39298689e-01 9.63722646e-01 4.32624295e-02 7.70902187e-02\n",
      " 9.98582125e-01 9.68643963e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 305 [0/54 (0%)]\tTrain Loss: 0.002356\n",
      "Train Epoch: 305 [8/54 (15%)]\tTrain Loss: 0.003580\n",
      "Train Epoch: 305 [16/54 (30%)]\tTrain Loss: 0.001491\n",
      "Train Epoch: 305 [24/54 (44%)]\tTrain Loss: 0.000611\n",
      "Train Epoch: 305 [32/54 (59%)]\tTrain Loss: 0.013479\n",
      "Train Epoch: 305 [40/54 (74%)]\tTrain Loss: 0.001700\n",
      "Train Epoch: 305 [48/54 (89%)]\tTrain Loss: 0.004708\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.34879148e-05 2.52358705e-01 1.35435164e-02 8.54004800e-01\n",
      " 1.05340499e-02 3.98570992e-04 9.17153060e-02 8.43387961e-01\n",
      " 2.17789784e-01 1.54879587e-02 5.47964752e-01 1.99551141e-04\n",
      " 3.26483995e-01 3.25690955e-04 7.61847794e-02 1.58852693e-02\n",
      " 1.85554717e-02 3.54224056e-01 1.65790588e-01 1.73887879e-01\n",
      " 3.06057264e-05 6.77456260e-01 9.92542982e-01 9.99997854e-01\n",
      " 9.42746643e-04 9.99992490e-01 9.99999881e-01 8.67555261e-01\n",
      " 3.04672532e-02 6.64105192e-02 3.95683898e-03 4.30428863e-01\n",
      " 3.85383368e-01 1.78168318e-03 1.76358444e-04 7.22710928e-03\n",
      " 1.42253106e-04 9.60316539e-01 6.32627681e-03 8.15155171e-03\n",
      " 3.29703558e-04 2.18038651e-04 1.54347448e-02 1.63775252e-03\n",
      " 6.88766003e-01 2.78858879e-05 3.18745017e-01 8.05007592e-02\n",
      " 7.03263879e-01 9.28431690e-01 2.19467968e-01 6.66340739e-02\n",
      " 2.75355647e-03 2.09979758e-01 6.69399567e-04 1.87594898e-03\n",
      " 9.93152380e-01 2.43705511e-02 5.34366351e-03 7.87978701e-04\n",
      " 9.95253563e-01 9.54729736e-01 9.19619858e-01 9.53786314e-01\n",
      " 9.96671021e-01 9.96936083e-01 9.94010329e-01 9.98994648e-01\n",
      " 9.99742091e-01 2.07461387e-01 7.64603794e-01 8.06456625e-01\n",
      " 9.99615312e-01 9.98895228e-01 9.85780299e-01 6.48380458e-01\n",
      " 9.58578110e-01 9.65929151e-01 9.94987249e-01 9.98761773e-01\n",
      " 9.99904633e-01 9.66692448e-01 9.99139428e-01 9.64190960e-01\n",
      " 9.70852256e-01 9.77582812e-01 9.99379635e-01 9.95593846e-01\n",
      " 3.24202925e-02 9.99632597e-01 9.99540329e-01 9.95350361e-01\n",
      " 9.38387811e-01 1.00000000e+00 9.99862671e-01 9.99986053e-01\n",
      " 1.06464006e-01 1.45453513e-01 9.48620260e-01 9.99478877e-01\n",
      " 2.11952999e-01 9.99436557e-01 9.88613367e-02 9.99962449e-01\n",
      " 9.64275539e-01 7.61762917e-01 9.99954700e-01 2.87468791e-01\n",
      " 5.25006326e-03 8.34605336e-01 8.80779743e-01 1.95349380e-02\n",
      " 9.99097109e-01 9.98564780e-01 8.64061236e-01 1.95400909e-01\n",
      " 8.97804320e-01 9.53340530e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 306 [0/54 (0%)]\tTrain Loss: 0.004612\n",
      "Train Epoch: 306 [8/54 (15%)]\tTrain Loss: 0.091423\n",
      "Train Epoch: 306 [16/54 (30%)]\tTrain Loss: 0.019897\n",
      "Train Epoch: 306 [24/54 (44%)]\tTrain Loss: 0.024566\n",
      "Train Epoch: 306 [32/54 (59%)]\tTrain Loss: 0.002264\n",
      "Train Epoch: 306 [40/54 (74%)]\tTrain Loss: 0.086618\n",
      "Train Epoch: 306 [48/54 (89%)]\tTrain Loss: 0.039225\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.11994865e-03 9.56448495e-01 8.34891737e-01 9.09963906e-01\n",
      " 5.27720630e-01 8.40171520e-03 9.90297735e-01 9.75188076e-01\n",
      " 5.44011414e-01 7.78498530e-01 9.56773341e-01 6.04935214e-02\n",
      " 2.99194604e-02 6.92734087e-04 1.55373678e-01 4.24794434e-03\n",
      " 1.00844831e-03 4.79946472e-02 8.39874506e-01 9.45993721e-01\n",
      " 5.88526018e-03 9.89711761e-01 9.99982834e-01 9.99998569e-01\n",
      " 2.35362854e-02 9.99999166e-01 9.99999642e-01 9.91125405e-01\n",
      " 3.60453248e-01 2.23792523e-01 7.15615094e-01 9.99236465e-01\n",
      " 7.96600044e-01 3.43079264e-05 2.14159139e-04 6.28727600e-02\n",
      " 3.58691998e-02 9.97305989e-01 4.53932695e-02 1.61577508e-01\n",
      " 3.63776311e-02 2.44909629e-01 1.51769102e-01 1.32702142e-02\n",
      " 1.20202564e-01 1.17026344e-02 9.55052078e-01 7.72627175e-01\n",
      " 9.99896765e-01 9.64086056e-01 9.97350335e-01 4.41270135e-02\n",
      " 1.90888755e-02 1.65613398e-01 6.35876432e-02 1.03133265e-03\n",
      " 9.77442503e-01 2.78868880e-02 1.08235240e-01 1.89318564e-02\n",
      " 9.84567642e-01 8.87298882e-01 9.08564091e-01 9.91681516e-01\n",
      " 9.95579541e-01 9.91383910e-01 9.99358594e-01 9.99987721e-01\n",
      " 9.99944210e-01 8.57410610e-01 8.62899721e-01 9.56315339e-01\n",
      " 9.96013999e-01 9.92827594e-01 9.99078989e-01 3.81370515e-01\n",
      " 9.99997139e-01 9.99996662e-01 9.98758554e-01 9.99851584e-01\n",
      " 9.99999642e-01 9.89687264e-01 9.98289526e-01 5.50165415e-01\n",
      " 9.83828843e-01 9.97213423e-01 9.96972322e-01 9.95587230e-01\n",
      " 2.41465475e-02 9.98010576e-01 9.99878287e-01 7.22581148e-01\n",
      " 6.03692412e-01 1.00000000e+00 9.98094976e-01 9.99832392e-01\n",
      " 3.61772650e-03 9.47370112e-01 9.54035401e-01 9.85546112e-01\n",
      " 1.76014915e-01 9.97342408e-01 1.22451916e-01 9.99739230e-01\n",
      " 9.70553339e-01 8.91783297e-01 1.00000000e+00 2.44154200e-01\n",
      " 3.90786268e-02 9.97962117e-01 5.98361850e-01 4.22560684e-02\n",
      " 8.17270875e-01 9.91736829e-01 1.90637946e-01 8.29312578e-02\n",
      " 9.93732393e-01 9.88930047e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 307 [0/54 (0%)]\tTrain Loss: 0.085852\n",
      "Train Epoch: 307 [8/54 (15%)]\tTrain Loss: 0.002258\n",
      "Train Epoch: 307 [16/54 (30%)]\tTrain Loss: 0.000851\n",
      "Train Epoch: 307 [24/54 (44%)]\tTrain Loss: 0.011428\n",
      "Train Epoch: 307 [32/54 (59%)]\tTrain Loss: 0.001019\n",
      "Train Epoch: 307 [40/54 (74%)]\tTrain Loss: 0.014395\n",
      "Train Epoch: 307 [48/54 (89%)]\tTrain Loss: 0.008458\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.37915330e-04 6.71708345e-01 4.58537787e-01 9.98706341e-01\n",
      " 8.86155844e-01 6.26388611e-03 7.65019000e-01 9.90940571e-01\n",
      " 2.34929904e-01 9.86604989e-01 4.29743737e-01 9.96179134e-03\n",
      " 1.90025084e-02 9.88122728e-03 3.90171945e-01 3.74942762e-03\n",
      " 1.21017415e-02 1.43668547e-01 9.23174322e-01 7.04496920e-01\n",
      " 1.12504996e-02 9.96345103e-01 9.99855638e-01 9.99925017e-01\n",
      " 3.67629081e-01 9.99589980e-01 9.99863148e-01 7.58881748e-01\n",
      " 6.12236083e-01 2.88574368e-01 1.63774807e-02 9.99212384e-01\n",
      " 2.61610419e-01 3.66459353e-05 2.03537362e-04 9.03597847e-03\n",
      " 5.35634346e-03 9.95662987e-01 2.84365192e-03 7.06860283e-03\n",
      " 4.35348367e-03 8.41981545e-03 3.61835390e-01 5.07184956e-03\n",
      " 2.83140600e-01 1.00254230e-02 4.83767122e-01 5.80947340e-01\n",
      " 9.96683300e-01 9.74980891e-01 9.94275033e-01 2.32774462e-03\n",
      " 7.22725410e-04 5.68697929e-01 2.77179442e-02 1.90778486e-02\n",
      " 9.74260986e-01 1.30319707e-02 2.34258011e-01 1.23634867e-01\n",
      " 9.98209119e-01 9.16127861e-01 7.70522952e-01 9.85785902e-01\n",
      " 9.97652829e-01 9.24243331e-01 9.95715797e-01 9.99865770e-01\n",
      " 9.99870777e-01 9.03611064e-01 9.48480725e-01 9.66163218e-01\n",
      " 9.98707533e-01 9.99704540e-01 9.90367651e-01 9.20449972e-01\n",
      " 9.99990702e-01 9.99985099e-01 9.99164343e-01 9.99838948e-01\n",
      " 9.99998450e-01 9.99156594e-01 9.99882579e-01 6.91642538e-02\n",
      " 9.41903651e-01 8.90893340e-01 9.86844003e-01 9.96446073e-01\n",
      " 7.49149546e-02 6.91502392e-01 8.98253143e-01 8.80916536e-01\n",
      " 8.77104580e-01 1.00000000e+00 9.92396414e-01 9.99652147e-01\n",
      " 2.90841423e-03 7.07425892e-01 7.73996174e-01 9.79549706e-01\n",
      " 2.08550319e-02 9.92519736e-01 3.67475003e-02 9.99725044e-01\n",
      " 9.77114022e-01 9.48296487e-01 1.00000000e+00 1.00041591e-02\n",
      " 1.07669597e-02 8.32856059e-01 5.03843576e-02 6.63086250e-02\n",
      " 5.77936649e-01 9.25682604e-01 7.94369727e-02 2.61721015e-01\n",
      " 9.86179233e-01 3.63227725e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 308 [0/54 (0%)]\tTrain Loss: 0.022069\n",
      "Train Epoch: 308 [8/54 (15%)]\tTrain Loss: 0.017096\n",
      "Train Epoch: 308 [16/54 (30%)]\tTrain Loss: 0.031378\n",
      "Train Epoch: 308 [24/54 (44%)]\tTrain Loss: 0.000335\n",
      "Train Epoch: 308 [32/54 (59%)]\tTrain Loss: 0.025874\n",
      "Train Epoch: 308 [40/54 (74%)]\tTrain Loss: 0.001956\n",
      "Train Epoch: 308 [48/54 (89%)]\tTrain Loss: 0.059393\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.13285641e-04 9.89989042e-01 9.82625842e-01 9.68512237e-01\n",
      " 3.99731815e-01 1.69085315e-03 9.89678621e-01 9.99086261e-01\n",
      " 2.80962765e-01 2.35505834e-01 6.51025400e-02 6.10617083e-03\n",
      " 1.53476326e-02 1.44841324e-03 2.11460799e-01 4.36008209e-03\n",
      " 2.14988235e-02 1.19789854e-01 9.28275645e-01 1.18161917e-01\n",
      " 3.09617002e-03 9.77916062e-01 9.99951124e-01 9.99968886e-01\n",
      " 1.33065790e-01 9.99996305e-01 1.00000000e+00 9.60993230e-01\n",
      " 3.13526422e-01 2.83909649e-01 1.46488324e-01 9.96383667e-01\n",
      " 3.39150667e-01 3.99922370e-04 9.05864523e-04 7.92038217e-02\n",
      " 1.06258942e-02 9.99050915e-01 1.13324597e-02 2.85969172e-02\n",
      " 3.36086587e-03 2.94228736e-02 1.38697922e-01 4.59749959e-02\n",
      " 1.15620755e-01 3.49021924e-04 2.52501108e-02 8.06412935e-01\n",
      " 9.99675632e-01 9.95724201e-01 9.84741151e-01 6.43304689e-03\n",
      " 1.16632855e-03 2.32935138e-02 6.70535781e-04 8.70164856e-03\n",
      " 9.94334817e-01 2.85506714e-03 1.08573399e-02 6.19149283e-02\n",
      " 9.99742806e-01 9.95047688e-01 9.87561822e-01 9.98323739e-01\n",
      " 9.96625304e-01 9.98022199e-01 9.99390364e-01 9.99992609e-01\n",
      " 9.99895573e-01 3.87924403e-01 9.56292152e-01 9.81891096e-01\n",
      " 9.99723136e-01 9.99299765e-01 9.99613106e-01 7.84971833e-01\n",
      " 1.00000000e+00 9.99998689e-01 9.99870777e-01 9.99952555e-01\n",
      " 9.99996662e-01 9.87794042e-01 9.99970317e-01 3.32710207e-01\n",
      " 9.92620170e-01 9.10690010e-01 9.46402073e-01 9.97543871e-01\n",
      " 1.81565151e-01 9.85994816e-01 9.99258935e-01 7.85542667e-01\n",
      " 9.04259562e-01 9.99999762e-01 9.94744658e-01 9.99871969e-01\n",
      " 5.78342821e-04 2.85345376e-01 3.34499687e-01 9.99262273e-01\n",
      " 3.55981663e-02 9.99937296e-01 2.87801772e-01 9.99927640e-01\n",
      " 9.99354303e-01 6.18601263e-01 9.99999881e-01 3.11349239e-02\n",
      " 2.25850418e-02 8.62700999e-01 1.07542761e-01 1.71814471e-01\n",
      " 7.03518271e-01 9.95013654e-01 3.37670982e-01 9.91274491e-02\n",
      " 9.99715745e-01 9.98782456e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 309 [0/54 (0%)]\tTrain Loss: 0.014657\n",
      "Train Epoch: 309 [8/54 (15%)]\tTrain Loss: 0.001676\n",
      "Train Epoch: 309 [16/54 (30%)]\tTrain Loss: 0.002702\n",
      "Train Epoch: 309 [24/54 (44%)]\tTrain Loss: 0.002517\n",
      "Train Epoch: 309 [32/54 (59%)]\tTrain Loss: 0.005225\n",
      "Train Epoch: 309 [40/54 (74%)]\tTrain Loss: 0.003042\n",
      "Train Epoch: 309 [48/54 (89%)]\tTrain Loss: 0.010736\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.48149645e-01 7.89271414e-01 9.27895308e-01 9.87812579e-01\n",
      " 8.05854738e-01 2.77883559e-01 7.78635621e-01 9.95324373e-01\n",
      " 6.44578815e-01 9.65889215e-01 9.50046420e-01 7.56593868e-02\n",
      " 2.49324933e-01 2.28429828e-02 8.57109606e-01 6.95726927e-03\n",
      " 9.83076543e-03 2.93635666e-01 9.48408306e-01 7.67697513e-01\n",
      " 4.33273800e-02 9.97467995e-01 9.99950290e-01 9.99999046e-01\n",
      " 7.22654462e-01 9.99999404e-01 9.99999762e-01 8.13738644e-01\n",
      " 6.32927358e-01 9.91259634e-01 9.12835836e-01 9.99969125e-01\n",
      " 9.87530470e-01 3.23359054e-05 1.82204682e-03 2.73457348e-01\n",
      " 3.00548971e-02 9.93610799e-01 6.67709857e-02 1.83376521e-01\n",
      " 2.61635631e-02 1.12762906e-01 6.20083325e-02 2.70891726e-01\n",
      " 5.27260005e-01 6.65054703e-03 9.82035041e-01 9.97272551e-01\n",
      " 1.00000000e+00 9.99931097e-01 9.99989390e-01 2.10222676e-02\n",
      " 6.03197562e-03 5.28763294e-01 8.02949164e-03 4.47803922e-02\n",
      " 9.99447525e-01 8.92003328e-02 2.09245190e-01 7.61788115e-02\n",
      " 9.99926805e-01 9.99297857e-01 9.99220371e-01 9.99668121e-01\n",
      " 9.98888075e-01 9.99968767e-01 9.99709070e-01 9.99997139e-01\n",
      " 9.99990582e-01 9.64009047e-01 9.94227648e-01 9.95590210e-01\n",
      " 9.99993324e-01 9.99990344e-01 9.99990582e-01 9.92418647e-01\n",
      " 9.99999762e-01 9.99995708e-01 9.99986529e-01 9.99999285e-01\n",
      " 1.00000000e+00 9.99981999e-01 9.99999285e-01 3.39572817e-01\n",
      " 9.91363049e-01 9.99845982e-01 9.99987483e-01 9.99986768e-01\n",
      " 1.32338822e-01 8.88866067e-01 9.99897957e-01 9.25412118e-01\n",
      " 9.94605601e-01 9.99999762e-01 9.98228371e-01 9.98611093e-01\n",
      " 7.97101203e-03 4.32960093e-01 8.90772820e-01 9.99214768e-01\n",
      " 5.07810898e-02 9.99538541e-01 6.63244575e-02 9.99881864e-01\n",
      " 9.99711215e-01 9.69014883e-01 1.00000000e+00 7.40944669e-02\n",
      " 1.85428143e-01 9.98402774e-01 3.68494317e-02 6.26638710e-01\n",
      " 8.96573246e-01 9.77967799e-01 5.23583114e-01 7.15993166e-01\n",
      " 6.11617506e-01 9.19426084e-01]\n",
      "predict [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 310 [0/54 (0%)]\tTrain Loss: 0.001172\n",
      "Train Epoch: 310 [8/54 (15%)]\tTrain Loss: 0.007982\n",
      "Train Epoch: 310 [16/54 (30%)]\tTrain Loss: 0.001921\n",
      "Train Epoch: 310 [24/54 (44%)]\tTrain Loss: 0.000126\n",
      "Train Epoch: 310 [32/54 (59%)]\tTrain Loss: 0.004760\n",
      "Train Epoch: 310 [40/54 (74%)]\tTrain Loss: 0.001793\n",
      "Train Epoch: 310 [48/54 (89%)]\tTrain Loss: 0.000577\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.22454336e-03 8.37637782e-01 1.29351079e-01 9.68055248e-01\n",
      " 1.73593581e-01 1.13672018e-02 2.42276207e-01 5.65146863e-01\n",
      " 3.66595715e-01 4.95196223e-01 5.12163103e-01 4.59453696e-03\n",
      " 2.60900687e-02 1.21057115e-03 1.59360692e-01 1.36267755e-03\n",
      " 1.41180167e-03 2.48565301e-01 9.75161433e-01 2.86327511e-01\n",
      " 2.16493346e-02 9.94969428e-01 9.99984741e-01 9.99987245e-01\n",
      " 1.94693357e-01 9.99999881e-01 1.00000000e+00 9.67943966e-01\n",
      " 8.28611374e-01 4.72234011e-01 2.80682325e-01 9.87993717e-01\n",
      " 3.78835440e-01 1.52567497e-06 6.18178410e-06 4.19934765e-02\n",
      " 3.52771557e-03 9.90421891e-01 3.41650657e-02 6.30628094e-02\n",
      " 3.78552568e-03 1.53157264e-01 6.35618865e-02 8.76185670e-03\n",
      " 4.48026419e-01 2.30864141e-04 9.17936027e-01 9.54151690e-01\n",
      " 9.99831796e-01 9.99470174e-01 9.99055326e-01 1.22399171e-04\n",
      " 4.99370508e-02 3.74569863e-01 9.82256681e-02 2.88215261e-02\n",
      " 9.98833001e-01 1.66396182e-02 2.81236768e-02 5.38329244e-01\n",
      " 9.99915242e-01 9.99524236e-01 9.99111235e-01 9.98059571e-01\n",
      " 9.93588209e-01 9.99859452e-01 9.99000967e-01 9.99999046e-01\n",
      " 9.99997377e-01 9.91569757e-01 9.47054505e-01 9.12422597e-01\n",
      " 9.99996543e-01 9.99921679e-01 9.99999881e-01 9.53326225e-01\n",
      " 9.99999404e-01 9.99974370e-01 9.99682069e-01 9.99945521e-01\n",
      " 9.99995708e-01 9.99575675e-01 9.99996066e-01 5.46744525e-01\n",
      " 9.87461865e-01 9.95590210e-01 9.99905229e-01 9.99932766e-01\n",
      " 2.33478770e-02 9.92413104e-01 9.99781311e-01 3.65393937e-01\n",
      " 8.38822365e-01 9.99999881e-01 9.99969602e-01 9.92494345e-01\n",
      " 8.18975642e-03 5.03985584e-01 8.93363297e-01 9.99288678e-01\n",
      " 1.37681991e-01 9.99537110e-01 1.25103174e-02 9.98855829e-01\n",
      " 9.94365096e-01 9.98685062e-01 9.99999881e-01 9.93243977e-02\n",
      " 4.02111933e-02 9.89430428e-01 3.37166758e-03 5.51920354e-01\n",
      " 7.49905646e-01 9.59991038e-01 3.16431254e-01 5.49967885e-01\n",
      " 9.99941945e-01 9.39000905e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "vote_pred [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 46 TN= 41 FN= 12 FP= 19\n",
      "TP+FP 65\n",
      "precision 0.7076923076923077\n",
      "recall 0.7931034482758621\n",
      "F1 0.7479674796747967\n",
      "acc 0.7372881355932204\n",
      "AUCp 0.7382183908045977\n",
      "AUC 0.7991379310344826\n",
      "\n",
      " The epoch is 310, average recall: 0.7931, average precision: 0.7077,average F1: 0.7480, average accuracy: 0.7373, average AUC: 0.7991\n",
      "Train Epoch: 311 [0/54 (0%)]\tTrain Loss: 0.000981\n",
      "Train Epoch: 311 [8/54 (15%)]\tTrain Loss: 0.044800\n",
      "Train Epoch: 311 [16/54 (30%)]\tTrain Loss: 0.005131\n",
      "Train Epoch: 311 [24/54 (44%)]\tTrain Loss: 0.003179\n",
      "Train Epoch: 311 [32/54 (59%)]\tTrain Loss: 0.000516\n",
      "Train Epoch: 311 [40/54 (74%)]\tTrain Loss: 0.004854\n",
      "Train Epoch: 311 [48/54 (89%)]\tTrain Loss: 0.000633\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.03720250e-04 9.36996579e-01 5.22868633e-02 9.64429438e-01\n",
      " 1.30762607e-02 1.01764710e-03 3.36545296e-02 6.66348636e-01\n",
      " 5.53972900e-01 1.92023754e-01 4.46802348e-01 5.80520893e-04\n",
      " 2.03134282e-03 3.50802594e-07 8.93259235e-03 4.27817286e-05\n",
      " 6.61093654e-05 9.33889151e-02 9.98716474e-01 8.05058241e-01\n",
      " 2.83929845e-03 9.98144388e-01 9.99990344e-01 9.99994278e-01\n",
      " 1.28401726e-01 1.00000000e+00 1.00000000e+00 9.65699673e-01\n",
      " 8.47213924e-01 7.99909890e-01 7.27248132e-01 9.99234557e-01\n",
      " 1.66938081e-01 4.51643309e-08 5.92129766e-07 3.98812145e-02\n",
      " 1.57661047e-02 9.99749243e-01 5.58486488e-03 2.59606242e-02\n",
      " 6.57180964e-04 2.06889212e-02 2.36170873e-01 1.83013512e-03\n",
      " 6.33583188e-01 4.02648548e-05 8.47724199e-01 5.02204955e-01\n",
      " 9.99229908e-01 9.87961113e-01 9.91933405e-01 5.90298841e-05\n",
      " 1.53011885e-02 2.88817614e-01 1.82139548e-03 3.52210458e-03\n",
      " 9.99551833e-01 1.28547177e-02 3.30336466e-02 1.54903485e-02\n",
      " 9.98664021e-01 9.96023297e-01 9.85288918e-01 9.62512553e-01\n",
      " 9.97916758e-01 9.97856319e-01 9.99497056e-01 9.99992132e-01\n",
      " 9.99830246e-01 7.23736823e-01 9.78313863e-01 9.70974505e-01\n",
      " 9.98653293e-01 9.73740041e-01 9.99995947e-01 9.84259546e-01\n",
      " 9.99997377e-01 9.99909878e-01 9.97526586e-01 9.99625683e-01\n",
      " 9.99958634e-01 9.98605549e-01 9.99881029e-01 6.34272695e-01\n",
      " 9.80823994e-01 9.90171731e-01 9.99871731e-01 9.99677658e-01\n",
      " 9.81024373e-03 9.92630005e-01 9.99981761e-01 2.57057369e-01\n",
      " 8.03862691e-01 9.99999881e-01 9.99481857e-01 9.73906338e-01\n",
      " 3.95389739e-03 2.13077277e-01 6.05142415e-01 9.61038053e-01\n",
      " 1.58553645e-02 9.98854637e-01 2.26928201e-02 9.98683393e-01\n",
      " 9.52840567e-01 5.81686318e-01 9.99770820e-01 1.33575425e-02\n",
      " 1.14575522e-02 9.68461573e-01 1.25823671e-03 6.84265932e-03\n",
      " 1.55558199e-01 8.96772265e-01 3.61646675e-02 3.77980858e-01\n",
      " 9.83496428e-01 9.90775287e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 312 [0/54 (0%)]\tTrain Loss: 0.026738\n",
      "Train Epoch: 312 [8/54 (15%)]\tTrain Loss: 0.005050\n",
      "Train Epoch: 312 [16/54 (30%)]\tTrain Loss: 0.001578\n",
      "Train Epoch: 312 [24/54 (44%)]\tTrain Loss: 0.000362\n",
      "Train Epoch: 312 [32/54 (59%)]\tTrain Loss: 0.000502\n",
      "Train Epoch: 312 [40/54 (74%)]\tTrain Loss: 0.005805\n",
      "Train Epoch: 312 [48/54 (89%)]\tTrain Loss: 0.006234\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.32576113e-03 9.83478248e-01 3.01371872e-01 9.82398331e-01\n",
      " 3.85501772e-01 2.46012490e-02 4.04129565e-01 9.57292438e-01\n",
      " 2.66658902e-01 2.85138249e-01 4.90407825e-01 1.50487016e-04\n",
      " 1.52404398e-01 5.00251888e-04 3.74928117e-01 4.73361695e-03\n",
      " 5.51414676e-04 7.02404529e-02 9.93654132e-01 5.16954839e-01\n",
      " 9.09844995e-04 9.99809563e-01 9.99999523e-01 9.99999404e-01\n",
      " 5.59133850e-02 1.00000000e+00 1.00000000e+00 9.11070228e-01\n",
      " 9.91322517e-01 9.95094061e-01 9.72971261e-01 9.99962091e-01\n",
      " 7.84364641e-01 1.81418659e-06 6.02541513e-05 1.13509586e-02\n",
      " 6.21720217e-03 9.99798596e-01 8.10358226e-02 2.08078802e-01\n",
      " 2.32877694e-02 1.05422340e-01 1.24642991e-01 1.39868990e-01\n",
      " 5.84306896e-01 1.02851801e-02 9.92510796e-01 8.00119340e-01\n",
      " 9.99980450e-01 9.93939161e-01 9.99460399e-01 5.44247963e-03\n",
      " 1.62328780e-02 7.96525419e-01 1.33929634e-02 4.77683842e-02\n",
      " 9.99023080e-01 2.25817129e-01 1.53722391e-02 4.76846360e-02\n",
      " 9.99692202e-01 9.98112559e-01 9.95971501e-01 9.94279861e-01\n",
      " 9.99809206e-01 9.99900222e-01 9.99979854e-01 1.00000000e+00\n",
      " 9.99991536e-01 9.79722559e-01 9.95464146e-01 9.96013165e-01\n",
      " 9.99493837e-01 9.99946713e-01 9.99997497e-01 9.89454031e-01\n",
      " 9.99994755e-01 9.99976516e-01 9.99936461e-01 9.99999285e-01\n",
      " 1.00000000e+00 9.99974251e-01 9.99997735e-01 3.52276057e-01\n",
      " 9.36178744e-01 9.98083234e-01 9.99935389e-01 9.99865890e-01\n",
      " 8.21151864e-03 9.99959946e-01 9.99980211e-01 7.56102741e-01\n",
      " 9.41416979e-01 1.00000000e+00 9.99721110e-01 9.64583695e-01\n",
      " 2.75509525e-03 1.59915030e-01 8.43593895e-01 9.99888062e-01\n",
      " 1.22712739e-01 9.99774754e-01 2.21749693e-02 9.99440253e-01\n",
      " 9.77766275e-01 9.83659267e-01 9.99998808e-01 4.75865752e-02\n",
      " 1.49067622e-02 9.95224178e-01 1.90544687e-02 5.74643612e-01\n",
      " 8.81348848e-01 9.84632969e-01 9.22481239e-01 7.42539644e-01\n",
      " 9.98393357e-01 9.84071136e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 313 [0/54 (0%)]\tTrain Loss: 0.001406\n",
      "Train Epoch: 313 [8/54 (15%)]\tTrain Loss: 0.000612\n",
      "Train Epoch: 313 [16/54 (30%)]\tTrain Loss: 0.001440\n",
      "Train Epoch: 313 [24/54 (44%)]\tTrain Loss: 0.001015\n",
      "Train Epoch: 313 [32/54 (59%)]\tTrain Loss: 0.000882\n",
      "Train Epoch: 313 [40/54 (74%)]\tTrain Loss: 0.008440\n",
      "Train Epoch: 313 [48/54 (89%)]\tTrain Loss: 0.036665\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.60718419e-04 9.18205738e-01 3.70359570e-01 9.51011598e-01\n",
      " 2.73396641e-01 5.17798821e-04 3.79389435e-01 9.44672763e-01\n",
      " 1.71616636e-02 7.02229321e-01 5.00884891e-01 1.16344402e-03\n",
      " 2.82629672e-02 1.37554451e-07 2.08397046e-01 1.75681908e-03\n",
      " 1.90815479e-01 4.68881093e-02 7.58432448e-01 3.31829548e-01\n",
      " 2.11214065e-03 9.33582783e-01 9.98420596e-01 9.99554813e-01\n",
      " 2.21179292e-01 9.99979258e-01 9.99870539e-01 9.73866343e-01\n",
      " 8.87862369e-02 4.75999653e-01 9.17731166e-01 9.98248816e-01\n",
      " 1.64503291e-01 2.92972018e-05 9.45241627e-05 2.22359840e-02\n",
      " 3.11449673e-02 9.97335374e-01 9.24533466e-04 1.06138047e-02\n",
      " 1.70764548e-03 8.01234692e-02 2.19425261e-01 6.16062607e-04\n",
      " 5.69867343e-02 3.93891707e-03 9.68226373e-01 9.16655421e-01\n",
      " 9.99948502e-01 9.87385631e-01 9.98724759e-01 2.02845619e-03\n",
      " 5.22139389e-03 9.27198827e-02 9.47379414e-03 6.44766260e-04\n",
      " 9.07877862e-01 9.62925889e-03 1.70505330e-01 1.49515063e-01\n",
      " 9.96510565e-01 9.70543921e-01 9.65446115e-01 9.46390033e-01\n",
      " 9.91864622e-01 7.46556938e-01 9.86100018e-01 9.99986291e-01\n",
      " 9.99876499e-01 7.90220618e-01 8.36888254e-01 8.32693934e-01\n",
      " 9.95335758e-01 9.98781025e-01 9.94115353e-01 9.41661835e-01\n",
      " 9.99986172e-01 9.99954343e-01 9.99793351e-01 9.99808729e-01\n",
      " 9.99992967e-01 9.99022007e-01 9.98665571e-01 1.36588025e-03\n",
      " 3.69925320e-01 9.97280002e-01 9.78428781e-01 9.90366340e-01\n",
      " 3.59325521e-02 9.67346668e-01 9.85259533e-01 6.99097097e-01\n",
      " 9.04448330e-01 9.99980807e-01 9.93139923e-01 9.95387256e-01\n",
      " 1.44204852e-04 2.89543778e-01 8.27030241e-01 9.90558028e-01\n",
      " 1.87871903e-01 9.90231812e-01 4.99735996e-02 9.89285409e-01\n",
      " 9.52065885e-01 8.49065900e-01 9.99905109e-01 3.90207693e-02\n",
      " 2.79593025e-03 9.63762820e-01 3.09094302e-02 1.20819956e-01\n",
      " 9.53679979e-01 9.70295668e-01 2.19588391e-02 1.28202364e-02\n",
      " 8.95774066e-01 8.08544099e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 314 [0/54 (0%)]\tTrain Loss: 0.000509\n",
      "Train Epoch: 314 [8/54 (15%)]\tTrain Loss: 0.001054\n",
      "Train Epoch: 314 [16/54 (30%)]\tTrain Loss: 0.001861\n",
      "Train Epoch: 314 [24/54 (44%)]\tTrain Loss: 0.001549\n",
      "Train Epoch: 314 [32/54 (59%)]\tTrain Loss: 0.003156\n",
      "Train Epoch: 314 [40/54 (74%)]\tTrain Loss: 0.003380\n",
      "Train Epoch: 314 [48/54 (89%)]\tTrain Loss: 0.004082\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.77310096e-04 2.68264890e-01 6.87828986e-03 3.38194847e-01\n",
      " 6.58560265e-03 3.49077163e-05 9.94042493e-03 1.34274140e-01\n",
      " 1.33208046e-03 3.75952810e-01 1.02185071e-01 1.56336278e-03\n",
      " 7.80247385e-04 4.22350354e-07 6.60159113e-03 5.28417786e-06\n",
      " 3.41607483e-05 1.76155288e-02 2.43789610e-02 1.20591968e-02\n",
      " 1.79010816e-03 7.29411960e-01 9.98769701e-01 9.99374449e-01\n",
      " 4.17824797e-02 9.99998689e-01 9.99996185e-01 9.12285864e-01\n",
      " 1.52821885e-02 5.45035768e-03 2.58221418e-01 9.61828768e-01\n",
      " 1.19410001e-01 4.16998364e-06 1.76686553e-05 9.15315468e-04\n",
      " 3.41533887e-05 9.66133773e-01 3.29873944e-03 1.22788139e-02\n",
      " 1.62741344e-03 3.84815559e-02 9.68032330e-03 2.10061460e-03\n",
      " 2.36520749e-02 2.61760387e-03 9.47286904e-01 8.10835719e-01\n",
      " 9.99999523e-01 9.98548329e-01 9.99554217e-01 2.72148270e-07\n",
      " 2.62830057e-04 6.86501808e-05 5.76293422e-03 1.45640649e-06\n",
      " 8.99756134e-01 7.81356266e-06 3.52186188e-02 3.89725599e-03\n",
      " 9.86869156e-01 8.57760847e-01 8.66800845e-01 8.06873441e-01\n",
      " 8.44650865e-01 5.78541636e-01 9.06698704e-01 9.99999404e-01\n",
      " 9.99859691e-01 9.15209770e-01 8.57388616e-01 9.42130148e-01\n",
      " 9.92141366e-01 9.98329222e-01 9.98125732e-01 7.41108537e-01\n",
      " 9.99014616e-01 9.98981774e-01 9.89243507e-01 9.99881744e-01\n",
      " 9.99999881e-01 9.84330714e-01 9.98638213e-01 4.47775461e-02\n",
      " 4.94074315e-01 9.99698997e-01 9.75856841e-01 9.83080804e-01\n",
      " 9.17826127e-03 6.73452318e-01 9.97994423e-01 2.73844957e-01\n",
      " 7.02928960e-01 9.99966502e-01 9.98608530e-01 9.79017794e-01\n",
      " 9.83071077e-05 4.27194327e-01 8.17683876e-01 9.62822020e-01\n",
      " 5.36622033e-02 9.99812305e-01 3.77529650e-03 9.46066082e-01\n",
      " 9.69234705e-01 6.92157686e-01 9.99999523e-01 5.52724069e-03\n",
      " 4.80321032e-04 9.61979210e-01 9.05444438e-04 5.76773994e-02\n",
      " 6.22947156e-01 8.59293520e-01 2.21063849e-03 1.40782194e-02\n",
      " 6.48120701e-01 9.34279040e-02]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 315 [0/54 (0%)]\tTrain Loss: 0.001441\n",
      "Train Epoch: 315 [8/54 (15%)]\tTrain Loss: 0.002411\n",
      "Train Epoch: 315 [16/54 (30%)]\tTrain Loss: 0.003432\n",
      "Train Epoch: 315 [24/54 (44%)]\tTrain Loss: 0.000809\n",
      "Train Epoch: 315 [32/54 (59%)]\tTrain Loss: 0.002625\n",
      "Train Epoch: 315 [40/54 (74%)]\tTrain Loss: 0.073143\n",
      "Train Epoch: 315 [48/54 (89%)]\tTrain Loss: 0.001017\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.52175902e-04 5.75391315e-02 5.83397166e-04 3.49184088e-02\n",
      " 3.48677230e-03 3.21338052e-06 1.14080824e-04 9.16454121e-02\n",
      " 4.03872924e-03 1.61526605e-01 3.94495903e-03 1.12508063e-03\n",
      " 3.94608724e-05 3.00476222e-06 2.68927030e-03 4.60757661e-07\n",
      " 9.69552366e-06 2.91040093e-02 1.47396815e-03 5.51343113e-02\n",
      " 1.22647011e-03 9.94235098e-01 9.83590901e-01 9.88402903e-01\n",
      " 2.79029645e-02 9.99747097e-01 9.99545038e-01 1.56932771e-01\n",
      " 2.29845662e-02 7.76501521e-02 1.79693215e-02 2.78328151e-01\n",
      " 2.00657244e-03 1.16603871e-07 7.39616610e-07 3.09604977e-04\n",
      " 1.03765407e-04 9.84644651e-01 4.33356315e-03 6.46176562e-03\n",
      " 1.37204723e-03 2.09464952e-02 2.30274629e-02 1.56150328e-03\n",
      " 6.30784556e-02 3.47248279e-04 7.66569197e-01 5.85495651e-01\n",
      " 9.94104087e-01 9.46832776e-01 9.94475782e-01 7.95530923e-07\n",
      " 3.93813280e-05 1.88114529e-03 8.24093644e-04 7.79222717e-07\n",
      " 6.44777894e-01 9.98225005e-05 7.63717061e-03 7.49414976e-05\n",
      " 9.33055997e-01 7.93010652e-01 7.54942715e-01 8.99208844e-01\n",
      " 4.25875366e-01 7.71054998e-02 8.99705172e-01 9.98265088e-01\n",
      " 9.98815417e-01 8.07773530e-01 9.26880002e-01 8.80682468e-01\n",
      " 9.46687996e-01 8.41882825e-01 9.91760492e-01 9.46709156e-01\n",
      " 9.99997377e-01 9.99999285e-01 9.85134006e-01 9.92734909e-01\n",
      " 9.99982715e-01 9.69678462e-01 9.91702378e-01 6.32665381e-02\n",
      " 8.15803647e-01 9.64547396e-01 9.75483716e-01 9.19472039e-01\n",
      " 9.54412026e-05 1.97144270e-01 8.29247117e-01 7.10675344e-02\n",
      " 6.13548875e-01 9.98537302e-01 9.96212125e-01 8.78575206e-01\n",
      " 4.95706663e-05 1.51123209e-02 6.65255561e-02 5.75194120e-01\n",
      " 1.93703584e-02 9.95505333e-01 8.38898050e-05 4.24765766e-01\n",
      " 9.84872937e-01 5.02670348e-01 9.99990106e-01 1.16679774e-04\n",
      " 2.28723202e-05 7.28924155e-01 1.87155863e-04 2.99672270e-03\n",
      " 4.35929224e-02 1.87439956e-02 5.32493170e-04 3.28976451e-03\n",
      " 1.78314984e-01 2.80129747e-03]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Train Epoch: 316 [0/54 (0%)]\tTrain Loss: 0.061057\n",
      "Train Epoch: 316 [8/54 (15%)]\tTrain Loss: 0.002905\n",
      "Train Epoch: 316 [16/54 (30%)]\tTrain Loss: 0.006136\n",
      "Train Epoch: 316 [24/54 (44%)]\tTrain Loss: 0.002933\n",
      "Train Epoch: 316 [32/54 (59%)]\tTrain Loss: 0.008844\n",
      "Train Epoch: 316 [40/54 (74%)]\tTrain Loss: 0.004137\n",
      "Train Epoch: 316 [48/54 (89%)]\tTrain Loss: 0.001485\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.01546834 0.99665087 0.96617359 0.95540893 0.02318369 0.02088932\n",
      " 0.98636395 0.52267945 0.79150319 0.97456497 0.51140708 0.07884419\n",
      " 0.57803589 0.85777473 0.9887467  0.18296264 0.2037835  0.41925144\n",
      " 0.77593237 0.72469974 0.32852474 0.99920875 0.99924821 0.99995446\n",
      " 0.93617916 0.99997818 0.9999994  0.99790478 0.84792179 0.98288721\n",
      " 0.99940419 0.99661678 0.8572911  0.00432126 0.00626652 0.10474904\n",
      " 0.08620632 0.98630095 0.12765275 0.16171299 0.04678383 0.11849549\n",
      " 0.03816872 0.45617205 0.86100137 0.32987753 0.97298783 0.78791451\n",
      " 0.99999964 0.99880946 0.99999607 0.00623967 0.40201581 0.85047454\n",
      " 0.12012359 0.24998873 0.99996531 0.44961289 0.85290265 0.95371121\n",
      " 0.9952153  0.99181128 0.98861396 0.99625766 0.99983573 0.99877495\n",
      " 0.99985802 0.99999905 0.99999523 0.88894242 0.97709227 0.96355891\n",
      " 0.99999583 0.99947208 0.99999976 0.9971962  1.         0.99999976\n",
      " 0.99984765 0.99990189 0.99999976 0.99999869 0.99999571 0.49792624\n",
      " 0.84685367 0.98357749 0.99938607 0.99917054 0.91088957 0.9993512\n",
      " 0.99998868 0.98614049 0.99386805 1.         0.99912268 0.99998355\n",
      " 0.28622028 0.65806347 0.86791414 0.99993443 0.56575894 0.98654789\n",
      " 0.1134147  0.97885233 0.99824286 0.99891841 0.99999988 0.31096768\n",
      " 0.12466711 0.99894196 0.44191155 0.9407602  0.99925953 0.99337232\n",
      " 0.76229095 0.2761372  0.99994493 0.87134451]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 317 [0/54 (0%)]\tTrain Loss: 0.008050\n",
      "Train Epoch: 317 [8/54 (15%)]\tTrain Loss: 0.002104\n",
      "Train Epoch: 317 [16/54 (30%)]\tTrain Loss: 0.000664\n",
      "Train Epoch: 317 [24/54 (44%)]\tTrain Loss: 0.091788\n",
      "Train Epoch: 317 [32/54 (59%)]\tTrain Loss: 0.000393\n",
      "Train Epoch: 317 [40/54 (74%)]\tTrain Loss: 0.002678\n",
      "Train Epoch: 317 [48/54 (89%)]\tTrain Loss: 0.000650\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.77976687e-03 9.51463223e-01 6.24128401e-01 9.94255602e-01\n",
      " 4.74798195e-02 4.35663667e-03 3.36332977e-01 2.91591406e-01\n",
      " 6.34814680e-01 9.89240348e-01 1.00139640e-01 4.28462215e-02\n",
      " 4.51999009e-01 4.30211350e-02 9.56362665e-01 1.13854939e-02\n",
      " 3.95075902e-02 4.99886036e-01 9.95734751e-01 2.83650249e-01\n",
      " 8.31039175e-02 9.97762322e-01 9.99993801e-01 9.99882221e-01\n",
      " 8.54780912e-01 9.99999881e-01 9.99992847e-01 9.57221508e-01\n",
      " 5.35680473e-01 7.81773746e-01 9.93733823e-01 9.96028423e-01\n",
      " 7.72006452e-01 5.91896474e-04 7.90829596e-04 8.10008943e-02\n",
      " 5.16080372e-02 9.83993113e-01 2.74406701e-01 6.32330403e-02\n",
      " 1.22894067e-02 5.73415831e-02 8.02811459e-02 9.50265862e-03\n",
      " 3.77630919e-01 1.01168500e-02 9.93246913e-01 8.23946774e-01\n",
      " 9.99996781e-01 9.87442195e-01 9.99886632e-01 3.70488269e-04\n",
      " 5.78297935e-02 4.40905601e-01 6.25351518e-02 8.30226205e-03\n",
      " 9.97983456e-01 2.95001660e-02 1.76236957e-01 7.22488761e-01\n",
      " 9.98899460e-01 9.95773017e-01 9.98112679e-01 9.99428928e-01\n",
      " 9.99632835e-01 9.88835752e-01 9.99976039e-01 9.99955535e-01\n",
      " 9.99997973e-01 9.71090257e-01 9.81549323e-01 9.91295815e-01\n",
      " 9.99973416e-01 9.99962091e-01 9.99997377e-01 9.99328256e-01\n",
      " 9.99999642e-01 9.99999285e-01 9.99639153e-01 9.99976158e-01\n",
      " 9.99995232e-01 9.99287307e-01 9.99939203e-01 8.80308926e-01\n",
      " 9.91541564e-01 9.99288142e-01 9.99545038e-01 9.97616053e-01\n",
      " 5.36063790e-01 9.97842550e-01 9.99715269e-01 9.05636191e-01\n",
      " 9.54601228e-01 9.99998927e-01 9.92664635e-01 9.98962164e-01\n",
      " 4.60504256e-02 8.22717845e-01 7.66059577e-01 9.99789059e-01\n",
      " 7.44538963e-01 9.99808729e-01 1.92985073e-01 8.74426961e-01\n",
      " 9.70787764e-01 9.92263317e-01 9.99995589e-01 5.47867417e-02\n",
      " 6.76412508e-02 9.82561588e-01 2.21439496e-01 5.91196418e-01\n",
      " 9.82285619e-01 9.79234457e-01 9.64503050e-01 7.47481048e-01\n",
      " 9.75776374e-01 9.89120722e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 318 [0/54 (0%)]\tTrain Loss: 0.003253\n",
      "Train Epoch: 318 [8/54 (15%)]\tTrain Loss: 0.008814\n",
      "Train Epoch: 318 [16/54 (30%)]\tTrain Loss: 0.003804\n",
      "Train Epoch: 318 [24/54 (44%)]\tTrain Loss: 0.111957\n",
      "Train Epoch: 318 [32/54 (59%)]\tTrain Loss: 0.008668\n",
      "Train Epoch: 318 [40/54 (74%)]\tTrain Loss: 0.005126\n",
      "Train Epoch: 318 [48/54 (89%)]\tTrain Loss: 0.001946\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.52765154e-03 9.88293409e-01 9.75515842e-01 9.15701449e-01\n",
      " 8.53487104e-02 2.29381607e-03 9.65858221e-01 8.11035633e-01\n",
      " 1.88949987e-01 4.12508756e-01 2.58497987e-02 2.33594235e-03\n",
      " 1.20442934e-01 4.09951098e-02 9.27412689e-01 5.07580233e-04\n",
      " 1.52760325e-02 1.99586023e-02 1.99117392e-01 1.25920130e-02\n",
      " 1.12095592e-03 9.60767031e-01 9.98913407e-01 9.99907136e-01\n",
      " 3.24623644e-01 9.99964833e-01 9.99953985e-01 6.93692923e-01\n",
      " 1.24743193e-01 3.23748499e-01 6.15998805e-01 4.58948284e-01\n",
      " 4.30874705e-01 1.44858786e-04 2.31554033e-03 7.79757723e-02\n",
      " 4.13814560e-03 7.37611532e-01 6.88170083e-03 2.62081753e-02\n",
      " 8.22216552e-03 3.68195996e-02 3.35012423e-03 4.72476007e-04\n",
      " 1.11013919e-01 6.31951320e-04 9.80850577e-01 8.92268538e-01\n",
      " 9.99999404e-01 9.86253977e-01 9.99978900e-01 6.98107993e-04\n",
      " 3.32518877e-03 5.89527264e-02 4.49563703e-03 1.14869047e-03\n",
      " 9.90554869e-01 2.65709753e-03 2.08352562e-02 4.03011948e-01\n",
      " 9.96150732e-01 9.92432833e-01 9.94148731e-01 9.93912220e-01\n",
      " 9.88661766e-01 9.42555904e-01 9.99686241e-01 9.99906063e-01\n",
      " 9.99999166e-01 8.35686266e-01 9.69819486e-01 9.55792427e-01\n",
      " 9.99897838e-01 9.96683300e-01 9.99780357e-01 9.76022303e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99647856e-01 9.99678016e-01\n",
      " 9.99998212e-01 9.99918222e-01 9.99994397e-01 1.12818172e-02\n",
      " 1.23537861e-01 9.12720144e-01 9.98077869e-01 9.96811450e-01\n",
      " 3.26922417e-01 9.81622219e-01 9.99042690e-01 6.60149515e-01\n",
      " 7.28075743e-01 9.99997616e-01 9.67746079e-01 9.93126750e-01\n",
      " 1.27473734e-02 3.26526724e-02 2.79439509e-01 9.99777257e-01\n",
      " 4.91618738e-02 9.95269835e-01 1.85081773e-02 7.13288307e-01\n",
      " 8.98080587e-01 9.23125565e-01 9.99997497e-01 3.60250659e-02\n",
      " 1.27205411e-02 6.96620107e-01 8.30167439e-03 4.08300459e-01\n",
      " 9.68510926e-01 9.71395671e-01 8.63169849e-01 1.99044511e-01\n",
      " 5.06854296e-01 7.55886912e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 319 [0/54 (0%)]\tTrain Loss: 0.002802\n",
      "Train Epoch: 319 [8/54 (15%)]\tTrain Loss: 0.011841\n",
      "Train Epoch: 319 [16/54 (30%)]\tTrain Loss: 0.000417\n",
      "Train Epoch: 319 [24/54 (44%)]\tTrain Loss: 0.001632\n",
      "Train Epoch: 319 [32/54 (59%)]\tTrain Loss: 0.005437\n",
      "Train Epoch: 319 [40/54 (74%)]\tTrain Loss: 0.004627\n",
      "Train Epoch: 319 [48/54 (89%)]\tTrain Loss: 0.000392\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.89477241e-03 9.98535872e-01 9.25968945e-01 7.11395979e-01\n",
      " 5.15124872e-02 2.63698515e-04 7.13465631e-01 8.37458134e-01\n",
      " 3.80877435e-01 7.20765054e-01 1.98196054e-01 2.22854577e-02\n",
      " 3.33501585e-02 3.33528908e-04 4.55200285e-01 1.51403001e-04\n",
      " 1.74412094e-02 1.01934649e-01 8.62830639e-01 7.90376738e-02\n",
      " 4.80064750e-03 9.91576791e-01 9.99591410e-01 9.99789536e-01\n",
      " 5.50840676e-01 9.99995112e-01 9.99881744e-01 8.71039271e-01\n",
      " 3.33543658e-01 4.05325890e-01 9.98420954e-01 9.97904658e-01\n",
      " 8.43640506e-01 7.87218960e-05 1.19898969e-03 5.25529310e-02\n",
      " 3.98274697e-02 9.99846816e-01 1.87451008e-03 1.18064815e-02\n",
      " 3.21320980e-03 1.64149012e-02 3.07265401e-01 3.44132213e-03\n",
      " 2.55005449e-01 2.69286837e-02 9.99921799e-01 9.93813872e-01\n",
      " 9.99999881e-01 9.96258855e-01 9.99973774e-01 9.31176357e-03\n",
      " 1.13977981e-03 1.58872128e-01 2.62099877e-02 4.05959639e-04\n",
      " 9.99537468e-01 1.76005717e-02 4.18035360e-03 1.72728091e-03\n",
      " 9.99852777e-01 9.98809934e-01 9.99175847e-01 9.98994529e-01\n",
      " 9.97822404e-01 9.60097730e-01 9.99823987e-01 9.99984980e-01\n",
      " 9.99999642e-01 9.91526544e-01 9.93894517e-01 9.96463716e-01\n",
      " 9.99834299e-01 9.99255955e-01 9.99573290e-01 9.99853849e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99994636e-01 9.99997854e-01\n",
      " 9.99999881e-01 9.99981642e-01 9.99984741e-01 2.49313846e-01\n",
      " 7.68907428e-01 9.95642185e-01 9.99515653e-01 9.97355938e-01\n",
      " 3.56040150e-02 9.92099404e-01 9.99343336e-01 9.47973073e-01\n",
      " 9.78943646e-01 9.99999762e-01 9.99350250e-01 9.94808376e-01\n",
      " 7.94957280e-02 1.00713722e-01 5.96200168e-01 9.96445715e-01\n",
      " 9.59056020e-02 9.99963880e-01 4.90843877e-02 9.97774303e-01\n",
      " 9.97840166e-01 9.87780452e-01 9.99999642e-01 5.54375350e-02\n",
      " 8.70073447e-04 6.86588168e-01 2.70650964e-02 5.32398410e-02\n",
      " 8.71864200e-01 9.72249448e-01 8.67395043e-01 7.78936803e-01\n",
      " 9.73412812e-01 9.72027481e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 320 [0/54 (0%)]\tTrain Loss: 0.000295\n",
      "Train Epoch: 320 [8/54 (15%)]\tTrain Loss: 0.004741\n",
      "Train Epoch: 320 [16/54 (30%)]\tTrain Loss: 0.001926\n",
      "Train Epoch: 320 [24/54 (44%)]\tTrain Loss: 0.042824\n",
      "Train Epoch: 320 [32/54 (59%)]\tTrain Loss: 0.002568\n",
      "Train Epoch: 320 [40/54 (74%)]\tTrain Loss: 0.001534\n",
      "Train Epoch: 320 [48/54 (89%)]\tTrain Loss: 0.012885\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.63769368e-04 9.77810383e-01 1.39533862e-01 4.46438968e-01\n",
      " 1.69677776e-03 2.79871840e-03 5.83205044e-01 1.26913622e-01\n",
      " 1.89606503e-01 5.96307456e-01 1.66096970e-01 1.40292116e-03\n",
      " 4.87780236e-02 8.82335997e-04 1.79014981e-01 2.16381322e-05\n",
      " 1.74382483e-04 1.18178036e-02 3.42084348e-01 4.12039421e-02\n",
      " 1.32628006e-03 9.33093250e-01 9.95426595e-01 9.99450624e-01\n",
      " 2.10962519e-01 9.99980092e-01 9.99991298e-01 7.66271472e-01\n",
      " 4.00971830e-01 4.49991763e-01 9.41444874e-01 8.36304367e-01\n",
      " 1.27681747e-01 2.78272501e-06 4.54323686e-04 1.86882555e-01\n",
      " 4.14765067e-02 8.17132175e-01 1.62607189e-02 4.44571581e-03\n",
      " 2.41691159e-04 1.04336113e-01 2.86210272e-02 3.78336422e-02\n",
      " 4.58278432e-02 7.07577157e-04 7.93406248e-01 3.22967529e-01\n",
      " 9.99978900e-01 9.58864272e-01 9.98922229e-01 4.32236302e-05\n",
      " 1.07364589e-02 1.56010296e-02 6.61349669e-02 2.58351257e-03\n",
      " 9.80206132e-01 2.63357833e-02 1.13277063e-01 2.74972022e-02\n",
      " 9.99468267e-01 9.97772157e-01 9.96629536e-01 9.99222636e-01\n",
      " 8.77694845e-01 9.26857054e-01 9.32775438e-01 9.99994755e-01\n",
      " 9.99973297e-01 5.72556317e-01 8.04148376e-01 9.36032712e-01\n",
      " 9.97533798e-01 9.80307639e-01 9.63327527e-01 9.83429313e-01\n",
      " 9.99999166e-01 9.99999642e-01 9.94640529e-01 9.98324573e-01\n",
      " 9.99789536e-01 9.99615073e-01 9.99854326e-01 1.50059879e-01\n",
      " 2.63870597e-01 7.82624960e-01 9.98895526e-01 9.96899247e-01\n",
      " 2.61923093e-02 9.91246879e-01 9.87149060e-01 8.87911975e-01\n",
      " 9.35583711e-01 9.99999166e-01 9.81466830e-01 9.65805411e-01\n",
      " 5.82240336e-02 1.76217481e-02 2.54671723e-01 9.98282313e-01\n",
      " 3.21960635e-02 9.84461486e-01 1.67583767e-02 9.19042766e-01\n",
      " 8.08764875e-01 9.84938860e-01 1.00000000e+00 3.76013108e-02\n",
      " 1.79659724e-02 5.32163560e-01 5.44923765e-04 4.74134721e-02\n",
      " 9.86084163e-01 6.04366839e-01 5.04704788e-02 2.98571568e-02\n",
      " 5.63728213e-01 4.07431364e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "vote_pred [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 46 TN= 41 FN= 12 FP= 19\n",
      "TP+FP 65\n",
      "precision 0.7076923076923077\n",
      "recall 0.7931034482758621\n",
      "F1 0.7479674796747967\n",
      "acc 0.7372881355932204\n",
      "AUCp 0.7382183908045977\n",
      "AUC 0.7709770114942529\n",
      "\n",
      " The epoch is 320, average recall: 0.7931, average precision: 0.7077,average F1: 0.7480, average accuracy: 0.7373, average AUC: 0.7710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 321 [0/54 (0%)]\tTrain Loss: 0.000548\n",
      "Train Epoch: 321 [8/54 (15%)]\tTrain Loss: 0.001594\n",
      "Train Epoch: 321 [16/54 (30%)]\tTrain Loss: 0.001426\n",
      "Train Epoch: 321 [24/54 (44%)]\tTrain Loss: 0.000188\n",
      "Train Epoch: 321 [32/54 (59%)]\tTrain Loss: 0.001888\n",
      "Train Epoch: 321 [40/54 (74%)]\tTrain Loss: 0.000308\n",
      "Train Epoch: 321 [48/54 (89%)]\tTrain Loss: 0.000955\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.71608660e-05 9.48552966e-01 3.33588794e-02 4.71306086e-01\n",
      " 1.01462263e-03 9.10416784e-05 3.29681784e-01 9.12851915e-02\n",
      " 1.65537983e-01 2.22882003e-01 9.49109066e-03 8.32838751e-03\n",
      " 7.26633953e-05 7.40026564e-07 2.37604212e-02 1.30282797e-06\n",
      " 1.26007435e-05 3.85232829e-02 4.08591092e-01 4.47278507e-02\n",
      " 2.32700421e-03 8.09203029e-01 9.91989076e-01 9.98499155e-01\n",
      " 4.30701412e-02 9.99984145e-01 9.99994278e-01 2.65100092e-01\n",
      " 3.46668184e-01 1.15228228e-01 3.84352267e-01 9.55706000e-01\n",
      " 1.98767353e-02 1.27303135e-09 9.88632536e-08 3.71143185e-02\n",
      " 2.19900184e-03 9.75580633e-01 1.22291164e-03 1.23945123e-03\n",
      " 6.39444042e-05 7.19439471e-03 1.30930528e-01 1.40951350e-04\n",
      " 4.17138115e-02 7.38529434e-06 6.66454434e-01 2.74526060e-01\n",
      " 9.97907281e-01 9.35307562e-01 9.87830698e-01 3.81421700e-07\n",
      " 1.85958343e-03 7.74366129e-03 6.27190806e-03 4.33240813e-04\n",
      " 9.81690228e-01 1.95427705e-03 8.69821236e-02 2.05787574e-03\n",
      " 9.53671277e-01 8.74915004e-01 7.25356877e-01 9.47701454e-01\n",
      " 2.57057369e-01 9.55020308e-01 9.67901111e-01 9.99913931e-01\n",
      " 9.99964237e-01 3.16017330e-01 5.29040158e-01 7.85898745e-01\n",
      " 9.51117396e-01 7.92181075e-01 9.18527663e-01 8.84615660e-01\n",
      " 9.99996781e-01 9.99994278e-01 9.87809658e-01 9.62170899e-01\n",
      " 9.91262913e-01 9.88517880e-01 9.99442518e-01 2.79197067e-01\n",
      " 7.40599811e-01 9.37021673e-01 9.95530307e-01 9.72743154e-01\n",
      " 5.28912880e-02 8.45969558e-01 9.82602000e-01 4.46141273e-01\n",
      " 8.32596362e-01 9.99998927e-01 9.06858921e-01 8.69710207e-01\n",
      " 1.14895857e-03 4.92680408e-02 6.68582171e-02 9.76939797e-01\n",
      " 1.33064277e-02 9.96730924e-01 1.42434344e-03 5.72977960e-01\n",
      " 5.16919494e-01 7.59976268e-01 9.99997258e-01 1.15499813e-02\n",
      " 1.34959409e-03 2.07424656e-01 6.23569358e-05 1.52027076e-02\n",
      " 6.41559184e-01 7.44265199e-01 4.46911855e-03 4.11274247e-02\n",
      " 9.44389820e-01 5.74125350e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 322 [0/54 (0%)]\tTrain Loss: 0.000566\n",
      "Train Epoch: 322 [8/54 (15%)]\tTrain Loss: 0.003591\n",
      "Train Epoch: 322 [16/54 (30%)]\tTrain Loss: 0.009282\n",
      "Train Epoch: 322 [24/54 (44%)]\tTrain Loss: 0.000075\n",
      "Train Epoch: 322 [32/54 (59%)]\tTrain Loss: 0.000355\n",
      "Train Epoch: 322 [40/54 (74%)]\tTrain Loss: 0.000076\n",
      "Train Epoch: 322 [48/54 (89%)]\tTrain Loss: 0.000593\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.97180518e-04 9.97343838e-01 3.27154398e-01 3.06071401e-01\n",
      " 1.10144597e-02 3.67661560e-04 6.01078093e-01 1.52067944e-01\n",
      " 4.52111810e-02 2.45289400e-01 7.31970789e-03 3.72301787e-04\n",
      " 7.01560755e-04 5.76233200e-04 5.00804901e-01 1.39857211e-05\n",
      " 1.34734798e-03 6.68937862e-02 7.15333223e-01 9.65746343e-02\n",
      " 2.26554446e-04 9.41976607e-01 9.98498082e-01 9.99847770e-01\n",
      " 6.52783662e-02 9.99997854e-01 9.99999881e-01 3.00871998e-01\n",
      " 6.11181140e-01 5.33112250e-02 9.51994836e-01 9.90187347e-01\n",
      " 1.02024980e-01 1.43288439e-08 2.28941573e-07 1.40218819e-02\n",
      " 6.33727293e-04 9.95361745e-01 2.30460102e-03 2.12554336e-02\n",
      " 6.23140833e-04 7.53536727e-03 3.31764668e-02 2.62822025e-04\n",
      " 5.28159144e-04 5.79500120e-05 9.59822178e-01 4.09968674e-01\n",
      " 9.99859810e-01 9.03852284e-01 9.94193256e-01 3.75236305e-05\n",
      " 5.53909398e-04 1.82444416e-03 2.79015955e-03 9.77874333e-06\n",
      " 9.99433100e-01 1.08818225e-04 1.79533921e-02 5.59979642e-04\n",
      " 9.99809086e-01 9.88039553e-01 9.93659437e-01 9.95982528e-01\n",
      " 6.23193920e-01 9.29659724e-01 9.97738957e-01 9.99999881e-01\n",
      " 9.99999642e-01 9.21446264e-01 8.30521643e-01 9.04012144e-01\n",
      " 9.96001303e-01 9.87725794e-01 9.79664087e-01 9.92867351e-01\n",
      " 9.99999881e-01 9.99999762e-01 9.99304414e-01 9.99871016e-01\n",
      " 9.99997258e-01 9.99664783e-01 9.99895334e-01 8.75319615e-02\n",
      " 4.31154430e-01 9.99517560e-01 9.97288585e-01 9.74901378e-01\n",
      " 3.42677571e-02 9.99795854e-01 9.60423768e-01 5.99867761e-01\n",
      " 9.62695062e-01 9.99996543e-01 9.25562799e-01 8.76297116e-01\n",
      " 1.79520594e-05 1.62281424e-01 1.45309418e-01 9.99783933e-01\n",
      " 5.47678545e-02 9.99991298e-01 7.38126505e-03 9.48121130e-01\n",
      " 9.46583629e-01 9.42073524e-01 1.00000000e+00 1.48332596e-03\n",
      " 1.37656629e-02 6.52638912e-01 7.34017137e-03 8.97645131e-02\n",
      " 6.52426243e-01 8.99154782e-01 8.67204309e-01 4.19598728e-01\n",
      " 9.96862054e-01 3.24963450e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0.]\n",
      "Train Epoch: 323 [0/54 (0%)]\tTrain Loss: 0.000169\n",
      "Train Epoch: 323 [8/54 (15%)]\tTrain Loss: 0.012061\n",
      "Train Epoch: 323 [16/54 (30%)]\tTrain Loss: 0.000439\n",
      "Train Epoch: 323 [24/54 (44%)]\tTrain Loss: 0.054269\n",
      "Train Epoch: 323 [32/54 (59%)]\tTrain Loss: 0.006407\n",
      "Train Epoch: 323 [40/54 (74%)]\tTrain Loss: 0.047478\n",
      "Train Epoch: 323 [48/54 (89%)]\tTrain Loss: 0.008421\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.00810519e-03 9.98954296e-01 4.98751909e-01 9.94211257e-01\n",
      " 6.03424191e-01 4.72879317e-03 9.63897943e-01 9.98759508e-01\n",
      " 1.18686214e-01 3.76444608e-01 8.89829159e-01 2.90397424e-02\n",
      " 3.45382273e-01 4.04907716e-03 7.51579702e-01 3.44339292e-03\n",
      " 2.48703331e-01 2.02341706e-01 9.90311742e-01 1.46790445e-01\n",
      " 1.27596955e-03 9.99109328e-01 9.99996543e-01 9.99960065e-01\n",
      " 8.18248391e-01 1.00000000e+00 9.99814808e-01 9.74491298e-01\n",
      " 9.98441994e-01 9.98786032e-01 9.95262861e-01 9.99847054e-01\n",
      " 9.92273748e-01 1.05451880e-04 3.13407829e-04 9.37530756e-01\n",
      " 7.60654271e-01 9.99911427e-01 8.61332864e-02 2.23164320e-01\n",
      " 7.12987483e-02 6.04590513e-02 3.22082639e-02 3.99625003e-02\n",
      " 9.68809187e-01 5.28881140e-03 9.99484897e-01 9.57466781e-01\n",
      " 9.99997258e-01 9.83639002e-01 9.99991417e-01 1.97010756e-01\n",
      " 5.48744678e-01 7.17364073e-01 1.34028774e-02 2.10740283e-01\n",
      " 9.99972463e-01 1.26115814e-01 9.19322670e-01 2.05742255e-01\n",
      " 9.99981165e-01 9.99628663e-01 9.99791563e-01 9.99903440e-01\n",
      " 9.99962687e-01 9.99860048e-01 9.99998093e-01 9.99999881e-01\n",
      " 1.00000000e+00 9.19875205e-01 9.73210573e-01 9.68109310e-01\n",
      " 9.99999881e-01 9.99997854e-01 9.99997020e-01 9.99984503e-01\n",
      " 1.00000000e+00 9.99999881e-01 9.99997497e-01 9.99995112e-01\n",
      " 9.99999523e-01 9.99999285e-01 9.99999762e-01 5.86412288e-02\n",
      " 8.77098262e-01 9.54896033e-01 9.99953628e-01 9.99966741e-01\n",
      " 8.11589062e-01 9.69334245e-01 9.95384872e-01 8.91171098e-01\n",
      " 9.78657663e-01 1.00000000e+00 9.90729272e-01 9.99971032e-01\n",
      " 1.76439419e-01 7.18470514e-02 6.51074648e-01 9.99988794e-01\n",
      " 4.68496740e-01 9.99980330e-01 1.88751429e-01 9.92867112e-01\n",
      " 9.95348036e-01 9.91560638e-01 9.99999762e-01 6.98394626e-02\n",
      " 2.97095235e-02 8.65729749e-01 1.09137222e-01 6.81328773e-02\n",
      " 9.28370595e-01 9.99983668e-01 3.20006847e-01 2.38033921e-01\n",
      " 9.96526420e-01 9.97452080e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 324 [0/54 (0%)]\tTrain Loss: 0.001833\n",
      "Train Epoch: 324 [8/54 (15%)]\tTrain Loss: 0.035855\n",
      "Train Epoch: 324 [16/54 (30%)]\tTrain Loss: 0.007423\n",
      "Train Epoch: 324 [24/54 (44%)]\tTrain Loss: 0.001393\n",
      "Train Epoch: 324 [32/54 (59%)]\tTrain Loss: 0.018485\n",
      "Train Epoch: 324 [40/54 (74%)]\tTrain Loss: 0.001082\n",
      "Train Epoch: 324 [48/54 (89%)]\tTrain Loss: 0.004828\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.78612825e-02 9.79343176e-01 9.18741107e-01 5.22642851e-01\n",
      " 5.15597701e-01 1.57906972e-02 6.53065801e-01 9.83898938e-01\n",
      " 1.31154492e-01 8.36046994e-01 1.86363146e-01 9.18441534e-01\n",
      " 1.55700161e-03 3.41182738e-03 3.50426376e-01 1.55202870e-04\n",
      " 1.59543275e-03 5.43848157e-01 9.11663115e-01 8.63727510e-01\n",
      " 9.16772988e-03 9.98677194e-01 9.99899268e-01 9.99999285e-01\n",
      " 7.45882273e-01 9.99998331e-01 1.00000000e+00 9.98273134e-01\n",
      " 9.14485931e-01 5.36266983e-01 3.83526891e-01 9.10635233e-01\n",
      " 1.38830736e-01 1.46212103e-03 2.22793058e-03 7.23495185e-01\n",
      " 2.29401141e-02 9.61658180e-01 2.91419663e-02 3.84762920e-02\n",
      " 5.92894107e-03 9.62031260e-02 9.15889721e-03 4.30706620e-01\n",
      " 7.61418581e-01 1.67784945e-03 9.93343353e-01 8.39994699e-02\n",
      " 9.99998689e-01 9.96423185e-01 9.99984741e-01 1.66897420e-02\n",
      " 6.27054740e-03 7.31603615e-03 2.32960135e-02 4.03568745e-02\n",
      " 9.99994278e-01 5.39724622e-03 9.42528486e-01 2.64695217e-03\n",
      " 9.99994636e-01 9.99836802e-01 9.99267876e-01 9.99105990e-01\n",
      " 8.45908463e-01 9.99322414e-01 9.96950448e-01 9.99987006e-01\n",
      " 9.99999881e-01 3.71469259e-01 9.92344320e-01 9.77803111e-01\n",
      " 9.99993443e-01 9.99723256e-01 9.97378707e-01 9.95781302e-01\n",
      " 9.99992728e-01 9.99524832e-01 9.98817086e-01 9.99890685e-01\n",
      " 9.99994516e-01 9.99999881e-01 1.00000000e+00 8.40929672e-02\n",
      " 6.10793471e-01 9.81898010e-01 9.99819219e-01 9.99630928e-01\n",
      " 9.11186099e-01 9.96536255e-01 9.99943852e-01 9.97802913e-01\n",
      " 9.98532295e-01 1.00000000e+00 9.80071664e-01 9.99876857e-01\n",
      " 8.80492553e-02 2.21861497e-01 4.93535966e-01 9.99852538e-01\n",
      " 6.77006543e-01 9.99856591e-01 9.92852077e-02 9.99585330e-01\n",
      " 9.82007980e-01 9.96048391e-01 1.00000000e+00 4.64913547e-01\n",
      " 1.32506806e-02 9.40491021e-01 2.32340824e-02 3.34656775e-01\n",
      " 4.99960810e-01 9.98932779e-01 2.00403184e-01 4.22020406e-02\n",
      " 9.55551207e-01 8.35034609e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 325 [0/54 (0%)]\tTrain Loss: 0.002992\n",
      "Train Epoch: 325 [8/54 (15%)]\tTrain Loss: 0.001190\n",
      "Train Epoch: 325 [16/54 (30%)]\tTrain Loss: 0.036468\n",
      "Train Epoch: 325 [24/54 (44%)]\tTrain Loss: 0.002237\n",
      "Train Epoch: 325 [32/54 (59%)]\tTrain Loss: 0.025840\n",
      "Train Epoch: 325 [40/54 (74%)]\tTrain Loss: 0.011333\n",
      "Train Epoch: 325 [48/54 (89%)]\tTrain Loss: 0.000859\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.79327948e-03 9.54810262e-01 3.86921376e-01 2.74262339e-01\n",
      " 1.50152206e-01 6.43251697e-03 7.34305441e-01 9.34749067e-01\n",
      " 2.83549540e-02 8.84954154e-01 1.49094373e-01 7.54593313e-01\n",
      " 1.05128791e-02 3.04087473e-04 5.27594447e-01 1.06436884e-04\n",
      " 1.73808238e-03 3.46499830e-01 5.86299777e-01 2.62463361e-01\n",
      " 8.28506425e-03 9.00922656e-01 9.99904990e-01 9.99996185e-01\n",
      " 5.21086097e-01 9.99993086e-01 9.99999404e-01 9.79114234e-01\n",
      " 7.80080557e-01 7.25971699e-01 7.97454178e-01 9.75466728e-01\n",
      " 4.37671512e-01 7.92852882e-03 3.87110445e-03 7.55447149e-02\n",
      " 1.08740909e-03 5.56712508e-01 2.63280682e-02 6.76879510e-02\n",
      " 4.21791850e-03 2.00667884e-02 4.78756335e-03 1.62233621e-01\n",
      " 2.30899915e-01 3.11559043e-03 9.98807073e-01 6.45919561e-01\n",
      " 1.00000000e+00 9.33455169e-01 9.99999881e-01 1.66705740e-03\n",
      " 2.07761955e-03 5.71459085e-02 1.09438196e-01 6.66828156e-02\n",
      " 9.96344268e-01 2.21554493e-03 5.94295561e-01 4.61095042e-04\n",
      " 9.99937177e-01 9.82206941e-01 9.88444924e-01 9.99265373e-01\n",
      " 9.97531235e-01 9.99504209e-01 9.99022603e-01 9.99986172e-01\n",
      " 9.92241144e-01 9.64772463e-01 9.48338389e-01 9.68087375e-01\n",
      " 9.99907970e-01 9.99999046e-01 9.99968290e-01 9.82951581e-01\n",
      " 9.99996781e-01 9.99713838e-01 9.98882830e-01 9.99981999e-01\n",
      " 9.99999523e-01 9.99998212e-01 9.99999285e-01 2.06754342e-01\n",
      " 3.31659138e-01 9.98944461e-01 9.97508168e-01 9.84938502e-01\n",
      " 8.81320000e-01 9.92936313e-01 9.99485016e-01 9.15152907e-01\n",
      " 7.60497808e-01 1.00000000e+00 9.82805550e-01 9.99997854e-01\n",
      " 3.82277891e-02 9.38186109e-01 7.06319392e-01 9.98866558e-01\n",
      " 6.05350196e-01 9.99754369e-01 1.75527986e-02 9.93352771e-01\n",
      " 9.57598269e-01 9.75371122e-01 1.00000000e+00 2.61353906e-02\n",
      " 6.07406534e-02 9.85402226e-01 1.91748720e-02 1.10433809e-01\n",
      " 9.90531921e-01 9.59481120e-01 5.85657433e-02 1.27906455e-02\n",
      " 7.77581155e-01 8.66625190e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 326 [0/54 (0%)]\tTrain Loss: 0.001060\n",
      "Train Epoch: 326 [8/54 (15%)]\tTrain Loss: 0.000691\n",
      "Train Epoch: 326 [16/54 (30%)]\tTrain Loss: 0.000591\n",
      "Train Epoch: 326 [24/54 (44%)]\tTrain Loss: 0.002139\n",
      "Train Epoch: 326 [32/54 (59%)]\tTrain Loss: 0.014797\n",
      "Train Epoch: 326 [40/54 (74%)]\tTrain Loss: 0.004742\n",
      "Train Epoch: 326 [48/54 (89%)]\tTrain Loss: 0.001641\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.72644251e-06 9.92296159e-01 5.70168018e-01 6.01229072e-01\n",
      " 2.82943577e-01 5.67309966e-04 7.43600905e-01 9.55269814e-01\n",
      " 2.94901039e-02 6.43837571e-01 1.32289171e-01 3.26425508e-02\n",
      " 5.13501540e-02 2.38683151e-05 4.78010513e-02 7.05302955e-05\n",
      " 2.59338226e-02 2.74338156e-01 6.34674966e-01 6.40500307e-01\n",
      " 1.76283019e-03 9.68612909e-01 9.99941349e-01 9.99884963e-01\n",
      " 4.67644930e-01 9.99999404e-01 9.99987364e-01 9.85228300e-01\n",
      " 8.27384651e-01 5.26540399e-01 4.53684367e-02 9.43803012e-01\n",
      " 1.82982087e-02 7.99249206e-03 5.49577503e-03 3.37896109e-01\n",
      " 1.71080709e-03 8.29868019e-01 1.03491053e-01 1.69142298e-02\n",
      " 9.66520747e-04 7.73951737e-03 5.98818995e-03 6.79089874e-02\n",
      " 2.42489442e-01 2.37228480e-04 8.92217159e-01 3.45171869e-01\n",
      " 9.99996901e-01 4.77596939e-01 9.99999523e-01 1.78209879e-03\n",
      " 2.41323898e-04 4.78647975e-03 1.89330243e-02 7.96602368e-02\n",
      " 9.87941086e-01 3.13878059e-02 7.59137750e-01 8.91210220e-05\n",
      " 9.99958158e-01 9.58687425e-01 9.91437256e-01 9.99439061e-01\n",
      " 9.92443144e-01 9.98143554e-01 9.97161746e-01 9.99998212e-01\n",
      " 1.00000000e+00 9.99473631e-01 7.08166182e-01 8.96922946e-01\n",
      " 9.99567211e-01 9.99997973e-01 9.99004185e-01 9.94979560e-01\n",
      " 9.99999881e-01 9.99992967e-01 9.98543620e-01 9.99394536e-01\n",
      " 9.99999881e-01 9.99950528e-01 9.99999762e-01 8.52512494e-02\n",
      " 1.54537424e-01 9.74182308e-01 9.94457603e-01 9.24921095e-01\n",
      " 7.33119905e-01 9.99985576e-01 9.89977598e-01 9.78093922e-01\n",
      " 8.13924909e-01 1.00000000e+00 9.99870539e-01 9.99980211e-01\n",
      " 1.89218484e-02 7.34972298e-01 9.85401094e-01 1.00000000e+00\n",
      " 3.81773531e-01 9.99989748e-01 1.18542826e-02 9.94759262e-01\n",
      " 9.62041676e-01 9.63532329e-01 1.00000000e+00 7.48501718e-02\n",
      " 3.26388255e-02 8.61913621e-01 1.76408783e-01 5.90080619e-01\n",
      " 9.99975324e-01 9.99568999e-01 7.73013458e-02 8.91354028e-03\n",
      " 9.89245057e-01 9.99641776e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 327 [0/54 (0%)]\tTrain Loss: 0.000620\n",
      "Train Epoch: 327 [8/54 (15%)]\tTrain Loss: 0.000557\n",
      "Train Epoch: 327 [16/54 (30%)]\tTrain Loss: 0.000089\n",
      "Train Epoch: 327 [24/54 (44%)]\tTrain Loss: 0.001828\n",
      "Train Epoch: 327 [32/54 (59%)]\tTrain Loss: 0.002012\n",
      "Train Epoch: 327 [40/54 (74%)]\tTrain Loss: 0.000288\n",
      "Train Epoch: 327 [48/54 (89%)]\tTrain Loss: 0.003729\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.36212145e-04 9.94579792e-01 5.77375650e-01 5.67393890e-03\n",
      " 6.25801412e-03 3.80054465e-04 4.21809524e-01 3.89736295e-02\n",
      " 6.00020494e-03 2.04130650e-01 3.14869732e-02 1.10063948e-01\n",
      " 1.51287546e-04 6.62038146e-05 7.31306244e-03 7.71911459e-07\n",
      " 3.41151099e-05 5.42904884e-02 2.49923696e-03 8.81144218e-03\n",
      " 2.19635003e-05 2.01094404e-01 4.80269581e-01 8.00149739e-01\n",
      " 9.46919527e-03 5.86221576e-01 9.95304585e-01 1.46041503e-02\n",
      " 1.71663046e-01 2.07293872e-02 8.49278364e-03 5.81511974e-01\n",
      " 2.39738636e-02 4.77660478e-07 6.97407668e-05 3.42572927e-02\n",
      " 6.52882212e-04 4.42410074e-02 1.34440430e-03 8.12716666e-04\n",
      " 8.08041150e-05 4.90505656e-04 5.47960214e-03 9.97089199e-04\n",
      " 1.17056910e-03 4.82643908e-03 9.66654480e-01 7.37789929e-01\n",
      " 9.99777377e-01 9.44743693e-01 9.99262393e-01 8.85062545e-05\n",
      " 3.76710977e-06 7.64788201e-05 2.79152649e-03 3.48387606e-04\n",
      " 9.51362252e-01 6.15448784e-03 2.03212118e-03 1.00432555e-06\n",
      " 9.99422550e-01 9.64680076e-01 9.99117315e-01 9.99903202e-01\n",
      " 5.21162641e-04 5.24404287e-01 8.75779629e-01 9.78646576e-01\n",
      " 9.99976873e-01 2.90428866e-02 8.37350905e-01 9.25444961e-01\n",
      " 9.96114492e-01 9.95076954e-01 8.94296706e-01 8.50526392e-01\n",
      " 9.99999762e-01 9.99996305e-01 9.98317003e-01 9.90905404e-01\n",
      " 9.99596536e-01 9.95875657e-01 9.99981046e-01 8.12428370e-02\n",
      " 9.95939970e-02 9.99041140e-01 9.78535950e-01 5.85332751e-01\n",
      " 7.83418026e-03 3.27741921e-01 9.55321252e-01 4.36294377e-02\n",
      " 4.30988133e-01 9.99483585e-01 8.08057547e-01 8.86736572e-01\n",
      " 6.63949118e-04 8.85014087e-02 4.27751422e-01 7.88599849e-01\n",
      " 1.98268723e-02 9.98298705e-01 3.54238902e-03 3.13625365e-01\n",
      " 2.98915714e-01 9.36870575e-01 9.99981403e-01 6.32913318e-04\n",
      " 1.70015792e-05 3.40275615e-01 1.27588247e-03 1.34863704e-03\n",
      " 2.28967920e-01 3.16128395e-02 4.28014211e-02 1.84999593e-02\n",
      " 8.95875871e-01 1.59166813e-01]\n",
      "predict [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Train Epoch: 328 [0/54 (0%)]\tTrain Loss: 0.004789\n",
      "Train Epoch: 328 [8/54 (15%)]\tTrain Loss: 0.004975\n",
      "Train Epoch: 328 [16/54 (30%)]\tTrain Loss: 0.000561\n",
      "Train Epoch: 328 [24/54 (44%)]\tTrain Loss: 0.001830\n",
      "Train Epoch: 328 [32/54 (59%)]\tTrain Loss: 0.015548\n",
      "Train Epoch: 328 [40/54 (74%)]\tTrain Loss: 0.004264\n",
      "Train Epoch: 328 [48/54 (89%)]\tTrain Loss: 0.007660\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.69964138e-04 8.69404256e-01 5.14379978e-01 9.26489770e-01\n",
      " 6.80190265e-01 7.89812021e-03 2.93689549e-01 9.99181926e-01\n",
      " 2.02954307e-01 7.09536791e-01 3.60443920e-01 2.02794716e-01\n",
      " 1.36209428e-02 2.89666490e-03 5.34915149e-01 1.88320747e-03\n",
      " 5.61675429e-03 2.33050033e-01 1.96438357e-01 1.45063892e-01\n",
      " 5.18943258e-02 9.05564606e-01 9.98600304e-01 9.99990821e-01\n",
      " 5.80058873e-01 9.99994755e-01 9.99997616e-01 8.28068733e-01\n",
      " 2.99588829e-01 5.16917288e-01 9.47057247e-01 9.97837126e-01\n",
      " 8.69084954e-01 3.86519991e-02 7.60855200e-03 4.31945115e-01\n",
      " 1.18586376e-01 9.36938047e-01 8.92163739e-02 3.27122778e-01\n",
      " 7.90599659e-02 1.55867592e-01 3.65891447e-03 1.96801499e-01\n",
      " 5.10272309e-02 4.17543575e-02 9.99506235e-01 9.96971130e-01\n",
      " 9.99999881e-01 9.26424503e-01 9.99993205e-01 3.15399989e-02\n",
      " 1.47828006e-03 7.10037397e-03 2.69705188e-02 4.22217734e-02\n",
      " 9.58733976e-01 4.82588969e-02 2.55225480e-01 9.35680000e-04\n",
      " 9.98613954e-01 9.41060007e-01 9.81894314e-01 9.98312473e-01\n",
      " 9.53181386e-01 9.99927044e-01 9.99979377e-01 9.99921560e-01\n",
      " 9.99948025e-01 7.98194408e-01 9.86521482e-01 9.91745412e-01\n",
      " 9.99890208e-01 9.99969363e-01 9.94165242e-01 8.40771437e-01\n",
      " 9.99964237e-01 9.99602497e-01 9.99625921e-01 9.99994040e-01\n",
      " 9.99989748e-01 9.99286950e-01 9.99742091e-01 1.18025184e-01\n",
      " 5.42522967e-01 9.99217510e-01 9.83762503e-01 8.55652928e-01\n",
      " 5.19049585e-01 8.97429764e-01 9.99745548e-01 9.01403904e-01\n",
      " 9.65668738e-01 9.99999881e-01 9.96533990e-01 9.99977589e-01\n",
      " 5.22258997e-01 6.46090269e-01 8.16385686e-01 9.99951601e-01\n",
      " 9.10617471e-01 9.98989522e-01 9.46761202e-03 9.84481215e-01\n",
      " 8.72205734e-01 9.83015597e-01 9.99964476e-01 5.33417575e-02\n",
      " 1.07986711e-01 9.90662932e-01 6.44140959e-01 1.97045505e-01\n",
      " 9.94483531e-01 9.99186456e-01 8.75719309e-01 4.79482085e-01\n",
      " 1.22997195e-01 5.93779445e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "Train Epoch: 329 [0/54 (0%)]\tTrain Loss: 0.001917\n",
      "Train Epoch: 329 [8/54 (15%)]\tTrain Loss: 0.015339\n",
      "Train Epoch: 329 [16/54 (30%)]\tTrain Loss: 0.007503\n",
      "Train Epoch: 329 [24/54 (44%)]\tTrain Loss: 0.007412\n",
      "Train Epoch: 329 [32/54 (59%)]\tTrain Loss: 0.001521\n",
      "Train Epoch: 329 [40/54 (74%)]\tTrain Loss: 0.027621\n",
      "Train Epoch: 329 [48/54 (89%)]\tTrain Loss: 0.007808\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.38187355e-03 9.47281539e-01 5.94675422e-01 9.21494842e-01\n",
      " 7.79280424e-01 2.56921770e-03 4.93099600e-01 9.87913787e-01\n",
      " 3.99111398e-02 8.81813586e-01 4.04019862e-01 8.32973793e-03\n",
      " 1.28926495e-02 5.67199383e-03 6.70603156e-01 1.90440356e-03\n",
      " 4.95994324e-03 3.22267562e-01 1.38585763e-02 2.03442480e-02\n",
      " 1.83080882e-02 9.76671934e-01 9.92554605e-01 9.98425007e-01\n",
      " 1.74534097e-01 9.99893785e-01 9.99996543e-01 5.23969769e-01\n",
      " 5.82811892e-01 5.41915536e-01 9.90739346e-01 9.97879028e-01\n",
      " 6.60107672e-01 1.65929541e-03 6.14339719e-03 8.29461753e-01\n",
      " 3.93849462e-02 9.71168280e-01 1.07692398e-01 3.35479230e-01\n",
      " 4.72854003e-02 1.66157678e-01 2.16216967e-03 3.22838068e-01\n",
      " 1.59608215e-01 9.90769546e-03 9.95488107e-01 9.88210678e-01\n",
      " 9.99999762e-01 6.04393423e-01 9.99928951e-01 4.39469032e-02\n",
      " 6.19835046e-04 1.05033137e-01 1.43376160e-02 2.85204668e-02\n",
      " 9.59675491e-01 1.57372028e-01 4.21119362e-01 3.89256922e-04\n",
      " 9.99336541e-01 9.31604147e-01 9.63713467e-01 9.95686054e-01\n",
      " 3.92533630e-01 9.99954104e-01 9.99996424e-01 9.99966860e-01\n",
      " 9.99997139e-01 7.37618923e-01 9.76623714e-01 9.88952219e-01\n",
      " 9.99776781e-01 9.99977946e-01 9.95325446e-01 3.66481960e-01\n",
      " 9.99930143e-01 9.99837518e-01 9.99149203e-01 9.99996781e-01\n",
      " 1.00000000e+00 9.99611437e-01 9.98367488e-01 7.41981715e-03\n",
      " 3.96077812e-01 9.98985946e-01 9.27938223e-01 5.93222678e-01\n",
      " 6.10507391e-02 9.65130925e-01 9.96791899e-01 9.61491346e-01\n",
      " 9.95385706e-01 9.99999404e-01 9.91205990e-01 9.99988198e-01\n",
      " 7.02634528e-02 8.41743410e-01 9.32346761e-01 9.99978900e-01\n",
      " 6.90142632e-01 9.99357641e-01 7.76595436e-03 9.96972561e-01\n",
      " 9.49150681e-01 9.77269769e-01 9.99932289e-01 2.58032922e-02\n",
      " 8.00153837e-02 9.98962164e-01 4.81497020e-01 3.82935375e-01\n",
      " 9.99563277e-01 9.94063079e-01 9.15140033e-01 2.86154985e-01\n",
      " 2.64236152e-01 6.19977295e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 330 [0/54 (0%)]\tTrain Loss: 0.000961\n",
      "Train Epoch: 330 [8/54 (15%)]\tTrain Loss: 0.003449\n",
      "Train Epoch: 330 [16/54 (30%)]\tTrain Loss: 0.001127\n",
      "Train Epoch: 330 [24/54 (44%)]\tTrain Loss: 0.097302\n",
      "Train Epoch: 330 [32/54 (59%)]\tTrain Loss: 0.004173\n",
      "Train Epoch: 330 [40/54 (74%)]\tTrain Loss: 0.000836\n",
      "Train Epoch: 330 [48/54 (89%)]\tTrain Loss: 0.001839\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.96059998e-02 6.03518784e-02 5.87703645e-01 9.11937773e-01\n",
      " 7.42458284e-01 5.46322903e-03 4.93604690e-01 9.99305010e-01\n",
      " 8.51486400e-02 1.05617233e-01 1.08110622e-01 3.34986262e-02\n",
      " 1.21244630e-02 2.52275709e-02 9.74199772e-01 1.68697315e-03\n",
      " 4.73732408e-03 1.04649467e-02 7.46718496e-02 4.60328571e-02\n",
      " 1.20531232e-03 9.64441061e-01 9.96805191e-01 9.99810278e-01\n",
      " 2.78715547e-02 9.99981761e-01 9.99998093e-01 4.39144492e-01\n",
      " 8.04524481e-01 5.95771968e-01 9.68649924e-01 9.97769117e-01\n",
      " 9.66958880e-01 2.05557284e-04 4.42106597e-04 7.63333514e-02\n",
      " 8.63463711e-03 9.98700976e-01 4.63038636e-03 2.04129949e-01\n",
      " 1.69748683e-02 1.21943848e-02 2.24884646e-03 2.77532279e-01\n",
      " 3.10944021e-01 2.70207580e-02 9.98197377e-01 9.54845965e-01\n",
      " 9.99999881e-01 9.44035947e-01 9.99967813e-01 1.30307302e-01\n",
      " 1.49664180e-02 2.14113235e-01 2.93751201e-03 1.72263905e-02\n",
      " 9.96678472e-01 3.72087695e-02 1.08387973e-02 8.43492569e-04\n",
      " 9.97683167e-01 9.44932699e-01 9.74169195e-01 9.95967507e-01\n",
      " 8.91934752e-01 9.99708712e-01 9.99670506e-01 9.99732196e-01\n",
      " 9.99999523e-01 9.87429082e-01 9.83467281e-01 9.88344908e-01\n",
      " 9.99925017e-01 9.99882698e-01 9.99108374e-01 9.41234946e-01\n",
      " 5.55533397e-10 6.16564799e-10 9.99892354e-01 9.99958634e-01\n",
      " 9.99986887e-01 9.99565184e-01 9.98068750e-01 9.87662151e-02\n",
      " 7.65574872e-01 9.99201477e-01 9.85834539e-01 8.66903186e-01\n",
      " 1.88707411e-02 7.11686671e-01 9.98246670e-01 7.45637119e-01\n",
      " 9.95911717e-01 1.00000000e+00 9.90640759e-01 9.99915123e-01\n",
      " 1.22134462e-02 3.94042969e-01 7.18478262e-01 9.94800687e-01\n",
      " 5.23735657e-02 9.99917388e-01 2.42776833e-02 9.99611199e-01\n",
      " 9.81084526e-01 9.58102167e-01 9.99803603e-01 1.22355791e-02\n",
      " 4.15854575e-03 8.68410289e-01 4.34854180e-01 1.85522139e-02\n",
      " 7.61835217e-01 2.94775486e-01 6.10115886e-01 2.83271402e-01\n",
      " 2.25373171e-03 1.35370460e-03]\n",
      "predict [0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "vote_pred [0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 38 FN= 13 FP= 22\n",
      "TP+FP 67\n",
      "precision 0.6716417910447762\n",
      "recall 0.7758620689655172\n",
      "F1 0.7200000000000001\n",
      "acc 0.7033898305084746\n",
      "AUCp 0.7045977011494253\n",
      "AUC 0.782183908045977\n",
      "\n",
      " The epoch is 330, average recall: 0.7759, average precision: 0.6716,average F1: 0.7200, average accuracy: 0.7034, average AUC: 0.7822\n",
      "Train Epoch: 331 [0/54 (0%)]\tTrain Loss: 0.000247\n",
      "Train Epoch: 331 [8/54 (15%)]\tTrain Loss: 0.009699\n",
      "Train Epoch: 331 [16/54 (30%)]\tTrain Loss: 0.000379\n",
      "Train Epoch: 331 [24/54 (44%)]\tTrain Loss: 0.004575\n",
      "Train Epoch: 331 [32/54 (59%)]\tTrain Loss: 0.001242\n",
      "Train Epoch: 331 [40/54 (74%)]\tTrain Loss: 0.028373\n",
      "Train Epoch: 331 [48/54 (89%)]\tTrain Loss: 0.000145\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.96572717e-04 2.00364336e-01 2.31432185e-01 5.37799776e-01\n",
      " 1.42252579e-01 2.38628825e-04 4.33716208e-01 9.97135997e-01\n",
      " 7.51251401e-03 2.87282079e-01 1.32829584e-02 6.81541220e-04\n",
      " 4.43305871e-05 8.25658615e-04 8.75198320e-02 3.72908326e-05\n",
      " 3.91861715e-04 3.83703634e-02 2.66004086e-01 5.65531701e-02\n",
      " 1.11464367e-04 9.45092320e-01 9.96724069e-01 9.98936355e-01\n",
      " 3.95538472e-03 9.99984622e-01 9.99991417e-01 4.61287856e-01\n",
      " 9.02801752e-01 2.55320281e-01 1.60213619e-01 9.97849822e-01\n",
      " 5.29749431e-02 2.24559130e-06 8.15358362e-06 9.18341894e-03\n",
      " 2.41245399e-03 9.97548282e-01 8.18920147e-04 6.94915801e-02\n",
      " 4.15487215e-03 5.59849571e-03 2.99704057e-04 2.62535866e-02\n",
      " 2.98564024e-02 7.84526300e-03 9.01508629e-01 7.05981925e-02\n",
      " 9.99991655e-01 9.71503377e-01 9.99797881e-01 1.29044056e-03\n",
      " 2.06579585e-04 1.13774464e-02 4.24218364e-03 1.34304352e-03\n",
      " 9.93599296e-01 1.75581593e-02 3.50060727e-04 2.14523934e-05\n",
      " 9.58627284e-01 9.61344659e-01 9.72745836e-01 9.95414972e-01\n",
      " 1.99337453e-01 9.49633658e-01 9.97778118e-01 9.35404062e-01\n",
      " 9.99999642e-01 9.97932792e-01 9.64201152e-01 9.87769663e-01\n",
      " 9.99991894e-01 9.98660803e-01 9.95266438e-01 9.45567012e-01\n",
      " 9.62430818e-07 4.96926941e-06 9.99689460e-01 9.99370396e-01\n",
      " 9.99992728e-01 1.00000000e+00 9.99987960e-01 8.15894548e-03\n",
      " 2.42037341e-01 9.96929586e-01 9.40254688e-01 8.13583732e-01\n",
      " 4.04013619e-02 9.91541326e-01 9.99999881e-01 4.89174277e-01\n",
      " 9.86735761e-01 1.00000000e+00 9.99847651e-01 9.99996305e-01\n",
      " 1.84102263e-03 1.47503167e-01 3.96609068e-01 9.99843359e-01\n",
      " 7.96847232e-03 9.99766886e-01 9.80589655e-04 9.99431670e-01\n",
      " 9.82294559e-01 9.99765933e-01 9.99999881e-01 3.06111667e-03\n",
      " 7.61501433e-04 9.18684959e-01 7.45063305e-01 6.02129437e-02\n",
      " 9.87590551e-01 6.15962744e-01 9.59948301e-01 2.37076506e-01\n",
      " 2.21921742e-04 2.03132123e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "Train Epoch: 332 [0/54 (0%)]\tTrain Loss: 0.000528\n",
      "Train Epoch: 332 [8/54 (15%)]\tTrain Loss: 0.000653\n",
      "Train Epoch: 332 [16/54 (30%)]\tTrain Loss: 0.002405\n",
      "Train Epoch: 332 [24/54 (44%)]\tTrain Loss: 0.037123\n",
      "Train Epoch: 332 [32/54 (59%)]\tTrain Loss: 0.000389\n",
      "Train Epoch: 332 [40/54 (74%)]\tTrain Loss: 0.003598\n",
      "Train Epoch: 332 [48/54 (89%)]\tTrain Loss: 0.016978\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.68037960e-03 1.30345330e-01 1.88149605e-02 8.18598986e-01\n",
      " 5.32557145e-02 1.61804748e-03 1.97880864e-01 9.91207838e-01\n",
      " 1.39632048e-02 9.13452804e-01 5.20316720e-01 1.01565838e-01\n",
      " 7.41474377e-03 3.19111906e-03 1.05253480e-01 1.15194402e-04\n",
      " 5.71249810e-04 1.84193015e-01 8.35582733e-01 6.39382079e-02\n",
      " 2.41679559e-03 9.90856290e-01 9.99695897e-01 9.99995589e-01\n",
      " 1.29880952e-02 1.00000000e+00 9.99999881e-01 6.23897433e-01\n",
      " 4.58639860e-01 3.63534719e-01 2.13639393e-01 9.79622006e-01\n",
      " 8.21173489e-01 2.58918677e-04 3.53520270e-04 2.13523153e-02\n",
      " 5.87735651e-03 9.97301936e-01 2.08282610e-03 6.65950999e-02\n",
      " 2.42284052e-02 6.21275185e-03 6.74133596e-04 1.76564362e-02\n",
      " 1.68948263e-01 3.50448594e-04 9.74519372e-01 1.91879887e-02\n",
      " 9.99993682e-01 8.33918810e-01 9.88740504e-01 2.94220261e-03\n",
      " 3.23640741e-02 1.97092630e-03 1.92882284e-03 2.12800363e-03\n",
      " 8.19128335e-01 4.81385132e-03 2.40737423e-02 5.78772975e-03\n",
      " 9.91587162e-01 9.39978719e-01 9.91132200e-01 9.97507572e-01\n",
      " 7.99389601e-01 9.98357117e-01 9.99990463e-01 2.43572891e-02\n",
      " 1.67522337e-02 6.96500778e-01 6.25446737e-01 7.96848834e-01\n",
      " 9.99999762e-01 9.99892473e-01 9.99936342e-01 9.01141286e-01\n",
      " 5.34550399e-12 5.64779725e-07 9.99228954e-01 9.99992251e-01\n",
      " 1.00000000e+00 9.99519110e-01 9.99989510e-01 8.65608156e-02\n",
      " 9.45266008e-01 9.73879457e-01 9.61474359e-01 8.24531615e-01\n",
      " 9.10435542e-02 6.14367843e-01 9.99993324e-01 2.15787321e-01\n",
      " 6.66928709e-01 1.00000000e+00 9.99995351e-01 9.99999881e-01\n",
      " 6.02372503e-03 6.57624304e-01 5.07052541e-01 9.99502063e-01\n",
      " 1.17624626e-02 9.98096526e-01 5.21384040e-03 9.98765707e-01\n",
      " 9.97446895e-01 9.34426069e-01 9.99985814e-01 2.53514759e-03\n",
      " 8.05871619e-04 7.26866007e-01 2.92564789e-03 8.07020522e-04\n",
      " 9.87500131e-01 8.68348539e-01 9.49756563e-01 1.62501231e-01\n",
      " 2.23286197e-01 6.39988482e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 333 [0/54 (0%)]\tTrain Loss: 0.006604\n",
      "Train Epoch: 333 [8/54 (15%)]\tTrain Loss: 0.000236\n",
      "Train Epoch: 333 [16/54 (30%)]\tTrain Loss: 0.012306\n",
      "Train Epoch: 333 [24/54 (44%)]\tTrain Loss: 0.004391\n",
      "Train Epoch: 333 [32/54 (59%)]\tTrain Loss: 0.016080\n",
      "Train Epoch: 333 [40/54 (74%)]\tTrain Loss: 0.062192\n",
      "Train Epoch: 333 [48/54 (89%)]\tTrain Loss: 0.000411\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.61913958e-05 9.65775132e-01 1.59006149e-01 5.05629122e-01\n",
      " 7.48203718e-04 4.05940300e-05 4.18189377e-01 6.82729855e-02\n",
      " 2.13308800e-02 1.04403958e-01 4.97108065e-02 1.75015637e-04\n",
      " 6.83174061e-04 1.84255391e-01 3.26752603e-01 1.55648217e-04\n",
      " 1.59279443e-05 4.31385785e-01 4.36348289e-01 3.72306071e-02\n",
      " 1.02728268e-03 9.95614529e-01 9.99534130e-01 9.99785841e-01\n",
      " 5.51894382e-02 9.99989390e-01 9.99981403e-01 7.90007055e-01\n",
      " 4.71338749e-01 8.40980232e-01 9.15607691e-01 9.85581338e-01\n",
      " 1.38371587e-01 8.18008914e-07 2.35765674e-06 6.73134997e-03\n",
      " 1.85675651e-03 9.99526739e-01 6.82339864e-03 7.85297677e-02\n",
      " 2.07236875e-02 1.53071294e-02 4.87437355e-04 7.67986476e-02\n",
      " 5.51112115e-01 5.37229003e-04 6.02277756e-01 9.90965888e-02\n",
      " 9.99816358e-01 9.74798858e-01 9.95426476e-01 1.10040162e-06\n",
      " 2.03117868e-03 4.22779194e-05 2.86023598e-04 2.42541588e-04\n",
      " 7.08513498e-01 2.18100147e-03 1.98403560e-03 2.80227017e-04\n",
      " 9.90988910e-01 9.27425086e-01 9.82067585e-01 9.92186785e-01\n",
      " 1.08126942e-02 9.97343838e-01 9.99813139e-01 9.99989152e-01\n",
      " 9.99994278e-01 7.21492469e-01 9.17783499e-01 8.77004325e-01\n",
      " 9.99990821e-01 9.99725044e-01 9.99920130e-01 9.91009831e-01\n",
      " 9.99999046e-01 9.99930143e-01 9.98162568e-01 9.99555171e-01\n",
      " 9.99986529e-01 9.99998808e-01 9.99995470e-01 2.50969023e-01\n",
      " 6.52541995e-01 9.95150387e-01 9.93684828e-01 9.75994945e-01\n",
      " 1.10538125e-01 9.99936700e-01 9.99984860e-01 6.27436116e-02\n",
      " 5.87541223e-01 9.99997497e-01 9.95909572e-01 9.99923825e-01\n",
      " 2.02997413e-04 4.25041765e-01 2.01886430e-01 9.99823630e-01\n",
      " 6.28366414e-03 9.94771779e-01 1.19073270e-02 7.75964975e-01\n",
      " 6.46268964e-01 9.95403528e-01 9.99937057e-01 1.81146786e-02\n",
      " 1.35651464e-02 9.98017430e-01 5.76189067e-03 1.41279921e-01\n",
      " 7.26918697e-01 9.94447947e-01 9.67545271e-01 9.16952491e-02\n",
      " 9.35065389e-01 7.38814399e-02]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0.]\n",
      "Train Epoch: 334 [0/54 (0%)]\tTrain Loss: 0.023588\n",
      "Train Epoch: 334 [8/54 (15%)]\tTrain Loss: 0.008365\n",
      "Train Epoch: 334 [16/54 (30%)]\tTrain Loss: 0.006515\n",
      "Train Epoch: 334 [24/54 (44%)]\tTrain Loss: 0.008173\n",
      "Train Epoch: 334 [32/54 (59%)]\tTrain Loss: 0.001952\n",
      "Train Epoch: 334 [40/54 (74%)]\tTrain Loss: 0.000595\n",
      "Train Epoch: 334 [48/54 (89%)]\tTrain Loss: 0.007393\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.14134718e-03 9.81570005e-01 8.17417145e-01 9.97882783e-01\n",
      " 3.73119116e-01 4.45839623e-03 9.82232213e-01 9.91987705e-01\n",
      " 3.72644179e-02 9.16681647e-01 7.78882027e-01 3.52656515e-03\n",
      " 4.50163111e-02 4.97671068e-02 7.46653855e-01 6.38087019e-02\n",
      " 3.05536250e-03 8.82064581e-01 6.85625970e-01 4.45841134e-01\n",
      " 4.33467841e-03 9.97156739e-01 9.99973178e-01 9.99875426e-01\n",
      " 1.51756659e-01 9.99999404e-01 9.99859333e-01 9.97991920e-01\n",
      " 9.84904945e-01 9.94774520e-01 9.95653629e-01 9.99840856e-01\n",
      " 9.79695201e-01 1.72870641e-03 5.89910802e-03 5.89582622e-01\n",
      " 7.53022730e-03 9.99986172e-01 2.51045883e-01 4.25413489e-01\n",
      " 5.33876605e-02 7.90011361e-02 2.18029879e-02 9.56916034e-01\n",
      " 8.73768926e-01 1.89477637e-01 9.99649048e-01 5.97230256e-01\n",
      " 9.99993324e-01 9.57078040e-01 9.99819458e-01 5.97307982e-04\n",
      " 6.95931539e-02 5.59392810e-01 1.47529086e-02 5.19597828e-01\n",
      " 9.99503970e-01 6.65745959e-02 1.55946806e-01 2.59299781e-02\n",
      " 9.99961615e-01 9.97372866e-01 9.99675393e-01 9.99616504e-01\n",
      " 9.90952611e-01 9.99810159e-01 9.99997973e-01 9.99990702e-01\n",
      " 9.99998927e-01 9.97710347e-01 9.85208035e-01 9.79636192e-01\n",
      " 1.00000000e+00 9.99973536e-01 9.99953032e-01 9.99999523e-01\n",
      " 9.99999762e-01 9.99981761e-01 9.99955416e-01 9.99999762e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99996424e-01 1.60127535e-01\n",
      " 7.68403828e-01 9.99427438e-01 9.99853849e-01 9.99907255e-01\n",
      " 2.53126115e-01 9.99365389e-01 9.99745309e-01 9.89650369e-01\n",
      " 9.99508858e-01 1.00000000e+00 9.99288559e-01 9.99859452e-01\n",
      " 2.49318436e-01 6.41035974e-01 2.62709141e-01 9.99999166e-01\n",
      " 1.03820562e-02 9.99944448e-01 5.89157417e-02 9.99998927e-01\n",
      " 9.99668956e-01 9.99959350e-01 1.00000000e+00 2.04454120e-02\n",
      " 9.13040340e-03 9.99220967e-01 1.09169260e-01 3.39553624e-01\n",
      " 9.98490095e-01 9.99043405e-01 9.55231071e-01 5.42377591e-01\n",
      " 5.34229815e-01 6.87547207e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 335 [0/54 (0%)]\tTrain Loss: 0.017660\n",
      "Train Epoch: 335 [8/54 (15%)]\tTrain Loss: 0.005317\n",
      "Train Epoch: 335 [16/54 (30%)]\tTrain Loss: 0.009296\n",
      "Train Epoch: 335 [24/54 (44%)]\tTrain Loss: 0.002155\n",
      "Train Epoch: 335 [32/54 (59%)]\tTrain Loss: 0.006006\n",
      "Train Epoch: 335 [40/54 (74%)]\tTrain Loss: 0.000833\n",
      "Train Epoch: 335 [48/54 (89%)]\tTrain Loss: 0.002154\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.88394263e-03 9.81337786e-01 1.50018007e-01 9.23160315e-01\n",
      " 1.10708043e-01 2.32764927e-04 7.04728961e-01 9.71920609e-01\n",
      " 2.42661498e-03 2.84136951e-01 5.23701727e-01 2.16382359e-05\n",
      " 5.03389947e-02 2.24965423e-01 9.79164362e-01 2.44653621e-03\n",
      " 9.46034095e-04 3.97242069e-01 9.61458683e-01 2.57416200e-02\n",
      " 8.68989620e-03 9.99570787e-01 9.99999881e-01 9.99998808e-01\n",
      " 2.27412567e-01 1.00000000e+00 9.99998569e-01 9.95451152e-01\n",
      " 8.63373339e-01 5.16956389e-01 8.02942455e-01 9.99269307e-01\n",
      " 9.89344418e-01 9.07377489e-06 3.39670769e-05 2.40038577e-02\n",
      " 2.50251144e-02 9.99999881e-01 9.27687436e-03 9.29529130e-01\n",
      " 7.12408483e-01 4.88924265e-01 1.85794302e-03 5.67469895e-01\n",
      " 8.10651124e-01 2.34592482e-02 9.95969653e-01 5.62324166e-01\n",
      " 9.99996662e-01 9.83677268e-01 9.91198599e-01 1.92383002e-03\n",
      " 1.96582004e-02 1.23736940e-01 5.17103150e-02 5.50357625e-03\n",
      " 9.81135309e-01 2.67600128e-03 3.50890085e-02 9.92977293e-04\n",
      " 9.99696493e-01 9.35622275e-01 9.97930050e-01 9.98652697e-01\n",
      " 9.59985673e-01 9.99998212e-01 9.99993920e-01 1.00000000e+00\n",
      " 1.00000000e+00 7.16598451e-01 9.40720916e-01 9.81569052e-01\n",
      " 9.99998689e-01 9.99843717e-01 9.99436319e-01 9.90054727e-01\n",
      " 9.99999762e-01 9.99998689e-01 9.99980688e-01 9.99999881e-01\n",
      " 9.99999642e-01 9.99858499e-01 9.99840140e-01 1.39405876e-01\n",
      " 9.19923723e-01 9.99579370e-01 9.98235464e-01 9.97724473e-01\n",
      " 1.61720127e-01 9.99998093e-01 9.99997735e-01 6.10156059e-01\n",
      " 8.53355050e-01 1.00000000e+00 9.99442160e-01 9.99927998e-01\n",
      " 6.28435090e-02 5.51761627e-01 4.18531269e-01 9.99999046e-01\n",
      " 1.36414282e-02 9.99981046e-01 2.91255675e-02 9.99755800e-01\n",
      " 9.96843815e-01 9.99532461e-01 9.99999642e-01 5.14077162e-03\n",
      " 3.76275815e-02 9.99971271e-01 9.94560309e-03 3.86857922e-04\n",
      " 7.46499360e-01 8.58691692e-01 7.33554780e-01 2.66710520e-01\n",
      " 6.59688056e-01 5.69938064e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 336 [0/54 (0%)]\tTrain Loss: 0.015984\n",
      "Train Epoch: 336 [8/54 (15%)]\tTrain Loss: 0.000489\n",
      "Train Epoch: 336 [16/54 (30%)]\tTrain Loss: 0.000415\n",
      "Train Epoch: 336 [24/54 (44%)]\tTrain Loss: 0.001539\n",
      "Train Epoch: 336 [32/54 (59%)]\tTrain Loss: 0.001338\n",
      "Train Epoch: 336 [40/54 (74%)]\tTrain Loss: 0.000330\n",
      "Train Epoch: 336 [48/54 (89%)]\tTrain Loss: 0.003991\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.11782039e-03 3.02683175e-01 2.16856861e-04 8.33697692e-02\n",
      " 8.65470991e-03 1.41587152e-04 7.19994423e-05 1.73816040e-01\n",
      " 3.69886821e-03 1.14050105e-01 7.66066238e-02 5.05151926e-04\n",
      " 2.08795276e-02 4.21598743e-05 2.52997316e-02 3.25152564e-06\n",
      " 1.19465012e-05 1.33072108e-01 9.99630332e-01 8.66413057e-01\n",
      " 4.99838442e-02 9.96073961e-01 9.99997854e-01 9.99885082e-01\n",
      " 1.56956002e-01 1.00000000e+00 9.99968886e-01 9.99590456e-01\n",
      " 6.58791661e-01 5.19165158e-01 7.74889767e-01 9.98167872e-01\n",
      " 9.87050176e-01 3.70823436e-05 9.96223662e-06 9.01120424e-04\n",
      " 3.07782385e-02 9.99993205e-01 1.30150244e-02 1.89736530e-01\n",
      " 6.21790998e-02 2.00999454e-02 3.90013563e-03 3.20938160e-03\n",
      " 4.16857332e-01 5.15843108e-02 9.67594087e-01 2.58767605e-01\n",
      " 9.99971032e-01 9.93343472e-01 9.99266684e-01 6.79572531e-06\n",
      " 2.92846188e-03 1.31516475e-02 2.65789665e-02 7.31038512e-04\n",
      " 9.94030297e-01 6.44608284e-04 6.88726269e-03 6.12542954e-06\n",
      " 9.99282181e-01 8.99003029e-01 9.95962083e-01 9.99678493e-01\n",
      " 8.80893588e-01 4.67360973e-01 9.97089863e-01 9.99999762e-01\n",
      " 9.99995232e-01 9.80738103e-01 8.84039164e-01 8.95899892e-01\n",
      " 9.99661446e-01 9.97163594e-01 9.95282233e-01 9.99974966e-01\n",
      " 9.99967933e-01 9.99769509e-01 9.98625755e-01 9.99969125e-01\n",
      " 9.99115169e-01 9.97865379e-01 9.97598469e-01 5.31713247e-01\n",
      " 9.64350998e-01 9.99993205e-01 9.98278737e-01 9.88867700e-01\n",
      " 1.63804460e-02 9.99945045e-01 9.99996901e-01 2.50552297e-02\n",
      " 8.55392218e-01 1.00000000e+00 9.99996901e-01 9.99983191e-01\n",
      " 5.24365865e-02 1.63010955e-01 3.93334687e-01 9.99859214e-01\n",
      " 2.40054745e-02 9.99862790e-01 6.51442446e-03 9.98578310e-01\n",
      " 9.99463737e-01 9.91063833e-01 9.99904275e-01 3.89920059e-03\n",
      " 5.57939103e-03 9.98998821e-01 1.75657291e-02 1.63617970e-05\n",
      " 1.15317196e-01 9.99787629e-01 9.96370912e-01 4.04407531e-01\n",
      " 7.97005415e-01 9.10290301e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 337 [0/54 (0%)]\tTrain Loss: 0.000532\n",
      "Train Epoch: 337 [8/54 (15%)]\tTrain Loss: 0.021705\n",
      "Train Epoch: 337 [16/54 (30%)]\tTrain Loss: 0.004492\n",
      "Train Epoch: 337 [24/54 (44%)]\tTrain Loss: 0.085617\n",
      "Train Epoch: 337 [32/54 (59%)]\tTrain Loss: 0.062133\n",
      "Train Epoch: 337 [40/54 (74%)]\tTrain Loss: 0.046167\n",
      "Train Epoch: 337 [48/54 (89%)]\tTrain Loss: 0.008329\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.66611899e-05 9.09766968e-05 1.23089239e-06 1.69898584e-01\n",
      " 3.61208200e-01 2.38908944e-03 1.85761073e-05 8.82254779e-01\n",
      " 1.96428075e-02 6.83546603e-01 8.14585853e-03 1.37886867e-01\n",
      " 3.40857096e-02 3.05407702e-05 1.53705548e-03 4.00348421e-04\n",
      " 4.92441282e-03 1.74448621e-02 2.33546626e-02 3.59632969e-02\n",
      " 4.40823380e-03 9.00854170e-01 9.67164755e-01 9.78819132e-01\n",
      " 1.42812446e-01 9.98206735e-01 9.99856472e-01 2.45974943e-01\n",
      " 4.18256177e-03 1.19476870e-03 1.75343473e-02 1.84296388e-02\n",
      " 2.15003803e-01 1.03555499e-02 1.77370803e-03 2.21433565e-02\n",
      " 4.04328154e-03 8.26359212e-01 1.66165859e-01 8.63484573e-03\n",
      " 1.09669976e-02 1.36495905e-03 1.94926783e-02 3.90300830e-03\n",
      " 1.13670230e-02 3.51312308e-04 5.52854061e-01 7.90537614e-03\n",
      " 9.99962091e-01 9.34887290e-01 9.99436080e-01 2.19305325e-02\n",
      " 1.44395912e-02 1.35994665e-02 8.25392827e-03 1.79868401e-03\n",
      " 6.91302478e-01 6.31132745e-04 6.23046532e-02 2.14355402e-02\n",
      " 9.76577103e-01 9.09917414e-01 9.50038135e-01 6.05578005e-01\n",
      " 9.62288558e-01 9.75313723e-01 9.89407003e-01 1.27363220e-01\n",
      " 9.99754131e-01 3.93884152e-01 7.70798385e-01 1.96019456e-01\n",
      " 9.99954343e-01 9.98935759e-01 6.07638717e-01 7.73443580e-01\n",
      " 4.27869556e-04 2.27168947e-03 8.61920714e-01 9.84355092e-01\n",
      " 8.24160099e-01 6.33576155e-01 9.97436583e-01 4.00369614e-01\n",
      " 4.38146055e-01 9.84575748e-01 7.16967225e-01 2.90454119e-01\n",
      " 4.13123444e-02 7.80647159e-01 9.99005020e-01 6.23710394e-01\n",
      " 9.00173008e-01 9.99997735e-01 8.06649923e-01 9.87718463e-01\n",
      " 3.97696113e-03 6.04993165e-01 4.38113719e-01 9.34153438e-01\n",
      " 9.60021690e-02 9.62765872e-01 5.23314662e-02 7.38234341e-01\n",
      " 7.32990682e-01 1.35674417e-01 9.99722421e-01 1.65688172e-02\n",
      " 2.51336321e-02 9.44835395e-02 9.03803051e-01 6.33198116e-03\n",
      " 1.87178984e-01 7.60571480e-01 3.00310642e-01 1.71457246e-01\n",
      " 7.60712087e-01 3.55839193e-01]\n",
      "predict [0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 338 [0/54 (0%)]\tTrain Loss: 0.004216\n",
      "Train Epoch: 338 [8/54 (15%)]\tTrain Loss: 0.097110\n",
      "Train Epoch: 338 [16/54 (30%)]\tTrain Loss: 0.003996\n",
      "Train Epoch: 338 [24/54 (44%)]\tTrain Loss: 0.003276\n",
      "Train Epoch: 338 [32/54 (59%)]\tTrain Loss: 0.015455\n",
      "Train Epoch: 338 [40/54 (74%)]\tTrain Loss: 0.004160\n",
      "Train Epoch: 338 [48/54 (89%)]\tTrain Loss: 0.015667\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.83103276e-05 9.99319196e-01 8.36859465e-01 9.96907651e-01\n",
      " 9.92702603e-01 2.24921550e-03 9.39621985e-01 9.97442126e-01\n",
      " 4.05968457e-01 9.98503685e-01 7.14615524e-01 5.41755497e-01\n",
      " 3.85538250e-01 3.23871434e-01 9.60120678e-01 1.94044590e-01\n",
      " 9.86839771e-01 7.50974298e-01 6.48880899e-01 3.19918692e-01\n",
      " 1.63821995e-01 9.99929667e-01 9.99870896e-01 9.98858929e-01\n",
      " 9.49287653e-01 9.99979377e-01 9.99947906e-01 9.88342226e-01\n",
      " 9.60439920e-01 8.45868230e-01 9.23677087e-01 9.71710980e-01\n",
      " 1.47232652e-01 7.72298798e-02 2.20025778e-02 9.73009527e-01\n",
      " 3.58208120e-01 9.99727786e-01 9.81204629e-01 9.54859853e-01\n",
      " 4.63727474e-01 6.60255790e-01 1.43619627e-01 3.25367182e-01\n",
      " 5.34094453e-01 2.96832761e-03 9.91024733e-01 5.10356128e-01\n",
      " 9.99980092e-01 9.70152199e-01 9.98177052e-01 3.46931629e-02\n",
      " 5.43871224e-01 9.03775394e-01 2.61028646e-03 1.22869492e-01\n",
      " 9.96860504e-01 7.11761415e-01 9.63302553e-01 5.98953843e-01\n",
      " 9.99422908e-01 9.44782436e-01 9.91509080e-01 9.77586806e-01\n",
      " 9.98441160e-01 9.99998569e-01 9.99999642e-01 9.99998450e-01\n",
      " 1.00000000e+00 9.82077539e-01 8.81657243e-01 7.94920743e-01\n",
      " 9.99999762e-01 9.99968171e-01 7.89614618e-01 9.98882711e-01\n",
      " 9.99999881e-01 9.99997973e-01 9.99952912e-01 9.99975085e-01\n",
      " 9.99994159e-01 9.99055922e-01 9.99780118e-01 9.76265907e-01\n",
      " 9.99460518e-01 9.99062598e-01 9.88170147e-01 9.85272944e-01\n",
      " 8.43719602e-01 9.99999642e-01 9.99997258e-01 9.97059524e-01\n",
      " 9.95972216e-01 9.99999881e-01 9.99992251e-01 9.99998569e-01\n",
      " 1.71954438e-01 9.51744556e-01 9.18509722e-01 9.99999285e-01\n",
      " 6.29552662e-01 9.99993920e-01 4.49776910e-02 9.98832285e-01\n",
      " 9.99212384e-01 9.66306269e-01 1.00000000e+00 1.17070049e-01\n",
      " 4.79119986e-01 9.89964545e-01 8.12685490e-01 9.89662170e-01\n",
      " 9.99988437e-01 9.89889741e-01 9.58818495e-01 8.65452230e-01\n",
      " 9.99999046e-01 9.99996424e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 339 [0/54 (0%)]\tTrain Loss: 0.033951\n",
      "Train Epoch: 339 [8/54 (15%)]\tTrain Loss: 0.006822\n",
      "Train Epoch: 339 [16/54 (30%)]\tTrain Loss: 0.000693\n",
      "Train Epoch: 339 [24/54 (44%)]\tTrain Loss: 0.003238\n",
      "Train Epoch: 339 [32/54 (59%)]\tTrain Loss: 0.005485\n",
      "Train Epoch: 339 [40/54 (74%)]\tTrain Loss: 0.005857\n",
      "Train Epoch: 339 [48/54 (89%)]\tTrain Loss: 0.001365\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.73727793e-02 9.98310566e-01 4.54809785e-01 4.82282013e-01\n",
      " 2.13316336e-01 1.43698510e-02 7.91092396e-01 9.48815227e-01\n",
      " 1.55510649e-01 9.08187747e-01 2.23387733e-01 5.32444892e-03\n",
      " 7.67357973e-03 1.07350107e-02 2.99798042e-01 2.60922126e-03\n",
      " 5.84396310e-02 1.41065553e-01 8.91054749e-01 1.58229128e-01\n",
      " 1.60898771e-02 9.51612413e-01 9.99856591e-01 9.80894983e-01\n",
      " 6.12846799e-02 9.99286115e-01 9.97448087e-01 6.67900681e-01\n",
      " 8.38884652e-01 8.62587214e-01 9.97727692e-01 9.97766733e-01\n",
      " 9.41883564e-01 4.56504757e-04 2.46004522e-04 1.48205161e-01\n",
      " 3.90865132e-02 9.73866463e-01 5.89626729e-01 3.40856761e-01\n",
      " 2.52988130e-01 8.13807622e-02 1.49418544e-02 4.42181602e-02\n",
      " 6.60984278e-01 9.91230682e-02 9.99932766e-01 9.76723790e-01\n",
      " 9.99999762e-01 9.79819059e-01 9.99996662e-01 1.08683817e-02\n",
      " 1.45153347e-02 4.77364272e-01 4.95234039e-03 8.68791994e-03\n",
      " 9.94265378e-01 6.76249564e-01 1.62808895e-02 3.04229707e-02\n",
      " 9.99762356e-01 8.23202491e-01 9.96088505e-01 9.97017860e-01\n",
      " 9.96907771e-01 9.99869823e-01 9.99989271e-01 9.99999762e-01\n",
      " 9.99999762e-01 9.76141214e-01 9.46799219e-01 8.95675480e-01\n",
      " 9.99998927e-01 9.99862075e-01 9.93711948e-01 9.99935150e-01\n",
      " 1.00000000e+00 9.99999881e-01 9.99370754e-01 9.99995351e-01\n",
      " 9.99967456e-01 9.99722064e-01 9.99985695e-01 7.19879150e-01\n",
      " 9.39050436e-01 9.98754501e-01 9.91212666e-01 9.49524224e-01\n",
      " 1.81876600e-01 9.83992994e-01 9.99245405e-01 9.74810421e-01\n",
      " 7.56154060e-01 9.99998808e-01 9.99458611e-01 9.99926209e-01\n",
      " 3.30213457e-02 5.93968511e-01 9.40113127e-01 9.99988675e-01\n",
      " 1.23722583e-01 9.99938965e-01 3.00898869e-03 9.94857669e-01\n",
      " 9.99507308e-01 9.38331008e-01 1.00000000e+00 6.80081919e-02\n",
      " 3.14285420e-02 9.87093627e-01 1.16232686e-01 7.21628249e-01\n",
      " 9.90225852e-01 9.38975513e-01 5.71856916e-01 3.64540935e-01\n",
      " 9.99900222e-01 8.10137510e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 340 [0/54 (0%)]\tTrain Loss: 0.009702\n",
      "Train Epoch: 340 [8/54 (15%)]\tTrain Loss: 0.013312\n",
      "Train Epoch: 340 [16/54 (30%)]\tTrain Loss: 0.023048\n",
      "Train Epoch: 340 [24/54 (44%)]\tTrain Loss: 0.000346\n",
      "Train Epoch: 340 [32/54 (59%)]\tTrain Loss: 0.016020\n",
      "Train Epoch: 340 [40/54 (74%)]\tTrain Loss: 0.014823\n",
      "Train Epoch: 340 [48/54 (89%)]\tTrain Loss: 0.024375\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.80289425e-04 9.99790132e-01 9.36182916e-01 7.44361222e-01\n",
      " 1.24669574e-01 6.44795771e-04 7.61180699e-01 9.32162762e-01\n",
      " 5.87485470e-02 9.97566342e-01 5.39233446e-01 3.61417174e-01\n",
      " 4.18738574e-02 4.53494722e-03 5.02417207e-01 6.96230331e-04\n",
      " 1.55500779e-02 6.78745329e-01 3.73428404e-01 3.43870759e-01\n",
      " 2.54172739e-03 9.99052942e-01 9.99876380e-01 9.98023391e-01\n",
      " 5.06360352e-01 9.99979734e-01 9.99846578e-01 8.45830977e-01\n",
      " 8.84115875e-01 9.29925740e-01 9.88347352e-01 9.96066034e-01\n",
      " 1.19006626e-01 2.88098236e-05 1.82587057e-04 1.25459194e-01\n",
      " 1.30488174e-02 9.35945272e-01 3.85306448e-01 6.43060625e-01\n",
      " 1.98687658e-01 1.77896619e-01 3.89300436e-02 3.20374876e-01\n",
      " 5.43086350e-01 1.24847854e-03 9.88862634e-01 9.07282829e-02\n",
      " 9.94843006e-01 9.75519240e-01 9.95811582e-01 7.14794407e-03\n",
      " 1.29183577e-02 6.13198578e-01 2.58136857e-02 4.83182818e-03\n",
      " 9.99399424e-01 2.00008780e-01 6.32764637e-01 8.54413677e-03\n",
      " 9.99863744e-01 8.50276530e-01 9.86089230e-01 9.80808139e-01\n",
      " 8.60234439e-01 9.97628272e-01 9.97588754e-01 1.00000000e+00\n",
      " 9.99999762e-01 1.29614457e-01 7.13784039e-01 5.11666894e-01\n",
      " 9.99825656e-01 9.99621749e-01 9.80668843e-01 9.87250149e-01\n",
      " 9.99999523e-01 9.99996424e-01 9.92837489e-01 9.99998450e-01\n",
      " 9.99963880e-01 9.95722651e-01 9.99987125e-01 6.09574676e-01\n",
      " 8.93391728e-01 9.97177839e-01 9.88676786e-01 9.08518851e-01\n",
      " 1.36939213e-01 9.99866009e-01 9.97276366e-01 9.36327100e-01\n",
      " 8.07704926e-01 9.99999762e-01 9.98492599e-01 9.99911189e-01\n",
      " 1.90480389e-02 9.81644213e-01 9.89431381e-01 9.99666333e-01\n",
      " 2.70976186e-01 9.98829305e-01 1.09070107e-01 9.85385776e-01\n",
      " 9.32864308e-01 5.98116875e-01 9.99959111e-01 2.36839026e-01\n",
      " 4.56755273e-02 9.97573555e-01 1.94247559e-01 3.65609139e-01\n",
      " 9.99857068e-01 9.56156313e-01 6.55434251e-01 3.01829696e-01\n",
      " 9.99999404e-01 9.89703357e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 47 TN= 38 FN= 11 FP= 22\n",
      "TP+FP 69\n",
      "precision 0.6811594202898551\n",
      "recall 0.8103448275862069\n",
      "F1 0.7401574803149606\n",
      "acc 0.7203389830508474\n",
      "AUCp 0.7218390804597701\n",
      "AUC 0.7594827586206896\n",
      "\n",
      " The epoch is 340, average recall: 0.8103, average precision: 0.6812,average F1: 0.7402, average accuracy: 0.7203, average AUC: 0.7595\n",
      "Train Epoch: 341 [0/54 (0%)]\tTrain Loss: 0.002051\n",
      "Train Epoch: 341 [8/54 (15%)]\tTrain Loss: 0.000985\n",
      "Train Epoch: 341 [16/54 (30%)]\tTrain Loss: 0.003597\n",
      "Train Epoch: 341 [24/54 (44%)]\tTrain Loss: 0.004003\n",
      "Train Epoch: 341 [32/54 (59%)]\tTrain Loss: 0.024318\n",
      "Train Epoch: 341 [40/54 (74%)]\tTrain Loss: 0.008997\n",
      "Train Epoch: 341 [48/54 (89%)]\tTrain Loss: 0.001637\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.87794462e-05 9.94792879e-01 3.04083854e-01 6.68122172e-01\n",
      " 1.27414361e-01 6.95630093e-04 6.67011738e-01 8.41488957e-01\n",
      " 1.17706314e-01 9.22103584e-01 9.61903691e-01 4.22603041e-02\n",
      " 7.21852407e-02 3.02740019e-02 5.07892549e-01 4.59375465e-03\n",
      " 4.45298990e-03 1.82060257e-01 4.61292803e-01 2.53576398e-01\n",
      " 2.05397755e-02 9.98081326e-01 9.99991179e-01 9.98658061e-01\n",
      " 7.60662109e-02 9.99999404e-01 9.99523520e-01 9.95403886e-01\n",
      " 9.55066502e-01 9.96200740e-01 9.49547470e-01 9.95136678e-01\n",
      " 8.51737797e-01 2.00286228e-03 2.28083081e-04 8.50063749e-03\n",
      " 1.82852894e-02 9.42419946e-01 1.36224050e-02 4.15770352e-01\n",
      " 6.96911812e-02 1.13176210e-02 2.90653436e-03 7.77736604e-01\n",
      " 3.61096948e-01 7.11896864e-04 5.69842935e-01 7.70040415e-03\n",
      " 9.97907639e-01 9.80573118e-01 6.58933640e-01 7.09962053e-03\n",
      " 1.77958697e-01 2.92161942e-01 2.97166575e-02 1.79947242e-01\n",
      " 9.93271768e-01 9.57859516e-01 1.57687843e-01 2.90094186e-02\n",
      " 9.84773397e-01 4.30702627e-01 7.70437717e-01 8.75386477e-01\n",
      " 9.79413271e-01 9.99959469e-01 9.98635709e-01 9.99999642e-01\n",
      " 9.99992132e-01 2.31965557e-02 1.85556084e-01 1.83175743e-01\n",
      " 9.99992728e-01 9.94833827e-01 9.95657086e-01 6.54744387e-01\n",
      " 9.99991059e-01 9.99944806e-01 9.98325884e-01 9.99997258e-01\n",
      " 9.98873770e-01 9.99374807e-01 9.96099114e-01 1.30572811e-01\n",
      " 5.85113049e-01 9.55699980e-01 8.97194624e-01 4.88832057e-01\n",
      " 8.57458293e-01 9.99994397e-01 9.99907613e-01 8.13269198e-01\n",
      " 6.85308993e-01 1.00000000e+00 9.99772608e-01 9.99993563e-01\n",
      " 4.10726935e-01 2.58479923e-01 8.67487431e-01 9.99998212e-01\n",
      " 2.81250160e-02 9.81863737e-01 9.55914408e-02 9.87151623e-01\n",
      " 7.09486127e-01 8.28858495e-01 9.82203007e-01 3.08220863e-01\n",
      " 3.49036083e-02 9.97746170e-01 9.18248534e-01 1.79438040e-01\n",
      " 9.97848034e-01 9.99947786e-01 9.24248636e-01 4.84236404e-02\n",
      " 9.99451220e-01 9.94381130e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 342 [0/54 (0%)]\tTrain Loss: 0.009580\n",
      "Train Epoch: 342 [8/54 (15%)]\tTrain Loss: 0.009975\n",
      "Train Epoch: 342 [16/54 (30%)]\tTrain Loss: 0.054342\n",
      "Train Epoch: 342 [24/54 (44%)]\tTrain Loss: 0.003716\n",
      "Train Epoch: 342 [32/54 (59%)]\tTrain Loss: 0.018025\n",
      "Train Epoch: 342 [40/54 (74%)]\tTrain Loss: 0.003653\n",
      "Train Epoch: 342 [48/54 (89%)]\tTrain Loss: 0.009395\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.53272818e-02 9.99988198e-01 9.19912159e-01 9.74772573e-01\n",
      " 7.97526538e-01 5.55166155e-02 9.97020662e-01 9.95171487e-01\n",
      " 5.10923505e-01 8.00563574e-01 9.54411149e-01 3.10284714e-03\n",
      " 3.91092598e-01 6.17310405e-01 9.94442523e-01 1.31914705e-01\n",
      " 3.01789641e-01 5.18943250e-01 6.74804688e-01 8.32131088e-01\n",
      " 1.08287215e-01 9.99869347e-01 9.99997973e-01 9.97074604e-01\n",
      " 2.14987576e-01 9.99993205e-01 9.99948382e-01 8.66322875e-01\n",
      " 9.98489976e-01 9.99622226e-01 9.94765401e-01 9.99841452e-01\n",
      " 9.88015950e-01 5.31986542e-03 5.31541358e-04 4.37421083e-01\n",
      " 1.02414109e-01 9.98000085e-01 3.87030452e-01 9.84203339e-01\n",
      " 9.17903602e-01 5.83585560e-01 1.63076110e-02 9.69332039e-01\n",
      " 7.44283497e-01 4.96395469e-01 9.71185267e-01 5.46626747e-01\n",
      " 1.00000000e+00 9.89953876e-01 9.99974251e-01 2.40922924e-02\n",
      " 7.28662670e-01 9.56487954e-01 2.46048689e-01 1.91026494e-01\n",
      " 9.99672413e-01 8.25160980e-01 8.81665051e-02 6.54634893e-01\n",
      " 9.99820530e-01 9.92172360e-01 9.99413013e-01 9.99602020e-01\n",
      " 9.99330401e-01 9.99999881e-01 9.99978542e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.97591257e-01 9.47858870e-01 9.62893724e-01\n",
      " 9.99999762e-01 9.99999404e-01 9.99395609e-01 9.97227490e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99916553e-01 9.99999762e-01\n",
      " 1.00000000e+00 9.99975085e-01 9.99992251e-01 3.80698383e-01\n",
      " 9.44103837e-01 9.99408841e-01 9.98974442e-01 9.93226349e-01\n",
      " 5.68879485e-01 9.99999404e-01 9.99581397e-01 9.99718249e-01\n",
      " 9.92302060e-01 9.99999881e-01 9.99587834e-01 9.99987721e-01\n",
      " 9.71969590e-02 3.25142026e-01 9.07246113e-01 9.99999881e-01\n",
      " 1.21037543e-01 9.99605358e-01 2.04137504e-01 9.99469817e-01\n",
      " 9.96350527e-01 9.99526024e-01 9.99999523e-01 6.95460975e-01\n",
      " 4.80787046e-02 9.99823391e-01 9.94201481e-01 9.59702730e-01\n",
      " 9.99985933e-01 9.53106642e-01 9.50494885e-01 8.68757740e-02\n",
      " 9.99868870e-01 9.99691010e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 343 [0/54 (0%)]\tTrain Loss: 0.031792\n",
      "Train Epoch: 343 [8/54 (15%)]\tTrain Loss: 0.000134\n",
      "Train Epoch: 343 [16/54 (30%)]\tTrain Loss: 0.008643\n",
      "Train Epoch: 343 [24/54 (44%)]\tTrain Loss: 0.000168\n",
      "Train Epoch: 343 [32/54 (59%)]\tTrain Loss: 0.003029\n",
      "Train Epoch: 343 [40/54 (74%)]\tTrain Loss: 0.001934\n",
      "Train Epoch: 343 [48/54 (89%)]\tTrain Loss: 0.009511\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.39250983e-04 9.94681180e-01 4.80980545e-01 5.53751111e-01\n",
      " 8.83647203e-02 2.49733479e-04 5.88431001e-01 9.39111829e-01\n",
      " 6.60749003e-02 7.16644451e-02 3.53903145e-01 3.16052203e-04\n",
      " 1.05170012e-02 1.38130412e-02 3.66344154e-01 5.38921275e-04\n",
      " 1.58404626e-04 1.34557903e-01 8.62876296e-01 8.31448197e-01\n",
      " 3.93592147e-03 9.93929982e-01 9.99914050e-01 9.97234881e-01\n",
      " 2.87014022e-02 9.99791563e-01 9.99923348e-01 3.62196743e-01\n",
      " 9.53678966e-01 9.22091544e-01 5.30116439e-01 9.97962475e-01\n",
      " 7.34848142e-01 5.51803669e-06 6.75955425e-06 2.00060923e-02\n",
      " 1.02533037e-02 9.82302368e-01 1.85898424e-03 1.97125435e-01\n",
      " 1.43575892e-02 5.28492453e-03 3.02481058e-04 7.87742436e-01\n",
      " 5.44668138e-01 5.05984984e-02 8.28520596e-01 3.55043143e-01\n",
      " 9.99999642e-01 5.44690490e-01 9.98293579e-01 2.42198676e-05\n",
      " 4.02801447e-02 6.43984824e-02 6.87141065e-03 4.21185821e-01\n",
      " 9.98219788e-01 3.72487992e-01 4.23167553e-03 4.90742270e-04\n",
      " 8.40243816e-01 4.51413363e-01 5.38347304e-01 7.49339998e-01\n",
      " 8.61686528e-01 9.99999404e-01 9.99551594e-01 9.99994993e-01\n",
      " 9.99901056e-01 6.95083380e-01 6.51537180e-01 6.78600430e-01\n",
      " 9.99897242e-01 9.43624020e-01 9.64994252e-01 8.16653788e-01\n",
      " 9.99999881e-01 9.99995947e-01 9.98121083e-01 9.99742091e-01\n",
      " 9.99991775e-01 9.97252762e-01 9.99405146e-01 7.65390545e-02\n",
      " 1.53956324e-01 9.81710613e-01 9.76962566e-01 6.22148991e-01\n",
      " 7.59928524e-02 9.99967694e-01 9.98970747e-01 9.58676159e-01\n",
      " 8.46317291e-01 9.99999523e-01 9.90329504e-01 9.98405993e-01\n",
      " 3.53069976e-03 2.35740580e-02 4.37560230e-01 9.99974608e-01\n",
      " 1.01943584e-02 9.57175314e-01 2.12372206e-02 9.94852602e-01\n",
      " 8.69377494e-01 9.92577612e-01 9.99993682e-01 1.32195666e-01\n",
      " 2.53296341e-03 9.99721110e-01 8.73123288e-01 4.20825511e-01\n",
      " 9.95597661e-01 9.85281050e-01 4.88159657e-01 8.98722932e-03\n",
      " 9.72790956e-01 3.52562457e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 344 [0/54 (0%)]\tTrain Loss: 0.003698\n",
      "Train Epoch: 344 [8/54 (15%)]\tTrain Loss: 0.013606\n",
      "Train Epoch: 344 [16/54 (30%)]\tTrain Loss: 0.000479\n",
      "Train Epoch: 344 [24/54 (44%)]\tTrain Loss: 0.000343\n",
      "Train Epoch: 344 [32/54 (59%)]\tTrain Loss: 0.007813\n",
      "Train Epoch: 344 [40/54 (74%)]\tTrain Loss: 0.058234\n",
      "Train Epoch: 344 [48/54 (89%)]\tTrain Loss: 0.001171\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.20852356e-04 9.81183648e-01 6.61689267e-02 4.26294714e-01\n",
      " 3.41319293e-02 1.15014229e-03 5.43388247e-01 4.60466325e-01\n",
      " 5.07104583e-02 8.23375821e-01 1.54938936e-01 2.53260194e-04\n",
      " 2.11451892e-02 1.90217525e-03 7.35270560e-01 7.25618983e-03\n",
      " 2.41421489e-03 2.38292634e-01 3.51624548e-01 2.72186339e-01\n",
      " 9.73091926e-03 9.99100685e-01 9.98409331e-01 9.99298096e-01\n",
      " 7.42509514e-02 9.99009728e-01 9.99979615e-01 6.90814197e-01\n",
      " 7.86008477e-01 6.09694839e-01 2.00004220e-01 9.95970666e-01\n",
      " 6.22312486e-01 2.13215335e-05 1.32024870e-05 9.19755995e-02\n",
      " 7.74555421e-03 9.12462771e-01 4.58186772e-03 5.73852658e-01\n",
      " 7.13291243e-02 8.73645321e-02 4.49264480e-04 5.40163398e-01\n",
      " 6.26137182e-02 1.06672151e-02 7.41868973e-01 2.36531183e-01\n",
      " 9.99999881e-01 3.80247116e-01 9.99886751e-01 1.03705774e-04\n",
      " 1.10347546e-03 1.00289788e-02 1.04666511e-02 1.78458467e-02\n",
      " 9.92471814e-01 1.59976352e-02 2.15230472e-02 2.46425916e-04\n",
      " 9.83103395e-01 5.10405898e-01 9.15529311e-01 9.77021277e-01\n",
      " 5.44667959e-01 9.99999166e-01 9.98662353e-01 1.00000000e+00\n",
      " 9.99996901e-01 9.38310444e-01 7.76728988e-01 8.12509120e-01\n",
      " 9.99939203e-01 9.99335229e-01 9.24925923e-01 6.51839852e-01\n",
      " 9.99987006e-01 9.99967456e-01 9.95722771e-01 9.99994874e-01\n",
      " 9.99976516e-01 9.99327183e-01 9.98313069e-01 1.05769962e-01\n",
      " 3.09718072e-01 9.84732330e-01 9.95601535e-01 8.28531682e-01\n",
      " 1.01978213e-01 9.99994874e-01 9.99839306e-01 9.65055645e-01\n",
      " 6.87071145e-01 9.99999404e-01 9.89876330e-01 9.96486902e-01\n",
      " 4.75247670e-03 3.73316444e-02 4.25418794e-01 1.00000000e+00\n",
      " 2.45755110e-02 9.94090736e-01 1.24718867e-01 9.98682201e-01\n",
      " 8.07323515e-01 9.93938446e-01 9.99999523e-01 5.86153030e-01\n",
      " 2.10141078e-01 9.98540163e-01 9.97175574e-01 9.38692868e-01\n",
      " 9.99533772e-01 9.94940519e-01 9.95203376e-01 1.74109519e-01\n",
      " 9.89419699e-01 9.81212080e-01]\n",
      "predict [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 345 [0/54 (0%)]\tTrain Loss: 0.003145\n",
      "Train Epoch: 345 [8/54 (15%)]\tTrain Loss: 0.019308\n",
      "Train Epoch: 345 [16/54 (30%)]\tTrain Loss: 0.000801\n",
      "Train Epoch: 345 [24/54 (44%)]\tTrain Loss: 0.013826\n",
      "Train Epoch: 345 [32/54 (59%)]\tTrain Loss: 0.040957\n",
      "Train Epoch: 345 [40/54 (74%)]\tTrain Loss: 0.011517\n",
      "Train Epoch: 345 [48/54 (89%)]\tTrain Loss: 0.007008\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.22385128e-05 6.72314286e-01 5.31299450e-02 6.53247476e-01\n",
      " 7.77568296e-03 1.21034049e-04 1.58094130e-02 1.33076146e-01\n",
      " 5.10526914e-03 1.84494723e-02 6.62262201e-01 4.06992901e-03\n",
      " 5.16877770e-02 1.29104601e-02 1.82146907e-01 2.92695622e-04\n",
      " 9.10967006e-04 2.51041949e-01 4.55419034e-01 2.02798378e-02\n",
      " 1.49628483e-02 4.63652730e-01 9.85359311e-01 9.92917955e-01\n",
      " 1.27255460e-02 9.99808609e-01 9.89920020e-01 1.43460840e-01\n",
      " 5.80732346e-01 7.67678797e-01 3.54171954e-02 6.82866395e-01\n",
      " 6.21732354e-01 2.47975549e-04 2.04121970e-04 7.75835896e-03\n",
      " 6.33098464e-03 1.52670890e-01 2.95856781e-03 3.69040817e-02\n",
      " 5.47137018e-03 3.59726162e-03 3.61111190e-04 5.93309430e-03\n",
      " 2.37976789e-01 1.81496993e-03 1.68648854e-01 2.26951241e-01\n",
      " 9.99928713e-01 4.52365905e-01 9.34276402e-01 7.73763191e-03\n",
      " 2.45207772e-02 1.42753366e-02 7.27316784e-03 2.13281810e-02\n",
      " 7.99738526e-01 4.23169732e-02 3.23235081e-03 4.34090151e-03\n",
      " 7.77011395e-01 3.44198525e-01 5.65659583e-01 7.42507041e-01\n",
      " 8.43119919e-01 9.99427080e-01 9.86017048e-01 9.55188990e-01\n",
      " 9.99415755e-01 2.93677658e-01 3.15483630e-01 2.55588561e-01\n",
      " 9.97341096e-01 9.77311671e-01 9.68361318e-01 1.05745874e-01\n",
      " 9.99215007e-01 9.99305367e-01 6.73474491e-01 9.89244580e-01\n",
      " 9.76881444e-01 4.36873227e-01 6.26523197e-01 6.87827095e-02\n",
      " 4.93088484e-01 9.07971799e-01 8.63082051e-01 3.44839096e-01\n",
      " 5.18968999e-02 9.34817374e-01 9.97807443e-01 1.29774407e-01\n",
      " 8.96934047e-02 9.98989046e-01 8.63268316e-01 8.07490528e-01\n",
      " 4.94193006e-03 4.80677467e-03 4.70607102e-01 9.88323033e-01\n",
      " 1.50191924e-02 9.80090141e-01 1.61216278e-02 4.70829099e-01\n",
      " 1.17155299e-01 7.85072267e-01 9.92074251e-01 1.32218457e-03\n",
      " 2.07265466e-03 9.28068638e-01 4.15291172e-03 5.87590621e-04\n",
      " 5.38199544e-01 7.61148095e-01 2.72950500e-01 1.90361645e-02\n",
      " 4.03050870e-01 8.83604288e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "Train Epoch: 346 [0/54 (0%)]\tTrain Loss: 0.016412\n",
      "Train Epoch: 346 [8/54 (15%)]\tTrain Loss: 0.002559\n",
      "Train Epoch: 346 [16/54 (30%)]\tTrain Loss: 0.000546\n",
      "Train Epoch: 346 [24/54 (44%)]\tTrain Loss: 0.002780\n",
      "Train Epoch: 346 [32/54 (59%)]\tTrain Loss: 0.043370\n",
      "Train Epoch: 346 [40/54 (74%)]\tTrain Loss: 0.000661\n",
      "Train Epoch: 346 [48/54 (89%)]\tTrain Loss: 0.014954\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.47582591e-02 9.34979618e-01 1.82008952e-01 9.73219156e-01\n",
      " 4.76641268e-01 2.10322794e-02 8.97544175e-02 9.72714245e-01\n",
      " 8.93216282e-02 8.05377066e-01 4.61066246e-01 1.85936689e-01\n",
      " 2.76466995e-01 2.11037174e-02 7.39723980e-01 2.72018299e-03\n",
      " 2.97848834e-03 4.33577478e-01 7.45718479e-01 3.26378375e-01\n",
      " 4.98447642e-02 9.59976733e-01 9.99076366e-01 9.99822795e-01\n",
      " 3.74205083e-01 9.99980092e-01 9.99913335e-01 7.00348675e-01\n",
      " 9.80006516e-01 7.57632613e-01 7.13291347e-01 9.93230820e-01\n",
      " 9.84552264e-01 4.98909329e-04 2.30602571e-04 1.00028105e-01\n",
      " 1.11412741e-01 7.24339247e-01 2.29161717e-02 3.29583347e-01\n",
      " 6.11219630e-02 2.65846271e-02 4.24372638e-03 4.87363487e-01\n",
      " 4.04384553e-01 3.72119397e-01 9.93579745e-01 6.57692671e-01\n",
      " 1.00000000e+00 9.40892100e-01 9.99853253e-01 3.87063017e-03\n",
      " 9.96378586e-02 5.57152987e-01 6.04265966e-02 1.33584246e-01\n",
      " 9.99827504e-01 3.16621549e-02 2.23090127e-01 4.39225733e-02\n",
      " 9.99327064e-01 9.76867914e-01 9.92343843e-01 9.78248835e-01\n",
      " 9.96923268e-01 9.99999285e-01 9.99768555e-01 9.99998808e-01\n",
      " 9.99999046e-01 9.99755800e-01 9.19854224e-01 9.11340117e-01\n",
      " 9.99944448e-01 9.99996066e-01 9.99971628e-01 9.71395910e-01\n",
      " 9.99956369e-01 9.99852300e-01 9.93321240e-01 9.99994040e-01\n",
      " 1.00000000e+00 9.99623179e-01 9.99992013e-01 2.32696965e-01\n",
      " 3.54513526e-01 9.89995241e-01 9.95622218e-01 9.83411133e-01\n",
      " 7.11056590e-02 9.99883652e-01 9.99685764e-01 9.04896140e-01\n",
      " 9.08564985e-01 1.00000000e+00 9.94140446e-01 9.94383216e-01\n",
      " 8.27324167e-02 1.99442834e-01 9.15055037e-01 9.99952555e-01\n",
      " 1.80543125e-01 9.99517798e-01 1.54520318e-01 9.99101162e-01\n",
      " 9.82913315e-01 9.98876035e-01 9.99999642e-01 5.01142502e-01\n",
      " 1.29417881e-01 9.98444736e-01 2.49905780e-01 8.45378339e-02\n",
      " 9.91890550e-01 9.63133633e-01 8.31470788e-01 4.97599006e-01\n",
      " 8.00907850e-01 9.16996300e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 347 [0/54 (0%)]\tTrain Loss: 0.016258\n",
      "Train Epoch: 347 [8/54 (15%)]\tTrain Loss: 0.001810\n",
      "Train Epoch: 347 [16/54 (30%)]\tTrain Loss: 0.018621\n",
      "Train Epoch: 347 [24/54 (44%)]\tTrain Loss: 0.014227\n",
      "Train Epoch: 347 [32/54 (59%)]\tTrain Loss: 0.007350\n",
      "Train Epoch: 347 [40/54 (74%)]\tTrain Loss: 0.002352\n",
      "Train Epoch: 347 [48/54 (89%)]\tTrain Loss: 0.006144\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.0069639  0.99092674 0.9371469  0.99756134 0.81672043 0.00416831\n",
      " 0.59509516 0.99050373 0.08606155 0.2926605  0.65821779 0.0449751\n",
      " 0.19409698 0.07082016 0.84716702 0.00890693 0.05356385 0.2143518\n",
      " 0.95805609 0.90707505 0.36119342 0.98480636 0.99993134 0.99999702\n",
      " 0.27002504 0.9999969  0.99999917 0.96899611 0.9968189  0.9755525\n",
      " 0.58168209 0.9954347  0.2892589  0.02565598 0.02005087 0.23271307\n",
      " 0.35177305 0.92421889 0.05581256 0.38204494 0.19292474 0.04991176\n",
      " 0.00410811 0.58639222 0.63106394 0.39649439 0.90162438 0.19426934\n",
      " 0.99970752 0.94355661 0.99006289 0.0024133  0.45944735 0.56913823\n",
      " 0.46522465 0.19224995 0.99635589 0.60283726 0.02731113 0.14910287\n",
      " 0.99993062 0.99854738 0.99304283 0.9983896  0.9987343  0.99999142\n",
      " 0.99994671 0.99998975 0.99999905 0.95793873 0.95023876 0.98182505\n",
      " 0.99996555 0.99998772 0.99904543 0.98506182 0.9999882  0.99992919\n",
      " 0.99973387 0.99998474 1.         0.99998307 0.99998164 0.64122808\n",
      " 0.90989375 0.99591547 0.9997769  0.99980229 0.51917279 0.99988425\n",
      " 0.99999595 0.88640761 0.81550813 1.         0.99999821 0.99992478\n",
      " 0.34935278 0.87832057 0.99883014 0.99999857 0.21513943 0.99960309\n",
      " 0.51818877 0.99867755 0.99849629 0.99998331 0.99999988 0.2696808\n",
      " 0.32968259 0.99952865 0.51116359 0.28782368 0.99729234 0.99985802\n",
      " 0.99833244 0.85393035 0.13040797 0.78428304]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 348 [0/54 (0%)]\tTrain Loss: 0.005962\n",
      "Train Epoch: 348 [8/54 (15%)]\tTrain Loss: 0.026043\n",
      "Train Epoch: 348 [16/54 (30%)]\tTrain Loss: 0.004041\n",
      "Train Epoch: 348 [24/54 (44%)]\tTrain Loss: 0.018905\n",
      "Train Epoch: 348 [32/54 (59%)]\tTrain Loss: 0.023952\n",
      "Train Epoch: 348 [40/54 (74%)]\tTrain Loss: 0.004056\n",
      "Train Epoch: 348 [48/54 (89%)]\tTrain Loss: 0.000235\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.68605726e-02 9.98540401e-01 9.96218503e-01 9.97048914e-01\n",
      " 7.72192538e-01 4.61899705e-04 9.22695339e-01 9.92589355e-01\n",
      " 5.12334984e-03 4.09792006e-01 3.16526264e-01 7.14648485e-01\n",
      " 2.18405481e-02 1.99925303e-02 6.87842488e-01 6.79704826e-04\n",
      " 1.89817010e-03 3.93747419e-01 8.77548754e-01 5.75757563e-01\n",
      " 5.43495715e-02 9.90246415e-01 9.99976039e-01 9.99961495e-01\n",
      " 3.06918353e-01 9.99995112e-01 9.99996305e-01 9.15874660e-01\n",
      " 9.95861590e-01 9.57045794e-01 3.90371025e-01 9.97009873e-01\n",
      " 5.19462883e-01 3.32968455e-04 4.55525791e-04 3.53522062e-01\n",
      " 4.25667316e-01 9.63469625e-01 2.59826537e-02 3.53753090e-01\n",
      " 3.49554330e-01 1.48123801e-01 3.18219489e-03 3.41446072e-01\n",
      " 2.97045857e-01 2.90141225e-01 9.81809735e-01 2.30168119e-01\n",
      " 9.99737561e-01 8.44210625e-01 9.98397410e-01 6.05215877e-03\n",
      " 2.07226962e-01 8.96014497e-02 2.30054613e-02 1.93987899e-02\n",
      " 9.96999264e-01 8.67439583e-02 3.02009843e-02 4.22603153e-02\n",
      " 9.99875307e-01 9.98821318e-01 9.97946322e-01 9.99457061e-01\n",
      " 9.95696664e-01 9.99975324e-01 9.99769270e-01 9.99999523e-01\n",
      " 9.99999762e-01 9.57771361e-01 9.76528823e-01 9.89795744e-01\n",
      " 9.99990821e-01 9.99971986e-01 9.99755681e-01 9.93146479e-01\n",
      " 9.99999166e-01 9.99998093e-01 9.99859810e-01 9.99998569e-01\n",
      " 1.00000000e+00 9.99988198e-01 9.99989629e-01 9.20579672e-01\n",
      " 9.49778497e-01 9.90104258e-01 9.98954654e-01 9.98993576e-01\n",
      " 4.00666922e-01 9.97659922e-01 9.99996424e-01 7.83579051e-01\n",
      " 7.66000390e-01 1.00000000e+00 9.99802768e-01 9.99856591e-01\n",
      " 2.74242163e-02 8.84215772e-01 9.74201560e-01 9.99896884e-01\n",
      " 1.24943256e-01 9.99880195e-01 6.21113539e-01 9.94762480e-01\n",
      " 9.87477064e-01 9.98101056e-01 9.99999046e-01 2.47937992e-01\n",
      " 2.29362715e-02 9.91540253e-01 7.77706355e-02 2.56841145e-02\n",
      " 8.98871601e-01 9.68985677e-01 9.94067073e-01 7.22784400e-01\n",
      " 7.83127546e-01 9.04726803e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 349 [0/54 (0%)]\tTrain Loss: 0.002107\n",
      "Train Epoch: 349 [8/54 (15%)]\tTrain Loss: 0.000350\n",
      "Train Epoch: 349 [16/54 (30%)]\tTrain Loss: 0.001277\n",
      "Train Epoch: 349 [24/54 (44%)]\tTrain Loss: 0.000707\n",
      "Train Epoch: 349 [32/54 (59%)]\tTrain Loss: 0.001165\n",
      "Train Epoch: 349 [40/54 (74%)]\tTrain Loss: 0.001833\n",
      "Train Epoch: 349 [48/54 (89%)]\tTrain Loss: 0.000427\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.30792484e-03 9.79187012e-01 5.16985595e-01 9.47046995e-01\n",
      " 2.76912361e-01 1.26746469e-04 7.59282634e-02 9.80757117e-01\n",
      " 4.31864755e-03 3.45939904e-01 2.40409687e-01 3.14061390e-03\n",
      " 2.55373716e-02 9.57544718e-04 2.30422288e-01 1.48280786e-04\n",
      " 3.72737471e-04 1.88777715e-01 8.33866119e-01 6.56291008e-01\n",
      " 7.49538327e-03 9.88464057e-01 9.99962211e-01 9.99981999e-01\n",
      " 1.26733050e-01 9.99998450e-01 9.99999046e-01 9.01057065e-01\n",
      " 9.77006733e-01 8.88507664e-01 7.47410655e-01 9.91116524e-01\n",
      " 6.94926143e-01 2.65489361e-05 1.92352200e-05 1.73047870e-01\n",
      " 1.52589157e-01 9.35731471e-01 3.69688123e-03 6.11295141e-02\n",
      " 3.35004292e-02 1.90492216e-02 2.55664042e-03 1.11515500e-01\n",
      " 4.69316363e-01 1.16632551e-01 9.29054558e-01 5.70828915e-02\n",
      " 9.98409867e-01 8.08306098e-01 9.92051840e-01 1.10935990e-03\n",
      " 8.23369697e-02 3.07115708e-02 1.88065916e-02 9.92045365e-03\n",
      " 9.98954415e-01 5.70823550e-02 7.40359910e-03 4.62237000e-03\n",
      " 9.99923348e-01 9.93265152e-01 9.97719467e-01 9.99227285e-01\n",
      " 9.98664021e-01 9.99967575e-01 9.99610841e-01 9.99997377e-01\n",
      " 9.99999642e-01 8.57591212e-01 9.38105822e-01 9.68687952e-01\n",
      " 9.99996305e-01 9.99971986e-01 9.99986053e-01 9.96768832e-01\n",
      " 9.99997735e-01 9.99986410e-01 9.99126732e-01 9.99999642e-01\n",
      " 1.00000000e+00 9.99997139e-01 9.99921203e-01 3.22857022e-01\n",
      " 5.54858327e-01 9.94799018e-01 9.99439061e-01 9.96091664e-01\n",
      " 3.58557940e-01 9.99522567e-01 9.99996543e-01 9.30752933e-01\n",
      " 8.07850480e-01 1.00000000e+00 9.99959946e-01 9.99986768e-01\n",
      " 5.87393902e-03 6.62269413e-01 9.94530022e-01 9.99984145e-01\n",
      " 4.26983647e-02 9.99910712e-01 5.67329347e-01 9.98922467e-01\n",
      " 9.96963203e-01 9.99059618e-01 9.99999285e-01 1.06307857e-01\n",
      " 1.00105833e-02 9.97535467e-01 1.59449279e-01 7.85868336e-03\n",
      " 9.41948056e-01 9.90625620e-01 9.96424973e-01 3.17728728e-01\n",
      " 2.94139951e-01 8.55168343e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      "Train Epoch: 350 [0/54 (0%)]\tTrain Loss: 0.004207\n",
      "Train Epoch: 350 [8/54 (15%)]\tTrain Loss: 0.003091\n",
      "Train Epoch: 350 [16/54 (30%)]\tTrain Loss: 0.000244\n",
      "Train Epoch: 350 [24/54 (44%)]\tTrain Loss: 0.000240\n",
      "Train Epoch: 350 [32/54 (59%)]\tTrain Loss: 0.001044\n",
      "Train Epoch: 350 [40/54 (74%)]\tTrain Loss: 0.004192\n",
      "Train Epoch: 350 [48/54 (89%)]\tTrain Loss: 0.000193\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.68764439e-05 9.22778130e-01 3.45175177e-01 6.13591373e-01\n",
      " 2.38864779e-01 8.70613178e-07 3.45347486e-02 6.22597814e-01\n",
      " 1.69849757e-03 4.50583220e-01 6.35438442e-01 5.73762576e-04\n",
      " 2.30385847e-02 1.11933559e-05 6.06071251e-03 1.24389524e-04\n",
      " 2.05696502e-04 4.68035862e-02 7.38939881e-01 6.50552511e-01\n",
      " 1.12644965e-02 8.60830903e-01 9.99945879e-01 9.99995470e-01\n",
      " 2.61741458e-03 9.99998569e-01 9.99998450e-01 4.98198330e-01\n",
      " 8.56740654e-01 4.74608302e-01 4.00183141e-01 9.34792697e-01\n",
      " 4.60150838e-01 1.26869083e-04 2.37736331e-05 1.54243931e-02\n",
      " 5.11616562e-03 9.16900218e-01 5.19064895e-04 5.46534248e-02\n",
      " 6.45178417e-03 2.06382945e-03 2.08110752e-04 2.90623382e-02\n",
      " 6.89401269e-01 4.43447195e-03 9.36265647e-01 3.54750231e-02\n",
      " 9.22305048e-01 8.70917559e-01 6.97905540e-01 1.26883143e-03\n",
      " 3.26275779e-03 2.70764101e-02 9.01924670e-02 1.80669446e-02\n",
      " 9.94904518e-01 5.14210016e-02 4.55826172e-04 2.93726271e-06\n",
      " 9.99889612e-01 9.95122015e-01 9.99101162e-01 9.99191463e-01\n",
      " 7.20193803e-01 9.99420524e-01 9.95913565e-01 9.99899268e-01\n",
      " 9.99957800e-01 1.76077500e-01 8.80469024e-01 9.53378320e-01\n",
      " 9.99999642e-01 9.99997854e-01 9.93989110e-01 9.77996767e-01\n",
      " 9.99937177e-01 9.99791801e-01 9.95422900e-01 9.99990702e-01\n",
      " 9.99996066e-01 9.99896884e-01 9.98125136e-01 6.24910355e-01\n",
      " 7.20889807e-01 9.85486031e-01 9.86888468e-01 9.08545315e-01\n",
      " 1.20103225e-01 9.99877453e-01 9.99998808e-01 7.86980629e-01\n",
      " 6.60033166e-01 1.00000000e+00 9.99994993e-01 9.99994159e-01\n",
      " 9.72347986e-03 3.69384974e-01 9.95594323e-01 9.99891639e-01\n",
      " 3.11929621e-02 9.99986410e-01 8.31056774e-01 9.99753416e-01\n",
      " 9.97900724e-01 9.98826683e-01 9.99999762e-01 1.45779178e-02\n",
      " 2.21822294e-04 9.62645471e-01 3.13831158e-02 7.94352964e-04\n",
      " 9.71302688e-01 9.99099970e-01 9.98036563e-01 6.63990602e-02\n",
      " 8.98106933e-01 9.40965533e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 47 TN= 36 FN= 11 FP= 24\n",
      "TP+FP 71\n",
      "precision 0.6619718309859155\n",
      "recall 0.8103448275862069\n",
      "F1 0.7286821705426356\n",
      "acc 0.7033898305084746\n",
      "AUCp 0.7051724137931034\n",
      "AUC 0.7862068965517242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The epoch is 350, average recall: 0.8103, average precision: 0.6620,average F1: 0.7287, average accuracy: 0.7034, average AUC: 0.7862\n",
      "Train Epoch: 351 [0/54 (0%)]\tTrain Loss: 0.000344\n",
      "Train Epoch: 351 [8/54 (15%)]\tTrain Loss: 0.000400\n",
      "Train Epoch: 351 [16/54 (30%)]\tTrain Loss: 0.019017\n",
      "Train Epoch: 351 [24/54 (44%)]\tTrain Loss: 0.002404\n",
      "Train Epoch: 351 [32/54 (59%)]\tTrain Loss: 0.003853\n",
      "Train Epoch: 351 [40/54 (74%)]\tTrain Loss: 0.005811\n",
      "Train Epoch: 351 [48/54 (89%)]\tTrain Loss: 0.035976\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.36373833e-02 9.66931343e-01 7.35599935e-01 9.93551612e-01\n",
      " 7.15950012e-01 2.50769593e-02 2.27437094e-01 9.96578634e-01\n",
      " 8.49671587e-02 6.03069603e-01 1.81896806e-01 1.09815504e-02\n",
      " 4.52763774e-02 9.83839016e-03 4.54955161e-01 1.21005403e-03\n",
      " 1.23736877e-02 3.63841116e-01 9.31266069e-01 4.29412991e-01\n",
      " 5.88574260e-03 9.97253358e-01 9.99975204e-01 9.99948382e-01\n",
      " 1.85151443e-01 9.99993801e-01 9.99998927e-01 9.32843029e-01\n",
      " 9.80230629e-01 9.74104822e-01 6.62903428e-01 9.74514723e-01\n",
      " 9.97927904e-01 2.47276625e-06 7.34275727e-06 1.26926482e-01\n",
      " 2.27700695e-02 9.55798745e-01 5.08747017e-03 3.28020118e-02\n",
      " 3.15053165e-02 4.37881984e-03 1.45341586e-02 4.43253666e-01\n",
      " 7.71867633e-01 2.63863280e-02 9.93051767e-01 7.19875634e-01\n",
      " 9.99999762e-01 9.91441250e-01 9.99964952e-01 5.18346112e-03\n",
      " 7.01301079e-03 7.35478103e-03 6.91157114e-03 2.21291725e-02\n",
      " 9.98802423e-01 3.28825824e-02 3.93140782e-03 3.36398371e-02\n",
      " 9.99854445e-01 9.94304597e-01 9.99388456e-01 9.99532580e-01\n",
      " 9.99692798e-01 9.99864936e-01 9.98726547e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.53064322e-01 9.79800284e-01 9.90781367e-01\n",
      " 9.99998689e-01 9.99999881e-01 9.99999762e-01 9.94995475e-01\n",
      " 9.99999881e-01 9.99999762e-01 9.99725282e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99858856e-01 9.99996662e-01 8.38692546e-01\n",
      " 8.81518424e-01 9.95074213e-01 9.98939693e-01 9.95311856e-01\n",
      " 1.48029059e-01 9.96376574e-01 9.99994516e-01 2.35448763e-01\n",
      " 8.22682023e-01 1.00000000e+00 9.99883890e-01 9.99937177e-01\n",
      " 9.14102606e-03 6.65756702e-01 9.41959798e-01 9.99856472e-01\n",
      " 1.30935442e-02 9.99978781e-01 2.51137942e-01 9.98259723e-01\n",
      " 9.90656435e-01 9.76156056e-01 9.99999762e-01 1.13072336e-01\n",
      " 2.83024507e-03 9.63224351e-01 6.36297911e-02 5.98118789e-02\n",
      " 9.35476542e-01 9.99859691e-01 9.99152780e-01 7.06173778e-01\n",
      " 9.68229771e-01 6.91880167e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 352 [0/54 (0%)]\tTrain Loss: 0.001161\n",
      "Train Epoch: 352 [8/54 (15%)]\tTrain Loss: 0.003632\n",
      "Train Epoch: 352 [16/54 (30%)]\tTrain Loss: 0.001041\n",
      "Train Epoch: 352 [24/54 (44%)]\tTrain Loss: 0.035157\n",
      "Train Epoch: 352 [32/54 (59%)]\tTrain Loss: 0.000612\n",
      "Train Epoch: 352 [40/54 (74%)]\tTrain Loss: 0.000469\n",
      "Train Epoch: 352 [48/54 (89%)]\tTrain Loss: 0.000594\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.22590978e-03 9.89679813e-01 9.59337473e-01 9.82027650e-01\n",
      " 6.88457310e-01 4.56881644e-05 8.77917588e-01 9.66016829e-01\n",
      " 1.87013987e-02 1.12406097e-01 8.46904796e-03 7.21373707e-02\n",
      " 1.74617395e-02 2.06809025e-03 2.97240943e-01 3.70039314e-04\n",
      " 1.56011875e-03 2.10076556e-01 4.86141175e-01 2.35688820e-01\n",
      " 5.87701313e-02 9.42005396e-01 9.99158382e-01 9.99961734e-01\n",
      " 1.60138264e-01 9.99795973e-01 9.99997258e-01 9.77895558e-01\n",
      " 8.97506356e-01 3.16299796e-01 4.97835219e-01 8.46364856e-01\n",
      " 6.33212507e-01 2.05349454e-04 5.06810320e-04 6.71743453e-02\n",
      " 1.05280675e-01 9.62880611e-01 1.79981943e-02 1.09954804e-01\n",
      " 8.90925340e-03 1.82321072e-02 2.32537554e-04 5.80765426e-01\n",
      " 2.86852658e-01 1.45352790e-02 8.92588019e-01 3.84032041e-01\n",
      " 9.99989271e-01 9.97370005e-01 9.98634636e-01 3.50544491e-04\n",
      " 2.72240210e-02 5.53172315e-04 2.19129492e-03 1.50853306e-01\n",
      " 9.80575323e-01 2.56431941e-02 4.89369209e-04 4.13357084e-05\n",
      " 9.96724427e-01 9.79739487e-01 9.82587397e-01 9.95162427e-01\n",
      " 8.28590810e-01 9.99781311e-01 9.97824669e-01 9.99972820e-01\n",
      " 1.00000000e+00 6.48682296e-01 9.82516408e-01 9.75454450e-01\n",
      " 9.99845743e-01 9.99872088e-01 9.98169184e-01 4.65736270e-01\n",
      " 9.99999881e-01 9.99998927e-01 9.97860610e-01 9.99997854e-01\n",
      " 9.99999642e-01 9.99753058e-01 9.99958515e-01 3.62627983e-01\n",
      " 3.75449896e-01 9.56908166e-01 9.26677167e-01 9.94279146e-01\n",
      " 1.38518557e-01 9.97881234e-01 9.99951005e-01 1.79731652e-01\n",
      " 8.98487568e-01 1.00000000e+00 9.99994636e-01 9.99967217e-01\n",
      " 4.98050405e-03 9.08491671e-01 9.60323691e-01 9.96080816e-01\n",
      " 2.36478206e-02 9.98698831e-01 7.60791659e-01 9.92358387e-01\n",
      " 9.75926459e-01 9.70589519e-01 9.99998569e-01 5.39760649e-01\n",
      " 5.64881973e-03 9.52317834e-01 3.63437742e-01 4.33668733e-01\n",
      " 9.83555019e-01 9.99005616e-01 9.63242114e-01 5.81863150e-02\n",
      " 9.97249305e-01 9.48960125e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 353 [0/54 (0%)]\tTrain Loss: 0.011222\n",
      "Train Epoch: 353 [8/54 (15%)]\tTrain Loss: 0.003005\n",
      "Train Epoch: 353 [16/54 (30%)]\tTrain Loss: 0.006398\n",
      "Train Epoch: 353 [24/54 (44%)]\tTrain Loss: 0.002539\n",
      "Train Epoch: 353 [32/54 (59%)]\tTrain Loss: 0.000263\n",
      "Train Epoch: 353 [40/54 (74%)]\tTrain Loss: 0.007864\n",
      "Train Epoch: 353 [48/54 (89%)]\tTrain Loss: 0.001415\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.11224129e-05 9.75627244e-01 4.81880546e-01 8.56548071e-01\n",
      " 9.07492191e-02 1.12826738e-05 2.15470925e-01 9.16193008e-01\n",
      " 8.28072801e-03 1.23444451e-02 2.60151806e-03 3.93702416e-04\n",
      " 1.09117408e-03 2.50080629e-04 1.50631547e-01 3.54033509e-05\n",
      " 9.22778054e-06 1.84063464e-01 6.97173178e-01 8.03960636e-02\n",
      " 4.49999887e-03 8.93376291e-01 9.85103428e-01 9.99762475e-01\n",
      " 3.32403034e-02 9.98239040e-01 9.99996185e-01 9.76900220e-01\n",
      " 7.71997929e-01 2.79152483e-01 3.29648405e-01 7.82388985e-01\n",
      " 1.42909661e-02 7.02733587e-08 5.32121976e-06 1.26518798e-03\n",
      " 8.97826045e-04 8.87293339e-01 1.33867201e-03 1.14356289e-02\n",
      " 9.27711080e-04 2.05651694e-03 5.15481865e-04 6.71051666e-02\n",
      " 2.19739154e-01 3.30423727e-03 8.93400490e-01 3.46949995e-01\n",
      " 9.99952793e-01 9.94667888e-01 9.98433650e-01 4.06794425e-05\n",
      " 6.87519860e-05 8.76955455e-05 3.60927149e-03 1.39461551e-03\n",
      " 9.84962344e-01 1.00515010e-02 3.91502108e-05 3.15835905e-06\n",
      " 9.97595251e-01 9.83185530e-01 9.85542178e-01 9.97582912e-01\n",
      " 9.27402079e-01 9.99884367e-01 9.99366939e-01 9.99956965e-01\n",
      " 1.00000000e+00 8.77114594e-01 9.72428322e-01 9.78179038e-01\n",
      " 9.99951243e-01 9.99634504e-01 9.99852777e-01 8.92912567e-01\n",
      " 9.99999881e-01 9.99999166e-01 9.99109328e-01 9.99990344e-01\n",
      " 9.99999642e-01 9.99578297e-01 9.99979734e-01 1.94859341e-01\n",
      " 5.39249592e-02 9.34608757e-01 9.83822286e-01 9.83816087e-01\n",
      " 2.80481540e-02 9.98569250e-01 9.99969721e-01 9.52040404e-02\n",
      " 8.81138980e-01 1.00000000e+00 9.99960065e-01 9.99821842e-01\n",
      " 6.41117664e-03 2.14430705e-01 8.62236023e-01 9.95592177e-01\n",
      " 3.13346460e-02 9.99608219e-01 1.05863690e-01 9.51378524e-01\n",
      " 9.61847842e-01 9.64682758e-01 9.99998927e-01 1.59672245e-01\n",
      " 7.43455207e-03 8.12630057e-01 2.56001707e-02 5.34261644e-01\n",
      " 8.85240793e-01 9.98682439e-01 9.72542405e-01 1.99815854e-02\n",
      " 9.66460764e-01 7.85317123e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 354 [0/54 (0%)]\tTrain Loss: 0.001264\n",
      "Train Epoch: 354 [8/54 (15%)]\tTrain Loss: 0.002541\n",
      "Train Epoch: 354 [16/54 (30%)]\tTrain Loss: 0.019137\n",
      "Train Epoch: 354 [24/54 (44%)]\tTrain Loss: 0.000924\n",
      "Train Epoch: 354 [32/54 (59%)]\tTrain Loss: 0.001060\n",
      "Train Epoch: 354 [40/54 (74%)]\tTrain Loss: 0.000272\n",
      "Train Epoch: 354 [48/54 (89%)]\tTrain Loss: 0.001536\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.48185276e-04 7.21857131e-01 3.57312292e-01 7.07351863e-01\n",
      " 1.29828364e-01 1.96448629e-04 3.50617796e-01 5.64076245e-01\n",
      " 3.37747904e-03 9.11042690e-02 1.17473607e-03 3.63156752e-04\n",
      " 7.83026777e-03 1.54142559e-03 9.13015604e-02 4.16157563e-04\n",
      " 5.21672599e-04 3.92339053e-03 4.64432687e-02 1.89325458e-03\n",
      " 1.68122246e-03 6.22183919e-01 9.97865736e-01 9.97147977e-01\n",
      " 1.01974057e-02 9.99726832e-01 9.99980927e-01 2.58120537e-01\n",
      " 2.11428136e-01 1.13752738e-01 6.19082898e-02 7.09180772e-01\n",
      " 3.01110428e-02 2.91260185e-05 2.41534835e-05 4.02954919e-03\n",
      " 1.55799733e-02 8.75740707e-01 2.41538673e-03 4.82191518e-02\n",
      " 3.85465659e-03 5.51561546e-03 2.93490040e-04 1.40975518e-02\n",
      " 3.00582666e-02 2.81710457e-03 3.44057888e-01 2.47643813e-01\n",
      " 9.99995351e-01 9.96346414e-01 9.96018946e-01 1.21061857e-04\n",
      " 1.69333071e-04 1.54029622e-04 4.85889352e-04 2.05807365e-03\n",
      " 4.36110795e-01 1.59489550e-02 5.46802359e-04 2.31498070e-05\n",
      " 9.17271078e-01 7.74035335e-01 9.41981494e-01 9.88336504e-01\n",
      " 4.63094711e-01 9.99706566e-01 9.98209715e-01 9.99660015e-01\n",
      " 9.99999881e-01 8.70018601e-01 8.51403356e-01 8.38490367e-01\n",
      " 9.97832954e-01 9.98966217e-01 8.55565727e-01 9.53335911e-02\n",
      " 9.99996066e-01 9.99996185e-01 9.92840528e-01 9.99876499e-01\n",
      " 9.99998212e-01 9.80693817e-01 9.95553315e-01 7.85513148e-02\n",
      " 3.82905126e-01 8.93733561e-01 8.31698060e-01 7.77906597e-01\n",
      " 7.35038891e-02 9.96996641e-01 9.99994993e-01 5.07947337e-03\n",
      " 3.93485948e-02 1.00000000e+00 9.99848247e-01 9.99954104e-01\n",
      " 5.00512833e-04 1.37992382e-01 6.72371387e-01 9.99834895e-01\n",
      " 6.11848757e-02 9.84342277e-01 8.05792063e-02 5.39943874e-01\n",
      " 1.46966517e-01 5.82111716e-01 9.99868751e-01 5.17339446e-02\n",
      " 3.63417482e-03 4.06287700e-01 7.05801100e-02 3.37995380e-01\n",
      " 9.62887466e-01 9.14288998e-01 8.83706868e-01 3.24385911e-02\n",
      " 9.93308067e-01 9.88213480e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 355 [0/54 (0%)]\tTrain Loss: 0.000599\n",
      "Train Epoch: 355 [8/54 (15%)]\tTrain Loss: 0.016803\n",
      "Train Epoch: 355 [16/54 (30%)]\tTrain Loss: 0.079390\n",
      "Train Epoch: 355 [24/54 (44%)]\tTrain Loss: 0.000805\n",
      "Train Epoch: 355 [32/54 (59%)]\tTrain Loss: 0.002208\n",
      "Train Epoch: 355 [40/54 (74%)]\tTrain Loss: 0.013524\n",
      "Train Epoch: 355 [48/54 (89%)]\tTrain Loss: 0.026504\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.43935535e-05 1.20254159e-01 3.95691320e-02 9.12591040e-01\n",
      " 9.48139489e-01 4.73041524e-04 3.95575678e-03 9.99594152e-01\n",
      " 2.85844714e-03 7.89795339e-01 8.73417675e-01 4.07331064e-02\n",
      " 5.19240618e-01 1.79843567e-02 2.51283109e-01 7.43014680e-04\n",
      " 3.49316150e-02 5.02980724e-02 9.99470770e-01 7.37720311e-01\n",
      " 6.72848701e-01 9.96523798e-01 9.99638200e-01 9.99969363e-01\n",
      " 4.81680006e-01 1.00000000e+00 9.99999523e-01 9.93471265e-01\n",
      " 9.98353481e-01 8.85457754e-01 2.26469025e-01 9.98986900e-01\n",
      " 8.26210529e-02 2.55969324e-04 1.09479744e-02 3.15854065e-02\n",
      " 2.12315455e-01 9.88681674e-01 1.90711230e-01 9.72905278e-01\n",
      " 8.80815566e-01 6.06221199e-01 7.68657122e-03 5.84677830e-02\n",
      " 9.49425697e-01 4.48495299e-01 9.98417377e-01 9.86748815e-01\n",
      " 1.00000000e+00 9.99785960e-01 9.99999285e-01 1.17949825e-02\n",
      " 4.58410010e-02 2.76270658e-01 3.90057415e-01 4.63359863e-01\n",
      " 9.99947309e-01 7.52886593e-01 4.38293396e-03 6.30445732e-03\n",
      " 9.99983430e-01 9.97111320e-01 9.99993682e-01 9.99998808e-01\n",
      " 9.99104559e-01 9.99995470e-01 9.99980211e-01 9.99903679e-01\n",
      " 9.99903321e-01 9.99827385e-01 9.95340109e-01 9.98051524e-01\n",
      " 9.99999762e-01 9.99999762e-01 9.99976158e-01 9.99997377e-01\n",
      " 9.99890924e-01 9.99656320e-01 9.99996662e-01 9.99998808e-01\n",
      " 9.99994397e-01 9.99999881e-01 9.99997735e-01 9.95956600e-01\n",
      " 9.85348046e-01 9.99997497e-01 9.99325871e-01 9.99828696e-01\n",
      " 7.77130067e-01 9.88163292e-01 9.99998808e-01 9.70764399e-01\n",
      " 9.80183661e-01 1.00000000e+00 9.99999523e-01 9.99979496e-01\n",
      " 5.57095110e-01 3.80479723e-01 9.23251331e-01 9.99999762e-01\n",
      " 1.02401592e-01 9.99999046e-01 8.44499946e-01 9.99374807e-01\n",
      " 9.99997020e-01 9.99997854e-01 1.00000000e+00 3.29677504e-03\n",
      " 2.23494694e-01 9.74449754e-01 1.70619160e-01 7.92145610e-01\n",
      " 9.97982383e-01 9.99347866e-01 7.41455257e-01 5.45987077e-02\n",
      " 7.62508884e-02 6.92849755e-01]\n",
      "predict [0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
      "Train Epoch: 356 [0/54 (0%)]\tTrain Loss: 0.013478\n",
      "Train Epoch: 356 [8/54 (15%)]\tTrain Loss: 0.028837\n",
      "Train Epoch: 356 [16/54 (30%)]\tTrain Loss: 0.008967\n",
      "Train Epoch: 356 [24/54 (44%)]\tTrain Loss: 0.001393\n",
      "Train Epoch: 356 [32/54 (59%)]\tTrain Loss: 0.001501\n",
      "Train Epoch: 356 [40/54 (74%)]\tTrain Loss: 0.004360\n",
      "Train Epoch: 356 [48/54 (89%)]\tTrain Loss: 0.020258\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.86437455e-07 1.27860576e-01 8.95672366e-02 9.93824720e-01\n",
      " 9.51378286e-01 6.33603777e-04 1.28784612e-01 9.96407568e-01\n",
      " 8.26723278e-02 7.81462252e-01 5.48838198e-01 4.56932820e-02\n",
      " 9.18337107e-02 1.24796838e-01 7.43070662e-01 8.46511277e-04\n",
      " 1.36616779e-02 2.14991316e-01 9.82596397e-01 3.75476897e-01\n",
      " 1.15475670e-01 9.75727022e-01 9.99834061e-01 9.99768198e-01\n",
      " 1.10974371e-01 9.99999285e-01 9.99987483e-01 8.79542470e-01\n",
      " 9.90679562e-01 9.75043595e-01 2.59618729e-01 9.88301218e-01\n",
      " 5.64302690e-03 2.38609869e-06 1.96878891e-03 4.42676730e-02\n",
      " 3.24589834e-02 4.31794196e-01 1.24637010e-02 8.66151333e-01\n",
      " 3.37140888e-01 2.62062907e-01 1.37606519e-03 3.07661034e-02\n",
      " 5.86630404e-01 1.07214982e-02 9.40954328e-01 2.72247940e-01\n",
      " 9.99990344e-01 9.98093903e-01 9.93125677e-01 7.20245065e-04\n",
      " 3.84959183e-03 1.59160215e-02 9.03011635e-02 5.46600938e-01\n",
      " 8.41935217e-01 7.45833576e-01 1.79218762e-02 4.85129654e-02\n",
      " 9.98132765e-01 9.76178885e-01 9.95680809e-01 9.99037266e-01\n",
      " 8.45448732e-01 9.99782145e-01 9.99879599e-01 9.99800980e-01\n",
      " 9.98684347e-01 9.44368362e-01 8.10527980e-01 8.83639872e-01\n",
      " 9.99905944e-01 9.99970078e-01 9.50725973e-01 9.95336950e-01\n",
      " 9.99837756e-01 9.99697208e-01 9.99184668e-01 9.99990940e-01\n",
      " 9.99961376e-01 9.99981880e-01 9.99801338e-01 7.65717983e-01\n",
      " 6.20045424e-01 9.97844458e-01 9.94984150e-01 9.94220614e-01\n",
      " 9.22611535e-01 9.97339666e-01 9.99998689e-01 4.31463838e-01\n",
      " 7.17496395e-01 9.99999881e-01 9.99977469e-01 9.99961138e-01\n",
      " 1.17036402e-01 1.66157484e-01 8.64369035e-01 9.99998212e-01\n",
      " 2.22526431e-01 9.97939885e-01 7.89700806e-01 9.52980638e-01\n",
      " 9.87298787e-01 9.98649061e-01 9.99796569e-01 4.29249369e-03\n",
      " 3.69111985e-01 8.84243727e-01 3.35313715e-02 1.42309934e-01\n",
      " 9.99521494e-01 9.95195210e-01 9.64200199e-01 6.09249212e-02\n",
      " 7.43584692e-01 9.75680113e-01]\n",
      "predict [0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 357 [0/54 (0%)]\tTrain Loss: 0.003329\n",
      "Train Epoch: 357 [8/54 (15%)]\tTrain Loss: 0.093074\n",
      "Train Epoch: 357 [16/54 (30%)]\tTrain Loss: 0.003666\n",
      "Train Epoch: 357 [24/54 (44%)]\tTrain Loss: 0.002724\n",
      "Train Epoch: 357 [32/54 (59%)]\tTrain Loss: 0.001092\n",
      "Train Epoch: 357 [40/54 (74%)]\tTrain Loss: 0.064129\n",
      "Train Epoch: 357 [48/54 (89%)]\tTrain Loss: 0.003860\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.69983341e-08 1.32643804e-01 5.53543456e-02 5.21898746e-01\n",
      " 3.11012596e-01 9.03617547e-06 1.57675445e-01 4.85959738e-01\n",
      " 1.17776385e-02 1.20926008e-01 3.79272201e-03 3.17494106e-03\n",
      " 9.42166604e-04 4.52361564e-05 3.32659739e-03 4.55057261e-06\n",
      " 1.08584791e-05 2.28013933e-01 6.57280207e-01 4.29631062e-02\n",
      " 1.82351808e-03 8.62046599e-01 9.73770678e-01 9.20438409e-01\n",
      " 5.84076624e-03 9.99911547e-01 9.98626947e-01 4.68720227e-01\n",
      " 5.55456042e-01 2.56869532e-02 1.71997286e-02 8.73530865e-01\n",
      " 1.34858373e-03 4.07149585e-08 3.94032613e-05 2.86572101e-03\n",
      " 3.87091801e-04 7.52167404e-01 9.76067036e-03 1.26035407e-01\n",
      " 4.77137603e-03 2.41968036e-02 1.23461783e-02 5.14537387e-04\n",
      " 7.07152858e-03 8.27921648e-03 8.86127710e-01 8.24040696e-02\n",
      " 9.97018576e-01 8.64298940e-01 8.12519252e-01 1.12144915e-06\n",
      " 2.03857446e-04 1.59501215e-05 1.15173741e-03 5.91999444e-04\n",
      " 7.58598745e-01 5.02098817e-03 1.21868763e-03 2.01010480e-04\n",
      " 9.04624641e-01 7.76943743e-01 9.34850216e-01 9.89486814e-01\n",
      " 6.75464198e-02 9.66487944e-01 9.96517181e-01 9.98278856e-01\n",
      " 9.99493361e-01 4.99951482e-01 3.92388612e-01 4.51419383e-01\n",
      " 9.99832153e-01 9.98874485e-01 8.95431757e-01 9.04975235e-01\n",
      " 9.99952435e-01 9.99846220e-01 9.38621640e-01 9.99994636e-01\n",
      " 9.99905348e-01 9.99740779e-01 9.99014378e-01 1.77573606e-01\n",
      " 1.61089495e-01 9.72326159e-01 9.65959728e-01 9.85424697e-01\n",
      " 1.31778613e-01 2.74613529e-01 9.99997258e-01 1.23303480e-01\n",
      " 1.50406182e-01 9.99996543e-01 9.97244596e-01 9.99950171e-01\n",
      " 9.68341250e-04 8.17973316e-02 2.60300100e-01 9.93665457e-01\n",
      " 5.58785871e-02 9.97837365e-01 1.76525991e-02 7.60546684e-01\n",
      " 6.82956338e-01 8.35542619e-01 9.98498201e-01 1.19300594e-03\n",
      " 5.43408208e-02 3.93075138e-01 1.37521094e-03 1.35296300e-01\n",
      " 9.59827006e-01 9.97462034e-01 1.31402045e-01 5.05817235e-02\n",
      " 8.70612383e-01 2.04247549e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 358 [0/54 (0%)]\tTrain Loss: 0.000166\n",
      "Train Epoch: 358 [8/54 (15%)]\tTrain Loss: 0.001219\n",
      "Train Epoch: 358 [16/54 (30%)]\tTrain Loss: 0.019012\n",
      "Train Epoch: 358 [24/54 (44%)]\tTrain Loss: 0.010351\n",
      "Train Epoch: 358 [32/54 (59%)]\tTrain Loss: 0.000670\n",
      "Train Epoch: 358 [40/54 (74%)]\tTrain Loss: 0.005136\n",
      "Train Epoch: 358 [48/54 (89%)]\tTrain Loss: 0.001846\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [6.23118524e-07 2.37019777e-01 3.10973823e-01 9.69871640e-01\n",
      " 9.03780460e-01 1.48757463e-04 5.49331784e-01 9.74890947e-01\n",
      " 4.35480177e-02 3.04035485e-01 3.59018654e-01 8.65070149e-02\n",
      " 4.84496385e-01 1.04120523e-02 2.02382669e-01 3.50752426e-03\n",
      " 4.00309637e-03 1.93329364e-01 8.49407554e-01 3.78742695e-01\n",
      " 4.50757034e-02 9.94905591e-01 9.99554336e-01 9.99686718e-01\n",
      " 8.30562562e-02 9.99998450e-01 9.99995947e-01 9.55048919e-01\n",
      " 8.90522897e-01 4.80817080e-01 5.75453222e-01 9.89238620e-01\n",
      " 3.01755756e-01 8.15215637e-04 2.05562823e-02 1.31859049e-01\n",
      " 1.86793376e-02 9.85580087e-01 1.72703803e-01 7.46376157e-01\n",
      " 6.95000738e-02 4.09045219e-01 5.69120934e-03 8.93066525e-02\n",
      " 4.00165081e-01 1.46887317e-01 9.95590687e-01 4.06355649e-01\n",
      " 9.99990344e-01 9.92616236e-01 9.93220568e-01 5.22340066e-04\n",
      " 1.03580980e-02 1.37535976e-02 2.60173045e-02 5.20262048e-02\n",
      " 9.99563873e-01 3.44542801e-01 2.75647920e-03 1.63519066e-02\n",
      " 9.99583662e-01 9.76680219e-01 9.97697413e-01 9.99296188e-01\n",
      " 9.55183506e-01 9.99937177e-01 9.99898553e-01 9.99924660e-01\n",
      " 9.99998093e-01 7.84994900e-01 7.09817886e-01 9.04959798e-01\n",
      " 9.99992728e-01 9.99981642e-01 9.83131051e-01 9.85166728e-01\n",
      " 9.99958396e-01 9.99861956e-01 9.99685287e-01 9.99999881e-01\n",
      " 9.99999523e-01 9.99997735e-01 9.99974847e-01 8.36991072e-01\n",
      " 6.89675868e-01 9.90269780e-01 9.97738600e-01 9.96990919e-01\n",
      " 9.50339615e-01 9.96606469e-01 9.99996781e-01 9.28208351e-01\n",
      " 8.45301569e-01 1.00000000e+00 9.99946475e-01 9.99998808e-01\n",
      " 7.63720348e-02 5.62594295e-01 7.43277490e-01 9.99999523e-01\n",
      " 3.88898045e-01 9.99318242e-01 7.90196002e-01 9.98517931e-01\n",
      " 9.96619821e-01 9.96071815e-01 9.99999642e-01 1.43549927e-02\n",
      " 1.79387853e-01 9.64440405e-01 5.46498954e-01 5.53952038e-01\n",
      " 9.99740303e-01 9.99947429e-01 7.52392173e-01 1.07862912e-01\n",
      " 9.04422760e-01 9.39966500e-01]\n",
      "predict [0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 359 [0/54 (0%)]\tTrain Loss: 0.044597\n",
      "Train Epoch: 359 [8/54 (15%)]\tTrain Loss: 0.004385\n",
      "Train Epoch: 359 [16/54 (30%)]\tTrain Loss: 0.014706\n",
      "Train Epoch: 359 [24/54 (44%)]\tTrain Loss: 0.003715\n",
      "Train Epoch: 359 [32/54 (59%)]\tTrain Loss: 0.000327\n",
      "Train Epoch: 359 [40/54 (74%)]\tTrain Loss: 0.051851\n",
      "Train Epoch: 359 [48/54 (89%)]\tTrain Loss: 0.004882\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.95913497e-04 9.31636021e-02 3.24648470e-02 9.08886015e-01\n",
      " 1.71050176e-01 4.62853466e-04 1.29260551e-02 9.84610736e-01\n",
      " 2.82342662e-04 1.21061385e-01 1.74707081e-02 1.36382924e-03\n",
      " 7.78391883e-02 4.22084384e-04 1.07017104e-02 2.14394910e-04\n",
      " 6.74231630e-03 1.83724854e-02 1.23514943e-01 1.12036586e-01\n",
      " 2.18229066e-03 7.74659097e-01 9.96464133e-01 9.97808397e-01\n",
      " 2.77526304e-03 9.99992371e-01 9.99868512e-01 4.58329439e-01\n",
      " 2.41213173e-01 2.56190542e-02 1.70317858e-01 9.27022994e-01\n",
      " 5.38647035e-03 8.16379325e-04 3.76595370e-03 6.05927547e-03\n",
      " 5.19878045e-03 8.31094861e-01 4.67182929e-03 8.01334251e-03\n",
      " 1.19688967e-03 6.85210852e-03 9.67685541e-04 2.53297668e-03\n",
      " 1.75751057e-02 1.38201024e-02 9.14757967e-01 6.58168718e-02\n",
      " 9.98381734e-01 9.81158972e-01 9.63723540e-01 1.03245827e-03\n",
      " 1.61677331e-03 2.34583369e-03 3.44444998e-03 3.08385189e-03\n",
      " 9.98495340e-01 2.04658732e-02 7.75859633e-04 2.99858372e-03\n",
      " 9.91791844e-01 8.83368075e-01 9.93807971e-01 9.91308033e-01\n",
      " 6.08773708e-01 9.93714392e-01 9.96971250e-01 9.93344426e-01\n",
      " 9.99158502e-01 1.07441455e-01 3.27955723e-01 5.40428102e-01\n",
      " 9.99165177e-01 9.95215416e-01 4.30188805e-01 9.42171097e-01\n",
      " 9.99984026e-01 9.99938369e-01 9.75180030e-01 9.99998450e-01\n",
      " 9.99603570e-01 9.99912620e-01 9.87543225e-01 5.83514690e-01\n",
      " 3.25232685e-01 9.06165540e-01 9.50610399e-01 9.46991205e-01\n",
      " 1.41087145e-01 9.82053995e-01 9.99782264e-01 6.55350506e-01\n",
      " 7.12541997e-01 9.99994993e-01 9.97316897e-01 9.99996185e-01\n",
      " 3.12167406e-03 8.95554572e-02 5.25939107e-01 9.99943256e-01\n",
      " 6.00352921e-02 9.99474466e-01 4.28244591e-01 9.92502093e-01\n",
      " 9.89852965e-01 8.36796403e-01 9.97886956e-01 3.35772056e-04\n",
      " 1.34101938e-02 6.99084401e-01 3.72538269e-01 2.85676634e-03\n",
      " 8.83902550e-01 9.96870458e-01 1.82035863e-01 1.62065309e-03\n",
      " 5.88366032e-01 5.34630895e-01]\n",
      "predict [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 360 [0/54 (0%)]\tTrain Loss: 0.001037\n",
      "Train Epoch: 360 [8/54 (15%)]\tTrain Loss: 0.073407\n",
      "Train Epoch: 360 [16/54 (30%)]\tTrain Loss: 0.013500\n",
      "Train Epoch: 360 [24/54 (44%)]\tTrain Loss: 0.002910\n",
      "Train Epoch: 360 [32/54 (59%)]\tTrain Loss: 0.017569\n",
      "Train Epoch: 360 [40/54 (74%)]\tTrain Loss: 0.002918\n",
      "Train Epoch: 360 [48/54 (89%)]\tTrain Loss: 0.012511\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.32932864e-05 9.23030972e-01 7.66139746e-01 9.44845438e-01\n",
      " 1.95543900e-01 1.62518365e-04 6.79575205e-01 9.50157285e-01\n",
      " 2.06454750e-03 5.79224527e-01 5.43540306e-02 1.96752092e-03\n",
      " 1.30729442e-02 6.51138881e-03 2.51929760e-01 2.59584835e-04\n",
      " 2.08054995e-03 1.66848868e-01 3.44986498e-01 8.43871608e-02\n",
      " 3.29212472e-03 9.69568312e-01 9.75835979e-01 9.99789774e-01\n",
      " 5.29271876e-03 9.99938369e-01 9.99999285e-01 7.76849627e-01\n",
      " 4.73245621e-01 1.02935828e-01 2.32389703e-01 9.84198570e-01\n",
      " 3.42389971e-01 3.31339857e-06 9.69597677e-05 2.70825550e-02\n",
      " 9.44148749e-03 9.84498322e-01 8.68978153e-04 7.81903565e-02\n",
      " 2.61084503e-03 5.83525747e-02 8.75514757e-04 9.93822590e-02\n",
      " 1.86367393e-01 2.65507661e-02 9.72847700e-01 1.31727904e-01\n",
      " 9.99999404e-01 9.96191859e-01 9.99576628e-01 1.00804470e-03\n",
      " 4.02112585e-03 2.46717222e-03 2.34472449e-03 1.95731339e-03\n",
      " 9.99975920e-01 1.38458032e-02 2.92862905e-03 5.65622859e-02\n",
      " 9.97066915e-01 9.53258038e-01 9.94175494e-01 9.98771966e-01\n",
      " 9.68708277e-01 9.99999404e-01 9.99989033e-01 9.99976873e-01\n",
      " 9.99989629e-01 9.98594820e-01 5.04485250e-01 6.99891567e-01\n",
      " 9.99999881e-01 9.99998093e-01 9.99944687e-01 9.83714163e-01\n",
      " 9.99999046e-01 9.99996066e-01 9.99628186e-01 1.00000000e+00\n",
      " 9.99999404e-01 9.99999642e-01 9.99998927e-01 4.42895830e-01\n",
      " 3.26165736e-01 9.96278703e-01 9.96184647e-01 9.98098075e-01\n",
      " 6.09646797e-01 8.53867352e-01 9.99999046e-01 9.81764615e-01\n",
      " 9.34443653e-01 1.00000000e+00 9.99797165e-01 9.99999285e-01\n",
      " 3.47058102e-02 9.43539366e-02 6.99443996e-01 9.99607861e-01\n",
      " 1.73519570e-02 9.99967813e-01 9.46216062e-02 9.99896765e-01\n",
      " 9.99899030e-01 9.98456478e-01 9.99999881e-01 6.71996782e-03\n",
      " 1.82945691e-02 9.65255201e-01 3.71845812e-01 1.10663645e-01\n",
      " 9.99514699e-01 9.98786271e-01 5.28774917e-01 3.09038386e-02\n",
      " 8.91462147e-01 8.08076501e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "vote_pred [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 45 TN= 43 FN= 13 FP= 17\n",
      "TP+FP 62\n",
      "precision 0.7258064516129032\n",
      "recall 0.7758620689655172\n",
      "F1 0.7500000000000001\n",
      "acc 0.7457627118644068\n",
      "AUCp 0.746264367816092\n",
      "AUC 0.8083333333333333\n",
      "\n",
      " The epoch is 360, average recall: 0.7759, average precision: 0.7258,average F1: 0.7500, average accuracy: 0.7458, average AUC: 0.8083\n",
      "Train Epoch: 361 [0/54 (0%)]\tTrain Loss: 0.001045\n",
      "Train Epoch: 361 [8/54 (15%)]\tTrain Loss: 0.001084\n",
      "Train Epoch: 361 [16/54 (30%)]\tTrain Loss: 0.001465\n",
      "Train Epoch: 361 [24/54 (44%)]\tTrain Loss: 0.000331\n",
      "Train Epoch: 361 [32/54 (59%)]\tTrain Loss: 0.027442\n",
      "Train Epoch: 361 [40/54 (74%)]\tTrain Loss: 0.000212\n",
      "Train Epoch: 361 [48/54 (89%)]\tTrain Loss: 0.000676\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.10736764e-04 9.51383591e-01 4.48620081e-01 9.99896169e-01\n",
      " 9.44635510e-01 7.28275263e-05 5.69704473e-01 9.99885201e-01\n",
      " 8.95277131e-03 9.96346891e-01 9.99596894e-01 5.44664264e-02\n",
      " 9.19498801e-01 9.21226674e-05 8.57825205e-03 3.94991748e-02\n",
      " 5.08021235e-01 1.98240981e-01 9.96845305e-01 9.94526565e-01\n",
      " 5.48805892e-01 9.99960780e-01 9.99972582e-01 9.99999404e-01\n",
      " 2.34334052e-01 1.00000000e+00 1.00000000e+00 9.99972343e-01\n",
      " 9.92995560e-01 7.86772549e-01 9.96806383e-01 9.98935759e-01\n",
      " 9.68169749e-01 2.60847032e-01 9.07764137e-02 9.95137155e-01\n",
      " 9.98090208e-01 9.99989152e-01 2.31434569e-01 9.83960450e-01\n",
      " 1.42191112e-01 5.35085380e-01 2.13074684e-02 7.04686463e-01\n",
      " 8.36071491e-01 4.77402918e-02 9.98999059e-01 4.46255326e-01\n",
      " 9.99999881e-01 9.99924421e-01 9.99462783e-01 9.09761786e-02\n",
      " 1.35866925e-02 2.13087909e-02 3.10190380e-01 1.43312505e-02\n",
      " 9.99999881e-01 9.46929395e-01 2.88689770e-02 9.97763053e-02\n",
      " 9.99998093e-01 9.99464214e-01 9.99971986e-01 9.99974251e-01\n",
      " 9.80901182e-01 9.99999881e-01 9.99999762e-01 9.99999523e-01\n",
      " 1.00000000e+00 9.97936130e-01 6.42041147e-01 9.22698259e-01\n",
      " 1.00000000e+00 1.00000000e+00 9.99999762e-01 9.99696493e-01\n",
      " 9.99999285e-01 9.99990821e-01 9.99816239e-01 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 9.99975204e-01 9.99311566e-01\n",
      " 9.98916388e-01 9.99967337e-01 9.99349177e-01 9.99682188e-01\n",
      " 9.97479856e-01 9.99831676e-01 1.00000000e+00 9.99455273e-01\n",
      " 9.99175966e-01 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 9.09633756e-01 9.50062990e-01 9.99955416e-01 1.00000000e+00\n",
      " 9.33840930e-01 9.99994874e-01 9.97947514e-01 1.00000000e+00\n",
      " 9.99999404e-01 9.99975204e-01 1.00000000e+00 2.54308492e-01\n",
      " 8.55185866e-01 9.99975324e-01 9.99950528e-01 7.19940424e-01\n",
      " 9.99999762e-01 9.99999881e-01 9.94470239e-01 9.29430068e-01\n",
      " 9.99496222e-01 9.99989390e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 362 [0/54 (0%)]\tTrain Loss: 0.018835\n",
      "Train Epoch: 362 [8/54 (15%)]\tTrain Loss: 0.023226\n",
      "Train Epoch: 362 [16/54 (30%)]\tTrain Loss: 0.000105\n",
      "Train Epoch: 362 [24/54 (44%)]\tTrain Loss: 0.128384\n",
      "Train Epoch: 362 [32/54 (59%)]\tTrain Loss: 0.096277\n",
      "Train Epoch: 362 [40/54 (74%)]\tTrain Loss: 0.000171\n",
      "Train Epoch: 362 [48/54 (89%)]\tTrain Loss: 0.032232\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.42856804e-03 9.27145541e-01 5.34213006e-01 9.50248539e-01\n",
      " 5.69231451e-01 6.65134424e-03 7.11848199e-01 8.10466647e-01\n",
      " 3.78739536e-02 2.56702363e-01 3.94972265e-02 5.55325449e-02\n",
      " 5.76641120e-04 6.68218313e-03 3.21342021e-01 2.04662370e-04\n",
      " 1.28178626e-05 1.82838008e-01 2.29922280e-01 8.03110301e-02\n",
      " 1.64972488e-02 9.02956367e-01 9.59234238e-01 9.99218106e-01\n",
      " 7.10978806e-02 9.98693287e-01 9.99831676e-01 4.41596359e-01\n",
      " 4.97612149e-01 5.22832930e-01 8.54783356e-01 9.98974442e-01\n",
      " 9.79635835e-01 3.82540009e-08 1.04337814e-05 4.92765643e-02\n",
      " 1.66010000e-02 6.40749574e-01 1.20664490e-02 4.44586664e-01\n",
      " 1.16078243e-01 1.35761797e-01 1.41170230e-02 5.38244210e-02\n",
      " 1.70073554e-01 6.35712147e-01 9.95224059e-01 8.98791313e-01\n",
      " 9.99999642e-01 9.86253560e-01 9.99913812e-01 4.00342033e-05\n",
      " 3.20458785e-03 2.64435634e-02 1.34109303e-01 4.83392645e-03\n",
      " 9.98704791e-01 1.11386314e-01 8.35372414e-03 4.70643863e-02\n",
      " 9.99101758e-01 8.75771761e-01 9.94901776e-01 9.98816729e-01\n",
      " 9.92688715e-01 9.99849558e-01 9.98321831e-01 9.99714673e-01\n",
      " 9.99996543e-01 9.96107638e-01 9.36604023e-01 9.74080086e-01\n",
      " 9.99989867e-01 9.99968052e-01 9.99990821e-01 9.85154331e-01\n",
      " 9.99998808e-01 9.99994397e-01 9.99080539e-01 9.99999762e-01\n",
      " 9.99992371e-01 9.99970436e-01 9.99995828e-01 8.84641707e-01\n",
      " 6.55595601e-01 9.99627709e-01 9.97314155e-01 9.98664260e-01\n",
      " 1.89221323e-01 2.56501939e-02 9.94275272e-01 8.10831904e-01\n",
      " 7.74226248e-01 9.99997735e-01 9.77645159e-01 9.99947906e-01\n",
      " 2.24926081e-02 3.21918368e-01 4.92469192e-01 9.41400588e-01\n",
      " 8.50361958e-02 9.99764144e-01 2.11111940e-02 9.24213886e-01\n",
      " 9.63763356e-01 9.96036947e-01 9.99999404e-01 1.54726878e-02\n",
      " 2.98288688e-02 9.16082025e-01 1.95163097e-02 6.23513460e-02\n",
      " 3.31653446e-01 2.36821547e-01 2.64375340e-02 7.21374303e-02\n",
      " 9.45833445e-01 4.68755901e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 363 [0/54 (0%)]\tTrain Loss: 0.000406\n",
      "Train Epoch: 363 [8/54 (15%)]\tTrain Loss: 0.001862\n",
      "Train Epoch: 363 [16/54 (30%)]\tTrain Loss: 0.002215\n",
      "Train Epoch: 363 [24/54 (44%)]\tTrain Loss: 0.002623\n",
      "Train Epoch: 363 [32/54 (59%)]\tTrain Loss: 0.008339\n",
      "Train Epoch: 363 [40/54 (74%)]\tTrain Loss: 0.011170\n",
      "Train Epoch: 363 [48/54 (89%)]\tTrain Loss: 0.007447\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [7.00729201e-04 5.38241088e-01 2.71673948e-01 9.86711085e-01\n",
      " 8.70676696e-01 1.66021730e-03 4.71277714e-01 9.56921697e-01\n",
      " 3.68839246e-03 3.53550792e-01 5.98499954e-01 1.90630881e-03\n",
      " 5.76502383e-01 1.92150902e-02 5.62077463e-02 2.61933007e-03\n",
      " 2.15301439e-02 4.81776334e-02 8.28338027e-01 6.60759032e-01\n",
      " 8.93868655e-02 9.52314615e-01 9.99395370e-01 9.99996543e-01\n",
      " 5.87835535e-02 9.99995589e-01 9.99999762e-01 8.37790191e-01\n",
      " 7.00216711e-01 2.62924939e-01 1.72267839e-01 9.71204281e-01\n",
      " 2.85051286e-01 1.05737103e-02 1.17551433e-02 2.64589846e-01\n",
      " 1.50228307e-01 8.94633412e-01 3.26092429e-02 6.28832042e-01\n",
      " 6.82565272e-02 6.46279007e-02 3.73960444e-04 7.08674937e-02\n",
      " 6.13115370e-01 2.20158305e-02 9.73210812e-01 2.10481897e-01\n",
      " 9.99713361e-01 9.99175131e-01 9.80009258e-01 1.70942321e-02\n",
      " 3.29882069e-03 8.49314779e-02 3.32804114e-01 2.89860088e-02\n",
      " 9.95068073e-01 5.73263288e-01 7.91750324e-04 1.23886019e-02\n",
      " 9.99961138e-01 9.94051993e-01 9.97203946e-01 9.99137223e-01\n",
      " 9.93033528e-01 9.99398470e-01 9.99630809e-01 9.99802649e-01\n",
      " 9.99953270e-01 6.75388873e-01 8.81255269e-01 9.87294018e-01\n",
      " 9.99998569e-01 9.99992371e-01 9.96622443e-01 9.46154535e-01\n",
      " 9.99974251e-01 9.99912024e-01 9.97798502e-01 9.99998689e-01\n",
      " 9.99934673e-01 9.99998093e-01 9.99591887e-01 3.57109904e-01\n",
      " 8.45309734e-01 9.94321823e-01 9.93345976e-01 9.99079466e-01\n",
      " 9.55674946e-01 9.74436820e-01 9.99998808e-01 9.10066664e-01\n",
      " 4.46647763e-01 1.00000000e+00 9.99864459e-01 1.00000000e+00\n",
      " 1.53929070e-01 2.92428613e-01 9.94913459e-01 9.99990106e-01\n",
      " 4.13325101e-01 9.99745309e-01 7.48897672e-01 9.99029994e-01\n",
      " 9.97300684e-01 9.94977653e-01 1.00000000e+00 2.38566268e-02\n",
      " 1.08662099e-01 9.97953653e-01 9.83566880e-01 6.57742858e-01\n",
      " 9.99193013e-01 9.95675027e-01 5.96258938e-01 7.89008960e-02\n",
      " 9.11799252e-01 9.95276093e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 364 [0/54 (0%)]\tTrain Loss: 0.011291\n",
      "Train Epoch: 364 [8/54 (15%)]\tTrain Loss: 0.000187\n",
      "Train Epoch: 364 [16/54 (30%)]\tTrain Loss: 0.001819\n",
      "Train Epoch: 364 [24/54 (44%)]\tTrain Loss: 0.000351\n",
      "Train Epoch: 364 [32/54 (59%)]\tTrain Loss: 0.000223\n",
      "Train Epoch: 364 [40/54 (74%)]\tTrain Loss: 0.001725\n",
      "Train Epoch: 364 [48/54 (89%)]\tTrain Loss: 0.022367\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.35625838e-04 9.93170977e-01 9.06388342e-01 9.83730137e-01\n",
      " 4.72535044e-01 2.85890093e-03 7.82597542e-01 9.98110533e-01\n",
      " 3.01923417e-02 7.34621108e-01 4.15278435e-01 1.83439441e-03\n",
      " 3.27602625e-02 3.26958694e-03 3.62340242e-01 5.13380917e-04\n",
      " 6.11243397e-03 2.80838698e-01 9.33777809e-01 5.33655405e-01\n",
      " 1.00687472e-02 9.99714077e-01 9.99917030e-01 9.99999166e-01\n",
      " 4.36809361e-02 9.99999881e-01 9.99999881e-01 9.32943821e-01\n",
      " 6.86144948e-01 5.84706128e-01 9.14740443e-01 9.98763084e-01\n",
      " 8.36146176e-01 1.02453996e-04 2.17911060e-04 4.62213419e-02\n",
      " 4.64398228e-02 9.92784262e-01 1.14328153e-02 7.20229268e-01\n",
      " 1.55291840e-01 2.16761410e-01 9.83727444e-03 9.60097834e-02\n",
      " 5.12117445e-01 1.11368299e-01 9.98904228e-01 9.52195823e-01\n",
      " 9.99999642e-01 9.89728153e-01 9.95870650e-01 2.41237599e-03\n",
      " 6.59641984e-04 1.73579734e-02 2.07842439e-02 4.04706458e-03\n",
      " 9.97564197e-01 1.53134570e-01 1.44411472e-03 4.26477082e-02\n",
      " 9.99882340e-01 9.74891841e-01 9.97723877e-01 9.99558270e-01\n",
      " 9.99574959e-01 9.99989629e-01 9.99982953e-01 9.99994993e-01\n",
      " 9.99997139e-01 9.63337839e-01 9.20152307e-01 9.83019173e-01\n",
      " 9.99999881e-01 9.99996066e-01 9.98776495e-01 9.93344545e-01\n",
      " 1.00000000e+00 9.99999881e-01 9.99986649e-01 1.00000000e+00\n",
      " 9.99999881e-01 9.99999881e-01 9.99944806e-01 7.15645313e-01\n",
      " 9.74480629e-01 9.99547780e-01 9.99682784e-01 9.99668360e-01\n",
      " 5.45657039e-01 9.79499161e-01 9.99980927e-01 9.53346550e-01\n",
      " 9.63751972e-01 1.00000000e+00 9.99979615e-01 1.00000000e+00\n",
      " 3.07372749e-01 3.66385132e-01 9.92132366e-01 9.99995589e-01\n",
      " 9.58796442e-02 9.99997377e-01 1.09023571e-01 9.71819043e-01\n",
      " 9.96274114e-01 9.98673558e-01 1.00000000e+00 1.65830192e-03\n",
      " 1.71077605e-02 9.91259515e-01 8.15280676e-01 1.02673233e-01\n",
      " 9.93483365e-01 9.99809206e-01 7.37060428e-01 4.63318020e-01\n",
      " 9.72745597e-01 9.96501565e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 365 [0/54 (0%)]\tTrain Loss: 0.000625\n",
      "Train Epoch: 365 [8/54 (15%)]\tTrain Loss: 0.000239\n",
      "Train Epoch: 365 [16/54 (30%)]\tTrain Loss: 0.001471\n",
      "Train Epoch: 365 [24/54 (44%)]\tTrain Loss: 0.000622\n",
      "Train Epoch: 365 [32/54 (59%)]\tTrain Loss: 0.011294\n",
      "Train Epoch: 365 [40/54 (74%)]\tTrain Loss: 0.000643\n",
      "Train Epoch: 365 [48/54 (89%)]\tTrain Loss: 0.000714\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.10407798e-03 9.86750782e-01 4.15995896e-01 9.98764277e-01\n",
      " 8.39186907e-01 3.28038307e-03 3.58428240e-01 9.99648333e-01\n",
      " 8.10245275e-02 7.59030402e-01 8.17068577e-01 9.11190175e-03\n",
      " 4.59633917e-01 4.96195804e-04 1.86010763e-01 2.59139983e-04\n",
      " 6.16569188e-04 4.51437756e-02 9.32391822e-01 1.37418494e-01\n",
      " 9.89651214e-03 9.99314666e-01 9.99936938e-01 9.99992251e-01\n",
      " 5.34180328e-02 1.00000000e+00 9.99998689e-01 8.99289668e-01\n",
      " 8.45493555e-01 6.44922912e-01 9.00847793e-01 9.99494791e-01\n",
      " 9.45437431e-01 8.27905533e-05 2.45743606e-04 9.78583917e-02\n",
      " 4.97514367e-01 9.97444272e-01 6.67149993e-03 6.18104041e-01\n",
      " 7.45523721e-02 1.75277278e-01 4.48737899e-03 8.02195370e-02\n",
      " 4.65787977e-01 6.62774920e-01 9.99827981e-01 9.51176882e-01\n",
      " 9.99999881e-01 9.97475445e-01 9.99573529e-01 1.30069302e-03\n",
      " 2.10933969e-03 1.26155958e-01 2.35071927e-01 4.40113433e-03\n",
      " 9.99557912e-01 1.48673698e-01 8.68450443e-04 1.13200434e-02\n",
      " 9.99923944e-01 9.14622068e-01 9.93759930e-01 9.98623967e-01\n",
      " 9.99709547e-01 9.99990940e-01 9.99995112e-01 9.99998689e-01\n",
      " 9.99999762e-01 9.01991963e-01 9.54323530e-01 9.94430244e-01\n",
      " 9.99999762e-01 9.99972701e-01 9.98666883e-01 9.91978288e-01\n",
      " 1.00000000e+00 9.99999881e-01 9.99864936e-01 1.00000000e+00\n",
      " 1.00000000e+00 9.99999881e-01 9.99995232e-01 5.78370750e-01\n",
      " 9.16529119e-01 9.99159098e-01 9.99273717e-01 9.99542475e-01\n",
      " 5.41186571e-01 9.79809642e-01 9.99961019e-01 9.89045620e-01\n",
      " 9.86113012e-01 1.00000000e+00 9.99981284e-01 1.00000000e+00\n",
      " 1.92742750e-01 1.70285925e-01 9.31581557e-01 9.99993563e-01\n",
      " 2.51036230e-02 9.99996305e-01 4.29786071e-02 9.96467233e-01\n",
      " 9.99787033e-01 9.99820530e-01 1.00000000e+00 2.83346162e-03\n",
      " 1.75386686e-02 9.99230027e-01 8.96786988e-01 3.98234911e-02\n",
      " 9.88368988e-01 9.99938965e-01 8.02832127e-01 3.76995832e-01\n",
      " 8.86363029e-01 9.27515507e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 366 [0/54 (0%)]\tTrain Loss: 0.000187\n",
      "Train Epoch: 366 [8/54 (15%)]\tTrain Loss: 0.000681\n",
      "Train Epoch: 366 [16/54 (30%)]\tTrain Loss: 0.000923\n",
      "Train Epoch: 366 [24/54 (44%)]\tTrain Loss: 0.001020\n",
      "Train Epoch: 366 [32/54 (59%)]\tTrain Loss: 0.000112\n",
      "Train Epoch: 366 [40/54 (74%)]\tTrain Loss: 0.002331\n",
      "Train Epoch: 366 [48/54 (89%)]\tTrain Loss: 0.000975\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [0.00312139 0.99950337 0.99876738 0.99910152 0.99834871 0.02626663\n",
      " 0.99528128 0.99994087 0.07687961 0.91224122 0.77633363 0.35600734\n",
      " 0.48986876 0.86065447 0.99833763 0.5591017  0.91276741 0.48200068\n",
      " 0.88456112 0.29008958 0.01236845 0.99993467 0.99996865 0.99963212\n",
      " 0.43210217 1.         0.99999988 0.95299661 0.98676699 0.99483216\n",
      " 0.99753392 0.99962103 0.73665321 0.00235967 0.01483878 0.98128486\n",
      " 0.84926164 0.99974161 0.41983745 0.98302162 0.93245596 0.77237725\n",
      " 0.08527228 0.99815303 0.19098061 0.08442695 0.99272209 0.5809074\n",
      " 0.99998879 0.98822695 0.99175864 0.08465693 0.06875888 0.50820112\n",
      " 0.04393756 0.13465059 0.99272341 0.82444239 0.2000972  0.88818657\n",
      " 0.99877769 0.86936319 0.98622185 0.99742788 0.99985063 1.\n",
      " 1.         0.99999976 0.99999964 0.97813147 0.45832342 0.76172638\n",
      " 1.         0.99999642 0.99975795 0.85374552 1.         1.\n",
      " 0.99999082 1.         1.         0.99999988 0.99999583 0.21042758\n",
      " 0.82149822 0.98402566 0.99783534 0.99608213 0.53853381 0.99983764\n",
      " 0.99999166 0.99777263 0.99346101 1.         0.99999869 1.\n",
      " 0.19971704 0.74526477 0.83151728 1.         0.03871314 0.99984086\n",
      " 0.17128685 0.99822897 0.99356478 0.99944216 1.         0.07120562\n",
      " 0.97612315 0.98704416 0.98432308 0.97689819 0.9999963  0.99999475\n",
      " 0.99387413 0.45658997 0.9986589  0.99979347]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 367 [0/54 (0%)]\tTrain Loss: 0.001798\n",
      "Train Epoch: 367 [8/54 (15%)]\tTrain Loss: 0.009181\n",
      "Train Epoch: 367 [16/54 (30%)]\tTrain Loss: 0.002256\n",
      "Train Epoch: 367 [24/54 (44%)]\tTrain Loss: 0.002387\n",
      "Train Epoch: 367 [32/54 (59%)]\tTrain Loss: 0.012869\n",
      "Train Epoch: 367 [40/54 (74%)]\tTrain Loss: 0.014426\n",
      "Train Epoch: 367 [48/54 (89%)]\tTrain Loss: 0.001777\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.60047447e-05 9.53433454e-01 5.75252593e-01 9.67824161e-01\n",
      " 3.52738261e-01 8.87925911e-04 2.95930117e-01 5.89271605e-01\n",
      " 7.25398771e-03 4.46565777e-01 9.31921959e-01 3.61350924e-02\n",
      " 9.35961753e-02 5.21806069e-03 6.72137380e-01 5.17520763e-04\n",
      " 2.56305910e-03 5.15419394e-02 8.08778346e-01 2.01937124e-01\n",
      " 7.69186066e-03 9.99505043e-01 9.98731911e-01 9.99958515e-01\n",
      " 6.94691911e-02 9.99999881e-01 9.99999881e-01 8.65597367e-01\n",
      " 5.64534724e-01 4.35118526e-01 1.34062707e-01 9.15413022e-01\n",
      " 5.76360047e-01 8.00898397e-06 8.48786003e-05 1.61273535e-02\n",
      " 6.98836846e-03 9.94044244e-01 2.18410022e-03 1.56413883e-01\n",
      " 1.01150973e-02 5.47968491e-04 6.30192953e-05 1.56562105e-01\n",
      " 1.49607742e-02 3.08859348e-03 8.84702265e-01 2.78718650e-01\n",
      " 9.99984622e-01 8.54892492e-01 9.89889324e-01 3.81739635e-04\n",
      " 3.42545356e-03 8.20638984e-03 1.21676037e-02 7.07447529e-03\n",
      " 9.99569237e-01 3.11644990e-02 3.97302676e-04 7.32747978e-03\n",
      " 9.96108353e-01 7.21840203e-01 9.21928406e-01 9.78777170e-01\n",
      " 9.99832034e-01 9.99969363e-01 9.99987602e-01 9.99999642e-01\n",
      " 9.99999762e-01 8.55537176e-01 2.96818107e-01 7.88420558e-01\n",
      " 9.99998331e-01 9.99989748e-01 9.99998808e-01 3.13635051e-01\n",
      " 1.00000000e+00 9.99999881e-01 9.97692347e-01 1.00000000e+00\n",
      " 9.99999881e-01 9.99042332e-01 9.99978423e-01 5.46648316e-02\n",
      " 6.56027019e-01 9.89243627e-01 9.97185528e-01 9.94976401e-01\n",
      " 1.65801957e-01 3.75615418e-01 9.99905705e-01 8.87962997e-01\n",
      " 7.64683723e-01 1.00000000e+00 9.99902844e-01 9.99995828e-01\n",
      " 3.47586139e-03 7.59867951e-02 9.46267545e-01 9.99972701e-01\n",
      " 6.13760436e-04 9.98171449e-01 3.41386721e-02 9.99942303e-01\n",
      " 9.98348236e-01 9.97832835e-01 1.00000000e+00 3.43815540e-04\n",
      " 2.64955983e-02 9.97136831e-01 2.34351065e-02 8.33406020e-03\n",
      " 9.99911070e-01 9.99640942e-01 3.94378603e-01 1.97253630e-01\n",
      " 8.64149451e-01 6.91564918e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 368 [0/54 (0%)]\tTrain Loss: 0.052560\n",
      "Train Epoch: 368 [8/54 (15%)]\tTrain Loss: 0.013507\n",
      "Train Epoch: 368 [16/54 (30%)]\tTrain Loss: 0.000420\n",
      "Train Epoch: 368 [24/54 (44%)]\tTrain Loss: 0.021884\n",
      "Train Epoch: 368 [32/54 (59%)]\tTrain Loss: 0.021694\n",
      "Train Epoch: 368 [40/54 (74%)]\tTrain Loss: 0.022451\n",
      "Train Epoch: 368 [48/54 (89%)]\tTrain Loss: 0.002161\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [4.64205805e-05 9.98169303e-01 9.98962402e-01 5.82445383e-01\n",
      " 1.04494452e-01 2.66055722e-04 9.11311328e-01 1.39105126e-01\n",
      " 1.38814030e-02 8.80362213e-01 2.65684366e-01 1.23204701e-01\n",
      " 3.92686483e-03 4.36836993e-03 9.13261697e-02 4.85876881e-05\n",
      " 1.13667676e-03 1.50964573e-01 4.63674545e-01 1.15667894e-01\n",
      " 4.24851291e-03 9.89307582e-01 9.77216125e-01 9.93506670e-01\n",
      " 2.29105547e-01 9.99933839e-01 9.95857894e-01 8.50724757e-01\n",
      " 4.92434412e-01 4.23191130e-01 2.85244554e-01 8.85796309e-01\n",
      " 2.46310413e-01 1.06972911e-08 1.88353733e-05 5.19127212e-02\n",
      " 9.27269552e-03 8.92358601e-01 3.10674799e-03 5.43254577e-02\n",
      " 7.68779963e-03 1.23646611e-03 1.69959734e-03 7.29134232e-02\n",
      " 2.10989062e-02 4.68096510e-03 7.37938046e-01 8.17586482e-02\n",
      " 9.95431423e-01 7.30429113e-01 8.24999154e-01 3.33672801e-06\n",
      " 5.45026967e-03 1.71727012e-03 7.83929776e-04 6.46826869e-04\n",
      " 9.39386427e-01 7.32034743e-02 4.75036763e-02 3.31833474e-02\n",
      " 7.21423686e-01 3.51378918e-01 2.83981264e-01 9.52853084e-01\n",
      " 8.70513976e-01 9.99684572e-01 9.99909282e-01 9.99029994e-01\n",
      " 9.96519923e-01 2.43183255e-01 2.72503674e-01 6.72681093e-01\n",
      " 9.85635996e-01 9.70003426e-01 9.97574747e-01 8.08116272e-02\n",
      " 1.00000000e+00 1.00000000e+00 9.96094048e-01 9.99552786e-01\n",
      " 9.99822676e-01 9.82177377e-01 9.99495864e-01 3.44016254e-01\n",
      " 8.49071026e-01 9.71071422e-01 9.91231620e-01 9.96348560e-01\n",
      " 7.29089603e-02 1.32825393e-02 9.98398483e-01 1.77639395e-01\n",
      " 3.82816553e-01 9.99992490e-01 9.97046173e-01 9.99891639e-01\n",
      " 1.78265162e-02 5.83804585e-02 5.16842604e-01 9.79754865e-01\n",
      " 1.94285385e-04 8.59881580e-01 3.96963283e-02 8.80032122e-01\n",
      " 4.85125870e-01 5.88705838e-01 9.99830842e-01 1.30823744e-03\n",
      " 4.34584282e-02 8.02420259e-01 3.73467017e-04 1.43737476e-02\n",
      " 8.73630226e-01 9.43625510e-01 9.54303797e-03 8.46908867e-01\n",
      " 7.61741281e-01 1.37009948e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 369 [0/54 (0%)]\tTrain Loss: 0.042196\n",
      "Train Epoch: 369 [8/54 (15%)]\tTrain Loss: 0.078012\n",
      "Train Epoch: 369 [16/54 (30%)]\tTrain Loss: 0.010930\n",
      "Train Epoch: 369 [24/54 (44%)]\tTrain Loss: 0.000609\n",
      "Train Epoch: 369 [32/54 (59%)]\tTrain Loss: 0.007589\n",
      "Train Epoch: 369 [40/54 (74%)]\tTrain Loss: 0.010067\n",
      "Train Epoch: 369 [48/54 (89%)]\tTrain Loss: 0.008645\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.46632951e-05 7.80685961e-01 1.67805463e-01 7.79812634e-01\n",
      " 2.39892811e-01 2.66996940e-04 5.50318137e-02 5.25166392e-01\n",
      " 5.60166594e-03 9.90343571e-01 2.61031717e-01 3.80733260e-03\n",
      " 9.08651575e-02 9.03713168e-04 2.70137247e-02 4.40903299e-04\n",
      " 2.95666535e-03 3.19214799e-02 6.76387995e-02 2.04297945e-01\n",
      " 8.60369578e-03 9.44122434e-01 9.89747643e-01 9.99731958e-01\n",
      " 7.84569681e-02 9.99988317e-01 9.99892950e-01 7.36302137e-01\n",
      " 3.18425372e-02 2.81827282e-02 7.33419508e-02 8.06344926e-01\n",
      " 1.23328865e-01 5.73291527e-06 2.68370441e-05 2.25821566e-02\n",
      " 8.38746224e-03 9.08985853e-01 9.29965579e-04 1.96248055e-01\n",
      " 1.65269768e-03 8.30286648e-03 1.13179631e-04 1.56972813e-03\n",
      " 2.84087546e-02 5.75509807e-03 9.40438092e-01 3.05357486e-01\n",
      " 9.99672413e-01 8.78526449e-01 6.41597509e-01 1.85180703e-04\n",
      " 2.87565473e-03 1.98771362e-03 2.54939217e-03 1.08178530e-04\n",
      " 7.83611774e-01 2.50023813e-03 5.74788824e-03 1.31993238e-02\n",
      " 9.68916178e-01 5.95314443e-01 7.54562974e-01 9.73783016e-01\n",
      " 6.96731567e-01 9.80591834e-01 9.98989165e-01 9.99296546e-01\n",
      " 2.88801461e-01 1.96098313e-02 1.59846723e-01 7.07031190e-01\n",
      " 9.98380780e-01 8.53172183e-01 9.53399658e-01 2.01613888e-01\n",
      " 9.99896407e-01 9.99846935e-01 9.98949826e-01 9.99937773e-01\n",
      " 9.99783933e-01 9.87830698e-01 9.99257863e-01 5.71452618e-01\n",
      " 9.76985991e-01 9.85966146e-01 9.93170381e-01 9.96817589e-01\n",
      " 2.79926717e-01 2.74822593e-01 9.99955058e-01 3.33849825e-02\n",
      " 6.29657134e-02 9.99999881e-01 9.92178798e-01 9.99970198e-01\n",
      " 4.23656628e-02 8.52396339e-02 8.68509173e-01 9.99991894e-01\n",
      " 3.62406415e-03 9.99349654e-01 2.83523463e-02 2.88561523e-01\n",
      " 8.93287063e-01 7.71201670e-01 9.98549044e-01 1.32585864e-03\n",
      " 3.47927399e-02 9.72201347e-01 4.02300507e-01 2.17416626e-03\n",
      " 8.90572786e-01 8.80688369e-01 1.09703310e-01 4.65574801e-01\n",
      " 7.69743025e-01 6.90109432e-01]\n",
      "predict [0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "Train Epoch: 370 [0/54 (0%)]\tTrain Loss: 0.000111\n",
      "Train Epoch: 370 [8/54 (15%)]\tTrain Loss: 0.002085\n",
      "Train Epoch: 370 [16/54 (30%)]\tTrain Loss: 0.001385\n",
      "Train Epoch: 370 [24/54 (44%)]\tTrain Loss: 0.000342\n",
      "Train Epoch: 370 [32/54 (59%)]\tTrain Loss: 0.000656\n",
      "Train Epoch: 370 [40/54 (74%)]\tTrain Loss: 0.002707\n",
      "Train Epoch: 370 [48/54 (89%)]\tTrain Loss: 0.007091\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.58777166e-05 7.79109895e-01 7.08238110e-02 9.63424027e-01\n",
      " 6.14129961e-01 1.60894459e-04 6.65248781e-02 9.70759869e-01\n",
      " 9.40569118e-03 7.61622965e-01 8.51289570e-01 5.58407381e-02\n",
      " 7.02405214e-01 7.12184643e-04 5.53794742e-01 2.90202722e-03\n",
      " 8.42793100e-03 1.52850479e-01 2.79574115e-02 3.39267589e-03\n",
      " 5.63732814e-03 9.84684289e-01 9.92293239e-01 9.98661757e-01\n",
      " 8.81332755e-02 9.99983072e-01 9.99982953e-01 9.69545543e-01\n",
      " 4.95393455e-01 8.66306424e-01 9.86049056e-01 9.80420351e-01\n",
      " 9.31086838e-01 4.57229413e-04 1.01512054e-03 3.76749992e-01\n",
      " 4.86797661e-01 7.27625847e-01 3.84966433e-02 6.07620925e-02\n",
      " 1.63295912e-03 1.10693246e-01 5.09215659e-03 5.31317711e-01\n",
      " 2.82276124e-01 1.29161239e-01 9.99679804e-01 8.08217943e-01\n",
      " 1.00000000e+00 9.94770348e-01 9.98756766e-01 3.73678491e-03\n",
      " 3.25002067e-04 5.49292341e-02 1.32167235e-03 6.42184168e-03\n",
      " 9.99315500e-01 4.29937965e-04 2.41506286e-03 1.39066605e-02\n",
      " 9.96152461e-01 9.10472929e-01 9.97162402e-01 9.99680400e-01\n",
      " 9.97822046e-01 9.99966383e-01 9.99912143e-01 9.99850035e-01\n",
      " 9.99999166e-01 6.58333898e-01 6.92328632e-01 9.54473853e-01\n",
      " 9.99998331e-01 9.99640465e-01 9.99881744e-01 7.49176681e-01\n",
      " 9.99993086e-01 9.99968767e-01 9.82211649e-01 9.99999762e-01\n",
      " 9.99980211e-01 9.99975562e-01 9.99978542e-01 6.25913203e-01\n",
      " 9.70431983e-01 9.98190105e-01 9.95844424e-01 9.93123829e-01\n",
      " 1.13809913e-01 6.52526855e-01 9.99228120e-01 6.85615540e-01\n",
      " 8.67217898e-01 9.99999881e-01 9.99928236e-01 9.99985576e-01\n",
      " 3.81843969e-02 4.12611365e-01 5.35873234e-01 9.99988914e-01\n",
      " 2.73797393e-01 9.99859333e-01 6.41648173e-01 9.86891329e-01\n",
      " 9.96397078e-01 9.94632721e-01 9.99996781e-01 6.81721745e-03\n",
      " 4.61494178e-02 9.69054222e-01 9.44305360e-01 5.02695367e-02\n",
      " 9.64139998e-01 9.99163985e-01 5.87452650e-01 1.15357392e-01\n",
      " 8.92347217e-01 7.46648192e-01]\n",
      "predict [0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "vote_pred [0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "targetlist [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "TP= 49 TN= 36 FN= 9 FP= 24\n",
      "TP+FP 73\n",
      "precision 0.6712328767123288\n",
      "recall 0.8448275862068966\n",
      "F1 0.7480916030534351\n",
      "acc 0.7203389830508474\n",
      "AUCp 0.7224137931034482\n",
      "AUC 0.7853448275862069\n",
      "\n",
      " The epoch is 370, average recall: 0.8448, average precision: 0.6712,average F1: 0.7481, average accuracy: 0.7203, average AUC: 0.7853\n",
      "Train Epoch: 371 [0/54 (0%)]\tTrain Loss: 0.004974\n",
      "Train Epoch: 371 [8/54 (15%)]\tTrain Loss: 0.010028\n",
      "Train Epoch: 371 [16/54 (30%)]\tTrain Loss: 0.001610\n",
      "Train Epoch: 371 [24/54 (44%)]\tTrain Loss: 0.007376\n",
      "Train Epoch: 371 [32/54 (59%)]\tTrain Loss: 0.000590\n",
      "Train Epoch: 371 [40/54 (74%)]\tTrain Loss: 0.000179\n",
      "Train Epoch: 371 [48/54 (89%)]\tTrain Loss: 0.000579\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [2.36361411e-05 9.80453253e-01 9.60609496e-01 9.33646679e-01\n",
      " 4.83257383e-01 6.90690184e-04 9.54271734e-01 6.54720545e-01\n",
      " 1.30983023e-02 4.67887521e-01 1.04387686e-01 3.49065522e-03\n",
      " 2.02287391e-01 3.02615836e-02 3.90034676e-01 1.42714661e-02\n",
      " 4.19673532e-01 1.15077704e-01 1.78244665e-01 2.14176392e-03\n",
      " 2.60921894e-03 9.80895698e-01 9.99917626e-01 9.95609581e-01\n",
      " 7.61925280e-02 9.99997139e-01 9.99982595e-01 9.67678010e-01\n",
      " 9.27170038e-01 9.83082771e-01 7.83402860e-01 9.64972794e-01\n",
      " 8.75104547e-01 4.98317604e-07 4.14682989e-04 1.88053772e-01\n",
      " 1.10234492e-01 9.65193987e-01 1.60998479e-03 2.61652827e-01\n",
      " 1.34479469e-02 2.36947179e-01 2.66842526e-05 2.99091160e-01\n",
      " 3.53863358e-01 2.35328451e-03 5.65139532e-01 4.03590649e-02\n",
      " 9.99998212e-01 9.11953330e-01 9.47982192e-01 1.54278496e-05\n",
      " 9.19329096e-03 1.00333942e-03 6.81439182e-04 2.28344258e-02\n",
      " 7.93245256e-01 4.08249209e-03 1.61743854e-04 8.81014407e-01\n",
      " 8.03355157e-01 6.78860664e-01 9.14596021e-01 9.93262112e-01\n",
      " 9.97111082e-01 9.99980807e-01 9.99993920e-01 9.99996424e-01\n",
      " 9.74859893e-01 5.95850527e-01 2.67927408e-01 3.83470237e-01\n",
      " 9.99999523e-01 9.99937892e-01 9.99999881e-01 6.49757311e-02\n",
      " 9.99999881e-01 9.99999881e-01 9.80751634e-01 1.00000000e+00\n",
      " 9.99999046e-01 9.99859691e-01 9.99936938e-01 2.33164593e-03\n",
      " 5.25180340e-01 8.98861527e-01 9.87773955e-01 8.42251539e-01\n",
      " 9.27423716e-01 3.80763978e-01 9.99528289e-01 6.26885332e-03\n",
      " 9.31778625e-02 1.00000000e+00 9.99841690e-01 9.99984026e-01\n",
      " 2.64828116e-01 5.97020723e-02 4.34178621e-01 9.99998093e-01\n",
      " 4.48656548e-03 9.42336738e-01 1.96351022e-01 8.99774432e-01\n",
      " 8.82276118e-01 9.81898785e-01 9.99701440e-01 6.63125217e-02\n",
      " 9.29373801e-01 9.91650105e-01 3.32120806e-01 4.67018932e-01\n",
      " 9.99010086e-01 9.99701023e-01 8.05932820e-01 8.58027339e-02\n",
      " 9.30371284e-01 5.68996310e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 372 [0/54 (0%)]\tTrain Loss: 0.002036\n",
      "Train Epoch: 372 [8/54 (15%)]\tTrain Loss: 0.053056\n",
      "Train Epoch: 372 [16/54 (30%)]\tTrain Loss: 0.004711\n",
      "Train Epoch: 372 [24/54 (44%)]\tTrain Loss: 0.000226\n",
      "Train Epoch: 372 [32/54 (59%)]\tTrain Loss: 0.000318\n",
      "Train Epoch: 372 [40/54 (74%)]\tTrain Loss: 0.020649\n",
      "Train Epoch: 372 [48/54 (89%)]\tTrain Loss: 0.000945\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [3.57971750e-02 9.92111325e-01 9.97997820e-01 9.66226995e-01\n",
      " 9.66937363e-01 2.65304145e-04 9.38508868e-01 7.67101109e-01\n",
      " 4.82863979e-03 6.23290181e-01 2.60065664e-02 5.57499789e-02\n",
      " 6.28781877e-03 6.15063636e-03 7.06001103e-01 3.71040369e-04\n",
      " 5.41692716e-04 4.24115211e-01 9.88975838e-02 8.20705388e-03\n",
      " 1.08408183e-03 8.24245691e-01 9.93764162e-01 9.97809827e-01\n",
      " 6.78485572e-01 9.99299765e-01 9.98027861e-01 4.91605967e-01\n",
      " 5.15185773e-01 3.21974963e-01 6.77621961e-01 9.73383904e-01\n",
      " 1.39735311e-01 1.88084858e-04 3.24090384e-03 6.61929131e-01\n",
      " 6.91245019e-01 8.10978770e-01 8.84027034e-03 1.95992738e-01\n",
      " 9.88853425e-02 1.39087932e-02 1.35489954e-05 6.49279594e-01\n",
      " 2.06164140e-02 1.16587020e-02 9.97555971e-01 2.29645014e-01\n",
      " 9.99892473e-01 7.52967060e-01 9.51699615e-01 7.63463868e-06\n",
      " 1.50691047e-01 3.78866005e-03 3.22046094e-06 5.05657354e-03\n",
      " 5.77316701e-01 2.00717896e-03 2.27025524e-02 8.07101905e-01\n",
      " 8.94562423e-01 3.32490392e-02 5.55744827e-01 9.11540270e-01\n",
      " 3.15332294e-01 9.99762237e-01 9.99246955e-01 9.99180973e-01\n",
      " 9.99503493e-01 3.47077101e-01 1.34402990e-01 2.43667930e-01\n",
      " 9.96598899e-01 9.16706920e-01 5.96779883e-01 1.49590299e-01\n",
      " 9.99998331e-01 9.99995589e-01 9.94646132e-01 9.99999523e-01\n",
      " 9.99987960e-01 9.89682138e-01 9.99997973e-01 4.93645668e-04\n",
      " 4.37141061e-02 9.33588386e-01 9.91850555e-01 9.72153425e-01\n",
      " 9.45370495e-01 6.95370883e-02 9.88157332e-01 1.43526316e-01\n",
      " 4.01512116e-01 9.99997377e-01 9.96418118e-01 9.99040425e-01\n",
      " 5.63078076e-02 1.74203753e-01 2.15077847e-02 9.79453087e-01\n",
      " 3.20084319e-02 9.95436370e-01 1.08672678e-02 9.18982387e-01\n",
      " 9.40047741e-01 8.13745677e-01 9.99974012e-01 5.08772768e-02\n",
      " 7.01994359e-01 9.49778616e-01 7.02421591e-02 2.91915640e-04\n",
      " 8.99301767e-01 9.69260097e-01 2.93140393e-03 2.00994126e-03\n",
      " 7.30593860e-01 2.59734988e-01]\n",
      "predict [0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Train Epoch: 373 [0/54 (0%)]\tTrain Loss: 0.047361\n",
      "Train Epoch: 373 [8/54 (15%)]\tTrain Loss: 0.018794\n",
      "Train Epoch: 373 [16/54 (30%)]\tTrain Loss: 0.001367\n",
      "Train Epoch: 373 [24/54 (44%)]\tTrain Loss: 0.065146\n",
      "Train Epoch: 373 [32/54 (59%)]\tTrain Loss: 0.003876\n",
      "Train Epoch: 373 [40/54 (74%)]\tTrain Loss: 0.002817\n",
      "Train Epoch: 373 [48/54 (89%)]\tTrain Loss: 0.001344\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [5.54112829e-02 9.54864323e-01 7.12524891e-01 9.94113743e-01\n",
      " 3.94079238e-01 5.56677999e-03 7.95027733e-01 9.99059260e-01\n",
      " 8.53384882e-02 6.56186163e-01 9.82625484e-01 3.13065462e-02\n",
      " 1.94510505e-01 2.25378070e-02 4.30617750e-01 1.66382436e-02\n",
      " 5.84129691e-02 2.46227384e-01 6.50733888e-01 7.33222067e-01\n",
      " 6.97292835e-02 9.16519940e-01 9.99661088e-01 9.99937654e-01\n",
      " 3.93862844e-01 9.99948025e-01 9.99805391e-01 9.36579287e-01\n",
      " 6.33554816e-01 3.13439518e-01 5.63722551e-01 9.91602004e-01\n",
      " 2.69609783e-02 6.55261101e-03 1.10997930e-02 3.59526068e-01\n",
      " 3.06379888e-02 9.66063082e-01 4.94587719e-02 3.85114580e-01\n",
      " 5.00373989e-02 6.78174291e-03 3.67815082e-04 5.05738966e-02\n",
      " 8.48430932e-01 2.51768023e-01 9.99467909e-01 9.64865029e-01\n",
      " 9.99953270e-01 9.79320884e-01 9.99427617e-01 3.93916070e-02\n",
      " 4.87708926e-01 1.85460657e-01 2.23489963e-02 3.14230248e-02\n",
      " 9.87449765e-01 6.18961275e-01 8.93701240e-02 8.98864031e-01\n",
      " 9.99974012e-01 9.99081492e-01 9.99826729e-01 9.99795854e-01\n",
      " 9.99776423e-01 9.99977708e-01 9.99905825e-01 9.99537587e-01\n",
      " 9.99553382e-01 9.85855043e-01 9.66001272e-01 9.84578073e-01\n",
      " 9.99996543e-01 9.99636412e-01 9.95023370e-01 9.99318600e-01\n",
      " 1.00000000e+00 9.99999762e-01 9.99938250e-01 9.99997497e-01\n",
      " 9.99999285e-01 9.99997377e-01 9.99998450e-01 6.39560461e-01\n",
      " 8.18086565e-01 9.90731299e-01 9.98564422e-01 9.97821212e-01\n",
      " 9.79981601e-01 9.84948933e-01 9.99711812e-01 9.56691384e-01\n",
      " 9.14740145e-01 9.99999881e-01 9.99996901e-01 9.99985456e-01\n",
      " 3.45377699e-02 8.21887195e-01 9.98956442e-01 9.99785841e-01\n",
      " 1.53194174e-01 9.99977708e-01 3.08963776e-01 9.99549091e-01\n",
      " 9.97877955e-01 9.94985938e-01 9.99987602e-01 6.95366114e-02\n",
      " 8.58219028e-01 9.96455967e-01 6.82658434e-01 6.97139725e-02\n",
      " 9.97909725e-01 9.99040544e-01 8.32230687e-01 5.91730401e-02\n",
      " 9.85222280e-01 8.29824746e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "Train Epoch: 374 [0/54 (0%)]\tTrain Loss: 0.004327\n",
      "Train Epoch: 374 [8/54 (15%)]\tTrain Loss: 0.005875\n",
      "Train Epoch: 374 [16/54 (30%)]\tTrain Loss: 0.022866\n",
      "Train Epoch: 374 [24/54 (44%)]\tTrain Loss: 0.053844\n",
      "Train Epoch: 374 [32/54 (59%)]\tTrain Loss: 0.003194\n",
      "Train Epoch: 374 [40/54 (74%)]\tTrain Loss: 0.001099\n",
      "Train Epoch: 374 [48/54 (89%)]\tTrain Loss: 0.000536\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [8.33436279e-05 9.92704928e-01 7.76404500e-01 9.35018361e-01\n",
      " 3.08357403e-02 6.19216326e-06 9.07933176e-01 7.60691941e-01\n",
      " 8.22387636e-03 1.86509281e-01 7.38668740e-01 5.10798730e-02\n",
      " 3.92071716e-03 4.05629216e-05 1.50541961e-01 1.09051114e-04\n",
      " 5.06694523e-05 2.59697974e-01 4.37707216e-01 3.81159663e-01\n",
      " 6.26860932e-02 9.86272216e-01 9.99504089e-01 9.98256505e-01\n",
      " 4.15692955e-01 9.99910593e-01 9.99679089e-01 8.42792094e-01\n",
      " 6.73576534e-01 8.74604940e-01 6.23832285e-01 9.99574125e-01\n",
      " 1.00482791e-03 1.01761131e-07 4.88231744e-05 2.50294060e-01\n",
      " 2.63599660e-02 9.63818610e-01 1.39682349e-02 2.10794464e-01\n",
      " 4.49506789e-02 7.43545145e-02 8.55606282e-04 5.11373160e-03\n",
      " 6.86162472e-01 1.87330246e-01 9.94881868e-01 8.69397879e-01\n",
      " 9.99931693e-01 9.66305017e-01 9.93766546e-01 5.31041962e-07\n",
      " 5.18701114e-02 3.68437804e-02 4.89012226e-02 9.04599729e-05\n",
      " 9.69718814e-01 9.26476493e-02 2.88473517e-02 1.74942330e-01\n",
      " 9.99650359e-01 9.87480819e-01 9.91567433e-01 9.96038079e-01\n",
      " 7.77330816e-01 9.96423542e-01 9.99753654e-01 9.99631882e-01\n",
      " 9.99994516e-01 9.94756341e-01 9.15877461e-01 9.43504214e-01\n",
      " 9.99837160e-01 9.98448610e-01 9.78970110e-01 9.62704122e-01\n",
      " 9.99999881e-01 9.99998689e-01 9.99445260e-01 9.99998093e-01\n",
      " 9.99995112e-01 9.99532938e-01 9.99886274e-01 7.82349586e-01\n",
      " 8.43639672e-01 9.92114305e-01 9.98341203e-01 9.99350846e-01\n",
      " 4.10039842e-01 7.88248122e-01 9.95955706e-01 3.21908712e-01\n",
      " 7.62538075e-01 9.99986053e-01 9.99894500e-01 9.97170985e-01\n",
      " 4.84320559e-02 9.53735590e-01 9.82059717e-01 9.99986887e-01\n",
      " 3.80289644e-01 9.99818146e-01 1.80107147e-01 9.90770698e-01\n",
      " 9.91713047e-01 9.87915516e-01 9.99997377e-01 5.24124317e-03\n",
      " 7.33783960e-01 9.94914532e-01 9.42871571e-02 3.44723533e-03\n",
      " 9.56154048e-01 9.69514310e-01 5.92804730e-01 6.47833705e-01\n",
      " 9.76233006e-01 9.00831521e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 375 [0/54 (0%)]\tTrain Loss: 0.008242\n",
      "Train Epoch: 375 [8/54 (15%)]\tTrain Loss: 0.003434\n",
      "Train Epoch: 375 [16/54 (30%)]\tTrain Loss: 0.043369\n",
      "Train Epoch: 375 [24/54 (44%)]\tTrain Loss: 0.004884\n",
      "Train Epoch: 375 [32/54 (59%)]\tTrain Loss: 0.003719\n",
      "Train Epoch: 375 [40/54 (74%)]\tTrain Loss: 0.000136\n",
      "Train Epoch: 375 [48/54 (89%)]\tTrain Loss: 0.001226\n",
      "target [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "score [1.37934927e-03 9.97553289e-01 9.85561550e-01 9.42276299e-01\n",
      " 7.26641119e-02 2.06063578e-05 9.54041123e-01 8.94886017e-01\n",
      " 4.61479370e-03 5.44299662e-01 9.66911495e-01 4.07460108e-02\n",
      " 2.05317643e-02 2.20632600e-03 2.81136811e-01 1.50118707e-04\n",
      " 4.49546351e-04 4.07176942e-01 5.49337029e-01 9.20182467e-01\n",
      " 4.56655286e-02 9.99246478e-01 9.99938250e-01 9.99870420e-01\n",
      " 6.96060777e-01 9.99999285e-01 9.99962807e-01 9.40066159e-01\n",
      " 7.29977071e-01 7.67812788e-01 4.88096386e-01 9.99481618e-01\n",
      " 2.25381949e-03 1.15922796e-06 2.46210711e-05 2.54061550e-01\n",
      " 1.85600817e-01 9.78681982e-01 3.01967636e-02 8.96231353e-01\n",
      " 2.84270972e-01 6.29773557e-01 1.09119352e-03 1.40153393e-01\n",
      " 7.05006182e-01 3.62706244e-01 9.84010279e-01 9.09098685e-01\n",
      " 9.99916911e-01 9.59245086e-01 9.86165881e-01 6.31387593e-06\n",
      " 3.41764957e-01 3.79617773e-02 2.01945812e-01 4.09587199e-04\n",
      " 9.94294465e-01 1.47200778e-01 1.64554030e-01 8.87402415e-01\n",
      " 9.99896049e-01 9.79015470e-01 9.93011773e-01 9.94339764e-01\n",
      " 8.74371111e-01 9.99701679e-01 9.98199821e-01 9.99927521e-01\n",
      " 9.99999285e-01 9.50765729e-01 9.43176627e-01 9.86788690e-01\n",
      " 9.99800980e-01 9.87170100e-01 9.13714409e-01 9.97008026e-01\n",
      " 1.00000000e+00 9.99999762e-01 9.99845982e-01 9.99999881e-01\n",
      " 9.99999881e-01 9.99962926e-01 9.99975681e-01 9.72510576e-01\n",
      " 9.82153594e-01 9.99370992e-01 9.99751508e-01 9.99890447e-01\n",
      " 5.05447865e-01 9.90395844e-01 9.99279797e-01 8.29228580e-01\n",
      " 8.57465029e-01 1.00000000e+00 9.99992371e-01 9.99816477e-01\n",
      " 2.93948725e-02 9.85597908e-01 9.93996143e-01 9.99998093e-01\n",
      " 2.17026144e-01 9.99989748e-01 9.01494682e-01 9.99858975e-01\n",
      " 9.98383880e-01 9.93555844e-01 9.99999762e-01 5.69002256e-02\n",
      " 3.01296353e-01 9.95682597e-01 5.40499032e-01 1.24519705e-04\n",
      " 9.64991152e-01 9.96382713e-01 8.32295239e-01 8.31203520e-01\n",
      " 9.99331772e-01 9.92635429e-01]\n",
      "predict [0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Train Epoch: 376 [0/54 (0%)]\tTrain Loss: 0.000962\n",
      "Train Epoch: 376 [8/54 (15%)]\tTrain Loss: 0.026672\n",
      "Train Epoch: 376 [16/54 (30%)]\tTrain Loss: 0.001037\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# train\n",
    "bs =batchsize\n",
    "votenum = 10\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(valset.__len__())\n",
    "vote_score = np.zeros(valset.__len__())\n",
    "\n",
    "lr = 0.001\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr) \n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
    "                                             \n",
    "scheduler = StepLR(optimizer, step_size=1)\n",
    "\n",
    "total_epoch = 500\n",
    "for epoch in range(1, total_epoch+1):\n",
    "    train(optimizer, epoch)\n",
    "    \n",
    "    targetlist, scorelist, predlist = val(epoch)\n",
    "    print('target',targetlist)\n",
    "    print('score',scorelist)\n",
    "    print('predict',predlist)\n",
    "    vote_pred = vote_pred + predlist \n",
    "    vote_score = vote_score + scorelist \n",
    "\n",
    "    if epoch % votenum == 0:\n",
    "        \n",
    "        # major vote\n",
    "        vote_pred[vote_pred <= (votenum/2)] = 0\n",
    "        vote_pred[vote_pred > (votenum/2)] = 1\n",
    "        vote_score = vote_score/votenum\n",
    "        \n",
    "        print('vote_pred', vote_pred)\n",
    "        print('targetlist', targetlist)\n",
    "        TP = ((vote_pred == 1) & (targetlist == 1)).sum()\n",
    "        TN = ((vote_pred == 0) & (targetlist == 0)).sum()\n",
    "        FN = ((vote_pred == 0) & (targetlist == 1)).sum()\n",
    "        FP = ((vote_pred == 1) & (targetlist == 0)).sum()\n",
    "        \n",
    "        \n",
    "        print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "        print('TP+FP',TP+FP)\n",
    "        p = TP / (TP + FP)\n",
    "        print('precision',p)\n",
    "        p = TP / (TP + FP)\n",
    "        r = TP / (TP + FN)\n",
    "        print('recall',r)\n",
    "        F1 = 2 * r * p / (r + p)\n",
    "        acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "        print('F1',F1)\n",
    "        print('acc',acc)\n",
    "        AUC = roc_auc_score(targetlist, vote_score)\n",
    "        print('AUCp', roc_auc_score(targetlist, vote_pred))\n",
    "        print('AUC', AUC)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if epoch == total_epoch:\n",
    "        torch.save(model.state_dict(), \"/data/cv_final/CT-Predict/2D-Pretrain/result/UCSD_{}_{}_{}_{}.pt\".format(modelname,alpha_name,epoch, datetime.datetime.now()))  \n",
    "\n",
    "        vote_pred = np.zeros(valset.__len__())\n",
    "        vote_score = np.zeros(valset.__len__())\n",
    "        print('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
    "average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\n",
    "\n",
    "        f = open('/data/cv_final/CT-Predict/2D-Pretrain/result/UCSD_{}_{}_{}_{}.txt'.format(modelname,alpha_name, epoch, lr), 'a+')\n",
    "        f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
    "average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "        epoch, r, p, F1, acc, AUC))\\\n",
    "        \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "import datetime\n",
    "bs = 1\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "epoch = 1\n",
    "r_list = []\n",
    "p_list = []\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "# TP = 0\n",
    "# TN = 0\n",
    "# FN = 0\n",
    "# FP = 0\n",
    "vote_pred = np.zeros(testset.__len__())\n",
    "vote_score = np.zeros(testset.__len__())\n",
    "\n",
    "\n",
    "targetlist, scorelist, predlist = test(epoch)\n",
    "print('target',targetlist)\n",
    "print('score',scorelist)\n",
    "print('predict',predlist)\n",
    "vote_pred = vote_pred + predlist \n",
    "vote_score = vote_score + scorelist \n",
    "\n",
    "TP = ((predlist == 1) & (targetlist == 1)).sum()\n",
    "\n",
    "TN = ((predlist == 0) & (targetlist == 0)).sum()\n",
    "FN = ((predlist == 0) & (targetlist == 1)).sum()\n",
    "FP = ((predlist == 1) & (targetlist == 0)).sum()\n",
    "\n",
    "print('TP=',TP,'TN=',TN,'FN=',FN,'FP=',FP)\n",
    "print('TP+FP',TP+FP)\n",
    "p = TP / (TP + FP)\n",
    "print('precision',p)\n",
    "p = TP / (TP + FP)\n",
    "r = TP / (TP + FN)\n",
    "print('recall',r)\n",
    "F1 = 2 * r * p / (r + p)\n",
    "acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "print('F1',F1)\n",
    "print('acc',acc)\n",
    "AUC = roc_auc_score(targetlist, vote_score)\n",
    "print('AUC', AUC)\n",
    "\n",
    "\n",
    "save_p = os.path.join(PATH_to_log_dir, f'test_UCSD_{modelname}_{alpha}_{epoch}_{datetime.datetime.now()}.txt')\n",
    "f = open(save_p, 'a+')\n",
    "f.write('\\n The epoch is {}, average recall: {:.4f}, average precision: {:.4f},\\\n",
    "average F1: {:.4f}, average accuracy: {:.4f}, average AUC: {:.4f}'.format(\n",
    "epoch, r, p, F1, acc, AUC))\n",
    "f.close()\n",
    "# torch.save(model.state_dict(), \"model_backup/medical_transfer/{}_{}_wuhan.pt\".format(modelname,alpha_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#x_axixtrain_pn_dislist()\n",
    "# print(his['train_loss'])\n",
    "x_axix = range(len(his['train_loss']))\n",
    "#\n",
    "sub_axix = filter(lambda x:x%200 == 0, x_axix)\n",
    "plt.title('Result Analysis')\n",
    "plt.plot(x_axix, his['train_acc'],  label='train accuracy')\n",
    "plt.plot(x_axix, his['val_acc'], label='val accuracy')\n",
    "\n",
    "# plt.plot(x_axix,his['train_loss'],  color='skyblue', label='train loss')\n",
    "# plt.plot(x_axix, his['val_loss'], color='blue', label='val loss')\n",
    "plt.legend() # \n",
    "\n",
    "plt.xlabel('iteration times')\n",
    "plt.ylabel('value')\n",
    "plt.show()\n",
    "#python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(his)\n",
    "df.to_csv('/data/cv_final/CT-Predict/2D-Pretrain/result/his.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = '/data/Data/prediction_img'\n",
    "import glob\n",
    "file_list = sorted(glob.glob(pred_path+\"/*.npy\"))\n",
    "file_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "target_list = file_list[10]\n",
    "input = np.empty([1, 128, 128 ,3])\n",
    "# for idx, p in enumerate(target_list):\n",
    "for c in range(3):\n",
    "    print(c)\n",
    "    input[0, :, :, c] = np.resize(np.load(p, allow_pickle=True), (128, 128))\n",
    "\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# input = input.resize([128, 128])\n",
    "print(input.shape)\n",
    "i = torch.tensor(input, dtype=torch.float).to(device)\n",
    "i = i.permute(3,0,1,2) # to (C,D,H,W)\n",
    "i = i.reshape([1, 3, 128, 128]).to(device)\n",
    "output = model(i)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = F.softmax(output, dim=1)\n",
    "score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " output.argmax(dim=1, keepdim=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
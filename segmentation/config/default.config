[train] #train parameters
epoch = 16
batch_size = 4
shuffle = True

reader_num = 8

optimizer = adam
learning_rate = 1e-2
weight_decay = 0
step_size = 1
lr_multiplier = 1

[eval] #eval parameters
batch_size = 4

shuffle = False

reader_num = 4

[data] #data parameters
train_dataset_type = npy_v1
train_formatter_type = Pipeline
train_data_path = /data/data/train/data
train_label_path = /data/data/train/label

valid_dataset_type = npy_v1
valid_formatter_type = Pipeline
valid_data_path = /data/data/valid/data
valid_label_path = /data/data/valid/label

test_dataset_type = npy_v1
test_formatter_type = Pipeline

load_into_mem = False
normalization = True
target_label = 0,1,2


use_weight_map = False
w0 = 1

[model] # model parameters
stage_1_input_size = 512
stage_1_output_class_num = 3
stage_1_weights = 0,0,0
stage_1_activation = sigmoid
stage_2_output_class_num = 3 
stage_2_input_size = 256
stage_2_weights = 0,0,0
stage_2_model = SegNet
stage_2_activation = softmax
output_dim = 1
model_name = Pipeline
module_name = SegNet
activation = softmax
input_channel_num = 1
output_class_num = 3
class_weights = 0,0,0


[output] #output parameters
output_time = 1
test_time = 1

output_file = /data/cv_final/segmentation/seg/output/output.txt
model_path = /data/cv_final/segmentation/seg/output/model
model_name = Pipeline
tensorboard_path = tensorboard

accuracy_method = IoU_sigmoid
output_function = Basic
output_value = micro_precision,macro_precision,macro_recall,macro_f1
